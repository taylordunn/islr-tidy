<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>4 Classification | An Introduction to Statistical Learning with the tidyverse</title>
  <meta name="description" content="Working through ISLR with the tidyverse and tidymodels" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="4 Classification | An Introduction to Statistical Learning with the tidyverse" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Working through ISLR with the tidyverse and tidymodels" />
  <meta name="github-repo" content="taylordunn/islr-tidy" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="4 Classification | An Introduction to Statistical Learning with the tidyverse" />
  
  <meta name="twitter:description" content="Working through ISLR with the tidyverse and tidymodels" />
  

<meta name="author" content="Taylor Dunn" />


<meta name="date" content="2021-11-23" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="linear-regression.html"/>

<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Who, what, and why?</a></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#an-overview-of-statistical-learning"><i class="fa fa-check"></i>An Overview of Statistical Learning</a>
<ul>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#wage-data"><i class="fa fa-check"></i>Wage Data</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#a-brief-history-of-statistical-learning"><i class="fa fa-check"></i>A Brief History of Statistical Learning</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#this-book"><i class="fa fa-check"></i>This Book</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="statistical-learning.html"><a href="statistical-learning.html"><i class="fa fa-check"></i><b>2</b> Statistical Learning</a>
<ul>
<li class="chapter" data-level="2.1" data-path="statistical-learning.html"><a href="statistical-learning.html#what-is-statistical-learning"><i class="fa fa-check"></i><b>2.1</b> What Is Statistical Learning?</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="statistical-learning.html"><a href="statistical-learning.html#why-estimate-f"><i class="fa fa-check"></i><b>2.1.1</b> Why Estimate <span class="math inline">\(f\)</span>?</a></li>
<li class="chapter" data-level="2.1.2" data-path="statistical-learning.html"><a href="statistical-learning.html#how-do-we-estimate-f"><i class="fa fa-check"></i><b>2.1.2</b> How Do We Estimate f?</a></li>
<li class="chapter" data-level="2.1.3" data-path="statistical-learning.html"><a href="statistical-learning.html#the-trade-off-between-prediction-accuracy-and-model-interpretability"><i class="fa fa-check"></i><b>2.1.3</b> The Trade-Off Between Prediction Accuracy and Model Interpretability</a></li>
<li class="chapter" data-level="2.1.4" data-path="statistical-learning.html"><a href="statistical-learning.html#supervised-versus-unsupervised-learning"><i class="fa fa-check"></i><b>2.1.4</b> Supervised Versus Unsupervised Learning</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="statistical-learning.html"><a href="statistical-learning.html#assessing-model-accuracy"><i class="fa fa-check"></i><b>2.2</b> Assessing Model Accuracy</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="statistical-learning.html"><a href="statistical-learning.html#measuring-the-quality-of-fit"><i class="fa fa-check"></i><b>2.2.1</b> Measuring the Quality of Fit</a></li>
<li class="chapter" data-level="2.2.2" data-path="statistical-learning.html"><a href="statistical-learning.html#the-bias-variance-trade-off"><i class="fa fa-check"></i><b>2.2.2</b> The Bias-Variance Trade-Off</a></li>
<li class="chapter" data-level="2.2.3" data-path="statistical-learning.html"><a href="statistical-learning.html#the-classification-setting"><i class="fa fa-check"></i><b>2.2.3</b> The Classification Setting</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="statistical-learning.html"><a href="statistical-learning.html#lab-introduction-to-r"><i class="fa fa-check"></i><b>2.3</b> Lab: Introduction to R</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="linear-regression.html"><a href="linear-regression.html"><i class="fa fa-check"></i><b>3</b> Linear Regression</a>
<ul>
<li class="chapter" data-level="3.1" data-path="linear-regression.html"><a href="linear-regression.html#simple-linear-regression"><i class="fa fa-check"></i><b>3.1</b> Simple Linear Regression</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="linear-regression.html"><a href="linear-regression.html#estimating-the-coefficients"><i class="fa fa-check"></i><b>3.1.1</b> Estimating the Coefficients</a></li>
<li class="chapter" data-level="3.1.2" data-path="linear-regression.html"><a href="linear-regression.html#assessing-the-accuracy-of-the-coefficient-estimates"><i class="fa fa-check"></i><b>3.1.2</b> Assessing the Accuracy of the Coefficient Estimates</a></li>
<li class="chapter" data-level="3.1.3" data-path="linear-regression.html"><a href="linear-regression.html#assessing-the-accuracy-of-the-model"><i class="fa fa-check"></i><b>3.1.3</b> Assessing the Accuracy of the Model</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="linear-regression.html"><a href="linear-regression.html#multiple-linear-regression"><i class="fa fa-check"></i><b>3.2</b> Multiple Linear Regression</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="linear-regression.html"><a href="linear-regression.html#estimating-the-regression-coefficients"><i class="fa fa-check"></i><b>3.2.1</b> Estimating the Regression Coefficients</a></li>
<li class="chapter" data-level="3.2.2" data-path="linear-regression.html"><a href="linear-regression.html#some-important-questions"><i class="fa fa-check"></i><b>3.2.2</b> Some Important Questions</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="linear-regression.html"><a href="linear-regression.html#other-considerations-in-the-regression-model"><i class="fa fa-check"></i><b>3.3</b> Other Considerations in the Regression Model</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="linear-regression.html"><a href="linear-regression.html#qualitative-predictors"><i class="fa fa-check"></i><b>3.3.1</b> Qualitative Predictors</a></li>
<li class="chapter" data-level="3.3.2" data-path="linear-regression.html"><a href="linear-regression.html#extensions-of-the-linear-model"><i class="fa fa-check"></i><b>3.3.2</b> Extensions of the Linear Model</a></li>
<li class="chapter" data-level="3.3.3" data-path="linear-regression.html"><a href="linear-regression.html#potential-problems"><i class="fa fa-check"></i><b>3.3.3</b> Potential Problems</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="linear-regression.html"><a href="linear-regression.html#the-marketing-plan"><i class="fa fa-check"></i><b>3.4</b> The Marketing Plan</a></li>
<li class="chapter" data-level="3.5" data-path="linear-regression.html"><a href="linear-regression.html#comparison-of-linear-regression-with-k-nearest-neighbors"><i class="fa fa-check"></i><b>3.5</b> Comparison of Linear Regression with <span class="math inline">\(K\)</span>-Nearest Neighbors</a></li>
<li class="chapter" data-level="3.6" data-path="linear-regression.html"><a href="linear-regression.html#lab-linear-regression"><i class="fa fa-check"></i><b>3.6</b> Lab: Linear Regression</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="linear-regression.html"><a href="linear-regression.html#libraries"><i class="fa fa-check"></i><b>3.6.1</b> Libraries</a></li>
<li class="chapter" data-level="3.6.2" data-path="linear-regression.html"><a href="linear-regression.html#simple-linear-regression-1"><i class="fa fa-check"></i><b>3.6.2</b> Simple Linear Regression</a></li>
<li class="chapter" data-level="3.6.3" data-path="linear-regression.html"><a href="linear-regression.html#multiple-linear-regression-1"><i class="fa fa-check"></i><b>3.6.3</b> Multiple Linear Regression</a></li>
<li class="chapter" data-level="3.6.4" data-path="linear-regression.html"><a href="linear-regression.html#interaction-terms"><i class="fa fa-check"></i><b>3.6.4</b> Interaction Terms</a></li>
<li class="chapter" data-level="3.6.5" data-path="linear-regression.html"><a href="linear-regression.html#non-linear-transformations-of-the-predictors"><i class="fa fa-check"></i><b>3.6.5</b> Non-linear Transformations of the Predictors</a></li>
<li class="chapter" data-level="3.6.6" data-path="linear-regression.html"><a href="linear-regression.html#qualitative-predictors-1"><i class="fa fa-check"></i><b>3.6.6</b> Qualitative Predictors</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="linear-regression.html"><a href="linear-regression.html#exercises"><i class="fa fa-check"></i><b>3.7</b> Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="linear-regression.html"><a href="linear-regression.html#applied"><i class="fa fa-check"></i>Applied</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="linear-regression.html"><a href="linear-regression.html#reproducibility"><i class="fa fa-check"></i>Reproducibility</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="classification.html"><a href="classification.html"><i class="fa fa-check"></i><b>4</b> Classification</a>
<ul>
<li class="chapter" data-level="4.1" data-path="classification.html"><a href="classification.html#an-overview-of-classification"><i class="fa fa-check"></i><b>4.1</b> An Overview of Classification</a></li>
<li class="chapter" data-level="4.2" data-path="classification.html"><a href="classification.html#why-not-linear-regression"><i class="fa fa-check"></i><b>4.2</b> Why Not Linear Regression?</a></li>
<li class="chapter" data-level="4.3" data-path="classification.html"><a href="classification.html#logistic-regression"><i class="fa fa-check"></i><b>4.3</b> Logistic Regression</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="classification.html"><a href="classification.html#the-logistic-model"><i class="fa fa-check"></i><b>4.3.1</b> The Logistic Model</a></li>
<li class="chapter" data-level="4.3.2" data-path="classification.html"><a href="classification.html#estimating-the-regression-coefficients-1"><i class="fa fa-check"></i><b>4.3.2</b> Estimating the Regression Coefficients</a></li>
<li class="chapter" data-level="4.3.3" data-path="classification.html"><a href="classification.html#making-predictions"><i class="fa fa-check"></i><b>4.3.3</b> Making Predictions</a></li>
<li class="chapter" data-level="4.3.4" data-path="classification.html"><a href="classification.html#multiple-logistic-regression"><i class="fa fa-check"></i><b>4.3.4</b> Multiple Logistic Regression</a></li>
<li class="chapter" data-level="4.3.5" data-path="classification.html"><a href="classification.html#multinomial-logistic-regression"><i class="fa fa-check"></i><b>4.3.5</b> Multinomial Logistic Regression</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="classification.html"><a href="classification.html#generative-models-for-classification"><i class="fa fa-check"></i><b>4.4</b> Generative Models for Classification</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="classification.html"><a href="classification.html#linear-discriminant-analysis-for-p-1"><i class="fa fa-check"></i><b>4.4.1</b> Linear Discriminant Analysis for <span class="math inline">\(p = 1\)</span></a></li>
<li class="chapter" data-level="4.4.2" data-path="classification.html"><a href="classification.html#linear-discriminant-analysis-for-p-1-1"><i class="fa fa-check"></i><b>4.4.2</b> Linear Discriminant Analysis for <span class="math inline">\(p &gt; 1\)</span></a></li>
<li class="chapter" data-level="4.4.3" data-path="classification.html"><a href="classification.html#quadratic-discriminant-analysis"><i class="fa fa-check"></i><b>4.4.3</b> Quadratic Discriminant Analysis</a></li>
<li class="chapter" data-level="4.4.4" data-path="classification.html"><a href="classification.html#naive-bayes"><i class="fa fa-check"></i><b>4.4.4</b> Naive Bayes</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="classification.html"><a href="classification.html#a-comparison-of-classification-methods"><i class="fa fa-check"></i><b>4.5</b> A Comparison of Classification Methods</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="classification.html"><a href="classification.html#an-analytical-comparison"><i class="fa fa-check"></i><b>4.5.1</b> An Analytical Comparison</a></li>
<li class="chapter" data-level="4.5.2" data-path="classification.html"><a href="classification.html#an-empirical-comparison"><i class="fa fa-check"></i><b>4.5.2</b> An Empirical Comparison</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="classification.html"><a href="classification.html#generalized-linear-models"><i class="fa fa-check"></i><b>4.6</b> Generalized Linear Models</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="classification.html"><a href="classification.html#linear-regression-on-the-bikeshare-data"><i class="fa fa-check"></i><b>4.6.1</b> Linear Regression on the Bikeshare Data</a></li>
</ul></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">An Introduction to Statistical Learning with the tidyverse</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="classification" class="section level1" number="4">
<h1><span class="header-section-number">4</span> Classification</h1>
<blockquote>
<p>But in many situations, the response
variable is instead qualitative. For example, eye color is qualitative. Often qualitative variables are referred to as categorical; we will use these
terms interchangeably. In this chapter, we study approaches for predicting
qualitative responses, a process that is known as classification.</p>
</blockquote>
<p>The methods covered in this chapter include logistic regression (and Poisson regression), linear discriminant analysis, quadratic discriminant analysis, naive Bayes, and <span class="math inline">\(K\)</span>-nearest neighbors.</p>
<div id="an-overview-of-classification" class="section level2" number="4.1">
<h2><span class="header-section-number">4.1</span> An Overview of Classification</h2>
<blockquote>
<p>In this chapter, we will illustrate the concept of classification using the
simulated <code>Default</code> data set. We are interested in predicting whether an
individual will default on his or her credit card payment, on the basis of
annual income and monthly credit card balance.</p>
</blockquote>
<p>Load the go-to packages and the <code>default</code> data set:</p>
<div class="sourceCode" id="cb176"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb176-1"><a href="classification.html#cb176-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb176-2"><a href="classification.html#cb176-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(broom)</span>
<span id="cb176-3"><a href="classification.html#cb176-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gt)</span>
<span id="cb176-4"><a href="classification.html#cb176-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(patchwork) <span class="co"># for composing plots</span></span>
<span id="cb176-5"><a href="classification.html#cb176-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Load my R package and set the ggplot theme</span></span>
<span id="cb176-6"><a href="classification.html#cb176-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dunnr)</span>
<span id="cb176-7"><a href="classification.html#cb176-7" aria-hidden="true" tabindex="-1"></a>extrafont<span class="sc">::</span><span class="fu">loadfonts</span>(<span class="at">device =</span> <span class="st">&quot;win&quot;</span>, <span class="at">quiet =</span> <span class="cn">TRUE</span>)</span>
<span id="cb176-8"><a href="classification.html#cb176-8" aria-hidden="true" tabindex="-1"></a><span class="fu">theme_set</span>(<span class="fu">theme_td</span>())</span>
<span id="cb176-9"><a href="classification.html#cb176-9" aria-hidden="true" tabindex="-1"></a><span class="fu">set_geom_fonts</span>()</span>
<span id="cb176-10"><a href="classification.html#cb176-10" aria-hidden="true" tabindex="-1"></a><span class="fu">set_palette</span>()</span>
<span id="cb176-11"><a href="classification.html#cb176-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb176-12"><a href="classification.html#cb176-12" aria-hidden="true" tabindex="-1"></a>default <span class="ot">&lt;-</span> ISLR2<span class="sc">::</span>Default</span>
<span id="cb176-13"><a href="classification.html#cb176-13" aria-hidden="true" tabindex="-1"></a><span class="fu">glimpse</span>(default)</span></code></pre></div>
<pre><code>## Rows: 10,000
## Columns: 4
## $ default &lt;fct&gt; No, No, No, No, No, No, No, No, No, No, No, No, No, No, No, No~
## $ student &lt;fct&gt; No, Yes, No, No, No, Yes, No, Yes, No, No, Yes, Yes, No, No, N~
## $ balance &lt;dbl&gt; 729.5265, 817.1804, 1073.5492, 529.2506, 785.6559, 919.5885, 8~
## $ income  &lt;dbl&gt; 44361.625, 12106.135, 31767.139, 35704.494, 38463.496, 7491.55~</code></pre>
<p>Randomly choose a subset of the 10000 observations and re-create Figure 4.1:</p>
<div class="sourceCode" id="cb178"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb178-1"><a href="classification.html#cb178-1" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> default <span class="sc">%&gt;%</span></span>
<span id="cb178-2"><a href="classification.html#cb178-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_count</span>(default, <span class="at">name =</span> <span class="st">&quot;n_group&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb178-3"><a href="classification.html#cb178-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">slice_sample</span>(</span>
<span id="cb178-4"><a href="classification.html#cb178-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">n =</span> <span class="dv">1000</span>,</span>
<span id="cb178-5"><a href="classification.html#cb178-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Inversely weight by group size to get more even distribution</span></span>
<span id="cb178-6"><a href="classification.html#cb178-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">weight_by =</span> <span class="fu">n</span>() <span class="sc">-</span> n_group</span>
<span id="cb178-7"><a href="classification.html#cb178-7" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb178-8"><a href="classification.html#cb178-8" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> d <span class="sc">%&gt;%</span></span>
<span id="cb178-9"><a href="classification.html#cb178-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> balance, <span class="at">y =</span> income)) <span class="sc">+</span></span>
<span id="cb178-10"><a href="classification.html#cb178-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">color =</span> default, <span class="at">shape =</span> default),</span>
<span id="cb178-11"><a href="classification.html#cb178-11" aria-hidden="true" tabindex="-1"></a>             <span class="at">alpha =</span> <span class="fl">0.5</span>, <span class="at">show.legend =</span> <span class="cn">FALSE</span>)</span>
<span id="cb178-12"><a href="classification.html#cb178-12" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> d <span class="sc">%&gt;%</span></span>
<span id="cb178-13"><a href="classification.html#cb178-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> default, <span class="at">y =</span> balance)) <span class="sc">+</span></span>
<span id="cb178-14"><a href="classification.html#cb178-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_boxplot</span>(<span class="fu">aes</span>(<span class="at">fill =</span> default), <span class="at">show.legend =</span> <span class="cn">FALSE</span>)</span>
<span id="cb178-15"><a href="classification.html#cb178-15" aria-hidden="true" tabindex="-1"></a>p3 <span class="ot">&lt;-</span> d <span class="sc">%&gt;%</span></span>
<span id="cb178-16"><a href="classification.html#cb178-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> default, <span class="at">y =</span> income)) <span class="sc">+</span></span>
<span id="cb178-17"><a href="classification.html#cb178-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_boxplot</span>(<span class="fu">aes</span>(<span class="at">fill =</span> default), <span class="at">show.legend =</span> <span class="cn">FALSE</span>)</span>
<span id="cb178-18"><a href="classification.html#cb178-18" aria-hidden="true" tabindex="-1"></a>p1 <span class="sc">|</span> (p2 <span class="sc">|</span> p3)</span></code></pre></div>
<p><img src="_main_files/figure-html/figure4.1-1.png" width="576" style="display: block; margin: auto;" /></p>
</div>
<div id="why-not-linear-regression" class="section level2" number="4.2">
<h2><span class="header-section-number">4.2</span> Why Not Linear Regression?</h2>
<p>Linear regression cannot predict un-ordered qualitative responses with more than two levels.</p>
<blockquote>
<p>Unfortunately, in general there is no natural way to
convert a qualitative response variable with more than two levels into a
quantitative response that is ready for linear regression.</p>
</blockquote>
<p>It is possible to use linear regression to predict a binary (two level) response.
For example, if we code stroke and drug overdose as dummy variables:</p>
<p><span class="math display">\[
Y =
\begin{cases}
0 &amp; \text{if stroke;} \\
1 &amp; \text{if drug overdose}.
\end{cases}
\]</span></p>
<p>Then we predict stroke if <span class="math inline">\(\hat{Y} &lt;= 0.5\)</span> and overdose if <span class="math inline">\(\hat{Y} &gt; 0.5\)</span>.
It turns out that these probability estimates are not unreasonble, but there can be issues:</p>
<blockquote>
<p>However, if we use linear regression, some of our estimates might be outside the [0, 1] interval (see Figure 4.2), making them
hard to interpret as probabilities! Nevertheless, the predictions provide an ordering and can be interpreted as crude probability estimates.</p>
</blockquote>
</div>
<div id="logistic-regression" class="section level2" number="4.3">
<h2><span class="header-section-number">4.3</span> Logistic Regression</h2>
<p>In logistic regression, we model the probability of <span class="math inline">\(Y\)</span> belonging to a class, rather than the response <span class="math inline">\(Y\)</span> itself.
The probability of <code>default</code> given <code>balance</code> can be written:</p>
<p><span class="math display">\[
\text{Pr}(\text{default = Yes}|\text{balance}) = p(\text{balance}).
\]</span></p>
<p>One might predict a default for an individual with <span class="math inline">\(p(\text{balance}) &gt; 0.5\)</span>.
Or they may alter the threshold to be conservative, e.g. <span class="math inline">\(p(\text{balance}) &gt; 0.1\)</span></p>
<div id="the-logistic-model" class="section level3" number="4.3.1">
<h3><span class="header-section-number">4.3.1</span> The Logistic Model</h3>
<p>As previously discussed, we could model the probability as linear:</p>
<p><span class="math display">\[
p(X) = \beta_0 + \beta_1 X
\]</span></p>
<p>but this could give probabilities outside of the range 0-1.
We must instead model <span class="math inline">\(p(X)\)</span> using a function that gives outputs 0-1.
Many functions meet this description, but logistic regression uses the logistic function:</p>
<p><span class="math display">\[
p(X) = \frac{e^{\beta_0 + \beta_1X}}{1 + e^{\beta_0 + \beta_1 X}}.
\]</span></p>
<p>Fit the linear and logistic probability models and re-create Figure 4.2:</p>
<div class="sourceCode" id="cb179"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb179-1"><a href="classification.html#cb179-1" aria-hidden="true" tabindex="-1"></a>lm_default_balance <span class="ot">&lt;-</span></span>
<span id="cb179-2"><a href="classification.html#cb179-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lm</span>(</span>
<span id="cb179-3"><a href="classification.html#cb179-3" aria-hidden="true" tabindex="-1"></a>    default <span class="sc">~</span> balance,</span>
<span id="cb179-4"><a href="classification.html#cb179-4" aria-hidden="true" tabindex="-1"></a>     <span class="co"># Turn the factor levels into 0 and 1</span></span>
<span id="cb179-5"><a href="classification.html#cb179-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> default <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">default =</span> <span class="fu">as.numeric</span>(default) <span class="sc">-</span> <span class="dv">1</span>)</span>
<span id="cb179-6"><a href="classification.html#cb179-6" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb179-7"><a href="classification.html#cb179-7" aria-hidden="true" tabindex="-1"></a>glm_default_balance <span class="ot">&lt;-</span></span>
<span id="cb179-8"><a href="classification.html#cb179-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">glm</span>(default <span class="sc">~</span> balance, <span class="at">data =</span> default,</span>
<span id="cb179-9"><a href="classification.html#cb179-9" aria-hidden="true" tabindex="-1"></a>      <span class="at">family =</span> <span class="fu">binomial</span>(<span class="at">link =</span> <span class="st">&quot;logit&quot;</span>))</span>
<span id="cb179-10"><a href="classification.html#cb179-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the data</span></span>
<span id="cb179-11"><a href="classification.html#cb179-11" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> default <span class="sc">%&gt;%</span></span>
<span id="cb179-12"><a href="classification.html#cb179-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> balance)) <span class="sc">+</span></span>
<span id="cb179-13"><a href="classification.html#cb179-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> <span class="fu">as.numeric</span>(default) <span class="sc">-</span> <span class="dv">1</span>), <span class="at">color =</span> td_colors<span class="sc">$</span>nice<span class="sc">$</span>soft_orange, <span class="at">alpha =</span> <span class="fl">0.5</span>)</span>
<span id="cb179-14"><a href="classification.html#cb179-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the linear model</span></span>
<span id="cb179-15"><a href="classification.html#cb179-15" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> p <span class="sc">+</span></span>
<span id="cb179-16"><a href="classification.html#cb179-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">slope =</span> <span class="fu">coef</span>(lm_default_balance)[<span class="st">&quot;balance&quot;</span>],</span>
<span id="cb179-17"><a href="classification.html#cb179-17" aria-hidden="true" tabindex="-1"></a>              <span class="at">intercept =</span> <span class="fu">coef</span>(lm_default_balance)[<span class="st">&quot;(Intercept)&quot;</span>],</span>
<span id="cb179-18"><a href="classification.html#cb179-18" aria-hidden="true" tabindex="-1"></a>              <span class="at">size =</span> <span class="fl">1.5</span>, <span class="at">color =</span> td_colors<span class="sc">$</span>nice<span class="sc">$</span>strong_blue) <span class="sc">+</span></span>
<span id="cb179-19"><a href="classification.html#cb179-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">y =</span> <span class="st">&quot;Probability of default&quot;</span>)</span>
<span id="cb179-20"><a href="classification.html#cb179-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the logistic model</span></span>
<span id="cb179-21"><a href="classification.html#cb179-21" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> p <span class="sc">+</span></span>
<span id="cb179-22"><a href="classification.html#cb179-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(</span>
<span id="cb179-23"><a href="classification.html#cb179-23" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">y =</span> pred_default),</span>
<span id="cb179-24"><a href="classification.html#cb179-24" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> <span class="fu">tibble</span>(<span class="at">balance =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">2700</span>, <span class="dv">1</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb179-25"><a href="classification.html#cb179-25" aria-hidden="true" tabindex="-1"></a>      <span class="fu">mutate</span>(</span>
<span id="cb179-26"><a href="classification.html#cb179-26" aria-hidden="true" tabindex="-1"></a>        <span class="at">sum_beta =</span> <span class="fu">coef</span>(glm_default_balance)[<span class="st">&quot;(Intercept)&quot;</span>] <span class="sc">+</span></span>
<span id="cb179-27"><a href="classification.html#cb179-27" aria-hidden="true" tabindex="-1"></a>                       balance <span class="sc">*</span> <span class="fu">coef</span>(glm_default_balance)[<span class="st">&quot;balance&quot;</span>],</span>
<span id="cb179-28"><a href="classification.html#cb179-28" aria-hidden="true" tabindex="-1"></a>        <span class="at">pred_default =</span> <span class="fu">plogis</span>(sum_beta)</span>
<span id="cb179-29"><a href="classification.html#cb179-29" aria-hidden="true" tabindex="-1"></a>      ),</span>
<span id="cb179-30"><a href="classification.html#cb179-30" aria-hidden="true" tabindex="-1"></a>    <span class="at">size =</span> <span class="fl">1.5</span>, <span class="at">color =</span> td_colors<span class="sc">$</span>nice<span class="sc">$</span>strong_blue</span>
<span id="cb179-31"><a href="classification.html#cb179-31" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb179-32"><a href="classification.html#cb179-32" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">y =</span> <span class="cn">NULL</span>)</span>
<span id="cb179-33"><a href="classification.html#cb179-33" aria-hidden="true" tabindex="-1"></a>p1 <span class="sc">|</span> p2</span></code></pre></div>
<p><img src="_main_files/figure-html/figure4.2-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>A very clear improvement.
The mean of the fitted probabilities in both models return the overall proportion of defaulters in the data set:</p>
<div class="sourceCode" id="cb180"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb180-1"><a href="classification.html#cb180-1" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(lm_default_balance, <span class="at">newdata =</span> default) <span class="sc">%&gt;%</span></span>
<span id="cb180-2"><a href="classification.html#cb180-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mean</span>()</span></code></pre></div>
<pre><code>## [1] 0.0333</code></pre>
<div class="sourceCode" id="cb182"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb182-1"><a href="classification.html#cb182-1" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(glm_default_balance, <span class="at">newdata =</span> default) <span class="sc">%&gt;%</span></span>
<span id="cb182-2"><a href="classification.html#cb182-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">plogis</span>() <span class="sc">%&gt;%</span></span>
<span id="cb182-3"><a href="classification.html#cb182-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mean</span>()</span></code></pre></div>
<pre><code>## [1] 0.0333</code></pre>
<p>The odds is found by re-arranging the logistic function:</p>
<p><span class="math display">\[
\frac{p(X)}{1 - p(X)} = e^{\beta_0 + \beta_1 X}.
\]</span></p>
<p>This can take any value between 0 (<span class="math inline">\(p(X) = 0\)</span>) and <span class="math inline">\(\infty\)</span> (<span class="math inline">\(p(X) = 1\)</span>).
Basic interpretation:</p>
<ul>
<li>A probability of 0.2 gives 1:4 odds.</li>
<li>A probability of 0.9 gives 9:1 odds.</li>
</ul>
<p>Taking the logarithm of both sides gives us the log odds or logit which is linear in <span class="math inline">\(X\)</span>:</p>
<p><span class="math display">\[
\log \left(\frac{p(X)}{1 - p(X)}\right) = \beta_0 + \beta_1 X.
\]</span>
A one unit change in <span class="math inline">\(X\)</span> increases the log odds by <span class="math inline">\(\beta_1\)</span>.
Equivalently, it multiplies the odds by <span class="math inline">\(e^{\beta_1}\)</span>.</p>
</div>
<div id="estimating-the-regression-coefficients-1" class="section level3" number="4.3.2">
<h3><span class="header-section-number">4.3.2</span> Estimating the Regression Coefficients</h3>
<p>We fit logistic regression models with maximum likelihood, which seeks estimates for <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> such that the predicted probabilities <span class="math inline">\(\hat{p}(x_i)\)</span> corresponds as closely as possible to the values <span class="math inline">\(y_i\)</span>.
This idea is formalized using a likelihood function:</p>
<p><span class="math display">\[
\ell (\beta_0, \beta_1) = \prod_{i: y_i = 1} p(x_i) \prod_{i&#39;: y_{i&#39;} = 0} (1 - p(x_{i&#39;})).
\]</span></p>
<p>We find the estimates <span class="math inline">\(\hat{\beta}_0\)</span> and <span class="math inline">\(\hat{\beta}_1\)</span> by maximizing this likelihood function.
Note that the least squares approach to linear regression is a special case of maximum likelihood.</p>
<p>Re-produce Table 4.1 using the fitted model:</p>
<div class="sourceCode" id="cb184"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb184-1"><a href="classification.html#cb184-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Since I will be reproducing this table often, write a function</span></span>
<span id="cb184-2"><a href="classification.html#cb184-2" aria-hidden="true" tabindex="-1"></a>tidy_custom <span class="ot">&lt;-</span> <span class="cf">function</span>(mod, <span class="at">coef_round =</span> <span class="dv">4</span>, <span class="at">se_round =</span> <span class="dv">4</span>, <span class="at">z_round =</span> <span class="dv">2</span>) {</span>
<span id="cb184-3"><a href="classification.html#cb184-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tidy</span>(mod) <span class="sc">%&gt;%</span></span>
<span id="cb184-4"><a href="classification.html#cb184-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">transmute</span>(</span>
<span id="cb184-5"><a href="classification.html#cb184-5" aria-hidden="true" tabindex="-1"></a>      term,</span>
<span id="cb184-6"><a href="classification.html#cb184-6" aria-hidden="true" tabindex="-1"></a>      <span class="at">coefficient =</span> <span class="fu">round</span>(estimate, coef_round),</span>
<span id="cb184-7"><a href="classification.html#cb184-7" aria-hidden="true" tabindex="-1"></a>      <span class="at">std.error =</span> <span class="fu">round</span>(std.error, se_round),</span>
<span id="cb184-8"><a href="classification.html#cb184-8" aria-hidden="true" tabindex="-1"></a>      <span class="st">`</span><span class="at">z-statistic</span><span class="st">`</span> <span class="ot">=</span> <span class="fu">round</span>(statistic, z_round),</span>
<span id="cb184-9"><a href="classification.html#cb184-9" aria-hidden="true" tabindex="-1"></a>      <span class="st">`</span><span class="at">p-value</span><span class="st">`</span> <span class="ot">=</span> scales<span class="sc">::</span><span class="fu">pvalue</span>(p.value)</span>
<span id="cb184-10"><a href="classification.html#cb184-10" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb184-11"><a href="classification.html#cb184-11" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb184-12"><a href="classification.html#cb184-12" aria-hidden="true" tabindex="-1"></a><span class="fu">tidy_custom</span>(glm_default_balance) <span class="sc">%&gt;%</span> <span class="fu">gt</span>() </span></code></pre></div>
<div id="iitolowwom" style="overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>html {
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;
}

#iitolowwom .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#iitolowwom .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#iitolowwom .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#iitolowwom .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 4px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#iitolowwom .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#iitolowwom .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#iitolowwom .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#iitolowwom .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#iitolowwom .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#iitolowwom .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#iitolowwom .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#iitolowwom .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#iitolowwom .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#iitolowwom .gt_from_md > :first-child {
  margin-top: 0;
}

#iitolowwom .gt_from_md > :last-child {
  margin-bottom: 0;
}

#iitolowwom .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#iitolowwom .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#iitolowwom .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#iitolowwom .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#iitolowwom .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#iitolowwom .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#iitolowwom .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#iitolowwom .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#iitolowwom .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#iitolowwom .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#iitolowwom .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#iitolowwom .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#iitolowwom .gt_left {
  text-align: left;
}

#iitolowwom .gt_center {
  text-align: center;
}

#iitolowwom .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#iitolowwom .gt_font_normal {
  font-weight: normal;
}

#iitolowwom .gt_font_bold {
  font-weight: bold;
}

#iitolowwom .gt_font_italic {
  font-style: italic;
}

#iitolowwom .gt_super {
  font-size: 65%;
}

#iitolowwom .gt_footnote_marks {
  font-style: italic;
  font-weight: normal;
  font-size: 65%;
}
</style>
<table class="gt_table">
  
  <thead class="gt_col_headings">
    <tr>
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1">term</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1">coefficient</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1">std.error</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1">z-statistic</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1">p-value</th>
    </tr>
  </thead>
  <tbody class="gt_table_body">
    <tr><td class="gt_row gt_left">(Intercept)</td>
<td class="gt_row gt_right">-10.6513</td>
<td class="gt_row gt_right">0.3612</td>
<td class="gt_row gt_right">-29.49</td>
<td class="gt_row gt_left">&lt;0.001</td></tr>
    <tr><td class="gt_row gt_left">balance</td>
<td class="gt_row gt_right">0.0055</td>
<td class="gt_row gt_right">0.0002</td>
<td class="gt_row gt_right">24.95</td>
<td class="gt_row gt_left">&lt;0.001</td></tr>
  </tbody>
  
  
</table>
</div>
<p>The <span class="math inline">\(z\)</span>-statistic plays the same role at the <span class="math inline">\(t\)</span>-statistic from linear regression.
It equals <span class="math inline">\(\hat{\beta}_1 / \text{SE}(\hat{\beta}_1)\)</span> and large (absolute) values indiciate evidence against the null hypothesis <span class="math inline">\(H_0: \beta_1 = 0\)</span>.
The small <span class="math inline">\(p\)</span>-value associated with <code>balance</code> in the above table is small, so we reject the null hypothesis.</p>
</div>
<div id="making-predictions" class="section level3" number="4.3.3">
<h3><span class="header-section-number">4.3.3</span> Making Predictions</h3>
<p>With the estimates, we can compute <code>default</code> probabilities for an individual with a <code>balance</code> of $1,000 and $2.000.</p>
<div class="sourceCode" id="cb185"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb185-1"><a href="classification.html#cb185-1" aria-hidden="true" tabindex="-1"></a>example_balance <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1000</span>, <span class="dv">2000</span>)</span>
<span id="cb185-2"><a href="classification.html#cb185-2" aria-hidden="true" tabindex="-1"></a><span class="co"># For convenience, add together the linear terms to get the log-odds</span></span>
<span id="cb185-3"><a href="classification.html#cb185-3" aria-hidden="true" tabindex="-1"></a>sum_beta <span class="ot">&lt;-</span> <span class="fu">coef</span>(glm_default_balance)[<span class="st">&quot;(Intercept)&quot;</span>] <span class="sc">+</span></span>
<span id="cb185-4"><a href="classification.html#cb185-4" aria-hidden="true" tabindex="-1"></a>  example_balance <span class="sc">*</span> <span class="fu">coef</span>(glm_default_balance)[<span class="st">&quot;balance&quot;</span>]</span>
<span id="cb185-5"><a href="classification.html#cb185-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb185-6"><a href="classification.html#cb185-6" aria-hidden="true" tabindex="-1"></a><span class="fu">exp</span>(sum_beta) <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(sum_beta))</span></code></pre></div>
<pre><code>## [1] 0.005752145 0.585769370</code></pre>
<p>Instead of manually writing out the full equation, here are some alternatives:</p>
<p>This logistic distribution function <code>stats::plogis</code> (sometimes called the inverse logit) returns probabilities from the given log-odds values:</p>
<div class="sourceCode" id="cb187"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb187-1"><a href="classification.html#cb187-1" aria-hidden="true" tabindex="-1"></a>stats<span class="sc">::</span><span class="fu">plogis</span>(sum_beta)</span></code></pre></div>
<pre><code>## [1] 0.005752145 0.585769370</code></pre>
<p>Calling the generic <code>predict</code> on a <code>glm</code> uses <code>predict.glm()</code>:</p>
<div class="sourceCode" id="cb189"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb189-1"><a href="classification.html#cb189-1" aria-hidden="true" tabindex="-1"></a><span class="co"># By default, predict.glm() returns log-odds</span></span>
<span id="cb189-2"><a href="classification.html#cb189-2" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(glm_default_balance,</span>
<span id="cb189-3"><a href="classification.html#cb189-3" aria-hidden="true" tabindex="-1"></a>        <span class="at">newdata =</span> <span class="fu">tibble</span>(<span class="at">balance =</span> example_balance)) <span class="sc">%&gt;%</span></span>
<span id="cb189-4"><a href="classification.html#cb189-4" aria-hidden="true" tabindex="-1"></a>  <span class="co"># So use the inverse logit</span></span>
<span id="cb189-5"><a href="classification.html#cb189-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">plogis</span>()</span></code></pre></div>
<pre><code>##           1           2 
## 0.005752145 0.585769370</code></pre>
<p>There is an argument to <code>predict.glm()</code> called <code>type</code> that specifies the scale of the returned predictions.
By default, <code>type</code> = “link” which refers to the link function which means log-odds are returned.
Setting <code>type</code> = “response” returns probabilities:</p>
<div class="sourceCode" id="cb191"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb191-1"><a href="classification.html#cb191-1" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(glm_default_balance, <span class="at">newdata =</span> <span class="fu">tibble</span>(<span class="at">balance =</span> example_balance),</span>
<span id="cb191-2"><a href="classification.html#cb191-2" aria-hidden="true" tabindex="-1"></a>        <span class="at">type =</span> <span class="st">&quot;response&quot;</span>)</span></code></pre></div>
<pre><code>##           1           2 
## 0.005752145 0.585769370</code></pre>
<p>Fit the model with <code>student</code> as the predictor and re-create Table 4.2:</p>
<div class="sourceCode" id="cb193"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb193-1"><a href="classification.html#cb193-1" aria-hidden="true" tabindex="-1"></a>glm_default_student <span class="ot">&lt;-</span></span>
<span id="cb193-2"><a href="classification.html#cb193-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">glm</span>(default <span class="sc">~</span> student, <span class="at">data =</span> default,</span>
<span id="cb193-3"><a href="classification.html#cb193-3" aria-hidden="true" tabindex="-1"></a>      <span class="co"># Note: don&#39;t need to specify binomial(link = &quot;logit&quot;) because it is the</span></span>
<span id="cb193-4"><a href="classification.html#cb193-4" aria-hidden="true" tabindex="-1"></a>      <span class="co">#  default link</span></span>
<span id="cb193-5"><a href="classification.html#cb193-5" aria-hidden="true" tabindex="-1"></a>      <span class="at">family =</span> binomial)</span>
<span id="cb193-6"><a href="classification.html#cb193-6" aria-hidden="true" tabindex="-1"></a><span class="fu">tidy_custom</span>(glm_default_student) <span class="sc">%&gt;%</span> <span class="fu">gt</span>()</span></code></pre></div>
<div id="dzgapspvwl" style="overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>html {
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;
}

#dzgapspvwl .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#dzgapspvwl .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#dzgapspvwl .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#dzgapspvwl .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 4px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#dzgapspvwl .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#dzgapspvwl .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#dzgapspvwl .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#dzgapspvwl .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#dzgapspvwl .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#dzgapspvwl .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#dzgapspvwl .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#dzgapspvwl .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#dzgapspvwl .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#dzgapspvwl .gt_from_md > :first-child {
  margin-top: 0;
}

#dzgapspvwl .gt_from_md > :last-child {
  margin-bottom: 0;
}

#dzgapspvwl .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#dzgapspvwl .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#dzgapspvwl .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#dzgapspvwl .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#dzgapspvwl .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#dzgapspvwl .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#dzgapspvwl .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#dzgapspvwl .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#dzgapspvwl .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#dzgapspvwl .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#dzgapspvwl .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#dzgapspvwl .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#dzgapspvwl .gt_left {
  text-align: left;
}

#dzgapspvwl .gt_center {
  text-align: center;
}

#dzgapspvwl .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#dzgapspvwl .gt_font_normal {
  font-weight: normal;
}

#dzgapspvwl .gt_font_bold {
  font-weight: bold;
}

#dzgapspvwl .gt_font_italic {
  font-style: italic;
}

#dzgapspvwl .gt_super {
  font-size: 65%;
}

#dzgapspvwl .gt_footnote_marks {
  font-style: italic;
  font-weight: normal;
  font-size: 65%;
}
</style>
<table class="gt_table">
  
  <thead class="gt_col_headings">
    <tr>
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1">term</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1">coefficient</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1">std.error</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1">z-statistic</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1">p-value</th>
    </tr>
  </thead>
  <tbody class="gt_table_body">
    <tr><td class="gt_row gt_left">(Intercept)</td>
<td class="gt_row gt_right">-3.5041</td>
<td class="gt_row gt_right">0.0707</td>
<td class="gt_row gt_right">-49.55</td>
<td class="gt_row gt_left">&lt;0.001</td></tr>
    <tr><td class="gt_row gt_left">studentYes</td>
<td class="gt_row gt_right">0.4049</td>
<td class="gt_row gt_right">0.1150</td>
<td class="gt_row gt_right">3.52</td>
<td class="gt_row gt_left">&lt;0.001</td></tr>
  </tbody>
  
  
</table>
</div>
<p>The probabilities for student and non-students:</p>
<div class="sourceCode" id="cb194"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb194-1"><a href="classification.html#cb194-1" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(glm_default_student, <span class="at">newdata =</span> <span class="fu">tibble</span>(<span class="at">student =</span> <span class="fu">c</span>(<span class="st">&quot;Yes&quot;</span>, <span class="st">&quot;No&quot;</span>)),</span>
<span id="cb194-2"><a href="classification.html#cb194-2" aria-hidden="true" tabindex="-1"></a>        <span class="at">type =</span> <span class="st">&quot;response&quot;</span>)</span></code></pre></div>
<pre><code>##          1          2 
## 0.04313859 0.02919501</code></pre>
</div>
<div id="multiple-logistic-regression" class="section level3" number="4.3.4">
<h3><span class="header-section-number">4.3.4</span> Multiple Logistic Regression</h3>
<p>The extension to multiple predictors <span class="math inline">\(p\)</span> is straightfoward:</p>
<p><span class="math display">\[
\log \left( \frac{p(X)}{1 - p(X)} \right) = \beta_0 + \beta_1 X_1 + \dots + \beta_p X_p.
\]</span></p>
<p>Fit the model with all three predictors (<code>income</code> in thousands of dollars):</p>
<div class="sourceCode" id="cb196"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb196-1"><a href="classification.html#cb196-1" aria-hidden="true" tabindex="-1"></a>glm_default_all <span class="ot">&lt;-</span></span>
<span id="cb196-2"><a href="classification.html#cb196-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">glm</span>(default <span class="sc">~</span> .,</span>
<span id="cb196-3"><a href="classification.html#cb196-3" aria-hidden="true" tabindex="-1"></a>      <span class="at">data =</span> default <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">income =</span> income <span class="sc">/</span> <span class="dv">1000</span>),</span>
<span id="cb196-4"><a href="classification.html#cb196-4" aria-hidden="true" tabindex="-1"></a>      <span class="at">family =</span> binomial)</span>
<span id="cb196-5"><a href="classification.html#cb196-5" aria-hidden="true" tabindex="-1"></a><span class="fu">tidy_custom</span>(glm_default_all) <span class="sc">%&gt;%</span> <span class="fu">gt</span>()</span></code></pre></div>
<div id="qbqjvrdpgf" style="overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>html {
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;
}

#qbqjvrdpgf .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#qbqjvrdpgf .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#qbqjvrdpgf .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#qbqjvrdpgf .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 4px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#qbqjvrdpgf .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#qbqjvrdpgf .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#qbqjvrdpgf .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#qbqjvrdpgf .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#qbqjvrdpgf .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#qbqjvrdpgf .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#qbqjvrdpgf .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#qbqjvrdpgf .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#qbqjvrdpgf .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#qbqjvrdpgf .gt_from_md > :first-child {
  margin-top: 0;
}

#qbqjvrdpgf .gt_from_md > :last-child {
  margin-bottom: 0;
}

#qbqjvrdpgf .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#qbqjvrdpgf .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#qbqjvrdpgf .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#qbqjvrdpgf .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#qbqjvrdpgf .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#qbqjvrdpgf .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#qbqjvrdpgf .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#qbqjvrdpgf .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#qbqjvrdpgf .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#qbqjvrdpgf .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#qbqjvrdpgf .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#qbqjvrdpgf .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#qbqjvrdpgf .gt_left {
  text-align: left;
}

#qbqjvrdpgf .gt_center {
  text-align: center;
}

#qbqjvrdpgf .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#qbqjvrdpgf .gt_font_normal {
  font-weight: normal;
}

#qbqjvrdpgf .gt_font_bold {
  font-weight: bold;
}

#qbqjvrdpgf .gt_font_italic {
  font-style: italic;
}

#qbqjvrdpgf .gt_super {
  font-size: 65%;
}

#qbqjvrdpgf .gt_footnote_marks {
  font-style: italic;
  font-weight: normal;
  font-size: 65%;
}
</style>
<table class="gt_table">
  
  <thead class="gt_col_headings">
    <tr>
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1">term</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1">coefficient</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1">std.error</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1">z-statistic</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1">p-value</th>
    </tr>
  </thead>
  <tbody class="gt_table_body">
    <tr><td class="gt_row gt_left">(Intercept)</td>
<td class="gt_row gt_right">-10.8690</td>
<td class="gt_row gt_right">0.4923</td>
<td class="gt_row gt_right">-22.08</td>
<td class="gt_row gt_left">&lt;0.001</td></tr>
    <tr><td class="gt_row gt_left">studentYes</td>
<td class="gt_row gt_right">-0.6468</td>
<td class="gt_row gt_right">0.2363</td>
<td class="gt_row gt_right">-2.74</td>
<td class="gt_row gt_left">0.006</td></tr>
    <tr><td class="gt_row gt_left">balance</td>
<td class="gt_row gt_right">0.0057</td>
<td class="gt_row gt_right">0.0002</td>
<td class="gt_row gt_right">24.74</td>
<td class="gt_row gt_left">&lt;0.001</td></tr>
    <tr><td class="gt_row gt_left">income</td>
<td class="gt_row gt_right">0.0030</td>
<td class="gt_row gt_right">0.0082</td>
<td class="gt_row gt_right">0.37</td>
<td class="gt_row gt_left">0.712</td></tr>
  </tbody>
  
  
</table>
</div>
<p>The coefficient for <code>student</code> is statistically significant and negative, whereas it was positive in the univariable model.
To understand this apparent paradox, re-create Figure 4.3:</p>
<div class="sourceCode" id="cb197"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb197-1"><a href="classification.html#cb197-1" aria-hidden="true" tabindex="-1"></a>balance_breaks <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">2700</span>, <span class="at">by =</span> <span class="dv">270</span>)</span>
<span id="cb197-2"><a href="classification.html#cb197-2" aria-hidden="true" tabindex="-1"></a>balance_midpoints <span class="ot">&lt;-</span></span>
<span id="cb197-3"><a href="classification.html#cb197-3" aria-hidden="true" tabindex="-1"></a>  (balance_breaks[<span class="dv">1</span><span class="sc">:</span>(<span class="fu">length</span>(balance_breaks) <span class="sc">-</span> <span class="dv">1</span>)] <span class="sc">+</span></span>
<span id="cb197-4"><a href="classification.html#cb197-4" aria-hidden="true" tabindex="-1"></a>     balance_breaks[<span class="dv">2</span><span class="sc">:</span><span class="fu">length</span>(balance_breaks)]) <span class="sc">/</span> <span class="dv">2</span></span>
<span id="cb197-5"><a href="classification.html#cb197-5" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> default <span class="sc">%&gt;%</span></span>
<span id="cb197-6"><a href="classification.html#cb197-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb197-7"><a href="classification.html#cb197-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">balance_binned =</span> <span class="fu">cut</span>(balance, <span class="at">breaks =</span> balance_breaks,</span>
<span id="cb197-8"><a href="classification.html#cb197-8" aria-hidden="true" tabindex="-1"></a>                         <span class="at">include.lowest =</span> <span class="cn">TRUE</span>, <span class="at">labels =</span> balance_midpoints),</span>
<span id="cb197-9"><a href="classification.html#cb197-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">balance_binned =</span> <span class="fu">as.numeric</span>(<span class="fu">as.character</span>(balance_binned))</span>
<span id="cb197-10"><a href="classification.html#cb197-10" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb197-11"><a href="classification.html#cb197-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(student, balance_binned) <span class="sc">%&gt;%</span></span>
<span id="cb197-12"><a href="classification.html#cb197-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">p_default =</span> <span class="fu">mean</span>(default <span class="sc">==</span> <span class="st">&quot;Yes&quot;</span>), <span class="at">.groups =</span> <span class="st">&quot;drop&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb197-13"><a href="classification.html#cb197-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> balance_binned, <span class="at">y =</span> p_default, <span class="at">color =</span> student)) <span class="sc">+</span></span>
<span id="cb197-14"><a href="classification.html#cb197-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">size =</span> <span class="fl">1.5</span>) <span class="sc">+</span></span>
<span id="cb197-15"><a href="classification.html#cb197-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(</span>
<span id="cb197-16"><a href="classification.html#cb197-16" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> default <span class="sc">%&gt;%</span></span>
<span id="cb197-17"><a href="classification.html#cb197-17" aria-hidden="true" tabindex="-1"></a>      <span class="fu">group_by</span>(student) <span class="sc">%&gt;%</span></span>
<span id="cb197-18"><a href="classification.html#cb197-18" aria-hidden="true" tabindex="-1"></a>      <span class="fu">summarise</span>(<span class="at">p_mean_default =</span> <span class="fu">mean</span>(default <span class="sc">==</span> <span class="st">&quot;Yes&quot;</span>),</span>
<span id="cb197-19"><a href="classification.html#cb197-19" aria-hidden="true" tabindex="-1"></a>                <span class="at">.groups =</span> <span class="st">&quot;drop&quot;</span>),</span>
<span id="cb197-20"><a href="classification.html#cb197-20" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">yintercept =</span> p_mean_default, <span class="at">color =</span> student), <span class="at">lty =</span> <span class="dv">2</span>, <span class="at">size =</span> <span class="dv">1</span></span>
<span id="cb197-21"><a href="classification.html#cb197-21" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb197-22"><a href="classification.html#cb197-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(td_colors<span class="sc">$</span>nice<span class="sc">$</span>strong_blue,</span>
<span id="cb197-23"><a href="classification.html#cb197-23" aria-hidden="true" tabindex="-1"></a>                                td_colors<span class="sc">$</span>nice<span class="sc">$</span>strong_red)) <span class="sc">+</span></span>
<span id="cb197-24"><a href="classification.html#cb197-24" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="fu">c</span>(<span class="fl">0.2</span>, <span class="fl">0.7</span>))</span>
<span id="cb197-25"><a href="classification.html#cb197-25" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> default <span class="sc">%&gt;%</span></span>
<span id="cb197-26"><a href="classification.html#cb197-26" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> student, <span class="at">y =</span> balance)) <span class="sc">+</span></span>
<span id="cb197-27"><a href="classification.html#cb197-27" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_boxplot</span>(<span class="fu">aes</span>(<span class="at">fill =</span> student)) <span class="sc">+</span></span>
<span id="cb197-28"><a href="classification.html#cb197-28" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(td_colors<span class="sc">$</span>nice<span class="sc">$</span>strong_blue,</span>
<span id="cb197-29"><a href="classification.html#cb197-29" aria-hidden="true" tabindex="-1"></a>                                td_colors<span class="sc">$</span>nice<span class="sc">$</span>strong_red)) <span class="sc">+</span></span>
<span id="cb197-30"><a href="classification.html#cb197-30" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">&quot;none&quot;</span>)</span>
<span id="cb197-31"><a href="classification.html#cb197-31" aria-hidden="true" tabindex="-1"></a>p1 <span class="sc">|</span> p2</span></code></pre></div>
<p><img src="_main_files/figure-html/figure4.3-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>In the left panel, we see that students have a higher overall default rate
(4.3%) than non-students
(2.9%) as shown by the dashed lines.
This is why, in the univariable regression, <code>student</code> was associated with an increase in probability of default.
But by the solid lines, we see that for most values of <code>balance</code>, students have lower default rates.
And that is what the multiple logistic regression model tells us: for fixed values of <code>balance</code> and <code>income</code>, a <code>student</code> is less likely to <code>default</code>.</p>
<p>This is explained by the right panel above: <code>student</code> and <code>balance</code> are correlated in that students tend to hold higher levels of debt, which is then associated with higher probability of default.</p>
<p>Taken altogether, we can conclude that a student is <em>less likely to default</em> than a non-student with the same credit card balance.
Without any information about their balance, however, a student is more likely to default because they are also more likely to carry a higher balance.</p>
<blockquote>
<p>This simple example illustrates the dangers and subtleties associated
with performing regressions involving only a single predictor when other
predictors may also be relevant. As in the linear regression setting, the
results obtained using one predictor may be quite different from those obtained using multiple predictors, especially when there is correlation among
the predictors. In general, the phenomenon seen in Figure 4.3 is known as
confounding.</p>
</blockquote>
<p>Make predictions for a student and non-student:</p>
<div class="sourceCode" id="cb198"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb198-1"><a href="classification.html#cb198-1" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb198-2"><a href="classification.html#cb198-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">student =</span> <span class="fu">c</span>(<span class="st">&quot;Yes&quot;</span>, <span class="st">&quot;No&quot;</span>), <span class="at">balance =</span> <span class="dv">1500</span>,</span>
<span id="cb198-3"><a href="classification.html#cb198-3" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Income in thousands</span></span>
<span id="cb198-4"><a href="classification.html#cb198-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">income =</span> <span class="dv">40000</span> <span class="sc">/</span> <span class="dv">1000</span></span>
<span id="cb198-5"><a href="classification.html#cb198-5" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb198-6"><a href="classification.html#cb198-6" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(glm_default_all, <span class="at">newdata =</span> d, <span class="at">type =</span> <span class="st">&quot;response&quot;</span>)</span></code></pre></div>
<pre><code>##          1          2 
## 0.05788194 0.10499192</code></pre>
</div>
<div id="multinomial-logistic-regression" class="section level3" number="4.3.5">
<h3><span class="header-section-number">4.3.5</span> Multinomial Logistic Regression</h3>
<p>For predicting <span class="math inline">\(K &gt; 2\)</span> classes, we can extend logistic regression in a method called multinomial logistic regression.
To do this, we choose a single class <span class="math inline">\(K\)</span> to serve as the baseline.
Then the probability of another class <span class="math inline">\(k\)</span> is:</p>
<p><span class="math display">\[
\text{Pr}(Y = k|X = x) = \frac{e^{\beta_{k0} + \beta_{k1} x_1 + \beta_{kp} x_p}}{1 + \sum_{l=1}^{K-1} e^{\beta_{l0} + \beta_{l1} x_1 + \beta_{lp} x_p}}
\]</span></p>
<p>for <span class="math inline">\(k = 1, \dots, K - 1\)</span>.
Then for the baseline class <span class="math inline">\(K\)</span>:</p>
<p><span class="math display">\[
\text{Pr}(Y = K|X = x) = \frac{1}{1 + \sum_{l=1}^{K-1} e^{\beta_{l0} + \beta_{l1} x_1 + \beta_{lp} x_p}}.
\]</span></p>
<p>The log-odds of a class <span class="math inline">\(k\)</span> is then linear in the predictors:</p>
<p><span class="math display">\[
\log \left( \frac{\text{Pr} (Y = k| X = x)}{\text{Pr} (Y = K| X = x)}\right) = \beta_{k0} + \beta_{k1} x_1 + \dots + \beta_{kp} x_p.
\]</span></p>
<p>Note that in the case of <span class="math inline">\(K = 2\)</span>, the numerator becomes <span class="math inline">\(p(X)\)</span> and the denominator <span class="math inline">\(1 - p(X)\)</span>, which is exactly the same the two-class logistic regression formula (Equation 4.6).</p>
<p>The choice of class <span class="math inline">\(K\)</span> as baseline was arbitrary.
The only thing that will change by choosing a different baseline will be the coefficient estimates, but the predictions (fitted values), and model metrics will be the same.</p>
<p>When performing multinomial logistic regression, we will sometimes use an alternative to dummy coding called softmax coding.</p>
<blockquote>
<p>The softmax coding is equivalent to the coding just described in the sense that the fitted values, log odds between any pair of classes, and other key model outputs will remain the
same, regardless of coding. But the softmax coding is used extensively in
some areas of the machine learning literature (and will appear again in
Chapter 10), so it is worth being aware of it. In the softmax coding, rather
than selecting a baseline class, we treat all <span class="math inline">\(K\)</span> classes symmetrically, and
assume that for <span class="math inline">\(k = 1,...,K\)</span>,</p>
</blockquote>
<p><span class="math display">\[
\text{Pr}(Y = k|X = x) = \frac{e^{\beta_{k0} + \beta_{k1} x_1 + \beta_{kp} x_p}}{ \sum_{l=1}^{K} e^{\beta_{l0} + \beta_{l1} x_1 + \beta_{lp} x_p}}.
\]</span></p>
<blockquote>
<p>Thus, rather than estimating coefficients for <span class="math inline">\(K − 1\)</span> classes, we actually
estimate coefficients for all <span class="math inline">\(K\)</span> classes. It is not hard to see that as a result
of (4.13), the log odds ratio between the <span class="math inline">\(k\)</span>th and <span class="math inline">\(k′\)</span>th classes equals</p>
</blockquote>
<p><span class="math display">\[
\frac{\log \text{Pr} (Y = k| X = x)}{\log \text{Pr} (Y = k&#39;| X = x)} = (\beta_{k0} - \beta_{k&#39;0}) + (\beta_{k1} - \beta_{k&#39;1}) x_1 + \dots + (\beta_{kp} - \beta_{k&#39;p}) x_p.
\]</span></p>
</div>
</div>
<div id="generative-models-for-classification" class="section level2" number="4.4">
<h2><span class="header-section-number">4.4</span> Generative Models for Classification</h2>
<blockquote>
<p>Logistic regression involves directly modeling <span class="math inline">\(\text{Pr} (Y = k|X = x)\)</span> using the
logistic function, given by (4.7) for the case of two response classes. In
statistical jargon, we model the conditional distribution of the response <span class="math inline">\(Y\)</span>,
given the predictor(s) <span class="math inline">\(X\)</span>. We now consider an alternative and less direct
approach to estimating these probabilities. In this new approach, we model
the distribution of the predictors <span class="math inline">\(X\)</span> separately in each of the response
classes (i.e. for each value of <span class="math inline">\(Y\)</span>). We then use Bayes’ theorem to flip these
around into estimates for <span class="math inline">\(\text{Pr} (Y = k|X = x)\)</span>. When the distribution of <span class="math inline">\(X\)</span>
within each class is assumed to be normal, it turns out that the model is
very similar in form to logistic regression.</p>
</blockquote>
<p>There are several reasons to choose this method over logistic regression:</p>
<blockquote>
<ul>
<li>When there is substantial separation between the two classes, the
parameter estimates for the logistic regression model are surprisingly
unstable. The methods that we consider in this section do not suffer
from this problem.</li>
<li>If the distribution of the predictors <span class="math inline">\(X\)</span> is approximately normal in
each of the classes and the sample size is small, then the approaches
in this section may be more accurate than logistic regression.</li>
<li>The methods in this section can be naturally extended to the case
of more than two response classes. (In the case of more than two
response classes, we can also use multinomial logistic regression from
Section 4.3.5.)</li>
</ul>
</blockquote>
<p>Consider a classification problem with <span class="math inline">\(K \geq 2\)</span> unordered classes.
Let <span class="math inline">\(\pi_k\)</span> represent the prior probability that a random observation is class <span class="math inline">\(k\)</span>.
Let <span class="math inline">\(f_k(X) \equiv \text{Pr}(X | Y = k)\)</span> denote the density function of <span class="math inline">\(X\)</span> for an observation in the <span class="math inline">\(k\)</span>th class.
Then Bayes’ theorem states that the posterior probability than observation <span class="math inline">\(X = x\)</span> belongs to the <span class="math inline">\(k\)</span>th class is</p>
<p><span class="math display">\[
\text{Pr} (Y = k|X = x) = \frac{\pi_k f_k(x)}{\sum_{l=1}^K \pi_l f_l (x)} = p_k(x).
\]</span></p>
<p>Aside: Bayes’ theorem in the most simplistic form is</p>
<p><span class="math display">\[
P(Y | X) = \frac{P(X | Y) P (Y)}{P(X)}.
\]</span></p>
<p>So the probability of <span class="math inline">\(X\)</span> given class <span class="math inline">\(Y\)</span> (= <span class="math inline">\(k\)</span>) is <span class="math inline">\(P(X|Y) = f_k (x)\)</span>, the independent probability of a class <span class="math inline">\(Y\)</span> is <span class="math inline">\(P(Y) = \pi_k\)</span>, and the denominator is a normalizing factor which sums over all possible values <span class="math inline">\(Y\)</span> to give the independent probability <span class="math inline">\(P(X) = \sum \pi_l f_l (x)\)</span>.</p>
<p>Estimating <span class="math inline">\(\pi_k\)</span> is easy if we have a random sample from the population – just take the fraction of the training observations belonging to class <span class="math inline">\(k\)</span>.
Estimating the density function <span class="math inline">\(f_k (x)\)</span> is much more challenging.</p>
<blockquote>
<p>We know from Chapter 2 that the Bayes classifier, which classifies an
observation <span class="math inline">\(x\)</span> to the class for which <span class="math inline">\(p_k(x)\)</span> is largest, has the lowest possible
error rate out of all classifiers. (Of course, this is only true if all of the
terms in (4.15) are correctly specified.) Therefore, if we can find a way to
estimate <span class="math inline">\(f_k(x)\)</span>, then we can plug it into (4.15) in order to approximate the
Bayes classifier.</p>
</blockquote>
<p>We now discuss three classifiers that use different estimates of <span class="math inline">\(f_k (x)\)</span>.</p>
<div id="linear-discriminant-analysis-for-p-1" class="section level3" number="4.4.1">
<h3><span class="header-section-number">4.4.1</span> Linear Discriminant Analysis for <span class="math inline">\(p = 1\)</span></h3>
<p>For the case of one predictor, we start by assuming that <span class="math inline">\(f_k (x)\)</span> is normal or Gaussian, which has the following density in one dimension:</p>
<p><span class="math display">\[
f_k (x) = \frac{1}{\sqrt{2 \pi} \sigma_k} \exp \left( - \frac{1}{2\sigma_k^2} (x - \mu_k)^2\right)
\]</span></p>
<p>where <span class="math inline">\(\mu_k\)</span> and <span class="math inline">\(\sigma_k^2\)</span> are the mean and variance of the <span class="math inline">\(k\)</span>th class.
For now, assume all classes have the same variance <span class="math inline">\(\sigma^2\)</span>.
Plugging the above into Bayes’ theorem, we have:</p>
<p><span class="math display">\[
p_k (x) =
\frac{\pi_k \frac{1}{\sqrt{2 \pi} \sigma} \exp \left( - \frac{1}{2\sigma^2} (x - \mu_k)^2\right)}
{\sum_{l=1}^K \pi_l \frac{1}{\sqrt{2 \pi} \sigma} \exp \left( - \frac{1}{2\sigma^2} (x - \mu_l)^2\right)}.
\]</span>
The Bayes classifier assigns an observation <span class="math inline">\(X = x\)</span> to the class for which the above is largest.
Taking the log and rearranging, this is equivalent to choosing the class for which:</p>
<p><span class="math display">\[
\delta_k (x) = x \frac{\mu_k}{\sigma^2} - \frac{\mu_k^2}{2 \sigma^2} + \log(\pi_k)
\]</span></p>
<p>is largest.</p>
<blockquote>
<p>For instance, if <span class="math inline">\(K = 2\)</span> and <span class="math inline">\(\pi_1 = \pi_2\)</span>, then the Bayes classifier
assigns an observation to class 1 if <span class="math inline">\(2x (\mu_1 − \mu_2) &gt; \mu_1^2 - \mu_2^2\)</span>, and to class 2 otherwise.
The Bayes decision boundary is the point for which <span class="math inline">\(\delta_1 (x) = \delta_2 (x)\)</span>; one can show that this amounts to</p>
</blockquote>
<p><span class="math display">\[
x = \frac{\mu_1^2 - \mu_2^2}{2 (\mu_1 - \mu_2)} = \frac{\mu_1 + \mu_2}{2}.
\]</span></p>
<p>Note that in the real world, we do not know that <span class="math inline">\(X\)</span> is drawn from a Gaussian distribution within each class, or all the parameters involved, so we are not able to calculate the decision boundary for the Bayes classifier.
This is where the linear discriminant analysis (LDA) method comes in.</p>
<p>If we are quite certain that <span class="math inline">\(X\)</span> is Gaussian within each class, then we can use LDA to approximate the Bayes classifier with these estimates:</p>
<p><span class="math display">\[
\begin{align}
\hat{\mu}_k &amp;= \frac{1}{n_k} \sum_{i: y_i = k} x_i\\
\hat{\sigma}^2_k &amp;= \frac{1}{n - K} \sum^K_{k=1} \sum_{i: y_i = k} (x_i - \hat{u}_k)^2
\end{align}
\]</span></p>
<p>where <span class="math inline">\(n\)</span> is the total number of training observations, and <span class="math inline">\(n_k\)</span> is the number in the <span class="math inline">\(k\)</span>th class.
The estimate for <span class="math inline">\(\hat{\mu}_k\)</span> is simply the average of the <span class="math inline">\(k\)</span>th class, and <span class="math inline">\(\hat{\sigma}^2\)</span> is the weighted average of the sample variances for each of the <span class="math inline">\(K\)</span> classes.
Sometimes we know the true fractions of class membership <span class="math inline">\(\pi_k\)</span> which can be used directly.
Otherwise, LDA simply uses the proportion from the training observations:</p>
<p><span class="math display">\[
\hat{\pi}_k = n_k / n.
\]</span></p>
<p>Observation <span class="math inline">\(X = x\)</span> is then assigned to the class for which</p>
<p><span class="math display">\[
\hat{\delta}_k (x) = x \frac{\hat{\mu}_k}{\hat{\sigma}^2} - \frac{\hat{\mu}_k^2}{2 \hat{\sigma}^2} + \log(\hat{\pi}_k)
\]</span></p>
<blockquote>
<p>The word linear in the classifier’s name stems from the fact
that the discriminant functions <span class="math inline">\(\hat{\delta}_k (x)\)</span> in (4.22) are linear functions of x (as opposed to a more complex function of <span class="math inline">\(x\)</span>)</p>
</blockquote>
<p>Re-create the example in Figure 4.4:</p>
<div class="sourceCode" id="cb200"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb200-1"><a href="classification.html#cb200-1" aria-hidden="true" tabindex="-1"></a>mu1 <span class="ot">&lt;-</span> <span class="sc">-</span><span class="fl">1.25</span></span>
<span id="cb200-2"><a href="classification.html#cb200-2" aria-hidden="true" tabindex="-1"></a>mu2 <span class="ot">&lt;-</span> <span class="fl">1.25</span></span>
<span id="cb200-3"><a href="classification.html#cb200-3" aria-hidden="true" tabindex="-1"></a>sigma1 <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb200-4"><a href="classification.html#cb200-4" aria-hidden="true" tabindex="-1"></a>sigma2 <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb200-5"><a href="classification.html#cb200-5" aria-hidden="true" tabindex="-1"></a>bayes_boundary <span class="ot">&lt;-</span> (mu1 <span class="sc">+</span> mu2) <span class="sc">/</span> <span class="dv">2</span></span>
<span id="cb200-6"><a href="classification.html#cb200-6" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(<span class="at">data =</span> <span class="fu">tibble</span>(<span class="at">x =</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">4</span>, <span class="dv">4</span>, <span class="fl">0.1</span>)), <span class="fu">aes</span>(x)) <span class="sc">+</span></span>
<span id="cb200-7"><a href="classification.html#cb200-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_function</span>(<span class="at">fun =</span> dnorm, <span class="at">args =</span> <span class="fu">list</span>(<span class="at">mean =</span> mu1, <span class="at">sd =</span> sigma1),</span>
<span id="cb200-8"><a href="classification.html#cb200-8" aria-hidden="true" tabindex="-1"></a>                <span class="at">geom =</span> <span class="st">&quot;line&quot;</span>, <span class="at">size =</span> <span class="fl">1.5</span>, <span class="at">color =</span> td_colors<span class="sc">$</span>nice<span class="sc">$</span>emerald) <span class="sc">+</span></span>
<span id="cb200-9"><a href="classification.html#cb200-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_function</span>(<span class="at">fun =</span> dnorm, <span class="at">args =</span> <span class="fu">list</span>(<span class="at">mean =</span> mu2, <span class="at">sd =</span> sigma2),</span>
<span id="cb200-10"><a href="classification.html#cb200-10" aria-hidden="true" tabindex="-1"></a>                <span class="at">geom =</span> <span class="st">&quot;line&quot;</span>, <span class="at">size =</span> <span class="fl">1.5</span>, <span class="at">color =</span> td_colors<span class="sc">$</span>nice<span class="sc">$</span>opera_mauve) <span class="sc">+</span></span>
<span id="cb200-11"><a href="classification.html#cb200-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> bayes_boundary, <span class="at">lty =</span> <span class="dv">2</span>, <span class="at">size =</span> <span class="fl">1.5</span>) <span class="sc">+</span></span>
<span id="cb200-12"><a href="classification.html#cb200-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">remove_axis</span>(<span class="st">&quot;y&quot;</span>)</span>
<span id="cb200-13"><a href="classification.html#cb200-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-14"><a href="classification.html#cb200-14" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb200-15"><a href="classification.html#cb200-15" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> <span class="fu">tribble</span>(</span>
<span id="cb200-16"><a href="classification.html#cb200-16" aria-hidden="true" tabindex="-1"></a>  <span class="sc">~</span>class, <span class="sc">~</span>x,</span>
<span id="cb200-17"><a href="classification.html#cb200-17" aria-hidden="true" tabindex="-1"></a>  <span class="dv">1</span>, <span class="fu">rnorm</span>(<span class="dv">20</span>, <span class="at">mean =</span> mu1, <span class="at">sd =</span> sigma1),</span>
<span id="cb200-18"><a href="classification.html#cb200-18" aria-hidden="true" tabindex="-1"></a>  <span class="dv">2</span>, <span class="fu">rnorm</span>(<span class="dv">20</span>, <span class="at">mean =</span> mu2, <span class="at">sd =</span> sigma2)</span>
<span id="cb200-19"><a href="classification.html#cb200-19" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span></span>
<span id="cb200-20"><a href="classification.html#cb200-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">unnest</span>(x)</span>
<span id="cb200-21"><a href="classification.html#cb200-21" aria-hidden="true" tabindex="-1"></a>lda_boundary <span class="ot">&lt;-</span></span>
<span id="cb200-22"><a href="classification.html#cb200-22" aria-hidden="true" tabindex="-1"></a>  (<span class="fu">mean</span>(<span class="fu">filter</span>(d, class <span class="sc">==</span> <span class="dv">1</span>)<span class="sc">$</span>x) <span class="sc">+</span> <span class="fu">mean</span>(<span class="fu">filter</span>(d, class <span class="sc">==</span> <span class="dv">2</span>)<span class="sc">$</span>x)) <span class="sc">/</span> <span class="dv">2</span></span>
<span id="cb200-23"><a href="classification.html#cb200-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-24"><a href="classification.html#cb200-24" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> d <span class="sc">%&gt;%</span></span>
<span id="cb200-25"><a href="classification.html#cb200-25" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(x, <span class="at">fill =</span> <span class="fu">factor</span>(class), <span class="at">color =</span> <span class="fu">factor</span>(class))) <span class="sc">+</span></span>
<span id="cb200-26"><a href="classification.html#cb200-26" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">bins =</span> <span class="dv">13</span>, <span class="at">alpha =</span> <span class="fl">0.5</span>, <span class="at">position =</span> <span class="st">&quot;identity&quot;</span>) <span class="sc">+</span></span>
<span id="cb200-27"><a href="classification.html#cb200-27" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> bayes_boundary, <span class="at">lty =</span> <span class="dv">2</span>, <span class="at">size =</span> <span class="fl">1.5</span>) <span class="sc">+</span></span>
<span id="cb200-28"><a href="classification.html#cb200-28" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> lda_boundary, <span class="at">lty =</span> <span class="dv">1</span>, <span class="at">size =</span> <span class="fl">1.5</span>) <span class="sc">+</span></span>
<span id="cb200-29"><a href="classification.html#cb200-29" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(td_colors<span class="sc">$</span>nice<span class="sc">$</span>emerald,</span>
<span id="cb200-30"><a href="classification.html#cb200-30" aria-hidden="true" tabindex="-1"></a>                               td_colors<span class="sc">$</span>nice<span class="sc">$</span>opera_mauve)) <span class="sc">+</span></span>
<span id="cb200-31"><a href="classification.html#cb200-31" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(td_colors<span class="sc">$</span>nice<span class="sc">$</span>emerald,</span>
<span id="cb200-32"><a href="classification.html#cb200-32" aria-hidden="true" tabindex="-1"></a>                               td_colors<span class="sc">$</span>nice<span class="sc">$</span>opera_mauve)) <span class="sc">+</span></span>
<span id="cb200-33"><a href="classification.html#cb200-33" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">&quot;none&quot;</span>)</span>
<span id="cb200-34"><a href="classification.html#cb200-34" aria-hidden="true" tabindex="-1"></a>p1 <span class="sc">|</span> p2</span></code></pre></div>
<p><img src="_main_files/figure-html/figure4.4-1.png" width="576" style="display: block; margin: auto;" />
Simulate a large number of test observations and compute the Bayes and LDA test error rates:</p>
<div class="sourceCode" id="cb201"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb201-1"><a href="classification.html#cb201-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2021</span>)</span>
<span id="cb201-2"><a href="classification.html#cb201-2" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> <span class="fu">tribble</span>(</span>
<span id="cb201-3"><a href="classification.html#cb201-3" aria-hidden="true" tabindex="-1"></a>  <span class="sc">~</span>class, <span class="sc">~</span>x,</span>
<span id="cb201-4"><a href="classification.html#cb201-4" aria-hidden="true" tabindex="-1"></a>  <span class="dv">1</span>, <span class="fu">rnorm</span>(<span class="fl">1e3</span>, <span class="at">mean =</span> mu1, <span class="at">sd =</span> sigma1),</span>
<span id="cb201-5"><a href="classification.html#cb201-5" aria-hidden="true" tabindex="-1"></a>  <span class="dv">2</span>, <span class="fu">rnorm</span>(<span class="fl">1e3</span>, <span class="at">mean =</span> mu2, <span class="at">sd =</span> sigma2)</span>
<span id="cb201-6"><a href="classification.html#cb201-6" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span></span>
<span id="cb201-7"><a href="classification.html#cb201-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">unnest</span>(x)</span>
<span id="cb201-8"><a href="classification.html#cb201-8" aria-hidden="true" tabindex="-1"></a><span class="co"># The LDA boundary must be recomputed with the new data</span></span>
<span id="cb201-9"><a href="classification.html#cb201-9" aria-hidden="true" tabindex="-1"></a>lda_boundary <span class="ot">&lt;-</span></span>
<span id="cb201-10"><a href="classification.html#cb201-10" aria-hidden="true" tabindex="-1"></a>  (<span class="fu">mean</span>(<span class="fu">filter</span>(d, class <span class="sc">==</span> <span class="dv">1</span>)<span class="sc">$</span>x) <span class="sc">+</span> <span class="fu">mean</span>(<span class="fu">filter</span>(d, class <span class="sc">==</span> <span class="dv">2</span>)<span class="sc">$</span>x)) <span class="sc">/</span> <span class="dv">2</span></span>
<span id="cb201-11"><a href="classification.html#cb201-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-12"><a href="classification.html#cb201-12" aria-hidden="true" tabindex="-1"></a>d <span class="sc">%&gt;%</span></span>
<span id="cb201-13"><a href="classification.html#cb201-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb201-14"><a href="classification.html#cb201-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">bayes_class =</span> <span class="fu">ifelse</span>(x <span class="sc">&gt;</span> bayes_boundary, <span class="dv">1</span>, <span class="dv">2</span>),</span>
<span id="cb201-15"><a href="classification.html#cb201-15" aria-hidden="true" tabindex="-1"></a>    <span class="at">lda_class =</span> <span class="fu">ifelse</span>(x <span class="sc">&gt;</span> lda_boundary, <span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb201-16"><a href="classification.html#cb201-16" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb201-17"><a href="classification.html#cb201-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(</span>
<span id="cb201-18"><a href="classification.html#cb201-18" aria-hidden="true" tabindex="-1"></a>    <span class="st">`</span><span class="at">Bayes error rate</span><span class="st">`</span> <span class="ot">=</span> <span class="fu">mean</span>(class <span class="sc">==</span> bayes_class),</span>
<span id="cb201-19"><a href="classification.html#cb201-19" aria-hidden="true" tabindex="-1"></a>    <span class="st">`</span><span class="at">LDA error rate</span><span class="st">`</span> <span class="ot">=</span> <span class="fu">mean</span>(class <span class="sc">==</span> lda_class)</span>
<span id="cb201-20"><a href="classification.html#cb201-20" aria-hidden="true" tabindex="-1"></a>  )</span></code></pre></div>
<pre><code>## # A tibble: 1 x 2
##   `Bayes error rate` `LDA error rate`
##                &lt;dbl&gt;            &lt;dbl&gt;
## 1              0.104            0.107</code></pre>
<p>Pretty close but, as expected, the Bayes classifier has the lower error rate.</p>
<blockquote>
<p>To reiterate, the LDA classifier results from assuming that the observations within each class come from a normal distribution with a class-specific mean and a common variance <span class="math inline">\(\sigma^2\)</span>, and plugging estimates for these
parameters into the Bayes classifier. In Section 4.4.3, we will consider a less
stringent set of assumptions, by allowing the observations in the <span class="math inline">\(k\)</span>th class
to have a class-specific variance, <span class="math inline">\(\sigma_k^2\)</span>.</p>
</blockquote>
</div>
<div id="linear-discriminant-analysis-for-p-1-1" class="section level3" number="4.4.2">
<h3><span class="header-section-number">4.4.2</span> Linear Discriminant Analysis for <span class="math inline">\(p &gt; 1\)</span></h3>
<p>Extending the LDA classifier for multiple predictors involves a multi-variate Gaussian distribution with class-specific mean vector and a common covariance matrix.</p>
<blockquote>
<p>The multivariate Gaussian distribution assumes that each individual predictor follows a one-dimensional normal distribution, as in (4.16), with some correlation between each pair of predictors.</p>
</blockquote>
<p>I’ll simulate some data with the <code>mvtnorm</code> package and plot probabilities with a 2D density plot (instead of the 3D in Figure 4.5):</p>
<div class="sourceCode" id="cb203"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb203-1"><a href="classification.html#cb203-1" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> <span class="fu">crossing</span>(<span class="at">x1 =</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">2</span>, <span class="dv">2</span>, <span class="fl">0.1</span>), <span class="at">x2 =</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">2</span>, <span class="dv">2</span>, <span class="fl">0.1</span>))</span>
<span id="cb203-2"><a href="classification.html#cb203-2" aria-hidden="true" tabindex="-1"></a>d1 <span class="ot">&lt;-</span> d <span class="sc">%&gt;%</span></span>
<span id="cb203-3"><a href="classification.html#cb203-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bind_cols</span>(</span>
<span id="cb203-4"><a href="classification.html#cb203-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">prob =</span> mvtnorm<span class="sc">::</span><span class="fu">dmvnorm</span>(</span>
<span id="cb203-5"><a href="classification.html#cb203-5" aria-hidden="true" tabindex="-1"></a>      <span class="at">x =</span> <span class="fu">as.matrix</span>(d),</span>
<span id="cb203-6"><a href="classification.html#cb203-6" aria-hidden="true" tabindex="-1"></a>      <span class="at">mean =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>), <span class="at">sigma =</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>), <span class="at">nrow =</span> <span class="dv">2</span>)</span>
<span id="cb203-7"><a href="classification.html#cb203-7" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb203-8"><a href="classification.html#cb203-8" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb203-9"><a href="classification.html#cb203-9" aria-hidden="true" tabindex="-1"></a>d2 <span class="ot">&lt;-</span> d <span class="sc">%&gt;%</span></span>
<span id="cb203-10"><a href="classification.html#cb203-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bind_cols</span>(</span>
<span id="cb203-11"><a href="classification.html#cb203-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">prob =</span> mvtnorm<span class="sc">::</span><span class="fu">dmvnorm</span>(</span>
<span id="cb203-12"><a href="classification.html#cb203-12" aria-hidden="true" tabindex="-1"></a>      <span class="at">x =</span> <span class="fu">as.matrix</span>(d),</span>
<span id="cb203-13"><a href="classification.html#cb203-13" aria-hidden="true" tabindex="-1"></a>      <span class="at">mean =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>), <span class="at">sigma =</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">1</span>, <span class="fl">0.7</span>, <span class="fl">0.7</span>, <span class="dv">1</span>), <span class="at">nrow =</span> <span class="dv">2</span>)</span>
<span id="cb203-14"><a href="classification.html#cb203-14" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb203-15"><a href="classification.html#cb203-15" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb203-16"><a href="classification.html#cb203-16" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> d1 <span class="sc">%&gt;%</span></span>
<span id="cb203-17"><a href="classification.html#cb203-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> x1, <span class="at">y =</span> x2)) <span class="sc">+</span></span>
<span id="cb203-18"><a href="classification.html#cb203-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_tile</span>(<span class="fu">aes</span>(<span class="at">fill =</span> prob)) <span class="sc">+</span></span>
<span id="cb203-19"><a href="classification.html#cb203-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="at">expand =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>)) <span class="sc">+</span></span>
<span id="cb203-20"><a href="classification.html#cb203-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_y_continuous</span>(<span class="at">expand =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>)) <span class="sc">+</span></span>
<span id="cb203-21"><a href="classification.html#cb203-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">&quot;none&quot;</span>)</span>
<span id="cb203-22"><a href="classification.html#cb203-22" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> d2 <span class="sc">%&gt;%</span></span>
<span id="cb203-23"><a href="classification.html#cb203-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> x1, <span class="at">y =</span> x2)) <span class="sc">+</span></span>
<span id="cb203-24"><a href="classification.html#cb203-24" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_tile</span>(<span class="fu">aes</span>(<span class="at">fill =</span> prob)) <span class="sc">+</span></span>
<span id="cb203-25"><a href="classification.html#cb203-25" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="at">expand =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>)) <span class="sc">+</span></span>
<span id="cb203-26"><a href="classification.html#cb203-26" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_y_continuous</span>(<span class="at">expand =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>)) <span class="sc">+</span></span>
<span id="cb203-27"><a href="classification.html#cb203-27" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">&quot;none&quot;</span>)</span>
<span id="cb203-28"><a href="classification.html#cb203-28" aria-hidden="true" tabindex="-1"></a>p1 <span class="sc">|</span> p2</span></code></pre></div>
<p><img src="_main_files/figure-html/figure4.5-1.png" width="576" style="display: block; margin: auto;" /></p>
<blockquote>
<p>To indicate that a <span class="math inline">\(p\)</span>-dimensional random variable <span class="math inline">\(X\)</span> has a multivariate Gaussian distribution, we write <span class="math inline">\(X \sim N(\mu, \Sigma)\)</span>. Here <span class="math inline">\(E(X) = \mu\)</span> is
the mean of <span class="math inline">\(X\)</span> (a vector with <span class="math inline">\(p\)</span> components), and <span class="math inline">\(\text{Cov}(X) = \Sigma\)</span> is the
<span class="math inline">\(p \times p\)</span> covariance matrix of <span class="math inline">\(X\)</span>.</p>
</blockquote>
<p>The LDA classifier assumes that the observations in the <span class="math inline">\(k\)</span>th class are drawn from a multivariate Gaussian distribution <span class="math inline">\(N(\mu_k, \Sigma)\)</span>.
The Bayes classifier assigns an observation <span class="math inline">\(X = x\)</span> to the class for which</p>
<p><span class="math display">\[
\delta_k (x) = x^T \Sigma^{-1} \mu_k - \frac{1}{2} \mu_k^T \Sigma^{-1} \mu_k + \log \pi_k
\]</span></p>
<p>is largest.</p>
<p>As with the univariable case, the LDA method involves estimating the unknown parameters <span class="math inline">\(\mu_k\)</span>, <span class="math inline">\(\pi_k\)</span> and <span class="math inline">\(\Sigma\)</span>.
Then the quantities <span class="math inline">\(\hat{\delta}_k (x)\)</span> are calculated and the observations <span class="math inline">\(X\)</span> are classified into the largest <span class="math inline">\(\hat{\delta}_k (k)\)</span>.</p>
<p>We can perform LDA using the <code>MASS</code> package to predict <code>default</code> from <code>student</code> and <code>balance</code>:</p>
<div class="sourceCode" id="cb204"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb204-1"><a href="classification.html#cb204-1" aria-hidden="true" tabindex="-1"></a>lda_default_balance_student <span class="ot">&lt;-</span></span>
<span id="cb204-2"><a href="classification.html#cb204-2" aria-hidden="true" tabindex="-1"></a>  MASS<span class="sc">::</span><span class="fu">lda</span>(default <span class="sc">~</span> balance <span class="sc">+</span> student, <span class="at">data =</span> default)</span>
<span id="cb204-3"><a href="classification.html#cb204-3" aria-hidden="true" tabindex="-1"></a>lda_default_balance_student</span></code></pre></div>
<pre><code>## Call:
## lda(default ~ balance + student, data = default)
## 
## Prior probabilities of groups:
##     No    Yes 
## 0.9667 0.0333 
## 
## Group means:
##       balance studentYes
## No   803.9438  0.2914037
## Yes 1747.8217  0.3813814
## 
## Coefficients of linear discriminants:
##                     LD1
## balance     0.002244397
## studentYes -0.249059498</code></pre>
<p>The resulting training error rate:</p>
<div class="sourceCode" id="cb206"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb206-1"><a href="classification.html#cb206-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(</span>
<span id="cb206-2"><a href="classification.html#cb206-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">predict</span>(lda_default_balance_student,</span>
<span id="cb206-3"><a href="classification.html#cb206-3" aria-hidden="true" tabindex="-1"></a>          <span class="at">newdata =</span> default)<span class="sc">$</span>class <span class="sc">!=</span> default<span class="sc">$</span>default</span>
<span id="cb206-4"><a href="classification.html#cb206-4" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<pre><code>## [1] 0.0275</code></pre>
<blockquote>
<p>This sounds like a low error rate, but two caveats must be noted.</p>
</blockquote>
<blockquote>
<ul>
<li>First of all, training error rates will usually be lower than test error
rates, which are the real quantity of interest. In other words, we
might expect this classifier to perform worse if we use it to predict
whether or not a new set of individuals will default. The reason is
that we specifically adjust the parameters of our model to do well on
the training data. The higher the ratio of parameters <span class="math inline">\(p\)</span> to number
of samples <span class="math inline">\(n\)</span>, the more we expect this overfitting to play a role.
For these data we don’t expect this to be a problem, since <span class="math inline">\(p = 2\)</span> and
<span class="math inline">\(n = 10,000\)</span>.</li>
<li>Second, since only 3.33% of the individuals in the training sample
defaulted, a simple but useless classifier that always predicts that
an individual will not default, regardless of his or her credit card
balance and student status, will result in an error rate of 3.33%. In
other words, the trivial null classifier will achieve an error rate that is only a bit higher than the LDA training set error rate.</li>
</ul>
</blockquote>
<p>Make predictions and produce the confusion matrix in Table 4.4:</p>
<div class="sourceCode" id="cb208"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb208-1"><a href="classification.html#cb208-1" aria-hidden="true" tabindex="-1"></a>lda_pred <span class="ot">&lt;-</span> </span>
<span id="cb208-2"><a href="classification.html#cb208-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bind_cols</span>(</span>
<span id="cb208-3"><a href="classification.html#cb208-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">pred_default =</span> <span class="fu">predict</span>(lda_default_balance_student,</span>
<span id="cb208-4"><a href="classification.html#cb208-4" aria-hidden="true" tabindex="-1"></a>                           <span class="at">newdata =</span> default)<span class="sc">$</span>class,</span>
<span id="cb208-5"><a href="classification.html#cb208-5" aria-hidden="true" tabindex="-1"></a>    default </span>
<span id="cb208-6"><a href="classification.html#cb208-6" aria-hidden="true" tabindex="-1"></a>  ) </span>
<span id="cb208-7"><a href="classification.html#cb208-7" aria-hidden="true" tabindex="-1"></a>lda_pred <span class="sc">%&gt;%</span></span>
<span id="cb208-8"><a href="classification.html#cb208-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">count</span>(pred_default, default) <span class="sc">%&gt;%</span></span>
<span id="cb208-9"><a href="classification.html#cb208-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_wider</span>(<span class="at">names_from =</span> default, <span class="at">values_from =</span> n) <span class="sc">%&gt;%</span></span>
<span id="cb208-10"><a href="classification.html#cb208-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Total =</span> No <span class="sc">+</span> Yes) <span class="sc">%&gt;%</span></span>
<span id="cb208-11"><a href="classification.html#cb208-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gt</span>(<span class="at">rowname_col =</span> <span class="st">&quot;pred_default&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb208-12"><a href="classification.html#cb208-12" aria-hidden="true" tabindex="-1"></a>  gt<span class="sc">::</span><span class="fu">tab_spanner</span>(<span class="at">label =</span> <span class="st">&quot;True default status&quot;</span>, <span class="at">columns =</span> <span class="fu">everything</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb208-13"><a href="classification.html#cb208-13" aria-hidden="true" tabindex="-1"></a>  gt<span class="sc">::</span><span class="fu">tab_stubhead</span>(<span class="st">&quot;Predicted&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb208-14"><a href="classification.html#cb208-14" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Can&#39;t get the Total row to round to 0 decimals</span></span>
<span id="cb208-15"><a href="classification.html#cb208-15" aria-hidden="true" tabindex="-1"></a>  gt<span class="sc">::</span><span class="fu">summary_rows</span>(<span class="at">fns =</span> <span class="fu">list</span>(<span class="at">Total =</span> <span class="sc">~</span><span class="fu">round</span>(<span class="fu">sum</span>(.), <span class="dv">0</span>)))</span></code></pre></div>
<div id="skvtyzcjea" style="overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>html {
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;
}

#skvtyzcjea .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#skvtyzcjea .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#skvtyzcjea .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#skvtyzcjea .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 4px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#skvtyzcjea .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#skvtyzcjea .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#skvtyzcjea .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#skvtyzcjea .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#skvtyzcjea .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#skvtyzcjea .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#skvtyzcjea .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#skvtyzcjea .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#skvtyzcjea .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#skvtyzcjea .gt_from_md > :first-child {
  margin-top: 0;
}

#skvtyzcjea .gt_from_md > :last-child {
  margin-bottom: 0;
}

#skvtyzcjea .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#skvtyzcjea .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#skvtyzcjea .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#skvtyzcjea .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#skvtyzcjea .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#skvtyzcjea .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#skvtyzcjea .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#skvtyzcjea .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#skvtyzcjea .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#skvtyzcjea .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#skvtyzcjea .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#skvtyzcjea .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#skvtyzcjea .gt_left {
  text-align: left;
}

#skvtyzcjea .gt_center {
  text-align: center;
}

#skvtyzcjea .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#skvtyzcjea .gt_font_normal {
  font-weight: normal;
}

#skvtyzcjea .gt_font_bold {
  font-weight: bold;
}

#skvtyzcjea .gt_font_italic {
  font-style: italic;
}

#skvtyzcjea .gt_super {
  font-size: 65%;
}

#skvtyzcjea .gt_footnote_marks {
  font-style: italic;
  font-weight: normal;
  font-size: 65%;
}
</style>
<table class="gt_table">
  
  <thead class="gt_col_headings">
    <tr>
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="2" colspan="1">Predicted</th>
      <th class="gt_center gt_columns_top_border gt_column_spanner_outer" rowspan="1" colspan="3">
        <span class="gt_column_spanner">True default status</span>
      </th>
    </tr>
    <tr>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1">No</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1">Yes</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1">Total</th>
    </tr>
  </thead>
  <tbody class="gt_table_body">
    <tr><td class="gt_row gt_left gt_stub">No</td>
<td class="gt_row gt_right">9644</td>
<td class="gt_row gt_right">252</td>
<td class="gt_row gt_right">9896</td></tr>
    <tr><td class="gt_row gt_left gt_stub">Yes</td>
<td class="gt_row gt_right">23</td>
<td class="gt_row gt_right">81</td>
<td class="gt_row gt_right">104</td></tr>
    <tr>
      <td class="gt_row gt_stub gt_right gt_grand_summary_row gt_first_grand_summary_row">Total</td>
      <td class="gt_row gt_right gt_grand_summary_row gt_first_grand_summary_row">9,667.00</td>
      <td class="gt_row gt_right gt_grand_summary_row gt_first_grand_summary_row">333.00</td>
      <td class="gt_row gt_right gt_grand_summary_row gt_first_grand_summary_row">10,000.00</td>
    </tr>
  </tbody>
  
  
</table>
</div>
<p>We only missed 23 individuals who did not default, out of 9667.
This is great, but we did quite poorly in predicting defaulters.</p>
<blockquote>
<p>However, of the 333 individuals who
defaulted, 252 (or 75.7%) were missed by LDA. So while the overall error
rate is low, the error rate among individuals who defaulted is very high.
From the perspective of a credit card company that is trying to identify
high-risk individuals, an error rate of 252/333 = 75.7% among individuals
who default may well be unacceptable.</p>
</blockquote>
<blockquote>
<p>Class-specific performance is also important in medicine and biology,
where the terms sensitivity and specificity characterize the performance of
a classifier or screening test. In this case the sensitivity is the percentage
of true defaulters that are identified; it equals 24.3%. The specificity is
the percentage of non-defaulters that are correctly identified; it equals (1 −
23/9667) = 99.8%.</p>
</blockquote>
<p>LDA has poor sensitivity here because it attempts to reduce the total error rate, regardless of class.
In the case of a credit card company, it is probably more valuable to correctly identify individuals who will default.</p>
<p>The LDA classifier, like the Bayes classifier to which it approximates, assigns an observation to the <code>default</code> = “Yes” class if</p>
<p><span class="math display">\[
\text{Pr}(\text{default = Yes}| X = x) &gt; 0.5.
\]</span></p>
<p>That is to say, these classifiers have a default threshold of 50% posterior probability.
We may lower these probability as needed.
To adjust this with the <code>MASS::lda</code> package, we can get the posterior probabilities directly via <code>predict.lda()</code>:</p>
<div class="sourceCode" id="cb209"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb209-1"><a href="classification.html#cb209-1" aria-hidden="true" tabindex="-1"></a>lda_posterior <span class="ot">&lt;-</span> <span class="fu">predict</span>(lda_default_balance_student, <span class="at">newdata =</span> default)<span class="sc">$</span>posterior</span>
<span id="cb209-2"><a href="classification.html#cb209-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(lda_posterior)</span></code></pre></div>
<pre><code>##          No         Yes
## 1 0.9968680 0.003131975
## 2 0.9971925 0.002807531
## 3 0.9843970 0.015603046
## 4 0.9987769 0.001223133
## 5 0.9959254 0.004074582
## 6 0.9954627 0.004537289</code></pre>
<p>Then use the threshold of 20% to re-create Table 4.5:</p>
<div class="sourceCode" id="cb211"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb211-1"><a href="classification.html#cb211-1" aria-hidden="true" tabindex="-1"></a>lda_pred_20 <span class="ot">&lt;-</span> <span class="fu">bind_cols</span>(</span>
<span id="cb211-2"><a href="classification.html#cb211-2" aria-hidden="true" tabindex="-1"></a>  default,</span>
<span id="cb211-3"><a href="classification.html#cb211-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">posterior_prob_default =</span> lda_posterior[,<span class="dv">2</span>]</span>
<span id="cb211-4"><a href="classification.html#cb211-4" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span></span>
<span id="cb211-5"><a href="classification.html#cb211-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb211-6"><a href="classification.html#cb211-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">pred_default =</span> <span class="fu">ifelse</span>(posterior_prob_default <span class="sc">&gt;</span> <span class="fl">0.2</span>, <span class="st">&quot;Yes&quot;</span>, <span class="st">&quot;No&quot;</span>)</span>
<span id="cb211-7"><a href="classification.html#cb211-7" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb211-8"><a href="classification.html#cb211-8" aria-hidden="true" tabindex="-1"></a>lda_pred_20 <span class="sc">%&gt;%</span></span>
<span id="cb211-9"><a href="classification.html#cb211-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">count</span>(pred_default, default) <span class="sc">%&gt;%</span></span>
<span id="cb211-10"><a href="classification.html#cb211-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_wider</span>(<span class="at">names_from =</span> default, <span class="at">values_from =</span> n) <span class="sc">%&gt;%</span></span>
<span id="cb211-11"><a href="classification.html#cb211-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Total =</span> No <span class="sc">+</span> Yes) <span class="sc">%&gt;%</span></span>
<span id="cb211-12"><a href="classification.html#cb211-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gt</span>(<span class="at">rowname_col =</span> <span class="st">&quot;pred_default&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb211-13"><a href="classification.html#cb211-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tab_spanner</span>(<span class="at">label =</span> <span class="st">&quot;True default status&quot;</span>, <span class="at">columns =</span> <span class="fu">everything</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb211-14"><a href="classification.html#cb211-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tab_stubhead</span>(<span class="st">&quot;Predicted&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb211-15"><a href="classification.html#cb211-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summary_rows</span>(<span class="at">fns =</span> <span class="fu">list</span>(<span class="at">Total =</span> <span class="sc">~</span><span class="fu">round</span>(<span class="fu">sum</span>(.), <span class="dv">0</span>)))</span></code></pre></div>
<div id="ggcbylpnri" style="overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>html {
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;
}

#ggcbylpnri .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#ggcbylpnri .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#ggcbylpnri .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#ggcbylpnri .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 4px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#ggcbylpnri .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#ggcbylpnri .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#ggcbylpnri .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#ggcbylpnri .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#ggcbylpnri .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#ggcbylpnri .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#ggcbylpnri .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#ggcbylpnri .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#ggcbylpnri .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#ggcbylpnri .gt_from_md > :first-child {
  margin-top: 0;
}

#ggcbylpnri .gt_from_md > :last-child {
  margin-bottom: 0;
}

#ggcbylpnri .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#ggcbylpnri .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#ggcbylpnri .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#ggcbylpnri .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#ggcbylpnri .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#ggcbylpnri .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#ggcbylpnri .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#ggcbylpnri .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#ggcbylpnri .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#ggcbylpnri .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#ggcbylpnri .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#ggcbylpnri .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#ggcbylpnri .gt_left {
  text-align: left;
}

#ggcbylpnri .gt_center {
  text-align: center;
}

#ggcbylpnri .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#ggcbylpnri .gt_font_normal {
  font-weight: normal;
}

#ggcbylpnri .gt_font_bold {
  font-weight: bold;
}

#ggcbylpnri .gt_font_italic {
  font-style: italic;
}

#ggcbylpnri .gt_super {
  font-size: 65%;
}

#ggcbylpnri .gt_footnote_marks {
  font-style: italic;
  font-weight: normal;
  font-size: 65%;
}
</style>
<table class="gt_table">
  
  <thead class="gt_col_headings">
    <tr>
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="2" colspan="1">Predicted</th>
      <th class="gt_center gt_columns_top_border gt_column_spanner_outer" rowspan="1" colspan="3">
        <span class="gt_column_spanner">True default status</span>
      </th>
    </tr>
    <tr>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1">No</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1">Yes</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1">Total</th>
    </tr>
  </thead>
  <tbody class="gt_table_body">
    <tr><td class="gt_row gt_left gt_stub">No</td>
<td class="gt_row gt_right">9432</td>
<td class="gt_row gt_right">138</td>
<td class="gt_row gt_right">9570</td></tr>
    <tr><td class="gt_row gt_left gt_stub">Yes</td>
<td class="gt_row gt_right">235</td>
<td class="gt_row gt_right">195</td>
<td class="gt_row gt_right">430</td></tr>
    <tr>
      <td class="gt_row gt_stub gt_right gt_grand_summary_row gt_first_grand_summary_row">Total</td>
      <td class="gt_row gt_right gt_grand_summary_row gt_first_grand_summary_row">9,667.00</td>
      <td class="gt_row gt_right gt_grand_summary_row gt_first_grand_summary_row">333.00</td>
      <td class="gt_row gt_right gt_grand_summary_row gt_first_grand_summary_row">10,000.00</td>
    </tr>
  </tbody>
  
  
</table>
</div>
<p>The sensitivity to detect defaulters has improved to 58.8%, but the specificity has dropped 97.5%.
The overall error rate has also increased to 3.7%.</p>
<blockquote>
<p>But a credit card company
may consider this slight increase in the total error rate to be a small price to
pay for more accurate identification of individuals who do indeed default.</p>
</blockquote>
<blockquote>
<p>How can we decide which threshold value is
best? Such a decision must be based on domain knowledge, such as detailed
information about the costs associated with default.</p>
</blockquote>
<p>The receiver operating character (ROC) curve is one way to visualize the trade-off between two types of error for different threshold values.
I like the <code>yardstick::roc_curve()</code> function for this purpose:</p>
<div class="sourceCode" id="cb212"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb212-1"><a href="classification.html#cb212-1" aria-hidden="true" tabindex="-1"></a>lda_roc <span class="ot">&lt;-</span></span>
<span id="cb212-2"><a href="classification.html#cb212-2" aria-hidden="true" tabindex="-1"></a>  yardstick<span class="sc">::</span><span class="fu">roc_curve</span>(</span>
<span id="cb212-3"><a href="classification.html#cb212-3" aria-hidden="true" tabindex="-1"></a>    lda_pred_20,</span>
<span id="cb212-4"><a href="classification.html#cb212-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Specify the class probability and the truth variables</span></span>
<span id="cb212-5"><a href="classification.html#cb212-5" aria-hidden="true" tabindex="-1"></a>    posterior_prob_default, <span class="at">truth =</span> default,</span>
<span id="cb212-6"><a href="classification.html#cb212-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># This argument specifies which level of truth (default) is considered</span></span>
<span id="cb212-7"><a href="classification.html#cb212-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">#  &quot;positive&quot;, so it will flip the ROC curve vertically</span></span>
<span id="cb212-8"><a href="classification.html#cb212-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">event_level =</span> <span class="st">&quot;second&quot;</span></span>
<span id="cb212-9"><a href="classification.html#cb212-9" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb212-10"><a href="classification.html#cb212-10" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(lda_roc)</span></code></pre></div>
<p><img src="_main_files/figure-html/figure4.8-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>The area under the curve (AUC) summarizes the overall performance of the classifier:</p>
<div class="sourceCode" id="cb213"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb213-1"><a href="classification.html#cb213-1" aria-hidden="true" tabindex="-1"></a>yardstick<span class="sc">::</span><span class="fu">roc_auc</span>(</span>
<span id="cb213-2"><a href="classification.html#cb213-2" aria-hidden="true" tabindex="-1"></a>  lda_pred_20,</span>
<span id="cb213-3"><a href="classification.html#cb213-3" aria-hidden="true" tabindex="-1"></a>  posterior_prob_default, <span class="at">truth =</span> default,</span>
<span id="cb213-4"><a href="classification.html#cb213-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">event_level =</span> <span class="st">&quot;second&quot;</span></span>
<span id="cb213-5"><a href="classification.html#cb213-5" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 3
##   .metric .estimator .estimate
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
## 1 roc_auc binary         0.950</code></pre>
<p>We get the exact same ROC AUC with logistic regression:</p>
<div class="sourceCode" id="cb215"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb215-1"><a href="classification.html#cb215-1" aria-hidden="true" tabindex="-1"></a>glm_default_balance_student <span class="ot">&lt;-</span></span>
<span id="cb215-2"><a href="classification.html#cb215-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">glm</span>(default <span class="sc">~</span> balance <span class="sc">+</span> student,</span>
<span id="cb215-3"><a href="classification.html#cb215-3" aria-hidden="true" tabindex="-1"></a>      <span class="at">data =</span> default, <span class="at">family =</span> binomial)</span>
<span id="cb215-4"><a href="classification.html#cb215-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb215-5"><a href="classification.html#cb215-5" aria-hidden="true" tabindex="-1"></a>glm_pred <span class="ot">&lt;-</span> <span class="fu">bind_cols</span>(</span>
<span id="cb215-6"><a href="classification.html#cb215-6" aria-hidden="true" tabindex="-1"></a>  default,</span>
<span id="cb215-7"><a href="classification.html#cb215-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">glm_prob_default =</span> <span class="fu">predict</span>(</span>
<span id="cb215-8"><a href="classification.html#cb215-8" aria-hidden="true" tabindex="-1"></a>    glm_default_balance_student,</span>
<span id="cb215-9"><a href="classification.html#cb215-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">newdata =</span> default, <span class="at">type =</span> <span class="st">&quot;response&quot;</span></span>
<span id="cb215-10"><a href="classification.html#cb215-10" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb215-11"><a href="classification.html#cb215-11" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb215-12"><a href="classification.html#cb215-12" aria-hidden="true" tabindex="-1"></a>yardstick<span class="sc">::</span><span class="fu">roc_auc</span>(</span>
<span id="cb215-13"><a href="classification.html#cb215-13" aria-hidden="true" tabindex="-1"></a>  glm_pred,</span>
<span id="cb215-14"><a href="classification.html#cb215-14" aria-hidden="true" tabindex="-1"></a>  glm_prob_default, <span class="at">truth =</span> default,</span>
<span id="cb215-15"><a href="classification.html#cb215-15" aria-hidden="true" tabindex="-1"></a>  <span class="at">event_level =</span> <span class="st">&quot;second&quot;</span></span>
<span id="cb215-16"><a href="classification.html#cb215-16" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 3
##   .metric .estimator .estimate
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
## 1 roc_auc binary         0.950</code></pre>
</div>
<div id="quadratic-discriminant-analysis" class="section level3" number="4.4.3">
<h3><span class="header-section-number">4.4.3</span> Quadratic Discriminant Analysis</h3>
<blockquote>
<p>As we have discussed, LDA assumes that the observations within each
class are drawn from a multivariate Gaussian distribution with a class-specific mean vector and a covariance matrix that is common to all <span class="math inline">\(K\)</span>
classes. Quadratic discriminant analysis (QDA) provides an alternative
approach. Like LDA, the QDA classifier results from assuming that the
observations from each class are drawn from a Gaussian distribution, and
plugging estimates for the parameters into Bayes’ theorem in order to perform prediction. However, unlike LDA, QDA assumes that each class has
its own covariance matrix. That is, it assumes that an observation from the
<span class="math inline">\(k\)</span>th class is of the form <span class="math inline">\(X \sim N(\mu_k, \Sigma_k)\)</span>, where <span class="math inline">\(\Sigma_k\)</span> is a covariance matrix
for the <span class="math inline">\(k\)</span>th class.</p>
</blockquote>
<p>An observation <span class="math inline">\(X = x\)</span> is assigned to the class for which</p>
<p><span class="math display">\[
\begin{align}
\delta_k (x) = - \frac{1}{2} (x - \mu_k)^T \Sigma^{-1}_k (x - \mu_k) - \frac{1}{2} \log |\Sigma_k|+ \log \pi_k.
\end{align}
\]</span></p>
<p>QDA gets its name from how the quantity <span class="math inline">\(x\)</span> appears as quadratic function in the first term of the above equation.</p>
<blockquote>
<p>Why does it matter whether or not we assume that the <span class="math inline">\(K\)</span> classes share a
common covariance matrix? In other words, why would one prefer LDA to
QDA, or vice-versa? The answer lies in the bias-variance trade-off. When
there are <span class="math inline">\(p\)</span> predictors, then estimating a covariance matrix requires estimating <span class="math inline">\(p(p+1)/2\)</span> parameters. QDA estimates a separate covariance matrix
for each class, for a total of <span class="math inline">\(Kp(p+1)/2\)</span> parameters.</p>
</blockquote>
<blockquote>
<p>Consequently, LDA is a much less flexible classifier than QDA, and
so has substantially lower variance. This can potentially lead to improved
prediction performance. But there is a trade-off: if LDA’s assumption that
the <span class="math inline">\(K\)</span> classes share a common covariance matrix is badly off, then LDA
can suffer from high bias.</p>
</blockquote>
<p>In short: use LDA if there are relatively few training observations, and use QDA for many.</p>
</div>
<div id="naive-bayes" class="section level3" number="4.4.4">
<h3><span class="header-section-number">4.4.4</span> Naive Bayes</h3>
<p>The naive Bayes classifier also estimates the conditional probability <span class="math inline">\(f_k (x) = \text{Pr}(X|Y = k)\)</span>.
In LDA, we made the very strong assumption that <span class="math inline">\(f_k\)</span> is the density function of a multivariate normal distribution with mean <span class="math inline">\(\mu_k\)</span> and shared covariance <span class="math inline">\(\Sigma\)</span>.
In QDA, the covariance <span class="math inline">\(\Sigma_k\)</span> is class-specific.
The naive Bayes classifier instead makes a single assumption:</p>
<blockquote>
<p>Within the <span class="math inline">\(k\)</span>th class, the <span class="math inline">\(p\)</span> predictors are independent.</p>
</blockquote>
<p>Mathematically:</p>
<p><span class="math display">\[
f_k (x) = f_{k1}(x_1) \times f_{k2}(x_2) \times \dots \times f_{kp}(x_p).
\]</span></p>
<p>where <span class="math inline">\(f_{kj}\)</span> is the density function of the <span class="math inline">\(j\)</span>th predictor among observations in the <span class="math inline">\(k\)</span>th class.</p>
<blockquote>
<p>Why is this assumption so powerful? Essentially, estimating a <span class="math inline">\(p\)</span>-dimensional density function is challenging because we must consider not only
the marginal distribution of each predictor — that is, the distribution of each predictor on its own — but also the joint distribution of the predictors
— that is, the association between the different predictors. In the case of
a multivariate normal distribution, the association between the different
predictors is summarized by the off-diagonal elements of the covariance
matrix. However, in general, this association can be very hard to characterize, and exceedingly challenging to estimate. But by assuming that the
<span class="math inline">\(p\)</span> covariates are independent within each class, we completely eliminate the
need to worry about the association between the <span class="math inline">\(p\)</span> predictors, because we
have simply assumed that there is no association between the predictors!</p>
</blockquote>
<p>This is a very stringent assumption – most of the time, we believe there to be some degree of association between predictors.
But naive Bayes can still perform well, especially when <span class="math inline">\(n\)</span> is not large enouugh relative to <span class="math inline">\(p\)</span> to effectively estimate the joint distribution of the predictors within each class.</p>
<blockquote>
<p>Essentially, the naive Bayes assumption introduces some bias, but
reduces variance, leading to a classifier that works quite well in practice as
a result of the bias-variance trade-off.</p>
</blockquote>
<p>Under the naive Bayes, assumption, the posterior probability becomes:</p>
<p><span class="math display">\[
\text{Pr}(Y = k|X = x) = \frac{\pi_k \times f_{k1}(x_1) \times \dots \times f_{kp} (x_p)}{\sum_{l=1}^K \pi_l \times f_{l1}(x_1) \times \dots \times f_{lp} (x_p)}
\]</span></p>
<p>for <span class="math inline">\(k = 1, \dots, K\)</span>.</p>
<p>To estimate the one-dimensional <span class="math inline">\(f_{kj}\)</span> from <span class="math inline">\(x_j\)</span>, we have a few options:</p>
<ul>
<li>Assume that the <span class="math inline">\(j\)</span>th predictor is drawn from a univariate normal distribution.
<ul>
<li><span class="math inline">\(X_j | Y = k \sim N(\mu_{jk}, \sigma_{jk}^2)\)</span>.</li>
<li>This is like QDA except the covariance matrix is diagonal because the predictors are independent.</li>
</ul></li>
<li>Use a non-parametric estimate for <span class="math inline">\(f_{kj}\)</span>.
<ul>
<li>A simple way: Estimate <span class="math inline">\(f_{kj}(x_j)\)</span> as the fraction of the training observations in the <span class="math inline">\(k\)</span>th class belonging to a histogram bin.</li>
<li>Alternatively, use a kernel density estimator, which is essentially a smoothed version of a histogram.</li>
</ul></li>
<li>For qualitative <span class="math inline">\(X_j\)</span>, simply count the proportion of training observations for the <span class="math inline">\(j\)</span>th predictor corresponding to each class.</li>
</ul>
<p>Apply the naive Bayes classifier with the <code>klaR</code> package:</p>
<div class="sourceCode" id="cb217"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb217-1"><a href="classification.html#cb217-1" aria-hidden="true" tabindex="-1"></a>nb_default <span class="ot">&lt;-</span></span>
<span id="cb217-2"><a href="classification.html#cb217-2" aria-hidden="true" tabindex="-1"></a>  klaR<span class="sc">::</span><span class="fu">NaiveBayes</span>(default <span class="sc">~</span> balance <span class="sc">+</span> student, <span class="at">data =</span> default)</span>
<span id="cb217-3"><a href="classification.html#cb217-3" aria-hidden="true" tabindex="-1"></a>nb_pred <span class="ot">&lt;-</span> <span class="fu">bind_cols</span>(</span>
<span id="cb217-4"><a href="classification.html#cb217-4" aria-hidden="true" tabindex="-1"></a>  default,</span>
<span id="cb217-5"><a href="classification.html#cb217-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">nb_prob_default =</span> <span class="fu">predict</span>(nb_default, <span class="at">newdata =</span> default)<span class="sc">$</span>posterior[,<span class="dv">2</span>]</span>
<span id="cb217-6"><a href="classification.html#cb217-6" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p>If we take a posterior probability of 50% or 20% as the thresholds for predicting a default, we get Tables 4.8 and 4.9:</p>
<div class="sourceCode" id="cb218"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb218-1"><a href="classification.html#cb218-1" aria-hidden="true" tabindex="-1"></a>nb_pred <span class="ot">&lt;-</span> nb_pred <span class="sc">%&gt;%</span></span>
<span id="cb218-2"><a href="classification.html#cb218-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb218-3"><a href="classification.html#cb218-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">pred_default_0.5 =</span> <span class="fu">ifelse</span>(nb_prob_default <span class="sc">&gt;</span> <span class="fl">0.5</span>, <span class="st">&quot;Yes&quot;</span>, <span class="st">&quot;No&quot;</span>),</span>
<span id="cb218-4"><a href="classification.html#cb218-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">pred_default_0.2 =</span> <span class="fu">ifelse</span>(nb_prob_default <span class="sc">&gt;</span> <span class="fl">0.2</span>, <span class="st">&quot;Yes&quot;</span>, <span class="st">&quot;No&quot;</span>)</span>
<span id="cb218-5"><a href="classification.html#cb218-5" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb218-6"><a href="classification.html#cb218-6" aria-hidden="true" tabindex="-1"></a>nb_pred <span class="sc">%&gt;%</span></span>
<span id="cb218-7"><a href="classification.html#cb218-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">count</span>(pred_default_0<span class="fl">.5</span>, default) <span class="sc">%&gt;%</span></span>
<span id="cb218-8"><a href="classification.html#cb218-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_wider</span>(<span class="at">names_from =</span> default, <span class="at">values_from =</span> n) <span class="sc">%&gt;%</span></span>
<span id="cb218-9"><a href="classification.html#cb218-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Total =</span> No <span class="sc">+</span> Yes) <span class="sc">%&gt;%</span></span>
<span id="cb218-10"><a href="classification.html#cb218-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gt</span>(<span class="at">rowname_col =</span> <span class="st">&quot;pred_default_0.5&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb218-11"><a href="classification.html#cb218-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tab_spanner</span>(<span class="at">label =</span> <span class="st">&quot;True default status&quot;</span>, <span class="at">columns =</span> <span class="fu">everything</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb218-12"><a href="classification.html#cb218-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tab_stubhead</span>(<span class="st">&quot;Predicted&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb218-13"><a href="classification.html#cb218-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summary_rows</span>(<span class="at">fns =</span> <span class="fu">list</span>(<span class="at">Total =</span> <span class="sc">~</span><span class="fu">round</span>(<span class="fu">sum</span>(.), <span class="dv">0</span>)))</span></code></pre></div>
<div id="ujgogwpkcm" style="overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>html {
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;
}

#ujgogwpkcm .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#ujgogwpkcm .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#ujgogwpkcm .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#ujgogwpkcm .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 4px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#ujgogwpkcm .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#ujgogwpkcm .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#ujgogwpkcm .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#ujgogwpkcm .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#ujgogwpkcm .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#ujgogwpkcm .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#ujgogwpkcm .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#ujgogwpkcm .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#ujgogwpkcm .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#ujgogwpkcm .gt_from_md > :first-child {
  margin-top: 0;
}

#ujgogwpkcm .gt_from_md > :last-child {
  margin-bottom: 0;
}

#ujgogwpkcm .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#ujgogwpkcm .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#ujgogwpkcm .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#ujgogwpkcm .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#ujgogwpkcm .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#ujgogwpkcm .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#ujgogwpkcm .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#ujgogwpkcm .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#ujgogwpkcm .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#ujgogwpkcm .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#ujgogwpkcm .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#ujgogwpkcm .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#ujgogwpkcm .gt_left {
  text-align: left;
}

#ujgogwpkcm .gt_center {
  text-align: center;
}

#ujgogwpkcm .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#ujgogwpkcm .gt_font_normal {
  font-weight: normal;
}

#ujgogwpkcm .gt_font_bold {
  font-weight: bold;
}

#ujgogwpkcm .gt_font_italic {
  font-style: italic;
}

#ujgogwpkcm .gt_super {
  font-size: 65%;
}

#ujgogwpkcm .gt_footnote_marks {
  font-style: italic;
  font-weight: normal;
  font-size: 65%;
}
</style>
<table class="gt_table">
  
  <thead class="gt_col_headings">
    <tr>
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="2" colspan="1">Predicted</th>
      <th class="gt_center gt_columns_top_border gt_column_spanner_outer" rowspan="1" colspan="3">
        <span class="gt_column_spanner">True default status</span>
      </th>
    </tr>
    <tr>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1">No</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1">Yes</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1">Total</th>
    </tr>
  </thead>
  <tbody class="gt_table_body">
    <tr><td class="gt_row gt_left gt_stub">No</td>
<td class="gt_row gt_right">9621</td>
<td class="gt_row gt_right">244</td>
<td class="gt_row gt_right">9865</td></tr>
    <tr><td class="gt_row gt_left gt_stub">Yes</td>
<td class="gt_row gt_right">46</td>
<td class="gt_row gt_right">89</td>
<td class="gt_row gt_right">135</td></tr>
    <tr>
      <td class="gt_row gt_stub gt_right gt_grand_summary_row gt_first_grand_summary_row">Total</td>
      <td class="gt_row gt_right gt_grand_summary_row gt_first_grand_summary_row">9,667.00</td>
      <td class="gt_row gt_right gt_grand_summary_row gt_first_grand_summary_row">333.00</td>
      <td class="gt_row gt_right gt_grand_summary_row gt_first_grand_summary_row">10,000.00</td>
    </tr>
  </tbody>
  
  
</table>
</div>
<div class="sourceCode" id="cb219"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb219-1"><a href="classification.html#cb219-1" aria-hidden="true" tabindex="-1"></a>nb_pred <span class="sc">%&gt;%</span></span>
<span id="cb219-2"><a href="classification.html#cb219-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">count</span>(pred_default_0<span class="fl">.2</span>, default) <span class="sc">%&gt;%</span></span>
<span id="cb219-3"><a href="classification.html#cb219-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_wider</span>(<span class="at">names_from =</span> default, <span class="at">values_from =</span> n) <span class="sc">%&gt;%</span></span>
<span id="cb219-4"><a href="classification.html#cb219-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Total =</span> No <span class="sc">+</span> Yes) <span class="sc">%&gt;%</span></span>
<span id="cb219-5"><a href="classification.html#cb219-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gt</span>(<span class="at">rowname_col =</span> <span class="st">&quot;pred_default_0.2&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb219-6"><a href="classification.html#cb219-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tab_spanner</span>(<span class="at">label =</span> <span class="st">&quot;True default status&quot;</span>, <span class="at">columns =</span> <span class="fu">everything</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb219-7"><a href="classification.html#cb219-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tab_stubhead</span>(<span class="st">&quot;Predicted&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb219-8"><a href="classification.html#cb219-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summary_rows</span>(<span class="at">fns =</span> <span class="fu">list</span>(<span class="at">Total =</span> <span class="sc">~</span><span class="fu">round</span>(<span class="fu">sum</span>(.), <span class="dv">0</span>)))</span></code></pre></div>
<div id="vfygpcxfsz" style="overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>html {
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;
}

#vfygpcxfsz .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#vfygpcxfsz .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#vfygpcxfsz .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#vfygpcxfsz .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 4px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#vfygpcxfsz .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#vfygpcxfsz .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#vfygpcxfsz .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#vfygpcxfsz .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#vfygpcxfsz .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#vfygpcxfsz .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#vfygpcxfsz .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#vfygpcxfsz .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#vfygpcxfsz .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#vfygpcxfsz .gt_from_md > :first-child {
  margin-top: 0;
}

#vfygpcxfsz .gt_from_md > :last-child {
  margin-bottom: 0;
}

#vfygpcxfsz .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#vfygpcxfsz .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#vfygpcxfsz .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#vfygpcxfsz .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#vfygpcxfsz .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#vfygpcxfsz .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#vfygpcxfsz .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#vfygpcxfsz .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#vfygpcxfsz .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#vfygpcxfsz .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#vfygpcxfsz .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#vfygpcxfsz .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#vfygpcxfsz .gt_left {
  text-align: left;
}

#vfygpcxfsz .gt_center {
  text-align: center;
}

#vfygpcxfsz .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#vfygpcxfsz .gt_font_normal {
  font-weight: normal;
}

#vfygpcxfsz .gt_font_bold {
  font-weight: bold;
}

#vfygpcxfsz .gt_font_italic {
  font-style: italic;
}

#vfygpcxfsz .gt_super {
  font-size: 65%;
}

#vfygpcxfsz .gt_footnote_marks {
  font-style: italic;
  font-weight: normal;
  font-size: 65%;
}
</style>
<table class="gt_table">
  
  <thead class="gt_col_headings">
    <tr>
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="2" colspan="1">Predicted</th>
      <th class="gt_center gt_columns_top_border gt_column_spanner_outer" rowspan="1" colspan="3">
        <span class="gt_column_spanner">True default status</span>
      </th>
    </tr>
    <tr>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1">No</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1">Yes</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1">Total</th>
    </tr>
  </thead>
  <tbody class="gt_table_body">
    <tr><td class="gt_row gt_left gt_stub">No</td>
<td class="gt_row gt_right">9339</td>
<td class="gt_row gt_right">130</td>
<td class="gt_row gt_right">9469</td></tr>
    <tr><td class="gt_row gt_left gt_stub">Yes</td>
<td class="gt_row gt_right">328</td>
<td class="gt_row gt_right">203</td>
<td class="gt_row gt_right">531</td></tr>
    <tr>
      <td class="gt_row gt_stub gt_right gt_grand_summary_row gt_first_grand_summary_row">Total</td>
      <td class="gt_row gt_right gt_grand_summary_row gt_first_grand_summary_row">9,667.00</td>
      <td class="gt_row gt_right gt_grand_summary_row gt_first_grand_summary_row">333.00</td>
      <td class="gt_row gt_right gt_grand_summary_row gt_first_grand_summary_row">10,000.00</td>
    </tr>
  </tbody>
  
  
</table>
</div>
<p>The numbers are slightly different from the text, which may have to do with how <span class="math inline">\(f_{kj}\)</span> for the quantitative <code>balance</code> was estimated.
The overall error rate, sensitivity, and specificity of the naive Bayes approach:</p>
<div class="sourceCode" id="cb220"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb220-1"><a href="classification.html#cb220-1" aria-hidden="true" tabindex="-1"></a>nb_pred <span class="sc">%&gt;%</span></span>
<span id="cb220-2"><a href="classification.html#cb220-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(default, pred_default_0<span class="fl">.2</span>, pred_default_0<span class="fl">.5</span>) <span class="sc">%&gt;%</span></span>
<span id="cb220-3"><a href="classification.html#cb220-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(<span class="fu">c</span>(pred_default_0<span class="fl">.5</span>, pred_default_0<span class="fl">.2</span>),</span>
<span id="cb220-4"><a href="classification.html#cb220-4" aria-hidden="true" tabindex="-1"></a>               <span class="at">names_to =</span> <span class="st">&quot;threshold&quot;</span>, <span class="at">values_to =</span> <span class="st">&quot;pred_default&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb220-5"><a href="classification.html#cb220-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">threshold =</span> <span class="fu">as.numeric</span>(<span class="fu">str_remove</span>(threshold, <span class="st">&quot;pred_default_&quot;</span>))) <span class="sc">%&gt;%</span></span>
<span id="cb220-6"><a href="classification.html#cb220-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(threshold) <span class="sc">%&gt;%</span></span>
<span id="cb220-7"><a href="classification.html#cb220-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(</span>
<span id="cb220-8"><a href="classification.html#cb220-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">overall_error =</span> <span class="fu">mean</span>(default <span class="sc">!=</span> pred_default),</span>
<span id="cb220-9"><a href="classification.html#cb220-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">sensitivity =</span> <span class="fu">sum</span>(default <span class="sc">==</span> <span class="st">&quot;Yes&quot;</span> <span class="sc">&amp;</span> pred_default <span class="sc">==</span> <span class="st">&quot;Yes&quot;</span>) <span class="sc">/</span></span>
<span id="cb220-10"><a href="classification.html#cb220-10" aria-hidden="true" tabindex="-1"></a>      <span class="fu">sum</span>(default <span class="sc">==</span> <span class="st">&quot;Yes&quot;</span>),</span>
<span id="cb220-11"><a href="classification.html#cb220-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">specificity =</span> <span class="fu">sum</span>(default <span class="sc">==</span> <span class="st">&quot;No&quot;</span> <span class="sc">&amp;</span> pred_default <span class="sc">==</span> <span class="st">&quot;No&quot;</span>) <span class="sc">/</span></span>
<span id="cb220-12"><a href="classification.html#cb220-12" aria-hidden="true" tabindex="-1"></a>      <span class="fu">sum</span>(default <span class="sc">==</span> <span class="st">&quot;No&quot;</span>),</span>
<span id="cb220-13"><a href="classification.html#cb220-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">.groups =</span> <span class="st">&quot;drop&quot;</span></span>
<span id="cb220-14"><a href="classification.html#cb220-14" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb220-15"><a href="classification.html#cb220-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="fu">across</span>(<span class="fu">everything</span>(), scales<span class="sc">::</span>percent)) <span class="sc">%&gt;%</span></span>
<span id="cb220-16"><a href="classification.html#cb220-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gt</span>()</span></code></pre></div>
<div id="dolyxdntek" style="overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>html {
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;
}

#dolyxdntek .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#dolyxdntek .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#dolyxdntek .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#dolyxdntek .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 4px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#dolyxdntek .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#dolyxdntek .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#dolyxdntek .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#dolyxdntek .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#dolyxdntek .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#dolyxdntek .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#dolyxdntek .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#dolyxdntek .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#dolyxdntek .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#dolyxdntek .gt_from_md > :first-child {
  margin-top: 0;
}

#dolyxdntek .gt_from_md > :last-child {
  margin-bottom: 0;
}

#dolyxdntek .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#dolyxdntek .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#dolyxdntek .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#dolyxdntek .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#dolyxdntek .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#dolyxdntek .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#dolyxdntek .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#dolyxdntek .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#dolyxdntek .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#dolyxdntek .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#dolyxdntek .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#dolyxdntek .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#dolyxdntek .gt_left {
  text-align: left;
}

#dolyxdntek .gt_center {
  text-align: center;
}

#dolyxdntek .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#dolyxdntek .gt_font_normal {
  font-weight: normal;
}

#dolyxdntek .gt_font_bold {
  font-weight: bold;
}

#dolyxdntek .gt_font_italic {
  font-style: italic;
}

#dolyxdntek .gt_super {
  font-size: 65%;
}

#dolyxdntek .gt_footnote_marks {
  font-style: italic;
  font-weight: normal;
  font-size: 65%;
}
</style>
<table class="gt_table">
  
  <thead class="gt_col_headings">
    <tr>
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1">threshold</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1">overall_error</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1">sensitivity</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1">specificity</th>
    </tr>
  </thead>
  <tbody class="gt_table_body">
    <tr><td class="gt_row gt_left">20%</td>
<td class="gt_row gt_left">4.6%</td>
<td class="gt_row gt_left">61%</td>
<td class="gt_row gt_left">96.6%</td></tr>
    <tr><td class="gt_row gt_left">50%</td>
<td class="gt_row gt_left">2.9%</td>
<td class="gt_row gt_left">27%</td>
<td class="gt_row gt_left">99.5%</td></tr>
  </tbody>
  
  
</table>
</div>
<p>The overall error rate is slightly higher, but a higher sensitivity was achieved.</p>
<blockquote>
<p>In this example, it should not be too surprising that naive Bayes does
not convincingly outperform LDA: this data set has <span class="math inline">\(n = 10,000\)</span> and <span class="math inline">\(p = 4\)</span>,
and so the reduction in variance resulting from the naive Bayes assumption
is not necessarily worthwhile. We expect to see a greater pay-off to using
naive Bayes relative to LDA or QDA in instances where <span class="math inline">\(p\)</span> is larger or <span class="math inline">\(n\)</span> is
smaller, so that reducing the variance is very important.</p>
</blockquote>
</div>
</div>
<div id="a-comparison-of-classification-methods" class="section level2" number="4.5">
<h2><span class="header-section-number">4.5</span> A Comparison of Classification Methods</h2>
<div id="an-analytical-comparison" class="section level3" number="4.5.1">
<h3><span class="header-section-number">4.5.1</span> An Analytical Comparison</h3>
<blockquote>
<p>We now perform an analytical (or mathematical) comparison of LDA,
QDA, naive Bayes, and logistic regression. We consider these approaches in
a setting with <span class="math inline">\(K\)</span> classes, so that we assign an observation to the class that
maximizes <span class="math inline">\(\text{Pr}(Y = k|X = x)\)</span>. Equivalently, we can set <span class="math inline">\(K\)</span> as the baseline
class and assign an observation to the class that maximizes</p>
</blockquote>
<p><span class="math display">\[
\log \left(\frac{\text{Pr}(Y = k|X = x)}{\text{Pr}(Y = K |X = x)}\right)
\]</span></p>
<blockquote>
<p>for <span class="math inline">\(k = 1, \dots, K\)</span>.</p>
</blockquote>
<p>The is the familiar log-odds of class <span class="math inline">\(k\)</span> compared to baseline class <span class="math inline">\(K\)</span>.</p>
<p>For LDA, we assumed the predictors within each class are drawn from a multivariate normal distribution with shared co-variance matrix.
The log-odds can be represented as:</p>
<p><span class="math display">\[
\begin{align}
\log \left(\frac{\text{Pr}(Y = k|X = x)}{\text{Pr}(Y = K |X = x)}\right) &amp;= \log \left(\frac{\pi_k f_k(x)}{\pi_K f_K(x)}\right)\\
&amp;= a_k + \sum_{j=1}^p b_{kj} x_j.
\end{align}
\]</span></p>
<p>where <span class="math inline">\(a_k\)</span> and <span class="math inline">\(b_{kj}\)</span> are functions of <span class="math inline">\(\pi_k\)</span>, <span class="math inline">\(\mu_k\)</span>, and <span class="math inline">\(\Sigma_k\)</span>.
Like logistic regression, LDA assumes that the log-odds of the probabilities are linear in <span class="math inline">\(x\)</span>.</p>
<p>Similarly, an additional function <span class="math inline">\(c_{kjl}\)</span> gives the log-odds in the QDA setting:</p>
<p><span class="math display">\[
\log \left(\frac{\text{Pr}(Y = k|X = x)}{\text{Pr}(Y = K |X = x)}\right)
= a_k + \sum_{j=1}^p b_{kj} x_j + \sum_{j=1}^p \sum_{l=1}^p c_{kjl} x_j x_l
\]</span></p>
<p>which is quadratic in <span class="math inline">\(x\)</span>.</p>
<p>Finally, the naive Bayes setting, with one-dimensional <span class="math inline">\(f_{kj}(x_j)\)</span>:</p>
<p>$$
<span class="math display">\[\begin{align}
\log \left(\frac{\text{Pr}(Y = k|X = x)}{\text{Pr}(Y = K |X = x)}\right) &amp;= \log \left(\frac{\pi_k f_k(x)}{\pi_K f_K(x)}\right)\\
&amp;= a_k + \sum_{j=1}^p g_{kj} (x_j).
\end{align}\]</span></p>
<p>$$</p>
<p>where <span class="math inline">\(g_{kj} (x_j) = \log \frac{f_{kj}(x_j)}{f_{Kj} (x_j)}\)</span>.
This is the form of a generalized additive model, a topic that is discussed further in Chapter 7.</p>
<p>Looking at these forms, we have the following observations:</p>
<ul>
<li>LDA is a special case of QDA with <span class="math inline">\(c_{kjl} = 0\)</span>.</li>
<li>Any classifier with a linear decision boundary is a special case of naive Bayes with <span class="math inline">\(b_{kj} (x_j) = b_{kj} x_j\)</span>. In particular, this means that LDA is a special case of naive Bayes.</li>
<li>Naive Bayes is also a special case of LDA if <span class="math inline">\(f_{kj} (x_j)\)</span> is a modeled as a one-dimensional Gaussian distribution.</li>
<li>QDA and naive Bayes are not special cases of the other.</li>
</ul>
<blockquote>
<p>None of these methods uniformly dominates the others: in any setting, the
choice of method will depend on the true distribution of the predictors in
each of the <span class="math inline">\(K\)</span> classes, as well as other considerations, such as the values of
<span class="math inline">\(n\)</span> and <span class="math inline">\(p\)</span>. The latter ties into the bias-variance trade-off.</p>
</blockquote>
<p>Then to tie this all to logistic regression, recall the multinomial form:</p>
<p><span class="math display">\[
\log \left( \frac{\text{Pr} (Y = k| X = x)}{\text{Pr} (Y = K| X = x)}\right) = \beta_{k0} + \sum_{j=1}^p \beta_{kj} x_j.
\]</span></p>
<p>This is identical to the linear form of the LDA as both are linear functions of the predictors.
The estimation approach differs of course:</p>
<blockquote>
<p>In LDA, the coefficients in this linear function are functions of estimates for <span class="math inline">\(\pi_k\)</span>, <span class="math inline">\(\pi_K\)</span>, <span class="math inline">\(\mu_k\)</span>, <span class="math inline">\(\mu_K\)</span>, and <span class="math inline">\(\Sigma\)</span>
obtained by assuming that <span class="math inline">\(X_1,\dots, X_p\)</span> follow a normal distribution within each class. By contrast, in logistic regression, the coefficients
are chosen to maximize the likelihood function (4.5). Thus, we expect LDA
to outperform logistic regression when the normality assumption (approximately) holds, and we expect logistic regression to perform better when it
does not.</p>
</blockquote>
<p>Lastly, some observations about <span class="math inline">\(K\)</span>-nearest neighbors, which is a non-parametric alternative to classification:</p>
<blockquote>
<ul>
<li>Because KNN is completely non-parametric, we can expect this approach to dominate LDA and logistic regression when the decision
boundary is highly non-linear, provided that <span class="math inline">\(n\)</span> is very large and <span class="math inline">\(p\)</span> is
small.</li>
<li>In order to provide accurate classification, KNN requires a lot of observations relative to the number of predictors – that is, <span class="math inline">\(n\)</span> much larger
than <span class="math inline">\(p\)</span>. This has to do with the fact that KNN is non-parametric, and
thus tends to reduce the bias while incurring a lot of variance.</li>
<li>In settings where the decision boundary is non-linear but <span class="math inline">\(n\)</span> is only
modest, or <span class="math inline">\(p\)</span> is not very small, then QDA may be preferred to KNN.
This is because QDA can provide a non-linear decision boundary
while taking advantage of a parametric form, which means that it
requires a smaller sample size for accurate classification, relative to
KNN.</li>
<li>Unlike logistic regression, KNN does not tell us which predictors are
important: we don’t get a table of coefficients as in Table 4.3.</li>
</ul>
</blockquote>
</div>
<div id="an-empirical-comparison" class="section level3" number="4.5.2">
<h3><span class="header-section-number">4.5.2</span> An Empirical Comparison</h3>
<p>As I don’t have access to the data, or the methodological details to simulate it, I won’t reproduce the results of this section.
But here is my summary of the six scenarios:</p>
<ul>
<li>Scenario 1: uncorrelated normal variables.
<ul>
<li>LDA, logistic regression performed well due to linear decision boundary.</li>
<li>KNN performed poorly.</li>
<li>QDA worse than LDA because it was more flexible than necessary.</li>
<li>Naive Bayes better than QDA because of independent predictors.</li>
</ul></li>
<li>Scenario 2: correlated normal variables.
<ul>
<li>Similar to scenario 1, except naive Bayes performed much worse due to correlated predictors.</li>
</ul></li>
<li>Scenario 3: correlated <span class="math inline">\(t\)</span>-distributed predictors (more extreme points than normal).
<ul>
<li>Logistic regression best (linear decision boundary).</li>
<li>LDA a bit worse because non-normal variables.</li>
</ul></li>
<li>Scenario 4: normal variables with different correlations per class.
<ul>
<li>The QDA assumption was correct, and therefore greatly outperformed other.</li>
</ul></li>
<li>Scenario 5: uncorrelated normal variables, but responses samples from the logistic function applied to a complicated non-linear function of the predictors.
<ul>
<li>The KNN-CV method gave the best results, followed by the more flexible QDA and naive Bayes.</li>
<li>KNN with <span class="math inline">\(K = 1\)</span> was the worst.</li>
</ul></li>
<li>Scenario 6: normal distribution with a different diagonal covariance matrix (uncorrelated) for each class, and with very small sample size.
<ul>
<li>Naive Bayes performed very well.</li>
<li>LDA and logistic regression performed worse due to unequal covariance matrices (non-linear decision boundary).</li>
<li>QDA performed a bit worse than naive Bayes due to small sample size, and difficulty estimating correlations between predictors.</li>
<li>KNN’s performance also suffered due to very small sample size.</li>
</ul></li>
</ul>
<blockquote>
<p>These six examples illustrate that no one method will dominate the others in every situation. When the true decision boundaries are linear, then
the LDA and logistic regression approaches will tend to perform well. When
the boundaries are moderately non-linear, QDA or naive Bayes may give
better results. Finally, for much more complicated decision boundaries, a
non-parametric approach such as KNN can be superior. But the level of
smoothness for a non-parametric approach must be chosen carefully. In the
next chapter we examine a number of approaches for choosing the correct
level of smoothness and, in general, for selecting the best overall method.</p>
</blockquote>
<blockquote>
<p>Finally, recall from Chapter 3 that in the regression setting we can accommodate a non-linear relationship between the predictors and
by performing regression using transformations of the predictors. A similar
approach could be taken in the classification setting. For instance, we could
create a more flexible version of logistic regression by including <span class="math inline">\(X^2\)</span>, <span class="math inline">\(X^3\)</span>,
and even <span class="math inline">\(X^4\)</span> as predictors. This may or may not improve logistic regression’s performance, depending on whether the increase in variance due to
the added flexibility is offset by a sufficiently large reduction in bias. We
could do the same for LDA. If we added all possible quadratic terms and
cross-products to LDA, the form of the model would be the same as the
QDA model, although the parameter estimates would be different. This
device allows us to move somewhere between an LDA and a QDA model.</p>
</blockquote>
</div>
</div>
<div id="generalized-linear-models" class="section level2" number="4.6">
<h2><span class="header-section-number">4.6</span> Generalized Linear Models</h2>
<p>Thus far, we have considered both quantitative and qualitative response <span class="math inline">\(Y\)</span>.
However, sometimes <span class="math inline">\(Y\)</span> is neither, and so linear regression and classification are not applicable.</p>
<p>The example data set to introduce generalized linear models in <code>bikeshare</code>:</p>
<div class="sourceCode" id="cb221"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb221-1"><a href="classification.html#cb221-1" aria-hidden="true" tabindex="-1"></a>bikeshare <span class="ot">&lt;-</span> ISLR2<span class="sc">::</span>Bikeshare</span>
<span id="cb221-2"><a href="classification.html#cb221-2" aria-hidden="true" tabindex="-1"></a><span class="fu">glimpse</span>(bikeshare)</span></code></pre></div>
<pre><code>## Rows: 8,645
## Columns: 15
## $ season     &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,~
## $ mnth       &lt;fct&gt; Jan, Jan, Jan, Jan, Jan, Jan, Jan, Jan, Jan, Jan, Jan, Jan,~
## $ day        &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,~
## $ hr         &lt;fct&gt; 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1~
## $ holiday    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,~
## $ weekday    &lt;dbl&gt; 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,~
## $ workingday &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,~
## $ weathersit &lt;fct&gt; clear, clear, clear, clear, clear, cloudy/misty, clear, cle~
## $ temp       &lt;dbl&gt; 0.24, 0.22, 0.22, 0.24, 0.24, 0.24, 0.22, 0.20, 0.24, 0.32,~
## $ atemp      &lt;dbl&gt; 0.2879, 0.2727, 0.2727, 0.2879, 0.2879, 0.2576, 0.2727, 0.2~
## $ hum        &lt;dbl&gt; 0.81, 0.80, 0.80, 0.75, 0.75, 0.75, 0.80, 0.86, 0.75, 0.76,~
## $ windspeed  &lt;dbl&gt; 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0896, 0.0000, 0.0~
## $ casual     &lt;dbl&gt; 3, 8, 5, 3, 0, 0, 2, 1, 1, 8, 12, 26, 29, 47, 35, 40, 41, 1~
## $ registered &lt;dbl&gt; 13, 32, 27, 10, 1, 1, 0, 2, 7, 6, 24, 30, 55, 47, 71, 70, 5~
## $ bikers     &lt;dbl&gt; 16, 40, 32, 13, 1, 1, 2, 3, 8, 14, 36, 56, 84, 94, 106, 110~</code></pre>
<blockquote>
<p>The response
is <code>bikers</code>, the number of hourly users of a bike sharing program in Washington, DC. This response value is neither qualitative nor quantitative:
instead, it takes on non-negative integer values, or counts. We will consider counts
predicting bikers using the covariates <code>mnth</code> (month of the year), <code>hr</code> (hour
of the day, from 0 to 23), <code>workingday</code> (an indicator variable that equals 1 if
it is neither a weekend nor a holiday), <code>temp</code> (the normalized temperature,
in Celsius), and <code>weathersit</code> (a qualitative variable that takes on one of four
possible values: clear; misty or cloudy; light rain or light snow; or heavy
rain or heavy snow.)
In the analyses that follow, we will treat <code>mnth</code>, <code>hr</code>, and <code>weathersit</code> as
qualitative variables.</p>
</blockquote>
<div id="linear-regression-on-the-bikeshare-data" class="section level3" number="4.6.1">
<h3><span class="header-section-number">4.6.1</span> Linear Regression on the Bikeshare Data</h3>
<p>Results of linear regression predicting <code>bikers</code>:</p>
<div class="sourceCode" id="cb223"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb223-1"><a href="classification.html#cb223-1" aria-hidden="true" tabindex="-1"></a>lm_bikers <span class="ot">&lt;-</span> <span class="fu">lm</span>(bikers <span class="sc">~</span> mnth <span class="sc">+</span> hr <span class="sc">+</span> workingday <span class="sc">+</span> temp <span class="sc">+</span> weathersit,</span>
<span id="cb223-2"><a href="classification.html#cb223-2" aria-hidden="true" tabindex="-1"></a>                <span class="at">data =</span> bikeshare)</span>
<span id="cb223-3"><a href="classification.html#cb223-3" aria-hidden="true" tabindex="-1"></a><span class="fu">tidy_custom</span>(lm_bikers, <span class="at">coef_round =</span> <span class="dv">2</span>, <span class="at">se_round =</span> <span class="dv">2</span>, <span class="at">z_round =</span> <span class="dv">2</span>) <span class="sc">%&gt;%</span></span>
<span id="cb223-4"><a href="classification.html#cb223-4" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Exclude mnth and hr due to space constraints</span></span>
<span id="cb223-5"><a href="classification.html#cb223-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(<span class="sc">!</span><span class="fu">str_detect</span>(term, <span class="st">&quot;mnth|hr&quot;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb223-6"><a href="classification.html#cb223-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gt</span>()</span></code></pre></div>
<div id="fxkprlntuf" style="overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>html {
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;
}

#fxkprlntuf .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#fxkprlntuf .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#fxkprlntuf .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#fxkprlntuf .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 4px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#fxkprlntuf .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#fxkprlntuf .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#fxkprlntuf .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#fxkprlntuf .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#fxkprlntuf .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#fxkprlntuf .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#fxkprlntuf .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#fxkprlntuf .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#fxkprlntuf .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#fxkprlntuf .gt_from_md > :first-child {
  margin-top: 0;
}

#fxkprlntuf .gt_from_md > :last-child {
  margin-bottom: 0;
}

#fxkprlntuf .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#fxkprlntuf .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#fxkprlntuf .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#fxkprlntuf .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#fxkprlntuf .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#fxkprlntuf .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#fxkprlntuf .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#fxkprlntuf .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#fxkprlntuf .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#fxkprlntuf .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#fxkprlntuf .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#fxkprlntuf .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#fxkprlntuf .gt_left {
  text-align: left;
}

#fxkprlntuf .gt_center {
  text-align: center;
}

#fxkprlntuf .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#fxkprlntuf .gt_font_normal {
  font-weight: normal;
}

#fxkprlntuf .gt_font_bold {
  font-weight: bold;
}

#fxkprlntuf .gt_font_italic {
  font-style: italic;
}

#fxkprlntuf .gt_super {
  font-size: 65%;
}

#fxkprlntuf .gt_footnote_marks {
  font-style: italic;
  font-weight: normal;
  font-size: 65%;
}
</style>
<table class="gt_table">
  
  <thead class="gt_col_headings">
    <tr>
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1">term</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1">coefficient</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1">std.error</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1">z-statistic</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1">p-value</th>
    </tr>
  </thead>
  <tbody class="gt_table_body">
    <tr><td class="gt_row gt_left">(Intercept)</td>
<td class="gt_row gt_right">-68.63</td>
<td class="gt_row gt_right">5.31</td>
<td class="gt_row gt_right">-12.93</td>
<td class="gt_row gt_left">&lt;0.001</td></tr>
    <tr><td class="gt_row gt_left">workingday</td>
<td class="gt_row gt_right">1.27</td>
<td class="gt_row gt_right">1.78</td>
<td class="gt_row gt_right">0.71</td>
<td class="gt_row gt_left">0.477</td></tr>
    <tr><td class="gt_row gt_left">temp</td>
<td class="gt_row gt_right">157.21</td>
<td class="gt_row gt_right">10.26</td>
<td class="gt_row gt_right">15.32</td>
<td class="gt_row gt_left">&lt;0.001</td></tr>
    <tr><td class="gt_row gt_left">weathersitcloudy/misty</td>
<td class="gt_row gt_right">-12.89</td>
<td class="gt_row gt_right">1.96</td>
<td class="gt_row gt_right">-6.56</td>
<td class="gt_row gt_left">&lt;0.001</td></tr>
    <tr><td class="gt_row gt_left">weathersitlight rain/snow</td>
<td class="gt_row gt_right">-66.49</td>
<td class="gt_row gt_right">2.97</td>
<td class="gt_row gt_right">-22.42</td>
<td class="gt_row gt_left">&lt;0.001</td></tr>
    <tr><td class="gt_row gt_left">weathersitheavy rain/snow</td>
<td class="gt_row gt_right">-109.74</td>
<td class="gt_row gt_right">76.67</td>
<td class="gt_row gt_right">-1.43</td>
<td class="gt_row gt_left">0.152</td></tr>
  </tbody>
  
  
</table>
</div>
<p>Re-creating Figure 4.13 takes some wrangling to get the appropriate coefficients:</p>
<div class="sourceCode" id="cb224"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb224-1"><a href="classification.html#cb224-1" aria-hidden="true" tabindex="-1"></a>month_coefs <span class="ot">&lt;-</span> <span class="fu">tidy</span>(lm_bikers) <span class="sc">%&gt;%</span></span>
<span id="cb224-2"><a href="classification.html#cb224-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(<span class="fu">str_detect</span>(term, <span class="st">&quot;Intercept|mnth&quot;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb224-3"><a href="classification.html#cb224-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">transmute</span>(</span>
<span id="cb224-4"><a href="classification.html#cb224-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">Month =</span> <span class="fu">ifelse</span>(</span>
<span id="cb224-5"><a href="classification.html#cb224-5" aria-hidden="true" tabindex="-1"></a>      <span class="co"># The reference level is January</span></span>
<span id="cb224-6"><a href="classification.html#cb224-6" aria-hidden="true" tabindex="-1"></a>      term <span class="sc">==</span> <span class="st">&quot;(Intercept)&quot;</span>, <span class="st">&quot;Jan&quot;</span>,</span>
<span id="cb224-7"><a href="classification.html#cb224-7" aria-hidden="true" tabindex="-1"></a>      <span class="fu">str_remove</span>(term, <span class="st">&quot;mnth&quot;</span>)</span>
<span id="cb224-8"><a href="classification.html#cb224-8" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">%&gt;%</span></span>
<span id="cb224-9"><a href="classification.html#cb224-9" aria-hidden="true" tabindex="-1"></a>      <span class="fu">fct_inorder</span>(),</span>
<span id="cb224-10"><a href="classification.html#cb224-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">Coefficient =</span> <span class="fu">ifelse</span>(</span>
<span id="cb224-11"><a href="classification.html#cb224-11" aria-hidden="true" tabindex="-1"></a>      <span class="co"># The coefficient for the reference level of just the intercept</span></span>
<span id="cb224-12"><a href="classification.html#cb224-12" aria-hidden="true" tabindex="-1"></a>      term <span class="sc">==</span> <span class="st">&quot;(Intercept)&quot;</span>, estimate,</span>
<span id="cb224-13"><a href="classification.html#cb224-13" aria-hidden="true" tabindex="-1"></a>      <span class="co"># Otherwise the coefficient is relative to the intercept</span></span>
<span id="cb224-14"><a href="classification.html#cb224-14" aria-hidden="true" tabindex="-1"></a>      estimate <span class="sc">+</span> estimate[term <span class="sc">==</span> <span class="st">&quot;(Intercept)&quot;</span>]</span>
<span id="cb224-15"><a href="classification.html#cb224-15" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb224-16"><a href="classification.html#cb224-16" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb224-17"><a href="classification.html#cb224-17" aria-hidden="true" tabindex="-1"></a>hour_coefs <span class="ot">&lt;-</span> <span class="fu">tidy</span>(lm_bikers) <span class="sc">%&gt;%</span></span>
<span id="cb224-18"><a href="classification.html#cb224-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(<span class="fu">str_detect</span>(term, <span class="st">&quot;Intercept|hr&quot;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb224-19"><a href="classification.html#cb224-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">transmute</span>(</span>
<span id="cb224-20"><a href="classification.html#cb224-20" aria-hidden="true" tabindex="-1"></a>    <span class="at">Hour =</span> <span class="fu">ifelse</span>(</span>
<span id="cb224-21"><a href="classification.html#cb224-21" aria-hidden="true" tabindex="-1"></a>      <span class="co"># The reference level is 00 hours (midnight)</span></span>
<span id="cb224-22"><a href="classification.html#cb224-22" aria-hidden="true" tabindex="-1"></a>      term <span class="sc">==</span> <span class="st">&quot;(Intercept)&quot;</span>, <span class="st">&quot;0&quot;</span>,</span>
<span id="cb224-23"><a href="classification.html#cb224-23" aria-hidden="true" tabindex="-1"></a>      <span class="fu">str_remove</span>(term, <span class="st">&quot;hr&quot;</span>)</span>
<span id="cb224-24"><a href="classification.html#cb224-24" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">%&gt;%</span></span>
<span id="cb224-25"><a href="classification.html#cb224-25" aria-hidden="true" tabindex="-1"></a>      <span class="fu">as.integer</span>(),</span>
<span id="cb224-26"><a href="classification.html#cb224-26" aria-hidden="true" tabindex="-1"></a>    <span class="at">Coefficient =</span> <span class="fu">ifelse</span>(</span>
<span id="cb224-27"><a href="classification.html#cb224-27" aria-hidden="true" tabindex="-1"></a>      <span class="co"># The coefficient for the reference level of just the intercept</span></span>
<span id="cb224-28"><a href="classification.html#cb224-28" aria-hidden="true" tabindex="-1"></a>      term <span class="sc">==</span> <span class="st">&quot;(Intercept)&quot;</span>, estimate,</span>
<span id="cb224-29"><a href="classification.html#cb224-29" aria-hidden="true" tabindex="-1"></a>      <span class="co"># Otherwise the coefficient is relative to the intercept</span></span>
<span id="cb224-30"><a href="classification.html#cb224-30" aria-hidden="true" tabindex="-1"></a>      estimate <span class="sc">+</span> estimate[term <span class="sc">==</span> <span class="st">&quot;(Intercept)&quot;</span>]</span>
<span id="cb224-31"><a href="classification.html#cb224-31" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb224-32"><a href="classification.html#cb224-32" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb224-33"><a href="classification.html#cb224-33" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> month_coefs <span class="sc">%&gt;%</span></span>
<span id="cb224-34"><a href="classification.html#cb224-34" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> Month, <span class="at">y =</span> Coefficient)) <span class="sc">+</span></span>
<span id="cb224-35"><a href="classification.html#cb224-35" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">color =</span> td_colors<span class="sc">$</span>nice<span class="sc">$</span>spanish_blue, <span class="at">size =</span> <span class="dv">3</span>) <span class="sc">+</span></span>
<span id="cb224-36"><a href="classification.html#cb224-36" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">group =</span> <span class="dv">1</span>), <span class="at">color =</span> td_colors<span class="sc">$</span>nice<span class="sc">$</span>spanish_blue, <span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb224-37"><a href="classification.html#cb224-37" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">axis.text.x =</span> <span class="fu">element_text</span>(<span class="at">angle =</span> <span class="dv">45</span>))</span>
<span id="cb224-38"><a href="classification.html#cb224-38" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> hour_coefs <span class="sc">%&gt;%</span></span>
<span id="cb224-39"><a href="classification.html#cb224-39" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> Hour, <span class="at">y =</span> Coefficient)) <span class="sc">+</span></span>
<span id="cb224-40"><a href="classification.html#cb224-40" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">color =</span> td_colors<span class="sc">$</span>nice<span class="sc">$</span>spanish_blue, <span class="at">size =</span> <span class="dv">3</span>) <span class="sc">+</span></span>
<span id="cb224-41"><a href="classification.html#cb224-41" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">group =</span> <span class="dv">1</span>), <span class="at">color =</span> td_colors<span class="sc">$</span>nice<span class="sc">$</span>spanish_blue, <span class="at">size =</span> <span class="dv">1</span>)</span>
<span id="cb224-42"><a href="classification.html#cb224-42" aria-hidden="true" tabindex="-1"></a>p1 <span class="sc">|</span> p2</span></code></pre></div>
<p><img src="_main_files/figure-html/figure4.13-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>The coefficients make intuitive sense, but the issues with the linear regression become apparent when we look at the predictions:</p>
<div class="sourceCode" id="cb225"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb225-1"><a href="classification.html#cb225-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggdist) <span class="co"># for the stat_halfeye() plotting function</span></span>
<span id="cb225-2"><a href="classification.html#cb225-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb225-3"><a href="classification.html#cb225-3" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(</span>
<span id="cb225-4"><a href="classification.html#cb225-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">pred_bikers =</span> <span class="fu">predict</span>(lm_bikers, <span class="at">newdata =</span> bikeshare,</span>
<span id="cb225-5"><a href="classification.html#cb225-5" aria-hidden="true" tabindex="-1"></a>                        <span class="at">type =</span> <span class="st">&quot;response&quot;</span>)</span>
<span id="cb225-6"><a href="classification.html#cb225-6" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span></span>
<span id="cb225-7"><a href="classification.html#cb225-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> pred_bikers, <span class="at">fill =</span> <span class="fu">stat</span>(x <span class="sc">&lt;</span> <span class="dv">0</span>))) <span class="sc">+</span></span>
<span id="cb225-8"><a href="classification.html#cb225-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_halfeye</span>() <span class="sc">+</span></span>
<span id="cb225-9"><a href="classification.html#cb225-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">&quot;grey75&quot;</span>, td_colors<span class="sc">$</span>nice<span class="sc">$</span>ruby_red)) <span class="sc">+</span></span>
<span id="cb225-10"><a href="classification.html#cb225-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">remove_axis</span>(<span class="st">&quot;y&quot;</span>) <span class="sc">+</span></span>
<span id="cb225-11"><a href="classification.html#cb225-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">&quot;none&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-118-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>9.6% of predictions are negative.</p>

<div id="refs" class="references csl-bib-body hanging-indent">
<div class="csl-entry">
Hastie, Trevor, Robert Tibshirani, and Jerome Friedman. 2009. <em><span class="nocase">The Elements of Statistical Learning</span></em>. Springer Series in Statistics. New York, NY: Springer New York. <a href="https://doi.org/10.1007/978-0-387-84858-7">https://doi.org/10.1007/978-0-387-84858-7</a>.
</div>
<div class="csl-entry">
Smith, Gary. 2018. <span>“<span class="nocase">Step away from stepwise</span>.”</span> <em>Journal of Big Data</em> 5 (1): 32. <a href="https://doi.org/10.1186/s40537-018-0143-6">https://doi.org/10.1186/s40537-018-0143-6</a>.
</div>
</div>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="linear-regression.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
