<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>5 Resampling Methods | An Introduction to Statistical Learning with the tidyverse</title>
  <meta name="description" content="Working through ISLR with the tidyverse and tidymodels" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="5 Resampling Methods | An Introduction to Statistical Learning with the tidyverse" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Working through ISLR with the tidyverse and tidymodels" />
  <meta name="github-repo" content="taylordunn/islr-tidy" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="5 Resampling Methods | An Introduction to Statistical Learning with the tidyverse" />
  
  <meta name="twitter:description" content="Working through ISLR with the tidyverse and tidymodels" />
  

<meta name="author" content="Taylor Dunn" />


<meta name="date" content="2022-01-15" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="classification.html"/>

<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Who, what, and why?</a></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#an-overview-of-statistical-learning"><i class="fa fa-check"></i>An Overview of Statistical Learning</a>
<ul>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#wage-data"><i class="fa fa-check"></i>Wage Data</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#a-brief-history-of-statistical-learning"><i class="fa fa-check"></i>A Brief History of Statistical Learning</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#this-book"><i class="fa fa-check"></i>This Book</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="statistical-learning.html"><a href="statistical-learning.html"><i class="fa fa-check"></i><b>2</b> Statistical Learning</a>
<ul>
<li class="chapter" data-level="2.1" data-path="statistical-learning.html"><a href="statistical-learning.html#what-is-statistical-learning"><i class="fa fa-check"></i><b>2.1</b> What Is Statistical Learning?</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="statistical-learning.html"><a href="statistical-learning.html#why-estimate-f"><i class="fa fa-check"></i><b>2.1.1</b> Why Estimate <span class="math inline">\(f\)</span>?</a></li>
<li class="chapter" data-level="2.1.2" data-path="statistical-learning.html"><a href="statistical-learning.html#how-do-we-estimate-f"><i class="fa fa-check"></i><b>2.1.2</b> How Do We Estimate f?</a></li>
<li class="chapter" data-level="2.1.3" data-path="statistical-learning.html"><a href="statistical-learning.html#the-trade-off-between-prediction-accuracy-and-model-interpretability"><i class="fa fa-check"></i><b>2.1.3</b> The Trade-Off Between Prediction Accuracy and Model Interpretability</a></li>
<li class="chapter" data-level="2.1.4" data-path="statistical-learning.html"><a href="statistical-learning.html#supervised-versus-unsupervised-learning"><i class="fa fa-check"></i><b>2.1.4</b> Supervised Versus Unsupervised Learning</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="statistical-learning.html"><a href="statistical-learning.html#assessing-model-accuracy"><i class="fa fa-check"></i><b>2.2</b> Assessing Model Accuracy</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="statistical-learning.html"><a href="statistical-learning.html#measuring-the-quality-of-fit"><i class="fa fa-check"></i><b>2.2.1</b> Measuring the Quality of Fit</a></li>
<li class="chapter" data-level="2.2.2" data-path="statistical-learning.html"><a href="statistical-learning.html#the-bias-variance-trade-off"><i class="fa fa-check"></i><b>2.2.2</b> The Bias-Variance Trade-Off</a></li>
<li class="chapter" data-level="2.2.3" data-path="statistical-learning.html"><a href="statistical-learning.html#the-classification-setting"><i class="fa fa-check"></i><b>2.2.3</b> The Classification Setting</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="statistical-learning.html"><a href="statistical-learning.html#lab-introduction-to-r"><i class="fa fa-check"></i><b>2.3</b> Lab: Introduction to R</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="linear-regression.html"><a href="linear-regression.html"><i class="fa fa-check"></i><b>3</b> Linear Regression</a>
<ul>
<li class="chapter" data-level="3.1" data-path="linear-regression.html"><a href="linear-regression.html#simple-linear-regression"><i class="fa fa-check"></i><b>3.1</b> Simple Linear Regression</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="linear-regression.html"><a href="linear-regression.html#estimating-the-coefficients"><i class="fa fa-check"></i><b>3.1.1</b> Estimating the Coefficients</a></li>
<li class="chapter" data-level="3.1.2" data-path="linear-regression.html"><a href="linear-regression.html#assessing-the-accuracy-of-the-coefficient-estimates"><i class="fa fa-check"></i><b>3.1.2</b> Assessing the Accuracy of the Coefficient Estimates</a></li>
<li class="chapter" data-level="3.1.3" data-path="linear-regression.html"><a href="linear-regression.html#assessing-the-accuracy-of-the-model"><i class="fa fa-check"></i><b>3.1.3</b> Assessing the Accuracy of the Model</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="linear-regression.html"><a href="linear-regression.html#multiple-linear-regression"><i class="fa fa-check"></i><b>3.2</b> Multiple Linear Regression</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="linear-regression.html"><a href="linear-regression.html#estimating-the-regression-coefficients"><i class="fa fa-check"></i><b>3.2.1</b> Estimating the Regression Coefficients</a></li>
<li class="chapter" data-level="3.2.2" data-path="linear-regression.html"><a href="linear-regression.html#some-important-questions"><i class="fa fa-check"></i><b>3.2.2</b> Some Important Questions</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="linear-regression.html"><a href="linear-regression.html#other-considerations-in-the-regression-model"><i class="fa fa-check"></i><b>3.3</b> Other Considerations in the Regression Model</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="linear-regression.html"><a href="linear-regression.html#qualitative-predictors"><i class="fa fa-check"></i><b>3.3.1</b> Qualitative Predictors</a></li>
<li class="chapter" data-level="3.3.2" data-path="linear-regression.html"><a href="linear-regression.html#extensions-of-the-linear-model"><i class="fa fa-check"></i><b>3.3.2</b> Extensions of the Linear Model</a></li>
<li class="chapter" data-level="3.3.3" data-path="linear-regression.html"><a href="linear-regression.html#potential-problems"><i class="fa fa-check"></i><b>3.3.3</b> Potential Problems</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="linear-regression.html"><a href="linear-regression.html#the-marketing-plan"><i class="fa fa-check"></i><b>3.4</b> The Marketing Plan</a></li>
<li class="chapter" data-level="3.5" data-path="linear-regression.html"><a href="linear-regression.html#comparison-of-linear-regression-with-k-nearest-neighbors"><i class="fa fa-check"></i><b>3.5</b> Comparison of Linear Regression with <span class="math inline">\(K\)</span>-Nearest Neighbors</a></li>
<li class="chapter" data-level="3.6" data-path="linear-regression.html"><a href="linear-regression.html#lab-linear-regression"><i class="fa fa-check"></i><b>3.6</b> Lab: Linear Regression</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="linear-regression.html"><a href="linear-regression.html#libraries"><i class="fa fa-check"></i><b>3.6.1</b> Libraries</a></li>
<li class="chapter" data-level="3.6.2" data-path="linear-regression.html"><a href="linear-regression.html#simple-linear-regression-1"><i class="fa fa-check"></i><b>3.6.2</b> Simple Linear Regression</a></li>
<li class="chapter" data-level="3.6.3" data-path="linear-regression.html"><a href="linear-regression.html#multiple-linear-regression-1"><i class="fa fa-check"></i><b>3.6.3</b> Multiple Linear Regression</a></li>
<li class="chapter" data-level="3.6.4" data-path="linear-regression.html"><a href="linear-regression.html#interaction-terms"><i class="fa fa-check"></i><b>3.6.4</b> Interaction Terms</a></li>
<li class="chapter" data-level="3.6.5" data-path="linear-regression.html"><a href="linear-regression.html#non-linear-transformations-of-the-predictors"><i class="fa fa-check"></i><b>3.6.5</b> Non-linear Transformations of the Predictors</a></li>
<li class="chapter" data-level="3.6.6" data-path="linear-regression.html"><a href="linear-regression.html#qualitative-predictors-1"><i class="fa fa-check"></i><b>3.6.6</b> Qualitative Predictors</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="linear-regression.html"><a href="linear-regression.html#exercises"><i class="fa fa-check"></i><b>3.7</b> Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="linear-regression.html"><a href="linear-regression.html#applied"><i class="fa fa-check"></i>Applied</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="linear-regression.html"><a href="linear-regression.html#reproducibility"><i class="fa fa-check"></i>Reproducibility</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="classification.html"><a href="classification.html"><i class="fa fa-check"></i><b>4</b> Classification</a>
<ul>
<li class="chapter" data-level="4.1" data-path="classification.html"><a href="classification.html#an-overview-of-classification"><i class="fa fa-check"></i><b>4.1</b> An Overview of Classification</a></li>
<li class="chapter" data-level="4.2" data-path="classification.html"><a href="classification.html#why-not-linear-regression"><i class="fa fa-check"></i><b>4.2</b> Why Not Linear Regression?</a></li>
<li class="chapter" data-level="4.3" data-path="classification.html"><a href="classification.html#logistic-regression"><i class="fa fa-check"></i><b>4.3</b> Logistic Regression</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="classification.html"><a href="classification.html#the-logistic-model"><i class="fa fa-check"></i><b>4.3.1</b> The Logistic Model</a></li>
<li class="chapter" data-level="4.3.2" data-path="classification.html"><a href="classification.html#estimating-the-regression-coefficients-1"><i class="fa fa-check"></i><b>4.3.2</b> Estimating the Regression Coefficients</a></li>
<li class="chapter" data-level="4.3.3" data-path="classification.html"><a href="classification.html#making-predictions"><i class="fa fa-check"></i><b>4.3.3</b> Making Predictions</a></li>
<li class="chapter" data-level="4.3.4" data-path="classification.html"><a href="classification.html#multiple-logistic-regression"><i class="fa fa-check"></i><b>4.3.4</b> Multiple Logistic Regression</a></li>
<li class="chapter" data-level="4.3.5" data-path="classification.html"><a href="classification.html#multinomial-logistic-regression"><i class="fa fa-check"></i><b>4.3.5</b> Multinomial Logistic Regression</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="classification.html"><a href="classification.html#generative-models-for-classification"><i class="fa fa-check"></i><b>4.4</b> Generative Models for Classification</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="classification.html"><a href="classification.html#linear-discriminant-analysis-for-p-1"><i class="fa fa-check"></i><b>4.4.1</b> Linear Discriminant Analysis for <span class="math inline">\(p = 1\)</span></a></li>
<li class="chapter" data-level="4.4.2" data-path="classification.html"><a href="classification.html#linear-discriminant-analysis-for-p-1-1"><i class="fa fa-check"></i><b>4.4.2</b> Linear Discriminant Analysis for <span class="math inline">\(p &gt; 1\)</span></a></li>
<li class="chapter" data-level="4.4.3" data-path="classification.html"><a href="classification.html#quadratic-discriminant-analysis"><i class="fa fa-check"></i><b>4.4.3</b> Quadratic Discriminant Analysis</a></li>
<li class="chapter" data-level="4.4.4" data-path="classification.html"><a href="classification.html#naive-bayes"><i class="fa fa-check"></i><b>4.4.4</b> Naive Bayes</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="classification.html"><a href="classification.html#a-comparison-of-classification-methods"><i class="fa fa-check"></i><b>4.5</b> A Comparison of Classification Methods</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="classification.html"><a href="classification.html#an-analytical-comparison"><i class="fa fa-check"></i><b>4.5.1</b> An Analytical Comparison</a></li>
<li class="chapter" data-level="4.5.2" data-path="classification.html"><a href="classification.html#an-empirical-comparison"><i class="fa fa-check"></i><b>4.5.2</b> An Empirical Comparison</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="classification.html"><a href="classification.html#generalized-linear-models"><i class="fa fa-check"></i><b>4.6</b> Generalized Linear Models</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="classification.html"><a href="classification.html#linear-regression-on-the-bikeshare-data"><i class="fa fa-check"></i><b>4.6.1</b> Linear Regression on the Bikeshare Data</a></li>
<li class="chapter" data-level="4.6.2" data-path="classification.html"><a href="classification.html#poisson-regression-on-bikeshare-data"><i class="fa fa-check"></i><b>4.6.2</b> Poisson Regression on Bikeshare Data</a></li>
<li class="chapter" data-level="4.6.3" data-path="classification.html"><a href="classification.html#generalized-linear-models-in-greater-generality"><i class="fa fa-check"></i><b>4.6.3</b> Generalized Linear Models in Greater Generality</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="classification.html"><a href="classification.html#lab-classification-methods"><i class="fa fa-check"></i><b>4.7</b> Lab: Classification Methods</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="classification.html"><a href="classification.html#the-stock-market-data"><i class="fa fa-check"></i><b>4.7.1</b> The Stock Market Data</a></li>
<li class="chapter" data-level="4.7.2" data-path="classification.html"><a href="classification.html#logistic-regression-1"><i class="fa fa-check"></i><b>4.7.2</b> Logistic Regression</a></li>
<li class="chapter" data-level="4.7.3" data-path="classification.html"><a href="classification.html#linear-discriminant-analysis"><i class="fa fa-check"></i><b>4.7.3</b> Linear Discriminant Analysis</a></li>
<li class="chapter" data-level="4.7.4" data-path="classification.html"><a href="classification.html#quadratic-discriminant-analysis-1"><i class="fa fa-check"></i><b>4.7.4</b> Quadratic Discriminant Analysis</a></li>
<li class="chapter" data-level="4.7.5" data-path="classification.html"><a href="classification.html#naive-bayes-1"><i class="fa fa-check"></i><b>4.7.5</b> Naive Bayes</a></li>
<li class="chapter" data-level="4.7.6" data-path="classification.html"><a href="classification.html#k-nearest-neighbors-1"><i class="fa fa-check"></i><b>4.7.6</b> <span class="math inline">\(K\)</span>-Nearest Neighbors</a></li>
<li class="chapter" data-level="4.7.7" data-path="classification.html"><a href="classification.html#poisson-regression"><i class="fa fa-check"></i><b>4.7.7</b> Poisson Regression</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="classification.html"><a href="classification.html#exercises-1"><i class="fa fa-check"></i><b>4.8</b> Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="classification.html"><a href="classification.html#applied-1"><i class="fa fa-check"></i>Applied</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="resampling-methods.html"><a href="resampling-methods.html"><i class="fa fa-check"></i><b>5</b> Resampling Methods</a>
<ul>
<li class="chapter" data-level="5.1" data-path="resampling-methods.html"><a href="resampling-methods.html#cross-validation"><i class="fa fa-check"></i><b>5.1</b> Cross Validation</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="resampling-methods.html"><a href="resampling-methods.html#the-validation-set-approach"><i class="fa fa-check"></i><b>5.1.1</b> The Validation Set Approach</a></li>
<li class="chapter" data-level="5.1.2" data-path="resampling-methods.html"><a href="resampling-methods.html#leave-one-out-cross-validation"><i class="fa fa-check"></i><b>5.1.2</b> Leave-One-Out Cross Validation</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="resampling-methods.html"><a href="resampling-methods.html#the-bootstrap"><i class="fa fa-check"></i><b>5.2</b> The Bootstrap</a></li>
<li class="chapter" data-level="5.3" data-path="resampling-methods.html"><a href="resampling-methods.html#lab-cross-validation-and-the-bootstrap"><i class="fa fa-check"></i><b>5.3</b> Lab: Cross-Validation and the Bootstrap</a></li>
<li class="chapter" data-level="5.4" data-path="resampling-methods.html"><a href="resampling-methods.html#exercises-2"><i class="fa fa-check"></i><b>5.4</b> Exercises</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">An Introduction to Statistical Learning with the tidyverse</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="resampling-methods" class="section level1" number="5">
<h1><span class="header-section-number">5</span> Resampling Methods</h1>
<blockquote>
<p>Resampling methods are an indispensable tool in modern statistics. They
involve repeatedly drawing samples from a training set and refitting a model
of interest on each sample in order to obtain additional information about
the fitted model. For example, in order to estimate the variability of a linear
regression fit, we can repeatedly draw different samples from the training
data, fit a linear regression to each new sample, and then examine the
extent to which the resulting fits differ. Such an approach may allow us to
obtain information that would not be available from fitting the model only
once using the original training sample.</p>
</blockquote>
<blockquote>
<p>In this chapter, we discuss two of the most commonly
used resampling methods, <em>cross-validation</em> and the <em>bootstrap</em>.</p>
</blockquote>
<p>Cross-validation is most often used to estimate test error associated with a statistical learning method, whereas the boostrap is most commonly used to provide a measure of accuracy for a given parameter/method.</p>
<blockquote>
<p>The process
of evaluating a model’s performance is known as <em>model assessment</em>, whereas
the process of selecting the proper level of flexibility for a model is known as <em>model selection</em>.</p>
</blockquote>
<div id="cross-validation" class="section level2" number="5.1">
<h2><span class="header-section-number">5.1</span> Cross Validation</h2>
<p>Sometimes we want to estimate the test error rate using the available training data.
A number of approaches can be used for this.
In this section we consider methods which involve <em>holding out</em> a subset of the training data from the fitting process, then applying the model to that hold-out set for model assessment.</p>
<div id="the-validation-set-approach" class="section level3" number="5.1.1">
<h3><span class="header-section-number">5.1.1</span> The Validation Set Approach</h3>
<p>This simple strategy involves randomly dividing available oberservations into the training and validation set.
The model is fitted on the training set, and used to make predictions on the validation set.
The corresponding metric from the validation set predictions – usually MSE in the case of a quantitative response – provides an estimate of the test error rate.
To illustrate this, load the <code>Auto</code> data set and R packages:</p>
<div class="sourceCode" id="cb332"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb332-1"><a href="resampling-methods.html#cb332-1" aria-hidden="true" tabindex="-1"></a>auto <span class="ot">&lt;-</span> ISLR2<span class="sc">::</span>Auto</span>
<span id="cb332-2"><a href="resampling-methods.html#cb332-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb332-3"><a href="resampling-methods.html#cb332-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb332-4"><a href="resampling-methods.html#cb332-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidymodels)</span>
<span id="cb332-5"><a href="resampling-methods.html#cb332-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(broom)</span>
<span id="cb332-6"><a href="resampling-methods.html#cb332-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gt)</span>
<span id="cb332-7"><a href="resampling-methods.html#cb332-7" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(patchwork) <span class="co"># for composing plots</span></span>
<span id="cb332-8"><a href="resampling-methods.html#cb332-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Load my R package and set the ggplot theme</span></span>
<span id="cb332-9"><a href="resampling-methods.html#cb332-9" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dunnr)</span>
<span id="cb332-10"><a href="resampling-methods.html#cb332-10" aria-hidden="true" tabindex="-1"></a>extrafont<span class="sc">::</span><span class="fu">loadfonts</span>(<span class="at">device =</span> <span class="st">&quot;win&quot;</span>, <span class="at">quiet =</span> <span class="cn">TRUE</span>)</span>
<span id="cb332-11"><a href="resampling-methods.html#cb332-11" aria-hidden="true" tabindex="-1"></a><span class="fu">theme_set</span>(<span class="fu">theme_td</span>())</span>
<span id="cb332-12"><a href="resampling-methods.html#cb332-12" aria-hidden="true" tabindex="-1"></a><span class="fu">set_geom_fonts</span>()</span>
<span id="cb332-13"><a href="resampling-methods.html#cb332-13" aria-hidden="true" tabindex="-1"></a><span class="fu">set_palette</span>()</span></code></pre></div>
<p>Randomly split the data into 50% training and 50% validation, fit on the training set, and compute the MSE on the validation set.
Since I’ll be repeating this 10 times to reproduce the figure, make it a function:<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a></p>
<div class="sourceCode" id="cb333"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb333-1"><a href="resampling-methods.html#cb333-1" aria-hidden="true" tabindex="-1"></a>evaluate_auto_fit <span class="ot">&lt;-</span> <span class="cf">function</span>(seed) {</span>
<span id="cb333-2"><a href="resampling-methods.html#cb333-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set.seed</span>(seed)</span>
<span id="cb333-3"><a href="resampling-methods.html#cb333-3" aria-hidden="true" tabindex="-1"></a>  auto_split <span class="ot">&lt;-</span> <span class="fu">initial_split</span>(auto, <span class="at">prop =</span> <span class="fl">0.5</span>)</span>
<span id="cb333-4"><a href="resampling-methods.html#cb333-4" aria-hidden="true" tabindex="-1"></a>  auto_train <span class="ot">&lt;-</span> <span class="fu">training</span>(auto_split)</span>
<span id="cb333-5"><a href="resampling-methods.html#cb333-5" aria-hidden="true" tabindex="-1"></a>  auto_validation <span class="ot">&lt;-</span> <span class="fu">testing</span>(auto_split)</span>
<span id="cb333-6"><a href="resampling-methods.html#cb333-6" aria-hidden="true" tabindex="-1"></a>  auto_rec <span class="ot">&lt;-</span> <span class="fu">recipe</span>(mpg <span class="sc">~</span> horsepower, <span class="at">data =</span> auto_train)</span>
<span id="cb333-7"><a href="resampling-methods.html#cb333-7" aria-hidden="true" tabindex="-1"></a>  lm_workflow <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">%&gt;%</span> <span class="fu">add_model</span>(<span class="fu">linear_reg</span>())</span>
<span id="cb333-8"><a href="resampling-methods.html#cb333-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb333-9"><a href="resampling-methods.html#cb333-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tibble</span>(<span class="at">poly =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>) <span class="sc">%&gt;%</span></span>
<span id="cb333-10"><a href="resampling-methods.html#cb333-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(</span>
<span id="cb333-11"><a href="resampling-methods.html#cb333-11" aria-hidden="true" tabindex="-1"></a>      <span class="at">lm_rec =</span> <span class="fu">map</span>(</span>
<span id="cb333-12"><a href="resampling-methods.html#cb333-12" aria-hidden="true" tabindex="-1"></a>        poly, <span class="sc">~</span> auto_rec <span class="sc">%&gt;%</span> <span class="fu">step_poly</span>(horsepower, <span class="at">degree =</span> .x)</span>
<span id="cb333-13"><a href="resampling-methods.html#cb333-13" aria-hidden="true" tabindex="-1"></a>      ),</span>
<span id="cb333-14"><a href="resampling-methods.html#cb333-14" aria-hidden="true" tabindex="-1"></a>      <span class="at">lm_fit =</span> <span class="fu">map</span>(</span>
<span id="cb333-15"><a href="resampling-methods.html#cb333-15" aria-hidden="true" tabindex="-1"></a>        lm_rec, <span class="sc">~</span> lm_workflow <span class="sc">%&gt;%</span> <span class="fu">add_recipe</span>(.x) <span class="sc">%&gt;%</span> <span class="fu">fit</span>(auto_train)</span>
<span id="cb333-16"><a href="resampling-methods.html#cb333-16" aria-hidden="true" tabindex="-1"></a>      ),</span>
<span id="cb333-17"><a href="resampling-methods.html#cb333-17" aria-hidden="true" tabindex="-1"></a>      <span class="at">lm_rmse =</span> <span class="fu">map_dbl</span>(</span>
<span id="cb333-18"><a href="resampling-methods.html#cb333-18" aria-hidden="true" tabindex="-1"></a>        lm_fit,</span>
<span id="cb333-19"><a href="resampling-methods.html#cb333-19" aria-hidden="true" tabindex="-1"></a>        <span class="sc">~</span> <span class="fu">augment</span>(.x, <span class="at">new_data =</span> auto_validation) <span class="sc">%&gt;%</span></span>
<span id="cb333-20"><a href="resampling-methods.html#cb333-20" aria-hidden="true" tabindex="-1"></a>          <span class="fu">rmse</span>(<span class="at">truth =</span> mpg, <span class="at">estimate =</span> .pred) <span class="sc">%&gt;%</span></span>
<span id="cb333-21"><a href="resampling-methods.html#cb333-21" aria-hidden="true" tabindex="-1"></a>          <span class="fu">pull</span>(.estimate)</span>
<span id="cb333-22"><a href="resampling-methods.html#cb333-22" aria-hidden="true" tabindex="-1"></a>      )</span>
<span id="cb333-23"><a href="resampling-methods.html#cb333-23" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb333-24"><a href="resampling-methods.html#cb333-24" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb333-25"><a href="resampling-methods.html#cb333-25" aria-hidden="true" tabindex="-1"></a><span class="fu">evaluate_auto_fit</span>(<span class="at">seed =</span> <span class="dv">308</span>)</span></code></pre></div>
<pre><code>## # A tibble: 10 x 4
##     poly lm_rec   lm_fit     lm_rmse
##    &lt;int&gt; &lt;list&gt;   &lt;list&gt;       &lt;dbl&gt;
##  1     1 &lt;recipe&gt; &lt;workflow&gt;    4.63
##  2     2 &lt;recipe&gt; &lt;workflow&gt;    4.17
##  3     3 &lt;recipe&gt; &lt;workflow&gt;    4.16
##  4     4 &lt;recipe&gt; &lt;workflow&gt;    4.16
##  5     5 &lt;recipe&gt; &lt;workflow&gt;    4.16
##  6     6 &lt;recipe&gt; &lt;workflow&gt;    4.14
##  7     7 &lt;recipe&gt; &lt;workflow&gt;    4.13
##  8     8 &lt;recipe&gt; &lt;workflow&gt;    4.22
##  9     9 &lt;recipe&gt; &lt;workflow&gt;    4.25
## 10    10 &lt;recipe&gt; &lt;workflow&gt;    4.26</code></pre>
<p>Now reproduce Figure 5.2:</p>
<div class="sourceCode" id="cb335"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb335-1"><a href="resampling-methods.html#cb335-1" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> <span class="fu">map_dfr</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>, evaluate_auto_fit, <span class="at">.id =</span> <span class="st">&quot;rep&quot;</span>)</span>
<span id="cb335-2"><a href="resampling-methods.html#cb335-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb335-3"><a href="resampling-methods.html#cb335-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Use a 10 color palette from the MetBrewer package</span></span>
<span id="cb335-4"><a href="resampling-methods.html#cb335-4" aria-hidden="true" tabindex="-1"></a>pal <span class="ot">&lt;-</span> MetBrewer<span class="sc">::</span><span class="fu">met.brewer</span>(<span class="st">&quot;Veronese&quot;</span>, <span class="dv">10</span>, <span class="at">type =</span> <span class="st">&quot;continuous&quot;</span>)</span>
<span id="cb335-5"><a href="resampling-methods.html#cb335-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb335-6"><a href="resampling-methods.html#cb335-6" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> d <span class="sc">%&gt;%</span></span>
<span id="cb335-7"><a href="resampling-methods.html#cb335-7" aria-hidden="true" tabindex="-1"></a>  <span class="co">#filter(rep == 1) %&gt;%</span></span>
<span id="cb335-8"><a href="resampling-methods.html#cb335-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> poly, <span class="at">y =</span> lm_rmse<span class="sc">^</span><span class="dv">2</span>, <span class="at">fill =</span> rep)) <span class="sc">+</span></span>
<span id="cb335-9"><a href="resampling-methods.html#cb335-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">color =</span> rep), <span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb335-10"><a href="resampling-methods.html#cb335-10" aria-hidden="true" tabindex="-1"></a>  <span class="co">#geom_point(aes(fill = rep), shape = 21,  color = &quot;white&quot;, size = 4) +</span></span>
<span id="cb335-11"><a href="resampling-methods.html#cb335-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">expand_limits</span>(<span class="at">y =</span> <span class="fu">c</span>(<span class="dv">15</span>, <span class="dv">30</span>)) <span class="sc">+</span></span>
<span id="cb335-12"><a href="resampling-methods.html#cb335-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="at">breaks =</span> <span class="fu">seq</span>(<span class="dv">2</span>, <span class="dv">10</span>, <span class="dv">2</span>)) <span class="sc">+</span></span>
<span id="cb335-13"><a href="resampling-methods.html#cb335-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> pal) <span class="sc">+</span></span>
<span id="cb335-14"><a href="resampling-methods.html#cb335-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_manual</span>(<span class="at">values =</span> pal) <span class="sc">+</span></span>
<span id="cb335-15"><a href="resampling-methods.html#cb335-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Degree of polynomial&quot;</span>) <span class="sc">+</span></span>
<span id="cb335-16"><a href="resampling-methods.html#cb335-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">&quot;none&quot;</span>)</span>
<span id="cb335-17"><a href="resampling-methods.html#cb335-17" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> p2 <span class="sc">%+%</span> <span class="fu">filter</span>(d, rep <span class="sc">==</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb335-18"><a href="resampling-methods.html#cb335-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">fill =</span> rep), <span class="at">shape =</span> <span class="dv">21</span>,  <span class="at">color =</span> <span class="st">&quot;white&quot;</span>, <span class="at">size =</span> <span class="dv">4</span>) <span class="sc">+</span></span>
<span id="cb335-19"><a href="resampling-methods.html#cb335-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">y =</span> <span class="st">&quot;MSE&quot;</span>)</span>
<span id="cb335-20"><a href="resampling-methods.html#cb335-20" aria-hidden="true" tabindex="-1"></a>p1 <span class="sc">|</span> p2</span></code></pre></div>
<p><img src="_main_files/figure-html/figure%205.2-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>As is clear from the right-hand panel, this approach is highly variable depending on the testing/validation set split.
Another downside is that, because the training set used to fit the data has fewer observations, it tends to overestimate the test error rate on the entire data set.</p>
</div>
<div id="leave-one-out-cross-validation" class="section level3" number="5.1.2">
<h3><span class="header-section-number">5.1.2</span> Leave-One-Out Cross Validation</h3>
<p><em>Leave-one-out cross validation</em> (LOOCV) attempts to address the shortcomings of the validation set approach.
It still involves splitting the <span class="math inline">\(n\)</span> observations into two parts, but it repeats it <span class="math inline">\(n\)</span> times, with a single observation <span class="math inline">\((x_i, y_i)\)</span> as the hold-out “set” and the remaining <span class="math inline">\(n-1\)</span> observations as the training set.
The MSE for each iteration is simply <span class="math inline">\(\text{MSE}_i = (y_i - \hat{y}_i)^2\)</span>.
Then the LOOCV estimate of the MSE is the average over all observations:</p>
<p><span class="math display">\[
\text{CV}_{(n)} = \frac{1}{n} \sum_{i=1}^n \text{MSE}_i.
\]</span></p>
<p>The LOOCV approach has a few advantages over the validation set approach:</p>
<blockquote>
<ul>
<li>First, it has far less bias. In LOOCV, we repeatedly fit the statistical learning method using training sets that contain <span class="math inline">\(n − 1\)</span> observations, almost as many as are in the entire data set. This is in contrast to the validation set approach, in which the training set is typically around half the size of the original data set. Consequently, the LOOCV approach tends not to overestimate the test error rate as much as the validation set approach does.</li>
<li>Second, in contrast to the validation approach which will yield different results when applied repeatedly due to randomness in the training/validation set splits, performing LOOCV multiple times will always yield the same results: there is no randomness in the training/validation set splits.</li>
</ul>
</blockquote>
</div>
</div>
<div id="the-bootstrap" class="section level2" number="5.2">
<h2><span class="header-section-number">5.2</span> The Bootstrap</h2>
</div>
<div id="lab-cross-validation-and-the-bootstrap" class="section level2" number="5.3">
<h2><span class="header-section-number">5.3</span> Lab: Cross-Validation and the Bootstrap</h2>
</div>
<div id="exercises-2" class="section level2" number="5.4">
<h2><span class="header-section-number">5.4</span> Exercises</h2>

<div id="refs" class="references csl-bib-body hanging-indent">
<div class="csl-entry">
Hastie, Trevor, Robert Tibshirani, and Jerome Friedman. 2009. <em><span class="nocase">The Elements of Statistical Learning</span></em>. Springer Series in Statistics. New York, NY: Springer New York. <a href="https://doi.org/10.1007/978-0-387-84858-7">https://doi.org/10.1007/978-0-387-84858-7</a>.
</div>
<div class="csl-entry">
Smith, Gary. 2018. <span>“<span class="nocase">Step away from stepwise</span>.”</span> <em>Journal of Big Data</em> 5 (1): 32. <a href="https://doi.org/10.1186/s40537-018-0143-6">https://doi.org/10.1186/s40537-018-0143-6</a>.
</div>
</div>
</div>
</div>






<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>In the text, they compute the MSE but here I am computing RMSE then squaring it. This is because <code>yardstick</code> has a <code>rmse()</code> function but not an <code>mse()</code> function. If I wanted to, I could define a custom metric <a href="https://yardstick.tidymodels.org/articles/custom-metrics.html">like so</a>.<a href="resampling-methods.html#fnref1" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="classification.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
