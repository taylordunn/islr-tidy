[["index.html", "An Introduction to Statistical Learning with the tidyverse and tidymodels Who, what, and why?", " An Introduction to Statistical Learning with the tidyverse and tidymodels Taylor Dunn 2022-04-09 Who, what, and why? I am a data scientist and statistician who is (mostly) self-taught from textbooks and generous people sharing their work online. Inspired by projects like Solomon Kurzs recoding of Statistical Rethinking, I decided to publicly document my notes and code as I work through An Introduction to Statistical Learning, 2nd edition by Gareth James, Daniela Witten, Trevor Hastie, and Robert Tibshirani. I prefer to work with the tidyverse collection of R packages, and so will be using those to wrangle and visualize the data. Along the way, Ill be teaching myself the tidymodels framework for machine learning. In general, my plan for each chapter/concept is to start with the original modeling package, then move towards the tidymodels approach in the labs and exercises. For example, Ill first perform logistic regression with glm(), then use parsnip::logistic_reg() by the end of the chapter. I think this will help me better appreciate the unified interface provided with tidymodels, and maybe help me better understand what is going on under the hood. I wont be doing every exercise or section. My main goal for this project is to improve my statistical programming, so I will focus on the applied exercises rather than the conceptual. As of 2022-04-09, Ive completed Chapters 1 through 6. "],["introduction.html", "1 Introduction An Overview of Statistical Learning A Brief History of Statistical Learning This Book", " 1 Introduction An Overview of Statistical Learning Broadly speaking, supervised statistical learning involves building a statistical model for predicting, or estimating, an output based on one or more inputs. With unsupervised statistical learning, there are inputs but no supervising output; nevertheless we can learn relationships and structure from such data. Wage Data Load the Wage data set via the ISLR2 package: library(ISLR2) wage &lt;- ISLR2::Wage head(wage) ## year age maritl race education region ## 231655 2006 18 1. Never Married 1. White 1. &lt; HS Grad 2. Middle Atlantic ## 86582 2004 24 1. Never Married 1. White 4. College Grad 2. Middle Atlantic ## 161300 2003 45 2. Married 1. White 3. Some College 2. Middle Atlantic ## 155159 2003 43 2. Married 3. Asian 4. College Grad 2. Middle Atlantic ## 11443 2005 50 4. Divorced 1. White 2. HS Grad 2. Middle Atlantic ## 376662 2008 54 2. Married 1. White 4. College Grad 2. Middle Atlantic ## jobclass health health_ins logwage wage ## 231655 1. Industrial 1. &lt;=Good 2. No 4.318063 75.04315 ## 86582 2. Information 2. &gt;=Very Good 2. No 4.255273 70.47602 ## 161300 1. Industrial 1. &lt;=Good 1. Yes 4.875061 130.98218 ## 155159 2. Information 2. &gt;=Very Good 1. Yes 5.041393 154.68529 ## 11443 2. Information 1. &lt;=Good 1. Yes 4.318063 75.04315 ## 376662 2. Information 2. &gt;=Very Good 1. Yes 4.845098 127.11574 Load the tidyverse, and set my ggplot2 theme: library(tidyverse) library(dunnr) # My personal R package library(patchwork) # For composing plots extrafont::loadfonts(device = &quot;win&quot;, quiet = TRUE) theme_set(theme_td()) set_geom_fonts() set_palette() Now attempt to re-create Figure 1.1: p1 &lt;- wage %&gt;% ggplot(aes(x = age, y = wage)) + geom_point(color = &quot;lightgrey&quot;) + geom_smooth(color = &quot;blue&quot;) p2 &lt;- wage %&gt;% ggplot(aes(x = year, y = wage)) + geom_point(color = &quot;lightgrey&quot;) + geom_smooth(method = &quot;lm&quot;, color = &quot;blue&quot;) p3 &lt;- wage %&gt;% # Need to re-label the factor levels mutate(education = fct_relabel(education, ~str_extract(., &quot;\\\\d&quot;))) %&gt;% ggplot(aes(x = education, y = wage)) + geom_boxplot(aes(fill = education)) + theme(legend.position = &quot;none&quot;) p1 + p2 + p3 A Brief History of Statistical Learning This Book The Elements of Statistical Learning (ESL) by Hastie, Tibshirani, and Friedman was first published in 2001. Since that time, it has become an important reference on the fundamentals of statistical machine learning. Its success derives from its comprehensive and detailed treatment of many important topics in statistical learning, as well as the fact that (relative to many upper-level statistics textbooks) it is accessible to a wide audience. The purpose of An Introduction to Statistical Learning (ISL) is to facilitate the transition of statistical learning from an academic to a mainstream field. ISL is not intended to replace ESL, which is a far more comprehensive text both in terms of the number of approaches considered and the depth to which they are explored. I may also pull from ESL (Hastie, Tibshirani, and Friedman 2009) at times for more detailed treatments of complex topics. ISL is based on the following four premises 1. Many statistical learning methods are relevant and useful in a wide range of academic and non-academic disciplines, beyond just the statistical sciences. 2. Statistical learning should not be viewed as a series of black boxes. 3. While it is important to know what job is performed by each cog, it is not necessary to have the skills to construct the machine inside the box! 4. We presume that the reader is interested in applying statistical learning methods to real-world problems. References "],["statistical-learning.html", "2 Statistical Learning 2.1 What Is Statistical Learning? 2.2 Assessing Model Accuracy 2.3 Lab: Introduction to R", " 2 Statistical Learning 2.1 What Is Statistical Learning? For a quantitative response \\(Y\\) and \\(p\\) different predictors \\(X_1, X_2, \\dots, X_p\\), we assume there is some relationship between \\(Y\\) and the predictors \\(X\\). This can be written in the very general form: \\[ Y = f(X) + \\epsilon \\] where \\(f\\) is some fixed but unkown function of \\(X_1, \\dots, X_p\\), and \\(\\epsilon\\) is a random error term, which is independent of \\(X\\) and has mean zero. In essence, statistical learning refers to a set of approaches for estimating f. In this chapter we outline some of the key theoretical concepts that arise in estimating f, as well as tools for evaluating the estimates obtained 2.1.1 Why Estimate \\(f\\)? For prediction and inference. Prediction In cases where inputs \\(X\\) are available, but output \\(Y\\) is not easily obtained, we can predict \\(Y\\) using \\[ \\hat{Y} = \\hat{f}(X) \\] where \\(\\hat{f}\\) represents our estimate for \\(f\\), and \\(\\hat{Y}\\) represents our prediction for \\(Y\\). We dont necessarily care about the form of \\(\\hat{f}\\)  it can be treated as a block box as long as it gives good predictions. Inference When we are interested in understanding the association between \\(Y\\) and \\(X\\), we wish to estimate \\(\\hat{f}\\) and know its exact form (i.e. we dont treat it as a block box). Depending on whether our ultimate goal is prediction, inference, or a combination of the two, different methods for estimating f may be appropriate. For example, linear models allow for relatively simple and inter- linear model pretable inference, but may not yield as accurate predictions as some other approaches. In contrast, some of the highly non-linear approaches that we discuss in the later chapters of this book can potentially provide quite accurate predictions for Y , but this comes at the expense of a less interpretable model for which inference is more challenging. 2.1.2 How Do We Estimate f? Our goal is to apply a statistical learning method to the training data in order to estimate the unknown function \\(f\\). In other words, we want to find a function \\(\\hat{f}\\) such that \\(Y \\approx \\hat{f}(X)\\) for any observation \\((X, Y)\\). Broadly speaking, most statistical learning methods for this task can be characterized as either parametric or non-parametric. We now briefly discuss these two types of approaches. Parametric Methods The parametric method involves estimating a set of parameters. It is a two-step model-based approach: Make an assumption about the function form or shape of \\(f\\). Fit or train the model. A simple assumption is that \\(f\\) is linear in \\(X\\): \\[ f(X) = \\beta_0 + \\beta_1 X_1 + \\dots + \\beta_p X_p \\] In the case of this linear model, we need to estimate the \\(\\beta\\) parameters such that \\(Y \\approx \\beta_0 + \\dots + \\beta_p X_p\\). The most common approach to fitting a model like this is (ordinary) least squares. Non-Parametric Methods Non-parametric methods do not make explicit assumptions about the functional form of \\(f\\). Instead they seek an estimate of \\(f\\) that gets as close to the data points as possible without being too rough or wiggly. Such approaches can have a major advantage over parametric approaches: by avoiding the assumption of a particular functional form for \\(f\\), they have the potential to accurately fit a wider range of possible shapes for \\(f\\). 2.1.3 The Trade-Off Between Prediction Accuracy and Model Interpretability One might reasonably ask the following question: why would we ever choose to use a more restrictive method instead of a very flexible approach? There are several reasons that we might prefer a more restrictive model. If we are mainly interested in inference, then restrictive models are much more interpretable. We have established that when inference is the goal, there are clear advantages to using simple and relatively inflexible statistical learning methods. In some settings, however, we are only interested in prediction, and the interpretability of the predictive model is simply not of interest. For instance, if we seek to develop an algorithm to predict the price of a stock, our sole requirement for the algorithm is that it predict accurately interpretability is not a concern. In this setting, we might expect that it will be best to use the most flexible model available. Surprisingly, this is not always the case! We will often obtain more accurate predictions using a less flexible method. 2.1.4 Supervised Versus Unsupervised Learning Supervised for each observation, there is an associated response we wish to fit a model that relates the response to predictors, with the aim of accurately predicting the response, or for better understanding the relationships the focus of the book Unsupervised no associated response we can seek to understand relationships between variables or between observations one example: cluster analysis 2.2 Assessing Model Accuracy There is no free lunch in statistics: no one method dominates all others over all possible data sets. On a particular data set, one specific method may work best, but some other method may work better on a similar but different data set. Hence it is an important task to decide for any given set of data which method produces the best results. Selecting the best approach can be one of the most challenging parts of performing statistical learning in practice. 2.2.1 Measuring the Quality of Fit In the regression setting, the most commonly-used measure is the mean squared error (MSE): \\[ \\text{MSE} = \\frac{1}{n} \\sum_{i=1}^n (y_i - \\hat{f}(x_i))^2 \\] We compute MSE with both training and testing data sets, but care much more about the latter. The goal is to minimize the testing MSE, but what if we only have training data? It is not always the case that we want to take the model that minimizes the training MSE due to overfitting. In practice, one can usually compute the training MSE with relative ease, but estimating test MSE is considerably more difficult because usually no test data are available. As the previous three examples illustrate, the flexibility level corresponding to the model with the minimal test MSE can vary considerably among data sets. 2.2.2 The Bias-Variance Trade-Off The expected test MSE for a given value of \\(x_0\\) can be decomposed into the sum of three quantities: \\[ E(y - \\hat{f}(x_0))^2 = \\text{Var}(\\hat{f}(x_0)) + [\\text{Bias}(\\hat{f}(x_0))]^2 + \\text{Var}(\\epsilon) \\] This tells us that, to minimize MSE, we need to select a statistical learning method that achieves low variance and low bias (because the variance of the error term is irreducible). The variance here refers to the amount by which \\(\\hat{f}\\) would change if estimated using different training data. This is minimized by more rigid models; flexible models tend to have high variance. The bias is, conceptually, the error introduced by approximating a complex real-life scenario with a much simpler model. A linear regression model tends to introduce much bias due to the very simplified assumption of linear relationships. Flexible methods tend to result in less bias. 2.2.3 The Classification Setting When estimating \\(f\\) with qualitative \\(y\\), the most common approach for quantifying accuracy is the training error rate. This is the proportion of mistakes made by \\(\\hat{f}\\) to the training data: \\[ \\frac{1}{n} \\sum_{i=1}^n I(y_i \\neq \\hat{y}_i) \\] As with the regression setting, we seek a classifier for which the test error rate is smallest. The Bayes Classifier It is possible to show (though the proof is outside of the scope of this book) that the test error rate given in (2.9) is minimized, on average, by a very simple classifier that assigns each observation to the most likely class, given its predictor values. In other words, we should simply assign a test observation with predictor vector \\(x_0\\) to the class \\(j\\) for which \\[ \\text{Pr}(Y = j | X = x_0) \\] is largest This very simple classifier is called the Bayes classifer. The Bayes error rate is analogous to the irreducible error, in that classes may overlap and cannot be correctly classified. \\(K\\)-Nearest Neighbors The Bayes classifier is the gold standard, but unattainable for real data because we do not know the conditional distribution \\(\\text{Pr}(Y|X)\\). One method to which to compared is the \\(K\\)-nearest neighbors (KNN) classifier. For a test observation \\(x_0\\), KNN involves identifying the \\(K\\) nearest points in the training data that are closest to \\(x_0\\), represented by \\(\\mathcal{N}_0\\). It then estimates the conditional probability of the classes using the fraction of the points: \\[ \\text{Pr}(Y = j|X = x_0) = \\frac{1}{K} \\sum_{i \\in \\mathcal{N}_0} I (y_i = j). \\] KNN classifies\\(x_0\\) into the class \\(k\\) with the highest probability. The choices of \\(k\\) has a drastic effect on the performance of the classifer. \\(K = 1\\) is the most flexible, i.e. low bias but high variance. A large value of \\(K\\) (which is relative to the density of points) is the least flexible, i.e. high bias but low variance. 2.3 Lab: Introduction to R Ill be skipping this, as it is just a basic introduction of base R. "],["linear-regression.html", "3 Linear Regression 3.1 Simple Linear Regression 3.2 Multiple Linear Regression 3.3 Other Considerations in the Regression Model 3.4 The Marketing Plan 3.5 Comparison of Linear Regression with \\(K\\)-Nearest Neighbors 3.6 Lab: Linear Regression 3.7 Exercises Reproducibility", " 3 Linear Regression 3.1 Simple Linear Regression A straightforward approach of predicting a quantitative \\(Y\\) from a single predictor \\(X\\), assuming an approximately linear relationship: \\[ Y \\approx \\beta_0 + \\beta_1 X \\] 3.1.1 Estimating the Coefficients Our goal is to obtain estimates of the coefficients \\(\\hat{\\beta}_0\\) and \\(\\hat{\\beta}_1\\) such that the linear model fits the data well. There are a number of ways of evaluating fit to data, but by far the most common approach is the least squares criterion. We define the residual sum of squares (RSS) as \\[ \\text{RSS} = e_1^2 + e_2^2 + \\dots + e_n^2 \\] where \\(e_i = y_i - \\hat{y}\\) is the \\(i\\)th (out of \\(n\\)) residual. The least squares approach chooses \\(\\hat{\\beta}_0\\) and \\(\\hat{\\beta}_1\\) to minimize the RSS. Using some calculus, one can show that \\[ \\begin{align} \\hat{\\beta}_1 &amp;= \\frac{\\sum (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum (x_i - \\bar{x})^2}\\\\ \\hat{\\beta}_0 &amp;= \\bar{y} - \\hat{\\beta}_1 \\bar{x} \\end{align} \\] To re-create Figure 3.1, import the Advertising data set: library(tidyverse) library(here) # Load my R package and set the ggplot theme library(dunnr) extrafont::loadfonts(device = &quot;win&quot;, quiet = TRUE) theme_set(theme_td()) set_geom_fonts() set_palette() advertising &lt;- read_csv(here(&quot;data&quot;, &quot;Advertising.csv&quot;)) glimpse(advertising) ## Rows: 200 ## Columns: 5 ## $ ...1 &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 1~ ## $ TV &lt;dbl&gt; 230.1, 44.5, 17.2, 151.5, 180.8, 8.7, 57.5, 120.2, 8.6, 199.~ ## $ radio &lt;dbl&gt; 37.8, 39.3, 45.9, 41.3, 10.8, 48.9, 32.8, 19.6, 2.1, 2.6, 5.~ ## $ newspaper &lt;dbl&gt; 69.2, 45.1, 69.3, 58.5, 58.4, 75.0, 23.5, 11.6, 1.0, 21.2, 2~ ## $ sales &lt;dbl&gt; 22.1, 10.4, 9.3, 18.5, 12.9, 7.2, 11.8, 13.2, 4.8, 10.6, 8.6~ Fit the simple linear model and draw the residuals to the line of best fit: lm_sales_tv &lt;- lm(sales ~ TV, data = advertising) advertising %&gt;% bind_cols( pred_sales = predict(lm_sales_tv, data = advertising) ) %&gt;% ggplot(aes(x = TV)) + geom_linerange(aes(ymin = sales, ymax = pred_sales)) + geom_point(aes(y = sales), color = &quot;red&quot;) + geom_abline(intercept = coef(lm_sales_tv)[1], slope = coef(lm_sales_tv)[2], color = &quot;blue&quot;, size = 1) We recover the same regression coefficients: \\(\\beta_0\\) = 7.03 and \\(\\beta_1\\) = 0.048. 3.1.2 Assessing the Accuracy of the Coefficient Estimates The analogy between linear regression and estimation of the mean of a random variable is an apt one based on the concept of bias. If we use the bias sample mean \\(\\hat{\\mu}\\) to estimate \\(\\mu\\), this estimate is unbiased, in the sense that unbiased on average, we expect \\(\\hat{\\mu}\\) to equal \\(\\mu\\). What exactly does this mean? It means that on the basis of one particular set of observations \\(y_1,\\dots, y_n\\), \\(\\hat{\\mu}\\) might overestimate \\(\\mu\\), and on the basis of another set of observations, \\(\\hat{\\mu}\\) might underestimate \\(\\mu\\). But if we could average a huge number of estimates of \\(\\mu\\) obtained from a huge number of sets of observations, then this average would exactly equal \\(\\mu\\). Hence, an unbiased estimator does not systematically over- or under-estimate the true parameter. A natural question is as follows: how accurate is the sample mean \\(\\hat{\\mu}\\) as an estimate of \\(\\mu\\)? We have established that the average of \\(\\hat{\\mu}\\)s over many data sets will be very close to \\(\\mu\\), but that a single estimate \\(\\hat{\\mu}\\) may be a substantial underestimate or overestimate of \\(\\mu\\). How far off will that single estimate of \\(\\hat{\\mu}\\) be? In general, we answer this question by computing the standard error of \\(\\hat{\\mu}\\), written as SE(\\(\\hat{\\mu}\\)). \\[ \\text{Var}(\\hat{\\mu}) = \\text{SE}(\\hat{\\mu})^2 = \\frac{\\sigma^2}{n} \\] where \\(\\sigma\\) is the standard deviation of each of the realizations \\(y_i\\) of \\(Y\\). Roughly speaking, the standard error tells us the average amount that this estimate \\(\\hat{\\mu}\\) differs from the actual value of \\(\\mu\\). To compute the standard errors associated with \\(\\hat{\\beta}_0\\) and \\(\\hat{\\beta}_1\\), we use the following formulas: \\[ \\begin{align} \\text{SE}(\\hat{\\beta}_0)^2 &amp;= \\sigma^2 \\left[ \\frac{1}{n} + \\frac{\\bar{x}^2}{\\sum (x_i - \\bar{x})^2}\\right] \\\\ \\text{SE}(\\hat{\\beta}_1)^2 &amp;= \\frac{\\sigma^2}{\\sum (x_i - \\bar{x})^2} \\end{align} \\] where \\(\\sigma^2 = \\text{Var}(\\epsilon)\\). In general, \\(\\sigma^2\\) is not known, but can be estimated from the data. This estimate of \\(\\sigma\\) is known as the residual standard error, and is given by the formula \\(\\text{RSE} = \\sqrt{\\text{RSS}/(n-2)}\\). For linear regression, we get approximate 95% confidence intervals for the coefficients as: \\[ \\begin{align} \\hat{\\beta}_1 \\pm 2 \\text{SE}(\\hat{\\beta}_1) \\\\ \\hat{\\beta}_0 \\pm 2 \\text{SE}(\\hat{\\beta}_0). \\end{align} \\] These approximations assume that the errors are Gaussian, and the factor of 2 will vary depending on the number of observations \\(n\\). The true value of this factor is the 2.5% and 97.5% quantile of a \\(t\\)-distribution with \\(n-2\\) degrees of freedom. We can show this with the stats::qt function: tibble( n = c(10, 50, 100, 500, 1000) ) %&gt;% mutate( qt_low = qt(p = 0.025, df = n - 2), qt_high = qt(p = 0.975, df = n - 2) ) %&gt;% gt::gt() html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #nvbvumocse .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #nvbvumocse .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #nvbvumocse .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #nvbvumocse .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #nvbvumocse .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #nvbvumocse .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #nvbvumocse .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #nvbvumocse .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #nvbvumocse .gt_column_spanner_outer:first-child { padding-left: 0; } #nvbvumocse .gt_column_spanner_outer:last-child { padding-right: 0; } #nvbvumocse .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #nvbvumocse .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #nvbvumocse .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #nvbvumocse .gt_from_md > :first-child { margin-top: 0; } #nvbvumocse .gt_from_md > :last-child { margin-bottom: 0; } #nvbvumocse .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #nvbvumocse .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #nvbvumocse .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #nvbvumocse .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #nvbvumocse .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #nvbvumocse .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #nvbvumocse .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #nvbvumocse .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #nvbvumocse .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #nvbvumocse .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #nvbvumocse .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #nvbvumocse .gt_sourcenote { font-size: 90%; padding: 4px; } #nvbvumocse .gt_left { text-align: left; } #nvbvumocse .gt_center { text-align: center; } #nvbvumocse .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #nvbvumocse .gt_font_normal { font-weight: normal; } #nvbvumocse .gt_font_bold { font-weight: bold; } #nvbvumocse .gt_font_italic { font-style: italic; } #nvbvumocse .gt_super { font-size: 65%; } #nvbvumocse .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } n qt_low qt_high 10 -2.306004 2.306004 50 -2.010635 2.010635 100 -1.984467 1.984467 500 -1.964739 1.964739 1000 -1.962344 1.962344 The quickest way to get the 95% confidence intervals for the coefficients is with stats::confint(): confint(lm_sales_tv) ## 2.5 % 97.5 % ## (Intercept) 6.12971927 7.93546783 ## TV 0.04223072 0.05284256 Computing them manually requires the standard errors of the coefficients. For this, I prefer broom::tidy: library(broom) tidy(lm_sales_tv) ## # A tibble: 2 x 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 7.03 0.458 15.4 1.41e-35 ## 2 TV 0.0475 0.00269 17.7 1.47e-42 Here is how you would calculate the SEs manually: n_obs &lt;- nrow(advertising) bar_x &lt;- mean(advertising$TV) # Residual sum of squares lm_sales_tv_rss &lt;- sum(resid(lm_sales_tv)^2) # Residual standard error (our estimate of sigma, the variance of errors) lm_sales_tv_rse &lt;- sqrt(lm_sales_tv_rss / (n_obs - 2)) # Intercept SE beta0_se &lt;- sqrt( lm_sales_tv_rse^2 * ((1 / n_obs) + bar_x^2 / (sum((advertising$TV - bar_x)^2))) ) # Slope SE beta1_se &lt;- sqrt( lm_sales_tv_rse^2 / (sum((advertising$TV - bar_x)^2)) ) c(beta0_se, beta1_se) ## [1] 0.457842940 0.002690607 Then get the 95% confidence intervals: tidy(lm_sales_tv) %&gt;% transmute( term, estimate, mult_fact = 2.0, ci_lower = estimate - mult_fact * std.error, ci_upper = estimate + mult_fact * std.error ) ## # A tibble: 2 x 5 ## term estimate mult_fact ci_lower ci_upper ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 7.03 2 6.12 7.95 ## 2 TV 0.0475 2 0.0422 0.0529 Note that the intervals dont exactly match those in the text. The true multiplication factor of the SEs for this data with 200 observations is 1.9720175: tidy(lm_sales_tv) %&gt;% transmute( term, estimate, mult_fact = qt(0.975, n_obs-2), ci_lower = estimate - mult_fact * std.error, ci_upper = estimate + mult_fact * std.error ) ## # A tibble: 2 x 5 ## term estimate mult_fact ci_lower ci_upper ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 7.03 1.97 6.13 7.94 ## 2 TV 0.0475 1.97 0.0422 0.0528 To test the null hypothesis that there is no relationship between \\(X\\) and \\(Y\\), we copmute a \\(t\\)-statistic as: \\[ t = \\frac{\\hat{\\beta}_1 - 0}{\\text{SE}(\\hat{\\beta}_1)} \\] where we have written out the \\(- 0\\) to explicitly indicate the alternative hypothesis that \\(\\beta_1\\) is different from 0. If the null is true, then we expect that the above formula will have a \\(t\\)-distribution with \\(n-2\\) degrees of freedom. Then taking the \\(t\\) value returned by our model, we compute the probability of observing a value equal to or greater than that value assuming \\(\\beta_1 = 0\\). This probability is the \\(p\\)-value. The \\(t\\)-statistics are returned by broom::tidy as the statistic variable. It also returns the \\(p\\)-values, which we can manually compute as well with stats::pt: tidy(lm_sales_tv) %&gt;% mutate( p.value_manual = 2 * pt(-statistic, df = n_obs - 2) ) ## # A tibble: 2 x 6 ## term estimate std.error statistic p.value p.value_manual ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 7.03 0.458 15.4 1.41e-35 1.41e-35 ## 2 TV 0.0475 0.00269 17.7 1.47e-42 1.47e-42 3.1.3 Assessing the Accuracy of the Model The quality of a linear regression fit is typically assessed using two related quantities: the residual standard error (RSE) and the \\(R^2\\) statistic. The broom::glance function gives summary statistics of a model: glance(lm_sales_tv) ## # A tibble: 1 x 12 ## r.squared adj.r.squared sigma statistic p.value df logLik AIC BIC ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.612 0.610 3.26 312. 1.47e-42 1 -519. 1044. 1054. ## # ... with 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt; Residual Standard Error The residual standard error (RSE) is sigma, variance explained \\(R^2\\) is r.squared, and the \\(F\\)-statistic is statistic. With this, we can re-create Table 3.2: library(gt) glance(lm_sales_tv) %&gt;% transmute(`Residual standard error` = round(sigma, 2), `R2` = round(r.squared, 3), `F-statistic` = round(statistic, 1)) %&gt;% mutate(across(everything(), as.character)) %&gt;% pivot_longer(everything(), names_to = &quot;Quantity&quot;, values_to = &quot;Value&quot;) %&gt;% gt() html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #vhutgxxoyg .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #vhutgxxoyg .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #vhutgxxoyg .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #vhutgxxoyg .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #vhutgxxoyg .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #vhutgxxoyg .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #vhutgxxoyg .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #vhutgxxoyg .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #vhutgxxoyg .gt_column_spanner_outer:first-child { padding-left: 0; } #vhutgxxoyg .gt_column_spanner_outer:last-child { padding-right: 0; } #vhutgxxoyg .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #vhutgxxoyg .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #vhutgxxoyg .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #vhutgxxoyg .gt_from_md > :first-child { margin-top: 0; } #vhutgxxoyg .gt_from_md > :last-child { margin-bottom: 0; } #vhutgxxoyg .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #vhutgxxoyg .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #vhutgxxoyg .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #vhutgxxoyg .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #vhutgxxoyg .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #vhutgxxoyg .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #vhutgxxoyg .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #vhutgxxoyg .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #vhutgxxoyg .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #vhutgxxoyg .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #vhutgxxoyg .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #vhutgxxoyg .gt_sourcenote { font-size: 90%; padding: 4px; } #vhutgxxoyg .gt_left { text-align: left; } #vhutgxxoyg .gt_center { text-align: center; } #vhutgxxoyg .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #vhutgxxoyg .gt_font_normal { font-weight: normal; } #vhutgxxoyg .gt_font_bold { font-weight: bold; } #vhutgxxoyg .gt_font_italic { font-style: italic; } #vhutgxxoyg .gt_super { font-size: 65%; } #vhutgxxoyg .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } Quantity Value Residual standard error 3.26 R2 0.612 F-statistic 312.1 \\(R^2\\) Statistic The RSE provides an absolute measure of lack of fit of the model (3.5) to the data. But since it is measured in the units of \\(Y\\), it is not always clear what constitutes a good RSE. The \\(R^2\\) statistic provides an alternative measure of fit. It takes the form of a proportionthe proportion of variance explained - and so it always takes on a value between 0 and 1, and is independent of the scale of \\(Y\\). \\[ R^2 = \\frac{\\text{TSS} - \\text{RSS}}{\\text{TSS}} = 1 - \\frac{\\text{RSS}}{\\text{TSS}} \\] where \\(\\text{TSS} = \\sum (y_i - \\bar{y})^2\\) is the total sum of squares. The easiest way to think of it in linear regression terms, is as a measure of improvement by the sloped line over a horizontal line (the mean of \\(Y\\)) through the data. The correlation between variables: \\[ \\text{Cor}(X, Y) = \\frac{\\sum (x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum (x_i - \\bar{x})^2} \\sqrt{\\sum (y_i - \\bar{y})^2}} \\] is exactly the same in the linear regression setting, \\(R^2 = r^2\\). In multivariable regression (the next section), this is (usually) not the case, in which case we use \\(R^2\\). 3.2 Multiple Linear Regression Simple linear regression is a useful approach for predicting a response on the basis of a single predictor variable. However, in practice we often have more than one predictor. One option is to run three separate simple linear regressions,  However, the approach of fitting a separate simple linear regression model for each predictor is not entirely satisfactory Instead of fitting a separate simple linear regression model for each predictor, a better approach is to extend the simple linear regression model (3.5) so that it can directly accommodate multiple predictors. The model with \\(p\\) predictors takes the form: \\[ Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\dots + \\beta_p X_p + \\epsilon. \\] We interpret the slope \\(\\beta_j\\) as the average effect on \\(Y\\) by a one unit increase in \\(X_j\\) while holding all other predictors fixed. 3.2.1 Estimating the Regression Coefficients The parameters are estimated using the same least squares approach as simple linear regression: choose \\(\\beta_0 \\dots \\beta_p\\) to minimize RSS. However, the formula to estimate these parameters have more complicated forms that are harder to interpret than in simple regression. Re-create Table 3.4 by regressing sales on TV, radio, and newspaper: lm_sales_mult &lt;- lm(sales ~ TV + radio + newspaper, data = advertising) # Since I will be reproducing this table often, write a function tidy_custom &lt;- function(mod, coef_round = 3, se_round = 4, t_round = 2) { tidy(mod) %&gt;% transmute( term, coefficient = round(estimate, coef_round), std.error = round(std.error, se_round), `t-statistic` = round(statistic, t_round), `p-value` = scales::pvalue(p.value) ) } tidy_custom(lm_sales_mult) %&gt;% gt() html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #emrhseyaxo .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #emrhseyaxo .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #emrhseyaxo .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #emrhseyaxo .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #emrhseyaxo .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #emrhseyaxo .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #emrhseyaxo .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #emrhseyaxo .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #emrhseyaxo .gt_column_spanner_outer:first-child { padding-left: 0; } #emrhseyaxo .gt_column_spanner_outer:last-child { padding-right: 0; } #emrhseyaxo .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #emrhseyaxo .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #emrhseyaxo .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #emrhseyaxo .gt_from_md > :first-child { margin-top: 0; } #emrhseyaxo .gt_from_md > :last-child { margin-bottom: 0; } #emrhseyaxo .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #emrhseyaxo .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #emrhseyaxo .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #emrhseyaxo .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #emrhseyaxo .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #emrhseyaxo .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #emrhseyaxo .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #emrhseyaxo .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #emrhseyaxo .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #emrhseyaxo .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #emrhseyaxo .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #emrhseyaxo .gt_sourcenote { font-size: 90%; padding: 4px; } #emrhseyaxo .gt_left { text-align: left; } #emrhseyaxo .gt_center { text-align: center; } #emrhseyaxo .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #emrhseyaxo .gt_font_normal { font-weight: normal; } #emrhseyaxo .gt_font_bold { font-weight: bold; } #emrhseyaxo .gt_font_italic { font-style: italic; } #emrhseyaxo .gt_super { font-size: 65%; } #emrhseyaxo .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } term coefficient std.error t-statistic p-value (Intercept) 2.939 0.3119 9.42 &lt;0.001 TV 0.046 0.0014 32.81 &lt;0.001 radio 0.189 0.0086 21.89 &lt;0.001 newspaper -0.001 0.0059 -0.18 0.860 To understand why there is no relationship between sales and newspaper, consider the correlation between the variables: library(corrr) advertising %&gt;% select(TV, radio, newspaper, sales) %&gt;% cor() %&gt;% as_tibble(rownames = &quot;var&quot;) %&gt;% mutate(across(-var, round, 4)) %&gt;% gt(rowname_col = &quot;var&quot;) html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #wgxkbqcbfc .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #wgxkbqcbfc .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #wgxkbqcbfc .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #wgxkbqcbfc .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #wgxkbqcbfc .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #wgxkbqcbfc .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #wgxkbqcbfc .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #wgxkbqcbfc .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #wgxkbqcbfc .gt_column_spanner_outer:first-child { padding-left: 0; } #wgxkbqcbfc .gt_column_spanner_outer:last-child { padding-right: 0; } #wgxkbqcbfc .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #wgxkbqcbfc .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #wgxkbqcbfc .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #wgxkbqcbfc .gt_from_md > :first-child { margin-top: 0; } #wgxkbqcbfc .gt_from_md > :last-child { margin-bottom: 0; } #wgxkbqcbfc .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #wgxkbqcbfc .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #wgxkbqcbfc .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #wgxkbqcbfc .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #wgxkbqcbfc .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #wgxkbqcbfc .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #wgxkbqcbfc .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #wgxkbqcbfc .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #wgxkbqcbfc .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #wgxkbqcbfc .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #wgxkbqcbfc .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #wgxkbqcbfc .gt_sourcenote { font-size: 90%; padding: 4px; } #wgxkbqcbfc .gt_left { text-align: left; } #wgxkbqcbfc .gt_center { text-align: center; } #wgxkbqcbfc .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #wgxkbqcbfc .gt_font_normal { font-weight: normal; } #wgxkbqcbfc .gt_font_bold { font-weight: bold; } #wgxkbqcbfc .gt_font_italic { font-style: italic; } #wgxkbqcbfc .gt_super { font-size: 65%; } #wgxkbqcbfc .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } TV radio newspaper sales TV 1.0000 0.0548 0.0566 0.7822 radio 0.0548 1.0000 0.3541 0.5762 newspaper 0.0566 0.3541 1.0000 0.2283 sales 0.7822 0.5762 0.2283 1.0000 High correlation between radio and newspaper suggest that the former is driving the relationship with sales. 3.2.2 Some Important Questions One: Is There a Relationship Between the Response and Predictors? Consider the hypothesis test: \\[ \\begin{align} H_0:&amp; \\beta_1 = \\beta_2 = \\dots = \\beta_p = 0 \\\\ H_a:&amp; \\text{at least one of } \\beta_j \\text{ is non-zero.} \\end{align} \\] This is performed by computing the \\(F\\)-statistic: \\[ F = \\frac{(\\text{TSS} - \\text{RSS})/p}{\\text{RSS}/(n - p - 1)} \\] The denominator should be familiar from simple linear regression: it is the RSS divided by the degrees of freedom, so our estimate of \\(\\sigma^2\\). Likewise, the expected value of the numerator is also \\(\\sigma^2\\) provided that \\(H_0\\) is true. Hence, when there is no relationship between response and predictors, we expect \\(F \\approx 1\\), and \\(F &gt; 1\\) when \\(H_a\\) is true. Instead of computing manually, use broom::glance to re-create Table 3.6: glance(lm_sales_mult) %&gt;% transmute(`Residual standard error` = round(sigma, 2), `R2` = round(r.squared, 3), `F-statistic` = round(statistic, 1)) %&gt;% mutate(across(everything(), as.character)) %&gt;% pivot_longer(everything(), names_to = &quot;Quantity&quot;, values_to = &quot;Value&quot;) %&gt;% gt() html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #cmckhzjmxi .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #cmckhzjmxi .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #cmckhzjmxi .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #cmckhzjmxi .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #cmckhzjmxi .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #cmckhzjmxi .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #cmckhzjmxi .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #cmckhzjmxi .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #cmckhzjmxi .gt_column_spanner_outer:first-child { padding-left: 0; } #cmckhzjmxi .gt_column_spanner_outer:last-child { padding-right: 0; } #cmckhzjmxi .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #cmckhzjmxi .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #cmckhzjmxi .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #cmckhzjmxi .gt_from_md > :first-child { margin-top: 0; } #cmckhzjmxi .gt_from_md > :last-child { margin-bottom: 0; } #cmckhzjmxi .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #cmckhzjmxi .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #cmckhzjmxi .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #cmckhzjmxi .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #cmckhzjmxi .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #cmckhzjmxi .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #cmckhzjmxi .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #cmckhzjmxi .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #cmckhzjmxi .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #cmckhzjmxi .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #cmckhzjmxi .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #cmckhzjmxi .gt_sourcenote { font-size: 90%; padding: 4px; } #cmckhzjmxi .gt_left { text-align: left; } #cmckhzjmxi .gt_center { text-align: center; } #cmckhzjmxi .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #cmckhzjmxi .gt_font_normal { font-weight: normal; } #cmckhzjmxi .gt_font_bold { font-weight: bold; } #cmckhzjmxi .gt_font_italic { font-style: italic; } #cmckhzjmxi .gt_super { font-size: 65%; } #cmckhzjmxi .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } Quantity Value Residual standard error 1.69 R2 0.897 F-statistic 570.3 The value of 570 is far larger than 1, which is compelling evidence against the null \\(H_0\\). The \\(F\\)-statistic follows the \\(F\\)-distribution (assuming \\(H_0\\) is true and the errors \\(\\epsilon_i\\) are normally distributed), so we can get a \\(p\\)-value using the values of \\(n\\) and \\(p\\). Or automatically with glance: glance(lm_sales_mult) %&gt;% select(statistic, p.value) ## # A tibble: 1 x 2 ## statistic p.value ## &lt;dbl&gt; &lt;dbl&gt; ## 1 570. 1.58e-96 Another way to do this is to explicitly fit the null model (no predictors, intercept only), and perform an analysis of variance with the two models using anova: lm_sales_null &lt;- lm(sales ~ 1, data = advertising) anova(lm_sales_null, lm_sales_mult) ## Analysis of Variance Table ## ## Model 1: sales ~ 1 ## Model 2: sales ~ TV + radio + newspaper ## Res.Df RSS Df Sum of Sq F Pr(&gt;F) ## 1 199 5417.1 ## 2 196 556.8 3 4860.3 570.27 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 This approach can also be used to test that a particular subset of \\(q\\) coefficients are zero: \\[ H_0: \\beta_{p-q+1} = \\beta_{p-q+2} = \\dots = \\beta_p = 0 \\\\ \\] In this case, we fit a second model that uses all the variables except those \\(q\\), with a residual sum of squares we call \\(\\text{RSS}_0\\). Then the appropriate \\(F\\)_statistic is: \\[ F = \\frac{(\\text{RSS}_0 - \\text{RSS})/q}{\\text{RSS}/(n-p-1)} \\] It turns out the multivariable model already does this for \\(q = 1\\). The square of each \\(t\\)-statistic is the exact same as the \\(F\\)-statistic we would get by removing that variable: tidy(lm_sales_mult) ## # A tibble: 4 x 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 2.94 0.312 9.42 1.27e-17 ## 2 TV 0.0458 0.00139 32.8 1.51e-81 ## 3 radio 0.189 0.00861 21.9 1.51e-54 ## 4 newspaper -0.00104 0.00587 -0.177 8.60e- 1 For example, the \\(t\\)-statistic for TV is 32.81. Use anova to compare models with and without `TV: anova( lm(sales ~ radio + newspaper, data = advertising), lm_sales_mult ) ## Analysis of Variance Table ## ## Model 1: sales ~ radio + newspaper ## Model 2: sales ~ TV + radio + newspaper ## Res.Df RSS Df Sum of Sq F Pr(&gt;F) ## 1 197 3614.8 ## 2 196 556.8 1 3058 1076.4 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 The \\(F\\)-statistic here is the square of the \\(t\\)-statistic: 1076.4. Two: Deciding on Important Variables The task of determining which predictors are associated with the response, in order to fit a single model involving only those predictors, is referred to as variable selection. Ideally, we would like to perform variable selection by trying out a lot of different models, each containing a different subset of the predictors. For instance, if \\(p = 2\\), then we can consider four models: (1) a model containing no variables, (2) a model containing \\(X_1\\) only, (3) a model containing \\(X_2\\) only, and (4) a model containing both \\(X_1\\) and \\(X_2\\). We can then select the best model out of all of the models that we have considered. How do we determine which model is best? Various statistics can be used to judge the quality of a model. These include Mallows \\(C_p\\), Akaike information criterion (AIC), Bayesian information criterion (BIC), and adjusted \\(R^2\\). These are discussed in more detail in Chapter 6. We can also determine which model is best by plotting various model outputs, such as the residuals, in order to search for patterns. There are a lot of reasons to avoid the stepwise variable selection methods detailed here (forward, backward and mixed). See this article and Smith (2018), for example. Three: Model Fit Most commonly, we use RSE and \\(R^2\\) to quantify model fit. In simple regression, \\(R^2\\) is the square of the correlation between response and predictor. In multiple linear regression, it equals the square of the correlation between response and the fitted linear model: \\(R^2 = \\text{Cor}(Y, \\hat{Y})^2\\). It turns out that \\(R^2\\) will always increase when more variables are added to the model, even if those variables are only weakly associated with the response. This is due to the fact that adding another variable always results in a decrease in the residual sum of squares on the training data (though not necessarily the testing data). Four: Predictions With a fit regression model, it is straightforward to make predictions of the response \\(Y\\). There are three sources of uncertainty in these predictions: The coefficient estimates \\(\\hat{\\beta}_i\\) are estimates of the true \\(\\beta_i\\). This inaccuracy is part of the reducible error. Assuming a linear model of \\(f(X)\\) is almost always an approximation of reality, so it is an additional form of reducible error we call model bias. The random error term \\(\\epsilon\\), which is irreducible. To quantify how much \\(Y\\) will vary from \\(\\hat{Y}\\), we use prediction intervals, which are always wider than confidence intervals because they incorporate both reducible error (in our estimate for \\(f(X)\\)) and irreducible error. 3.3 Other Considerations in the Regression Model 3.3.1 Qualitative Predictors Predictors with Only Two Levels With only two levels in the predictor, we use models that look like this: \\[ y_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i = \\begin{cases} \\beta_0 + \\beta_1 + \\epsilon_i, &amp; \\text{if } i\\text{th person owns a house} \\\\ \\beta_0 + \\epsilon_i, &amp; \\text{if } i\\text{th person does not}. \\end{cases} \\] Load the credit data set and regress credit card balance on home ownership: credit &lt;- ISLR2::Credit lm_balance_own &lt;- lm(Balance ~ Own, data = credit) tidy_custom(lm_balance_own, coef_round = 2, se_round = 2, t_round = 3) %&gt;% gt() html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #yrqddktfmq .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #yrqddktfmq .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #yrqddktfmq .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #yrqddktfmq .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #yrqddktfmq .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #yrqddktfmq .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #yrqddktfmq .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #yrqddktfmq .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #yrqddktfmq .gt_column_spanner_outer:first-child { padding-left: 0; } #yrqddktfmq .gt_column_spanner_outer:last-child { padding-right: 0; } #yrqddktfmq .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #yrqddktfmq .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #yrqddktfmq .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #yrqddktfmq .gt_from_md > :first-child { margin-top: 0; } #yrqddktfmq .gt_from_md > :last-child { margin-bottom: 0; } #yrqddktfmq .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #yrqddktfmq .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #yrqddktfmq .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #yrqddktfmq .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #yrqddktfmq .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #yrqddktfmq .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #yrqddktfmq .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #yrqddktfmq .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #yrqddktfmq .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #yrqddktfmq .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #yrqddktfmq .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #yrqddktfmq .gt_sourcenote { font-size: 90%; padding: 4px; } #yrqddktfmq .gt_left { text-align: left; } #yrqddktfmq .gt_center { text-align: center; } #yrqddktfmq .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #yrqddktfmq .gt_font_normal { font-weight: normal; } #yrqddktfmq .gt_font_bold { font-weight: bold; } #yrqddktfmq .gt_font_italic { font-style: italic; } #yrqddktfmq .gt_super { font-size: 65%; } #yrqddktfmq .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } term coefficient std.error t-statistic p-value (Intercept) 509.80 33.13 15.389 &lt;0.001 OwnYes 19.73 46.05 0.429 0.669 Qualitative Predictors with More than Two Levels And with region (three levels): \\[ y_i = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\epsilon_i = \\begin{cases} \\beta_0 + \\beta_1 + \\epsilon_i, &amp; \\text{if } i\\text{th person is from the South} \\\\ \\beta_0 + \\beta_2 + \\epsilon_i, &amp; \\text{if } i\\text{th person is from the West} \\\\ \\beta_0 + \\epsilon_i, &amp; \\text{if } i\\text{th person is from the East}. \\end{cases} \\] lm_balance_region &lt;- lm(Balance ~ Region, data = credit) tidy_custom(lm_balance_region, coef_round = 2, se_round = 2, t_round = 3) %&gt;% gt() html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #kpqxputolv .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #kpqxputolv .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #kpqxputolv .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #kpqxputolv .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #kpqxputolv .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #kpqxputolv .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #kpqxputolv .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #kpqxputolv .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #kpqxputolv .gt_column_spanner_outer:first-child { padding-left: 0; } #kpqxputolv .gt_column_spanner_outer:last-child { padding-right: 0; } #kpqxputolv .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #kpqxputolv .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #kpqxputolv .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #kpqxputolv .gt_from_md > :first-child { margin-top: 0; } #kpqxputolv .gt_from_md > :last-child { margin-bottom: 0; } #kpqxputolv .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #kpqxputolv .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #kpqxputolv .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #kpqxputolv .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #kpqxputolv .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #kpqxputolv .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #kpqxputolv .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #kpqxputolv .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #kpqxputolv .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #kpqxputolv .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #kpqxputolv .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #kpqxputolv .gt_sourcenote { font-size: 90%; padding: 4px; } #kpqxputolv .gt_left { text-align: left; } #kpqxputolv .gt_center { text-align: center; } #kpqxputolv .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #kpqxputolv .gt_font_normal { font-weight: normal; } #kpqxputolv .gt_font_bold { font-weight: bold; } #kpqxputolv .gt_font_italic { font-style: italic; } #kpqxputolv .gt_super { font-size: 65%; } #kpqxputolv .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } term coefficient std.error t-statistic p-value (Intercept) 531.00 46.32 11.464 &lt;0.001 RegionSouth -12.50 56.68 -0.221 0.826 RegionWest -18.69 65.02 -0.287 0.774 To run the \\(F\\)-test, use anova(): anova(lm_balance_region) ## Analysis of Variance Table ## ## Response: Balance ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Region 2 18454 9227 0.0434 0.9575 ## Residuals 397 84321458 212397 which tells us that we cannot reject the null that there is no relationship between balance and region. 3.3.2 Extensions of the Linear Model The standard linear regression model (3.19) provides interpretable results and works quite well on many real-world problems. However, it makes several highly restrictive assumptions that are often violated in practice. Two of the most important assumptions state that the relationship between the predictors and response are additive and linear. Removing the Additive Assumption This assumption is that the association between a predictor \\(X_j\\) and the response \\(Y\\) does not depend on the values of other predictors. In our advertising example, suppose that spending money on radio actually increases the effectiveness of TV advertising, i.e. the the slope term for TV actually increases as radio increases. In marketing, this is synergy. In statistics, this is an interaction effect. The models with and without an interaction effect are: \\[ \\begin{align} Y &amp;= \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\epsilon \\\\ Y &amp;= \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\beta_3 X_1 X_2 + \\epsilon \\end{align} \\] The effect on sales, with an interaction term between TV and radio: lm_sales_inter &lt;- lm(sales ~ radio * TV, data = advertising) tidy_custom(lm_sales_inter, coef_round = 4, se_round = 3) %&gt;% gt() html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #rxqdidzwoe .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #rxqdidzwoe .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #rxqdidzwoe .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #rxqdidzwoe .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #rxqdidzwoe .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #rxqdidzwoe .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #rxqdidzwoe .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #rxqdidzwoe .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #rxqdidzwoe .gt_column_spanner_outer:first-child { padding-left: 0; } #rxqdidzwoe .gt_column_spanner_outer:last-child { padding-right: 0; } #rxqdidzwoe .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #rxqdidzwoe .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #rxqdidzwoe .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #rxqdidzwoe .gt_from_md > :first-child { margin-top: 0; } #rxqdidzwoe .gt_from_md > :last-child { margin-bottom: 0; } #rxqdidzwoe .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #rxqdidzwoe .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #rxqdidzwoe .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #rxqdidzwoe .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #rxqdidzwoe .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #rxqdidzwoe .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #rxqdidzwoe .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #rxqdidzwoe .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #rxqdidzwoe .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #rxqdidzwoe .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #rxqdidzwoe .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #rxqdidzwoe .gt_sourcenote { font-size: 90%; padding: 4px; } #rxqdidzwoe .gt_left { text-align: left; } #rxqdidzwoe .gt_center { text-align: center; } #rxqdidzwoe .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #rxqdidzwoe .gt_font_normal { font-weight: normal; } #rxqdidzwoe .gt_font_bold { font-weight: bold; } #rxqdidzwoe .gt_font_italic { font-style: italic; } #rxqdidzwoe .gt_super { font-size: 65%; } #rxqdidzwoe .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } term coefficient std.error t-statistic p-value (Intercept) 6.7502 0.248 27.23 &lt;0.001 radio 0.0289 0.009 3.24 0.001 TV 0.0191 0.002 12.70 &lt;0.001 radio:TV 0.0011 0.000 20.73 &lt;0.001 Compare the model with and without the interaction term: lm_sales_radio_tv &lt;- lm(sales ~ radio + TV, data = advertising) glance(lm_sales_radio_tv) %&gt;% mutate(model = &quot;additive&quot;) %&gt;% bind_rows( glance(lm_sales_inter) %&gt;% mutate(model = &quot;interaction&quot;) ) %&gt;% select(model, r.squared, AIC, BIC) %&gt;% gt() html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #rchrmbdryv .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #rchrmbdryv .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #rchrmbdryv .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #rchrmbdryv .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #rchrmbdryv .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #rchrmbdryv .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #rchrmbdryv .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #rchrmbdryv .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #rchrmbdryv .gt_column_spanner_outer:first-child { padding-left: 0; } #rchrmbdryv .gt_column_spanner_outer:last-child { padding-right: 0; } #rchrmbdryv .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #rchrmbdryv .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #rchrmbdryv .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #rchrmbdryv .gt_from_md > :first-child { margin-top: 0; } #rchrmbdryv .gt_from_md > :last-child { margin-bottom: 0; } #rchrmbdryv .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #rchrmbdryv .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #rchrmbdryv .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #rchrmbdryv .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #rchrmbdryv .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #rchrmbdryv .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #rchrmbdryv .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #rchrmbdryv .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #rchrmbdryv .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #rchrmbdryv .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #rchrmbdryv .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #rchrmbdryv .gt_sourcenote { font-size: 90%; padding: 4px; } #rchrmbdryv .gt_left { text-align: left; } #rchrmbdryv .gt_center { text-align: center; } #rchrmbdryv .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #rchrmbdryv .gt_font_normal { font-weight: normal; } #rchrmbdryv .gt_font_bold { font-weight: bold; } #rchrmbdryv .gt_font_italic { font-style: italic; } #rchrmbdryv .gt_super { font-size: 65%; } #rchrmbdryv .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } model r.squared AIC BIC additive 0.8971943 780.3941 793.5874 interaction 0.9677905 550.2778 566.7694 What if the interaction term was highly insignificant, but the associated main effects were not? The hierarchical principle states that if we include an interaction in a model, we should also include the main effects, even if the \\(p\\)-values of their coefficients are not significant. The concept of interactions applies just as well to qualitative variables. Re-create Figure 3.7, comparing the balance model with and without an interaction term of Income and Student: lm_balance_income_student &lt;- lm(Balance ~ Income + Student, data = credit) lm_balance_income_student_inter &lt;- lm(Balance ~ Income * Student, data = credit) d &lt;- tibble(Income = seq(0, 150, 0.1)) %&gt;% crossing(Student = factor(c(&quot;No&quot;, &quot;Yes&quot;))) augment(lm_balance_income_student, newdata = d) %&gt;% mutate(model = &quot;additive&quot;) %&gt;% bind_rows( augment(lm_balance_income_student_inter, newdata = d) %&gt;% mutate(model = &quot;interaction&quot;) ) %&gt;% ggplot(aes(x = Income, y = .fitted, color = Student)) + geom_line(size = 1.5) + facet_wrap(~model, nrow = 1) + add_facet_borders() + labs(y = &quot;Balance&quot;) This suggests that the positive relationship between Income and Balance is smaller for students. Non-linear Relationships This assumption is that there is a linear relationship between response and predictors, but in some cases, the true relationship may be non-linear. A simple way to account for non-linearity is to use polynomial regression. Fit mpg to horsepower as a linear term, quadratic term, and up to the fifth degree: auto &lt;- ISLR2::Auto lm_mpg_hp &lt;- lm(mpg ~ horsepower, data = auto) lm_mpg_hp2 &lt;- lm(mpg ~ horsepower + I(horsepower^2), data = auto) lm_mpg_hp5 &lt;- lm( mpg ~ horsepower + I(horsepower^2) + I(horsepower^3) + I(horsepower^4) + I(horsepower^5), data = auto ) d &lt;- tibble(horsepower = seq(1, 250, 0.1)) bind_rows( augment(lm_mpg_hp, newdata = d) %&gt;% mutate(model = &quot;Linear&quot;), augment(lm_mpg_hp2, newdata = d) %&gt;% mutate(model = &quot;Degree 2&quot;), augment(lm_mpg_hp5, newdata = d) %&gt;% mutate(model = &quot;Degree 5&quot;) ) %&gt;% ggplot(aes(x = horsepower, y = .fitted, color = model)) + geom_point( aes(y = mpg), data = auto, color = &quot;darkgrey&quot;, shape = 21, size = 3 ) + geom_line(size = 1.5) + coord_cartesian(xlim = c(40, 230), ylim = c(8, 52)) + add_facet_borders() + theme(legend.position = c(0.7, 0.8)) + labs(y = &quot;mpg&quot;, color = NULL) And compare model assessment statistics: glance(lm_mpg_hp) %&gt;% mutate(model = &quot;Linear&quot;) %&gt;% bind_rows( glance(lm_mpg_hp2) %&gt;% mutate(model = &quot;Degree 2&quot;) ) %&gt;% bind_rows( glance(lm_mpg_hp5) %&gt;% mutate(model = &quot;Degree 5&quot;) ) %&gt;% select(model, r.squared, AIC, BIC) %&gt;% mutate(across(-model, round, 3)) %&gt;% gt() html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #vhudhbxnla .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #vhudhbxnla .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #vhudhbxnla .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #vhudhbxnla .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #vhudhbxnla .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #vhudhbxnla .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #vhudhbxnla .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #vhudhbxnla .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #vhudhbxnla .gt_column_spanner_outer:first-child { padding-left: 0; } #vhudhbxnla .gt_column_spanner_outer:last-child { padding-right: 0; } #vhudhbxnla .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #vhudhbxnla .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #vhudhbxnla .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #vhudhbxnla .gt_from_md > :first-child { margin-top: 0; } #vhudhbxnla .gt_from_md > :last-child { margin-bottom: 0; } #vhudhbxnla .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #vhudhbxnla .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #vhudhbxnla .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #vhudhbxnla .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #vhudhbxnla .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #vhudhbxnla .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #vhudhbxnla .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #vhudhbxnla .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #vhudhbxnla .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #vhudhbxnla .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #vhudhbxnla .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #vhudhbxnla .gt_sourcenote { font-size: 90%; padding: 4px; } #vhudhbxnla .gt_left { text-align: left; } #vhudhbxnla .gt_center { text-align: center; } #vhudhbxnla .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #vhudhbxnla .gt_font_normal { font-weight: normal; } #vhudhbxnla .gt_font_bold { font-weight: bold; } #vhudhbxnla .gt_font_italic { font-style: italic; } #vhudhbxnla .gt_super { font-size: 65%; } #vhudhbxnla .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } model r.squared AIC BIC Linear 0.606 2363.324 2375.237 Degree 2 0.688 2274.354 2290.239 Degree 5 0.697 2268.663 2296.462 3.3.3 Potential Problems 1. Non-linearity of the Data If the true relationship between response and predictors is far from linear, then we can should be able to see this in residual plots. In R, we can call the generic plot() function on the model objects to quickly get these plots: plot(lm_mpg_hp, 1) plot(lm_mpg_hp2, 1) Ideally these residual plots will show no discernible pattern. Above, there is a clear U-shape in the linear model indicating non-linearity in the data. This appears to be improved by the quadratic term. 2. Correlation of Error Terms An important assumption of the linear regression model is that the error terms, \\(\\epsilon\\), are uncorrelated. What does this mean? For instance, if the errors are uncorrelated, then the fact that \\(\\epsilon_i\\) is positive provides little or no information about the sign of \\(\\epsilon_{i+1}\\). The standard errors that are computed for the estimated regression coefficients or the fitted values are based on the assumption of uncorrelated error terms. If in fact there is correlation among the error terms, then the estimated standard errors will tend to underestimate the true standard errors. As a result, confidence and prediction intervals will be narrower than they should be. For example, a 95% confidence interval may in reality have a much lower probability than 0.95 of containing the true value of the parameter. In addition, p-values associated with the model will be lower than they should be; this could cause us to erroneously conclude that a parameter is statistically significant. In short, if the error terms are correlated, we may have an unwarranted sense of confidence in our model. The extreme example in the text is an accidental doubling of the data, which we can try out with the advertising multiple regression model: lm_sales_mult_double &lt;- lm(sales ~ TV + radio + newspaper, data = bind_rows(advertising, advertising)) bind_rows( bind_cols(data = &quot;original&quot;, tidy_custom(lm_sales_mult)), bind_cols(data = &quot;double&quot;, tidy_custom(lm_sales_mult_double)) ) %&gt;% group_by(data) %&gt;% gt() html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #zixysttjal .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #zixysttjal .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #zixysttjal .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #zixysttjal .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #zixysttjal .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #zixysttjal .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #zixysttjal .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #zixysttjal .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #zixysttjal .gt_column_spanner_outer:first-child { padding-left: 0; } #zixysttjal .gt_column_spanner_outer:last-child { padding-right: 0; } #zixysttjal .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #zixysttjal .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #zixysttjal .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #zixysttjal .gt_from_md > :first-child { margin-top: 0; } #zixysttjal .gt_from_md > :last-child { margin-bottom: 0; } #zixysttjal .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #zixysttjal .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #zixysttjal .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #zixysttjal .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #zixysttjal .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #zixysttjal .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #zixysttjal .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #zixysttjal .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #zixysttjal .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #zixysttjal .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #zixysttjal .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #zixysttjal .gt_sourcenote { font-size: 90%; padding: 4px; } #zixysttjal .gt_left { text-align: left; } #zixysttjal .gt_center { text-align: center; } #zixysttjal .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #zixysttjal .gt_font_normal { font-weight: normal; } #zixysttjal .gt_font_bold { font-weight: bold; } #zixysttjal .gt_font_italic { font-style: italic; } #zixysttjal .gt_super { font-size: 65%; } #zixysttjal .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } term coefficient std.error t-statistic p-value original (Intercept) 2.939 0.3119 9.42 &lt;0.001 TV 0.046 0.0014 32.81 &lt;0.001 radio 0.189 0.0086 21.89 &lt;0.001 newspaper -0.001 0.0059 -0.18 0.860 double (Intercept) 2.939 0.2194 13.39 &lt;0.001 TV 0.046 0.0010 46.63 &lt;0.001 radio 0.189 0.0061 31.12 &lt;0.001 newspaper -0.001 0.0041 -0.25 0.802 3. Non-constant Variance of Error Terms Another important assumption is that the error terms have constant variance, \\(\\text{Var}(\\epsilon_i) = \\sigma^2\\). If they do not, we say there is heteroscedasticity, which we can see in the residual plot as a funnel shape. For example: d &lt;- tibble( x = rnorm(300, mean = 20, sd = 5) ) %&gt;% rowwise() %&gt;% mutate( y = x * rnorm(1, mean = 1, sd = x / 20) ) plot(lm(y ~ x, data = d), 1) 4. Outliers An outlier is a point for which \\(y_i\\) is far from the value predicted by the model. Outliers can arise for a variety of reasons, such as incorrect recording of an observation during data collection. We can typically see outliers in the residuals plots: plot(lm_mpg_hp, 1) In this case, point numbers 334, 323, and 330 were identified as outliers. It is hard to say when a residual is a problem that should be addressed. We can also plot the studentized (or standardized) residuals, which are computed by dividing each residual by its estimated standard error: plot(lm_mpg_hp, 5) Here we see a few outliers with standardized residuals above 2. 5. High Leverage Points Outliers are unusual response values \\(y_i\\), while observations with high leverage have unusual values for \\(x_i\\). In the above plot, the points 117 and 94 were identified as high leverage, as well as having fairly high residuals. These data would be worth investigating further. 6. Collinearity Collinearity refers to the situation in which two or more predictor variables are closely related to one another. In the credit data, we see collinearity between the limit and rating variables: credit %&gt;% select(Limit, Age, Rating) %&gt;% pivot_longer(cols = c(Age, Rating)) %&gt;% ggplot(aes(x = Limit, y = value)) + geom_point() + facet_wrap(~name, nrow = 1, scales = &quot;free_y&quot;) The presence of collinearity can pose problems in the regression context, since it can be difficult to separate out the individual effects of collinear variables on the response. In other words, since limit and rating tend to increase or decrease together, it can be difficult to determine how each one separately is associated with the response, balance. Since collinearity reduces the accuracy of the estimates of the regression coefficients, it causes the standard error for \\(\\hat{\\beta}_j\\) to grow. Recall that the \\(t\\)-statistic for each predictor is calculated by dividing \\(\\hat{\\beta}_j\\) by its standard error. Consequently, collinearity results in a decline in the \\(t\\)-statistic. As a result, in the presence of collinearity, we may fail to reject \\(H_0: \\beta_j = 0\\). This means that the power of the hypothesis test  the probability of correctly detecting a non-zero coefficient  is reduced by collinearity. Fit the two models and summarize in a table: lm_balance_age_limit &lt;- lm(Balance ~ Age + Limit, data = credit) lm_balance_rating_limit &lt;- lm(Balance ~ Rating + Limit, data = credit) bind_rows( bind_cols(mod = &quot;Model 1&quot;, tidy_custom(lm_balance_age_limit)), bind_cols(mod = &quot;Model 2&quot;, tidy_custom(lm_balance_rating_limit)) ) %&gt;% group_by(mod) %&gt;% gt(rowname_col = &quot;term&quot;) html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #tecaedybwg .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #tecaedybwg .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #tecaedybwg .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #tecaedybwg .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #tecaedybwg .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #tecaedybwg .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #tecaedybwg .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #tecaedybwg .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #tecaedybwg .gt_column_spanner_outer:first-child { padding-left: 0; } #tecaedybwg .gt_column_spanner_outer:last-child { padding-right: 0; } #tecaedybwg .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #tecaedybwg .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #tecaedybwg .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #tecaedybwg .gt_from_md > :first-child { margin-top: 0; } #tecaedybwg .gt_from_md > :last-child { margin-bottom: 0; } #tecaedybwg .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #tecaedybwg .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #tecaedybwg .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #tecaedybwg .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #tecaedybwg .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #tecaedybwg .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #tecaedybwg .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #tecaedybwg .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #tecaedybwg .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #tecaedybwg .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #tecaedybwg .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #tecaedybwg .gt_sourcenote { font-size: 90%; padding: 4px; } #tecaedybwg .gt_left { text-align: left; } #tecaedybwg .gt_center { text-align: center; } #tecaedybwg .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #tecaedybwg .gt_font_normal { font-weight: normal; } #tecaedybwg .gt_font_bold { font-weight: bold; } #tecaedybwg .gt_font_italic { font-style: italic; } #tecaedybwg .gt_super { font-size: 65%; } #tecaedybwg .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } coefficient std.error t-statistic p-value Model 1 (Intercept) -173.411 43.8284 -3.96 &lt;0.001 Age -2.291 0.6725 -3.41 &lt;0.001 Limit 0.173 0.0050 34.50 &lt;0.001 Model 2 (Intercept) -377.537 45.2542 -8.34 &lt;0.001 Rating 2.202 0.9523 2.31 0.021 Limit 0.025 0.0638 0.38 0.701 A simple way to detect collinearity is to look at the correlation matrix of predictors. However, when there is multicollinearity (more than 2 variables correlated), we wont see anything wrong in the pairwise correlation matrix. A better way is to compute the variance inflation factor (VIF). The VIF of a parameter if the ratio of \\(\\text{Var}(\\hat{\\beta}_j)\\) when fitting the full model divided by the variance when fit on its own. VIF values which exceed 5 or 10 indicate a problematic amount of collinearity. It can be computed using the formula: \\[ \\text{VIF}(\\hat{\\beta}_j) = \\frac{1}{1 - R^2_{X_j | X_-j}} \\] where \\(R^2_{X_j | X_-j}\\) is the \\(R^2\\) from a regression of \\(X_j\\) onto all other predictors. Compute it manually with the predictor rating regressed on age and limit: rating_r2 &lt;- summary( lm(Rating ~ Age + Limit, data = credit) )$r.squared round(1 / (1 - rating_r2), 2) ## [1] 160.67 To calculate VIFs, there are R functions such as car::vif which can be used, but it is fairly simple to calculate by hand: lm_rating_age_limit &lt;- lm(Rating ~ Age + Limit, data = credit) lm_age_rating_limit &lt;- lm(Age ~ Rating + Limit, data = credit) lm_limit_age_rating &lt;- lm(Limit ~ Age + Rating, data = credit) tribble( ~Predictor, ~`R^2`, &quot;Age&quot;, 1 / (1 - summary(lm_age_rating_limit)$r.squared), &quot;Rating&quot;, 1 / (1 - summary(lm_rating_age_limit)$r.squared), &quot;Limit&quot;, 1 / (1 - summary(lm_limit_age_rating)$r.squared) ) %&gt;% mutate(`R^2` = round(`R^2`, 2)) %&gt;% gt() html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #qaovviazfj .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #qaovviazfj .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #qaovviazfj .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #qaovviazfj .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #qaovviazfj .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #qaovviazfj .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #qaovviazfj .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #qaovviazfj .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #qaovviazfj .gt_column_spanner_outer:first-child { padding-left: 0; } #qaovviazfj .gt_column_spanner_outer:last-child { padding-right: 0; } #qaovviazfj .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #qaovviazfj .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #qaovviazfj .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #qaovviazfj .gt_from_md > :first-child { margin-top: 0; } #qaovviazfj .gt_from_md > :last-child { margin-bottom: 0; } #qaovviazfj .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #qaovviazfj .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #qaovviazfj .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #qaovviazfj .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #qaovviazfj .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #qaovviazfj .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #qaovviazfj .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #qaovviazfj .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #qaovviazfj .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #qaovviazfj .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #qaovviazfj .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #qaovviazfj .gt_sourcenote { font-size: 90%; padding: 4px; } #qaovviazfj .gt_left { text-align: left; } #qaovviazfj .gt_center { text-align: center; } #qaovviazfj .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #qaovviazfj .gt_font_normal { font-weight: normal; } #qaovviazfj .gt_font_bold { font-weight: bold; } #qaovviazfj .gt_font_italic { font-style: italic; } #qaovviazfj .gt_super { font-size: 65%; } #qaovviazfj .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } Predictor R^2 Age 1.01 Rating 160.67 Limit 160.59 When dealing with high collinearity, such as with rating and limit here, the first solution is to drop one of the variables from the regression. This should be okay because the dropped variable is likely redundant. Another solution would be to combine the collinear variables together into a single predictor, e.g. taking the average of standardized limit and rating. 3.4 The Marketing Plan Is there a relationship between sales and advertising budget: From the multiple regression \\(F\\)-test (Table 3.6), \\(F =\\) 570.27 (\\(p\\) &lt;0.001). There is clear evidence of a relationship. How strong is the relationship? Calculate the RSE from the model: # Manually calculated RSE sqrt( sum(resid(lm_sales_mult)^2) / # Degrees of freedom: n - p - 1 (nrow(advertising) - 3 - 1) ) ## [1] 1.68551 # The helper functon RSE is easier sigma(lm_sales_mult) ## [1] 1.68551 On the scale of the response, with a mean (SD) of 14 (5.2), the RSE indicates a percentage error of about: (sigma(lm_sales_mult) / mean(advertising$sales)) %&gt;% scales::percent() ## [1] &quot;12%&quot; The \\(R^2\\) value is 0.8972106, indicating approximately 90% of the variance in sales is explained by the three predictors. Which media are associated with sales? Though a simplified view of association, we say that TV and radio are significantly associated with sales due to their low \\(p\\)-values, and that newspaper is not. How large is the association between each medium and sales? Compute 95% confidence intervals from SEs for each predictor: tidy(lm_sales_mult, conf.int = 0.95) %&gt;% transmute( term, across(c(estimate, conf.low, conf.high), round, 3) ) %&gt;% gt() html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #dwsfjyffto .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #dwsfjyffto .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #dwsfjyffto .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #dwsfjyffto .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #dwsfjyffto .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #dwsfjyffto .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #dwsfjyffto .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #dwsfjyffto .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #dwsfjyffto .gt_column_spanner_outer:first-child { padding-left: 0; } #dwsfjyffto .gt_column_spanner_outer:last-child { padding-right: 0; } #dwsfjyffto .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #dwsfjyffto .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #dwsfjyffto .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #dwsfjyffto .gt_from_md > :first-child { margin-top: 0; } #dwsfjyffto .gt_from_md > :last-child { margin-bottom: 0; } #dwsfjyffto .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #dwsfjyffto .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #dwsfjyffto .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #dwsfjyffto .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #dwsfjyffto .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #dwsfjyffto .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #dwsfjyffto .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #dwsfjyffto .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #dwsfjyffto .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #dwsfjyffto .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #dwsfjyffto .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #dwsfjyffto .gt_sourcenote { font-size: 90%; padding: 4px; } #dwsfjyffto .gt_left { text-align: left; } #dwsfjyffto .gt_center { text-align: center; } #dwsfjyffto .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #dwsfjyffto .gt_font_normal { font-weight: normal; } #dwsfjyffto .gt_font_bold { font-weight: bold; } #dwsfjyffto .gt_font_italic { font-style: italic; } #dwsfjyffto .gt_super { font-size: 65%; } #dwsfjyffto .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } term estimate conf.low conf.high (Intercept) 2.939 2.324 3.554 TV 0.046 0.043 0.049 radio 0.189 0.172 0.206 newspaper -0.001 -0.013 0.011 TV and radio CIs are both narrow and dont include zero. The interval for newspaper does include zero. Look for collinearity: car::vif(lm_sales_mult) ## TV radio newspaper ## 1.004611 1.144952 1.145187 No evidence from VIF scores. How accurately can we predict future sales? We can either predict an individual response, \\(Y = f(X) + \\epsilon\\) with a prediction interval, or the average response \\(f(X)\\) with a confidence interval. This is done with the predict.lm() function and by setting the argument interval: # Make up some new data to predict sales d &lt;- tibble(TV = 160.0, radio = 15.0, newspaper = 72.0) predict( lm_sales_mult, newdata = d, interval = &quot;prediction&quot;, level = 0.95 ) ## fit lwr upr ## 1 13.01448 9.637749 16.39122 predict( lm_sales_mult, newdata = d, interval = &quot;confidence&quot;, level = 0.95 ) ## fit lwr upr ## 1 13.01448 12.4204 13.60857 As expected, the former is wider than the latter due to incorporating the irreducible error. Is the relationship linear? The residual plot: plot(lm_sales_mult, 1) The shape of these residuals suggests a non-linear relationship. Is there synergy among the advertising media? To account for the non-linearity, we included an interaction term between TV and radio. The \\(p\\)-value of the interaction term: tidy_custom(lm_sales_inter) %&gt;% gt() html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #jejkgjhugc .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #jejkgjhugc .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #jejkgjhugc .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #jejkgjhugc .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #jejkgjhugc .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #jejkgjhugc .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #jejkgjhugc .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #jejkgjhugc .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #jejkgjhugc .gt_column_spanner_outer:first-child { padding-left: 0; } #jejkgjhugc .gt_column_spanner_outer:last-child { padding-right: 0; } #jejkgjhugc .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #jejkgjhugc .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #jejkgjhugc .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #jejkgjhugc .gt_from_md > :first-child { margin-top: 0; } #jejkgjhugc .gt_from_md > :last-child { margin-bottom: 0; } #jejkgjhugc .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #jejkgjhugc .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #jejkgjhugc .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #jejkgjhugc .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #jejkgjhugc .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #jejkgjhugc .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #jejkgjhugc .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #jejkgjhugc .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #jejkgjhugc .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #jejkgjhugc .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #jejkgjhugc .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #jejkgjhugc .gt_sourcenote { font-size: 90%; padding: 4px; } #jejkgjhugc .gt_left { text-align: left; } #jejkgjhugc .gt_center { text-align: center; } #jejkgjhugc .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #jejkgjhugc .gt_font_normal { font-weight: normal; } #jejkgjhugc .gt_font_bold { font-weight: bold; } #jejkgjhugc .gt_font_italic { font-style: italic; } #jejkgjhugc .gt_super { font-size: 65%; } #jejkgjhugc .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } term coefficient std.error t-statistic p-value (Intercept) 6.750 0.2479 27.23 &lt;0.001 radio 0.029 0.0089 3.24 0.001 TV 0.019 0.0015 12.70 &lt;0.001 radio:TV 0.001 0.0001 20.73 &lt;0.001 and the increase in \\(R^2\\): summary(lm_sales_radio_tv)$r.squared ## [1] 0.8971943 summary(lm_sales_inter)$r.squared ## [1] 0.9677905 suggests a substantial improvement over the additive model. 3.5 Comparison of Linear Regression with \\(K\\)-Nearest Neighbors Parametric methods are often easy to fit, and easy to interpret, but the disadvantage is the strong assumption about the form of \\(f(X)\\). Non-parametric methods do not explicitly assume a form for \\(f(X)\\) and therefore provide an alternative and more flexible approach to regression. One of the simplest and best-known methods is \\(K\\)-nearest neighbors regression (closely related to the KNN classifier from Chapter 2). From the \\(K\\) nearest neighbors (represented by the set \\(\\mathcal{N}_0\\)) to a prediction point \\(x_0\\), it estimates \\(f(x_0)\\) using the average: \\[ \\hat{f}(x_0) = \\frac{1}{K} \\sum_{x_i \\in \\mathcal{N}_0} y_i. \\] On the choice of \\(K\\): In general, the optimal value for \\(K\\) will depend on the bias-variance tradeoff, which we introduced in Chapter 2. A small value for \\(K\\) provides the most flexible fit, which will have low bias but high variance. This variance is due to the fact that the prediction in a given region is entirely dependent on just one observation. In contrast, larger values of \\(K\\) provide a smoother and less variable fit; the prediction in a region is an average of several points, and so changing one observation has a smaller effect. However, the smoothing may cause bias by masking some of the structure in \\(f(X)\\). In Chapter 5, we introduce several approaches for estimating test error rates. These methods can be used to identify the optimal value of \\(K\\) in KNN regression. In what setting will a parametric approach such as least squares linear regression outperform a non-parametric approach such as KNN regression? The answer is simple: the parametric approach will outperform the non-parametric approach if the parametric form that has been selected is close to the true form of \\(f\\). There is another consideration when performing KNN with many predictors \\(p\\): However, spreading 50 observations over \\(p\\) = 20 dimensions results in a phenomenon in which a given observation has no nearby neighbors - this is the so-called curse of dimensionality. That is, the \\(K\\) observations that are nearest to a given test observation \\(x_0\\) may be very far away from \\(x_0\\) in \\(p\\)-dimensional space when \\(p\\) is large, leading to a very poor prediction of \\(f(x_0)\\) and hence a poor KNN fit. As a general rule, parametric methods will tend to outperform non-parametric approaches when there is a small number of observations per predictor. However: Even when the dimension is small, we might prefer linear regression to KNN from an interpretability standpoint. If the test MSE of KNN is only slightly lower than that of linear regression, we might be willing to forego a little bit of prediction accuracy for the sake of a simple model that can be described in terms of just a few coefficients, and for which \\(p\\)-values are available. 3.6 Lab: Linear Regression 3.6.1 Libraries Load the boston data rather than the full ISLR2 package: boston &lt;- ISLR2::Boston 3.6.2 Simple Linear Regression Regress median value of owner-occupied homes medv on percentage of houses with lower socioeconomic status lstat: lm_medv_lstat &lt;- lm(medv ~ lstat, data = boston) summary(lm_medv_lstat) ## ## Call: ## lm(formula = medv ~ lstat, data = boston) ## ## Residuals: ## Min 1Q Median 3Q Max ## -15.168 -3.990 -1.318 2.034 24.500 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 34.55384 0.56263 61.41 &lt;2e-16 *** ## lstat -0.95005 0.03873 -24.53 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 6.216 on 504 degrees of freedom ## Multiple R-squared: 0.5441, Adjusted R-squared: 0.5432 ## F-statistic: 601.6 on 1 and 504 DF, p-value: &lt; 2.2e-16 Compute confidence and prediction intervals at different values of lstat: nd &lt;- tibble(lstat = c(5, 10, 15)) bind_cols( nd, as_tibble(predict(lm_medv_lstat, nd, interval = &quot;confidence&quot;)) ) ## # A tibble: 3 x 4 ## lstat fit lwr upr ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 5 29.8 29.0 30.6 ## 2 10 25.1 24.5 25.6 ## 3 15 20.3 19.7 20.9 bind_cols( nd, as_tibble(predict(lm_medv_lstat, nd, interval = &quot;prediction&quot;)) ) ## # A tibble: 3 x 4 ## lstat fit lwr upr ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 5 29.8 17.6 42.0 ## 2 10 25.1 12.8 37.3 ## 3 15 20.3 8.08 32.5 The broom::augment function is a more convenient method: broom::augment( lm_medv_lstat, newdata = nd, interval = &quot;confidence&quot; ) ## # A tibble: 3 x 4 ## lstat .fitted .lower .upper ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 5 29.8 29.0 30.6 ## 2 10 25.1 24.5 25.6 ## 3 15 20.3 19.7 20.9 Plot the relationship between medv and lstat: boston %&gt;% ggplot(aes(x = lstat, y = medv)) + geom_point(alpha = 0.3) + geom_abline(slope = coef(lm_medv_lstat)[&quot;lstat&quot;], intercept = coef(lm_medv_lstat)[&quot;(Intercept)&quot;], size = 1.0, color = td_colors$nice$day9_yellow) To display model diagnostics, we can call plot() on the model object as we have before, but I like the performance package because it uses ggplot2: performance::check_model(lm_medv_lstat) The stats::hatvalues() function is a new one to me, for computing leverage: hatvalues(lm_medv_lstat)[which.max(hatvalues(lm_medv_lstat))] ## 375 ## 0.02686517 Unsurprisingly, this point is the one with the largest value of lstat: boston %&gt;% transmute(row = 1:n(), lstat, medv) %&gt;% filter(lstat == max(lstat)) ## row lstat medv ## 1 375 37.97 13.8 3.6.3 Multiple Linear Regression Fit to all predictors and check VIF with the performance package: lm_medv_all &lt;- lm(medv ~ ., data = boston) performance::check_collinearity(lm_medv_all) ## # Check for Multicollinearity ## ## Low Correlation ## ## Term VIF Increased SE Tolerance ## crim 1.77 1.33 0.57 ## zn 2.30 1.52 0.44 ## indus 3.99 2.00 0.25 ## chas 1.07 1.03 0.93 ## nox 4.37 2.09 0.23 ## rm 1.91 1.38 0.52 ## age 3.09 1.76 0.32 ## dis 3.95 1.99 0.25 ## ptratio 1.80 1.34 0.56 ## lstat 2.87 1.69 0.35 ## ## Moderate Correlation ## ## Term VIF Increased SE Tolerance ## rad 7.45 2.73 0.13 ## tax 9.00 3.00 0.11 The rad (accessibility to radial highways) and tax (property tax rate) variables have moderate VIF. 3.6.4 Interaction Terms Interaction between lstat and age: lm_medv_lstat_age &lt;- lm(medv ~ lstat * age, data = boston) tidy_custom(lm_medv_lstat_age) %&gt;% gt() html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #mqtkiucsjo .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #mqtkiucsjo .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #mqtkiucsjo .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #mqtkiucsjo .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #mqtkiucsjo .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #mqtkiucsjo .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #mqtkiucsjo .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #mqtkiucsjo .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #mqtkiucsjo .gt_column_spanner_outer:first-child { padding-left: 0; } #mqtkiucsjo .gt_column_spanner_outer:last-child { padding-right: 0; } #mqtkiucsjo .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #mqtkiucsjo .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #mqtkiucsjo .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #mqtkiucsjo .gt_from_md > :first-child { margin-top: 0; } #mqtkiucsjo .gt_from_md > :last-child { margin-bottom: 0; } #mqtkiucsjo .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #mqtkiucsjo .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #mqtkiucsjo .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #mqtkiucsjo .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #mqtkiucsjo .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #mqtkiucsjo .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #mqtkiucsjo .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #mqtkiucsjo .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #mqtkiucsjo .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #mqtkiucsjo .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #mqtkiucsjo .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #mqtkiucsjo .gt_sourcenote { font-size: 90%; padding: 4px; } #mqtkiucsjo .gt_left { text-align: left; } #mqtkiucsjo .gt_center { text-align: center; } #mqtkiucsjo .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #mqtkiucsjo .gt_font_normal { font-weight: normal; } #mqtkiucsjo .gt_font_bold { font-weight: bold; } #mqtkiucsjo .gt_font_italic { font-style: italic; } #mqtkiucsjo .gt_super { font-size: 65%; } #mqtkiucsjo .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } term coefficient std.error t-statistic p-value (Intercept) 36.089 1.4698 24.55 &lt;0.001 lstat -1.392 0.1675 -8.31 &lt;0.001 age -0.001 0.0199 -0.04 0.971 lstat:age 0.004 0.0019 2.24 0.025 3.6.5 Non-linear Transformations of the Predictors Perform a regression of medv onto lstat and lstat^2, and compare fits with anova: lm_medv_lstat2 &lt;- lm(medv ~ lstat + I(lstat^2), data = boston) anova(lm_medv_lstat, lm_medv_lstat2) ## Analysis of Variance Table ## ## Model 1: medv ~ lstat ## Model 2: medv ~ lstat + I(lstat^2) ## Res.Df RSS Df Sum of Sq F Pr(&gt;F) ## 1 504 19472 ## 2 503 15347 1 4125.1 135.2 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 The quadratic model is superior by the \\(F\\)-test. Check the residuals: performance::check_model(lm_medv_lstat2, check = &quot;linearity&quot;) The quadratic term is an obvious improvement, but still some non-linearity at large values of medv. The poly() function is a quick way to include higher order terms: # Orthogonalized predictors by default lm_medv_lstat5 &lt;- lm(medv ~ poly(lstat, 5), data = boston) tidy_custom(lm_medv_lstat5) ## # A tibble: 6 x 5 ## term coefficient std.error `t-statistic` `p-value` ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 (Intercept) 22.5 0.232 97.2 &lt;0.001 ## 2 poly(lstat, 5)1 -152. 5.21 -29.2 &lt;0.001 ## 3 poly(lstat, 5)2 64.2 5.21 12.3 &lt;0.001 ## 4 poly(lstat, 5)3 -27.1 5.21 -5.19 &lt;0.001 ## 5 poly(lstat, 5)4 25.5 5.21 4.88 &lt;0.001 ## 6 poly(lstat, 5)5 -19.3 5.21 -3.69 &lt;0.001 # Raw polynomials lm_medv_lstat5_raw &lt;- lm(medv ~ poly(lstat, 5, raw = TRUE), data = boston) tidy_custom(lm_medv_lstat5_raw) ## # A tibble: 6 x 5 ## term coefficient std.error `t-statistic` `p-value` ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 (Intercept) 67.7 3.60 18.8 &lt;0.001 ## 2 poly(lstat, 5, raw = TRUE)1 -12.0 1.53 -7.86 &lt;0.001 ## 3 poly(lstat, 5, raw = TRUE)2 1.27 0.223 5.7 &lt;0.001 ## 4 poly(lstat, 5, raw = TRUE)3 -0.068 0.0144 -4.75 &lt;0.001 ## 5 poly(lstat, 5, raw = TRUE)4 0.002 0.0004 4.14 &lt;0.001 ## 6 poly(lstat, 5, raw = TRUE)5 0 0 -3.69 &lt;0.001 3.6.6 Qualitative Predictors Load carseats: carseats &lt;- ISLR2::Carseats The contrasts() function shows the dummy coding for the qualitative ShelveLoc variable: contrasts(carseats$ShelveLoc) ## Good Medium ## Bad 0 0 ## Good 1 0 ## Medium 0 1 Fit the model and print the coefficients related to ShelveLoc: lm_sales &lt;- lm(Sales ~ . + Income:Advertising + Price:Age, data = carseats) tidy_custom(lm_sales) %&gt;% filter(str_detect(term, &quot;ShelveLoc|Intercept&quot;)) ## # A tibble: 3 x 5 ## term coefficient std.error `t-statistic` `p-value` ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 (Intercept) 6.58 1.01 6.52 &lt;0.001 ## 2 ShelveLocGood 4.85 0.153 31.7 &lt;0.001 ## 3 ShelveLocMedium 1.95 0.126 15.5 &lt;0.001 3.7 Exercises Applied Ill attempt to do these exercises in the tidymodels framework. library(tidymodels) 8. Simple linear regression with Auto This is way overkill for a simple linear regression, but here is a tidymodels workflow object for regressing mpg on horsepower: lm_mpg_hp_recipe &lt;- recipe(mpg ~ horsepower, data = auto) lm_mpg_hp_spec &lt;- linear_reg() %&gt;% set_mode(&quot;regression&quot;) %&gt;% set_engine(&quot;lm&quot;) lm_mpg_hp_workflow &lt;- workflow() %&gt;% add_recipe(lm_mpg_hp_recipe) %&gt;% add_model(lm_mpg_hp_spec) lm_mpg_hp_workflow ## == Workflow ==================================================================== ## Preprocessor: Recipe ## Model: linear_reg() ## ## -- Preprocessor ---------------------------------------------------------------- ## 0 Recipe Steps ## ## -- Model ----------------------------------------------------------------------- ## Linear Regression Model Specification (regression) ## ## Computational engine: lm Fit the model and print the estimates: lm_mpg_hp_fit &lt;- lm_mpg_hp_workflow %&gt;% fit(data = auto) tidy_custom(lm_mpg_hp_fit) %&gt;% gt() html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #grfxcerunh .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #grfxcerunh .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #grfxcerunh .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #grfxcerunh .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #grfxcerunh .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #grfxcerunh .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #grfxcerunh .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #grfxcerunh .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #grfxcerunh .gt_column_spanner_outer:first-child { padding-left: 0; } #grfxcerunh .gt_column_spanner_outer:last-child { padding-right: 0; } #grfxcerunh .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #grfxcerunh .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #grfxcerunh .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #grfxcerunh .gt_from_md > :first-child { margin-top: 0; } #grfxcerunh .gt_from_md > :last-child { margin-bottom: 0; } #grfxcerunh .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #grfxcerunh .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #grfxcerunh .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #grfxcerunh .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #grfxcerunh .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #grfxcerunh .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #grfxcerunh .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #grfxcerunh .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #grfxcerunh .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #grfxcerunh .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #grfxcerunh .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #grfxcerunh .gt_sourcenote { font-size: 90%; padding: 4px; } #grfxcerunh .gt_left { text-align: left; } #grfxcerunh .gt_center { text-align: center; } #grfxcerunh .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #grfxcerunh .gt_font_normal { font-weight: normal; } #grfxcerunh .gt_font_bold { font-weight: bold; } #grfxcerunh .gt_font_italic { font-style: italic; } #grfxcerunh .gt_super { font-size: 65%; } #grfxcerunh .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } term coefficient std.error t-statistic p-value (Intercept) 39.936 0.7175 55.66 &lt;0.001 horsepower -0.158 0.0064 -24.49 &lt;0.001 The tidymodels framework uses the same functions as we have seen (the engine specifies the lm function), but in principled fashion with a standardized interface. We can extract the actual lm object from lm_mpg_hp_fit using extract_fit_engine() lm_mpg_hp_fit_engine &lt;- lm_mpg_hp_fit %&gt;% extract_fit_engine() summary(lm_mpg_hp_fit_engine) ## ## Call: ## stats::lm(formula = ..y ~ ., data = data) ## ## Residuals: ## Min 1Q Median 3Q Max ## -13.5710 -3.2592 -0.3435 2.7630 16.9240 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 39.935861 0.717499 55.66 &lt;2e-16 *** ## horsepower -0.157845 0.006446 -24.49 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 4.906 on 390 degrees of freedom ## Multiple R-squared: 0.6059, Adjusted R-squared: 0.6049 ## F-statistic: 599.7 on 1 and 390 DF, p-value: &lt; 2.2e-16 Observations on the model: There is a relationship between mpg and horsepower. Is is highly significant (\\(p\\) &lt;0.001) with \\(R^2\\) = 0.61 The relationship is negative. Every unit of horsepower is associated with a -0.16 reduction in miles per gallon. The confidence and prediction intervals of predicted mpg given horsepower = 98: predict(lm_mpg_hp_fit, tibble(horsepower = 98), type = &quot;conf_int&quot;, # Don&#39;t have to call this, because it is the default value level = 0.95) ## # A tibble: 1 x 2 ## .pred_lower .pred_upper ## &lt;dbl&gt; &lt;dbl&gt; ## 1 24.0 25.0 predict(lm_mpg_hp_fit, tibble(horsepower = 98), type = &quot;pred_int&quot;) ## # A tibble: 1 x 2 ## .pred_lower .pred_upper ## &lt;dbl&gt; &lt;dbl&gt; ## 1 14.8 34.1 Note that the lm_mpg_hp_fit is a workflow object, and so the parsnip::predict.model_fit() function takes a different argument (type) to specify confidence/prediction intervals. Before, we were calling predict.lm() which uses the interval argument. Note that it also doesnt return the point estimate, just the lower and upper values. Plot with best fit line: auto %&gt;% ggplot(aes(x = horsepower)) + geom_point(aes(y = mpg), size = 2, alpha = 0.4) + geom_abline(slope = coef(lm_mpg_hp_fit_engine)[&quot;horsepower&quot;], intercept = coef(lm_mpg_hp_fit_engine)[&quot;(Intercept)&quot;], size = 2, color = td_colors$nice$emerald) Diagnostic plots: lm_mpg_hp_fit_engine %&gt;% performance::check_model() Two potential problems: non-linearity (top left plot) and homogeneity of variance (top right). 9. Multiple linear regression with Auto Scatterplot of all variables. For quickly producing these correlation matrices, I like the GGally::ggpairs() function: GGally::ggpairs(auto %&gt;% select(-name)) ## Registered S3 method overwritten by &#39;GGally&#39;: ## method from ## +.gg ggplot2 Compute the correlations. The above plot shows the correlation coefficients, but here is the cor() output: cor(auto %&gt;% select(-name)) ## mpg cylinders displacement horsepower weight ## mpg 1.0000000 -0.7776175 -0.8051269 -0.7784268 -0.8322442 ## cylinders -0.7776175 1.0000000 0.9508233 0.8429834 0.8975273 ## displacement -0.8051269 0.9508233 1.0000000 0.8972570 0.9329944 ## horsepower -0.7784268 0.8429834 0.8972570 1.0000000 0.8645377 ## weight -0.8322442 0.8975273 0.9329944 0.8645377 1.0000000 ## acceleration 0.4233285 -0.5046834 -0.5438005 -0.6891955 -0.4168392 ## year 0.5805410 -0.3456474 -0.3698552 -0.4163615 -0.3091199 ## origin 0.5652088 -0.5689316 -0.6145351 -0.4551715 -0.5850054 ## acceleration year origin ## mpg 0.4233285 0.5805410 0.5652088 ## cylinders -0.5046834 -0.3456474 -0.5689316 ## displacement -0.5438005 -0.3698552 -0.6145351 ## horsepower -0.6891955 -0.4163615 -0.4551715 ## weight -0.4168392 -0.3091199 -0.5850054 ## acceleration 1.0000000 0.2903161 0.2127458 ## year 0.2903161 1.0000000 0.1815277 ## origin 0.2127458 0.1815277 1.0000000 Fit the multiple linear regression. lm_mpg_recipe &lt;- recipe(mpg ~ ., data = auto) %&gt;% step_rm(name) # Skip the spec step, and just put it directly into the workflow lm_mpg_workflow &lt;- workflow() %&gt;% add_recipe(lm_mpg_recipe) %&gt;% # By default, linear_reg() will use lm as the engine and regression as mode add_model(linear_reg()) lm_mpg_workflow ## == Workflow ==================================================================== ## Preprocessor: Recipe ## Model: linear_reg() ## ## -- Preprocessor ---------------------------------------------------------------- ## 1 Recipe Step ## ## * step_rm() ## ## -- Model ----------------------------------------------------------------------- ## Linear Regression Model Specification (regression) ## ## Computational engine: lm lm_mpg_fit &lt;- lm_mpg_workflow %&gt;% fit(data = auto) lm_mpg_fit_engine &lt;- extract_fit_engine(lm_mpg_fit) summary(lm_mpg_fit_engine) ## ## Call: ## stats::lm(formula = ..y ~ ., data = data) ## ## Residuals: ## Min 1Q Median 3Q Max ## -9.5903 -2.1565 -0.1169 1.8690 13.0604 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -17.218435 4.644294 -3.707 0.00024 *** ## cylinders -0.493376 0.323282 -1.526 0.12780 ## displacement 0.019896 0.007515 2.647 0.00844 ** ## horsepower -0.016951 0.013787 -1.230 0.21963 ## weight -0.006474 0.000652 -9.929 &lt; 2e-16 *** ## acceleration 0.080576 0.098845 0.815 0.41548 ## year 0.750773 0.050973 14.729 &lt; 2e-16 *** ## origin 1.426141 0.278136 5.127 4.67e-07 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 3.328 on 384 degrees of freedom ## Multiple R-squared: 0.8215, Adjusted R-squared: 0.8182 ## F-statistic: 252.4 on 7 and 384 DF, p-value: &lt; 2.2e-16 There is a relationship between the predictors and mpg: \\(F\\) = 252.4 The following terms are statistically significant: (Intercept), displacement, weight, year, origin The coefficient for year suggests that, for every increment in car model year, mpg increases by 0.75 Diagnostic plots. lm_mpg_fit %&gt;% extract_fit_engine() %&gt;% performance::check_model() Some non-linearity and moderate collinearity. There is a point with high leverage, but it has a fairly small standardized residual. 10. Multiple linear regression with Carseats Fit a model to predict Sales using Price, Urban, and US. For demonstration, here Ill use the minimal code possible while still using tidymodels (i.e. skip recipe and workflow steps): lm_sales_price_urban_us_fit &lt;- linear_reg() %&gt;% # default engine = &quot;lm&quot; fit(Sales ~ Price + Urban + US, data = carseats) fit_tidy &lt;- tidy(lm_sales_price_urban_us_fit) tidy_custom(lm_sales_price_urban_us_fit) %&gt;% gt() html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #kilmffetek .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #kilmffetek .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #kilmffetek .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #kilmffetek .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #kilmffetek .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #kilmffetek .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #kilmffetek .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #kilmffetek .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #kilmffetek .gt_column_spanner_outer:first-child { padding-left: 0; } #kilmffetek .gt_column_spanner_outer:last-child { padding-right: 0; } #kilmffetek .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #kilmffetek .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #kilmffetek .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #kilmffetek .gt_from_md > :first-child { margin-top: 0; } #kilmffetek .gt_from_md > :last-child { margin-bottom: 0; } #kilmffetek .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #kilmffetek .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #kilmffetek .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #kilmffetek .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #kilmffetek .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #kilmffetek .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #kilmffetek .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #kilmffetek .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #kilmffetek .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #kilmffetek .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #kilmffetek .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #kilmffetek .gt_sourcenote { font-size: 90%; padding: 4px; } #kilmffetek .gt_left { text-align: left; } #kilmffetek .gt_center { text-align: center; } #kilmffetek .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #kilmffetek .gt_font_normal { font-weight: normal; } #kilmffetek .gt_font_bold { font-weight: bold; } #kilmffetek .gt_font_italic { font-style: italic; } #kilmffetek .gt_super { font-size: 65%; } #kilmffetek .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } term coefficient std.error t-statistic p-value (Intercept) 13.043 0.6510 20.04 &lt;0.001 Price -0.054 0.0052 -10.39 &lt;0.001 UrbanYes -0.022 0.2717 -0.08 0.936 USYes 1.201 0.2590 4.63 &lt;0.001 Provide an interpretation of each coefficient. There is a significant negative relationship between Sales and Price: A difference of -0.054 thousand unit sales per dollar of price There is no significant association between Urban and Sales: Urban stores sell -0.022 thousand units compared to non-urban There is a significant difference between US and non-US stores. US stores sell 1.2 thousand more units on average compared to non-US Write out the model formula. There is a nice package called equatiomatic for writing out model formulae: lm_sales_price_urban_us_fit %&gt;% extract_fit_engine() %&gt;% equatiomatic::extract_eq() \\[ \\operatorname{Sales} = \\alpha + \\beta_{1}(\\operatorname{Price}) + \\beta_{2}(\\operatorname{Urban}_{\\operatorname{Yes}}) + \\beta_{3}(\\operatorname{US}_{\\operatorname{Yes}}) + \\epsilon \\] Note that it uses \\(\\alpha\\), rather than \\(\\beta_0\\), to represent intercepts by default. For which predictions can you reject the null hypothesis \\(H_0: \\beta_j = 0\\)? For \\(\\beta_1\\) (Price) and \\(\\beta_3\\) (US). Fit a smaller model with just the predictors in (d). lm_sales_price_us_fit &lt;- linear_reg() %&gt;% fit(Sales ~ Price + US, data = carseats) tidy_custom(lm_sales_price_us_fit) %&gt;% gt() html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #oruyigwlpq .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #oruyigwlpq .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #oruyigwlpq .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #oruyigwlpq .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #oruyigwlpq .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #oruyigwlpq .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #oruyigwlpq .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #oruyigwlpq .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #oruyigwlpq .gt_column_spanner_outer:first-child { padding-left: 0; } #oruyigwlpq .gt_column_spanner_outer:last-child { padding-right: 0; } #oruyigwlpq .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #oruyigwlpq .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #oruyigwlpq .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #oruyigwlpq .gt_from_md > :first-child { margin-top: 0; } #oruyigwlpq .gt_from_md > :last-child { margin-bottom: 0; } #oruyigwlpq .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #oruyigwlpq .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #oruyigwlpq .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #oruyigwlpq .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #oruyigwlpq .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #oruyigwlpq .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #oruyigwlpq .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #oruyigwlpq .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #oruyigwlpq .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #oruyigwlpq .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #oruyigwlpq .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #oruyigwlpq .gt_sourcenote { font-size: 90%; padding: 4px; } #oruyigwlpq .gt_left { text-align: left; } #oruyigwlpq .gt_center { text-align: center; } #oruyigwlpq .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #oruyigwlpq .gt_font_normal { font-weight: normal; } #oruyigwlpq .gt_font_bold { font-weight: bold; } #oruyigwlpq .gt_font_italic { font-style: italic; } #oruyigwlpq .gt_super { font-size: 65%; } #oruyigwlpq .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } term coefficient std.error t-statistic p-value (Intercept) 13.031 0.6310 20.65 &lt;0.001 Price -0.054 0.0052 -10.42 &lt;0.001 USYes 1.200 0.2585 4.64 &lt;0.001 How well do the model fits the data? bind_rows( bind_cols(model = &quot;small&quot;, glance(lm_sales_price_us_fit)), bind_cols(model = &quot;full&quot;, glance(lm_sales_price_urban_us_fit)) ) %&gt;% transmute( model, R2 = round(r.squared, 3), RSE = round(sigma, 3) ) %&gt;% gt() html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #dgjputwqqb .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #dgjputwqqb .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #dgjputwqqb .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #dgjputwqqb .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #dgjputwqqb .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #dgjputwqqb .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #dgjputwqqb .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #dgjputwqqb .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #dgjputwqqb .gt_column_spanner_outer:first-child { padding-left: 0; } #dgjputwqqb .gt_column_spanner_outer:last-child { padding-right: 0; } #dgjputwqqb .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #dgjputwqqb .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #dgjputwqqb .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #dgjputwqqb .gt_from_md > :first-child { margin-top: 0; } #dgjputwqqb .gt_from_md > :last-child { margin-bottom: 0; } #dgjputwqqb .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #dgjputwqqb .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #dgjputwqqb .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #dgjputwqqb .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #dgjputwqqb .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #dgjputwqqb .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #dgjputwqqb .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #dgjputwqqb .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #dgjputwqqb .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #dgjputwqqb .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #dgjputwqqb .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #dgjputwqqb .gt_sourcenote { font-size: 90%; padding: 4px; } #dgjputwqqb .gt_left { text-align: left; } #dgjputwqqb .gt_center { text-align: center; } #dgjputwqqb .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #dgjputwqqb .gt_font_normal { font-weight: normal; } #dgjputwqqb .gt_font_bold { font-weight: bold; } #dgjputwqqb .gt_font_italic { font-style: italic; } #dgjputwqqb .gt_super { font-size: 65%; } #dgjputwqqb .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } model R2 RSE small 0.239 2.469 full 0.239 2.472 Excluding Urban makes no difference to \\(R^2\\). Run an \\(F\\)-test as well: anova( extract_fit_engine(lm_sales_price_urban_us_fit), extract_fit_engine(lm_sales_price_us_fit) ) ## Analysis of Variance Table ## ## Model 1: Sales ~ Price + Urban + US ## Model 2: Sales ~ Price + US ## Res.Df RSS Df Sum of Sq F Pr(&gt;F) ## 1 396 2420.8 ## 2 397 2420.9 -1 -0.03979 0.0065 0.9357 Obtain 95% confidence intervals for the coefficients from (e). tidy(lm_sales_price_us_fit, conf.int = 0.95) %&gt;% transmute( term, across(c(estimate, conf.low, conf.high), round, 3) ) %&gt;% gt() html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #avwurmfizk .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #avwurmfizk .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #avwurmfizk .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #avwurmfizk .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #avwurmfizk .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #avwurmfizk .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #avwurmfizk .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #avwurmfizk .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #avwurmfizk .gt_column_spanner_outer:first-child { padding-left: 0; } #avwurmfizk .gt_column_spanner_outer:last-child { padding-right: 0; } #avwurmfizk .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #avwurmfizk .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #avwurmfizk .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #avwurmfizk .gt_from_md > :first-child { margin-top: 0; } #avwurmfizk .gt_from_md > :last-child { margin-bottom: 0; } #avwurmfizk .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #avwurmfizk .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #avwurmfizk .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #avwurmfizk .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #avwurmfizk .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #avwurmfizk .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #avwurmfizk .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #avwurmfizk .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #avwurmfizk .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #avwurmfizk .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #avwurmfizk .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #avwurmfizk .gt_sourcenote { font-size: 90%; padding: 4px; } #avwurmfizk .gt_left { text-align: left; } #avwurmfizk .gt_center { text-align: center; } #avwurmfizk .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #avwurmfizk .gt_font_normal { font-weight: normal; } #avwurmfizk .gt_font_bold { font-weight: bold; } #avwurmfizk .gt_font_italic { font-style: italic; } #avwurmfizk .gt_super { font-size: 65%; } #avwurmfizk .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } term estimate conf.low conf.high (Intercept) 13.031 11.790 14.271 Price -0.054 -0.065 -0.044 USYes 1.200 0.692 1.708 Is there evidence of outliers or high leverage observations in the model from (e)? lm_sales_price_us_fit %&gt;% performance::check_model(check = &quot;outliers&quot;) No evidence of outliers or high leverage points. 13. Simple linear regression to simulated data set.seed(1) Generate 100 observations from \\(N(0,1)\\). x &lt;- rnorm(100, 0, 1) Generate 100 observations from \\(N(0, 0.25)\\). eps &lt;- rnorm(100, 0, 0.25) Generate \\(Y = -1 + 0.5 X + \\epsilon\\) y &lt;- -1 + 0.5 * x + eps length(y) ## [1] 100 \\(\\beta_0\\) = -1, and \\(\\beta_1\\) = 0.5. Scatterplot between x and y. d &lt;- tibble(x, y) p &lt;- ggplot(d) + geom_point(aes(x, y)) p Fit the simple linear regression and compare estimates to simulation parameters. lm_y_x &lt;- lm(y ~ x, data = d) tidy_custom(lm_y_x) %&gt;% gt() html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #maszwdpqyg .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #maszwdpqyg .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #maszwdpqyg .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #maszwdpqyg .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #maszwdpqyg .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #maszwdpqyg .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #maszwdpqyg .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #maszwdpqyg .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #maszwdpqyg .gt_column_spanner_outer:first-child { padding-left: 0; } #maszwdpqyg .gt_column_spanner_outer:last-child { padding-right: 0; } #maszwdpqyg .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #maszwdpqyg .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #maszwdpqyg .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #maszwdpqyg .gt_from_md > :first-child { margin-top: 0; } #maszwdpqyg .gt_from_md > :last-child { margin-bottom: 0; } #maszwdpqyg .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #maszwdpqyg .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #maszwdpqyg .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #maszwdpqyg .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #maszwdpqyg .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #maszwdpqyg .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #maszwdpqyg .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #maszwdpqyg .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #maszwdpqyg .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #maszwdpqyg .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #maszwdpqyg .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #maszwdpqyg .gt_sourcenote { font-size: 90%; padding: 4px; } #maszwdpqyg .gt_left { text-align: left; } #maszwdpqyg .gt_center { text-align: center; } #maszwdpqyg .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #maszwdpqyg .gt_font_normal { font-weight: normal; } #maszwdpqyg .gt_font_bold { font-weight: bold; } #maszwdpqyg .gt_font_italic { font-style: italic; } #maszwdpqyg .gt_super { font-size: 65%; } #maszwdpqyg .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } term coefficient std.error t-statistic p-value (Intercept) -1.009 0.0242 -41.63 &lt;0.001 x 0.500 0.0269 18.56 &lt;0.001 \\(\\hat{\\beta_0}\\) and \\(\\hat{\\beta_1}\\) are very close (essentially equal) to the simulation values. Plot the least squares and population regression lines. d_lines &lt;- tribble( ~line, ~slope, ~intercept, &quot;Population&quot;, 0.5, -1, &quot;Least squares&quot;, coef(lm_y_x)[2], coef(lm_y_x)[1] ) p + geom_abline( data = d_lines, aes(slope = slope, intercept = intercept, color = line), size = 1.5, alpha = 0.5 ) + labs(color = NULL) + theme(legend.position = &quot;top&quot;) Exactly on top of each other. Fit a polynomial regression using \\(x^2\\). lm_y_x2 &lt;- lm(y ~ x + I(x^2), data = d) anova(lm_y_x, lm_y_x2) ## Analysis of Variance Table ## ## Model 1: y ~ x ## Model 2: y ~ x + I(x^2) ## Res.Df RSS Df Sum of Sq F Pr(&gt;F) ## 1 98 5.6772 ## 2 97 5.5643 1 0.11291 1.9682 0.1638 By an \\(F\\)-test, the \\(x^2\\) term did not improve the model fit. We can also look at \\(R^2\\): c(summary(lm_y_x)$r.squared, summary(lm_y_x2)$r.squared) ## [1] 0.7784361 0.7828424 Repeat with less noise. d_less &lt;- tibble( x, y = -1 + 0.5 * x + rnorm(100, 0, 0.1) ) lm_y_x_less &lt;- lm(y ~ x, data = d_less) p &lt;- ggplot(d_less) + geom_point(aes(x, y)) p d_lines &lt;- tribble( ~line, ~slope, ~intercept, &quot;Population&quot;, 0.5, -1, &quot;Least squares&quot;, coef(lm_y_x_less)[2], coef(lm_y_x_less)[1] ) p + geom_abline( data = d_lines, aes(slope = slope, intercept = intercept, color = line), size = 1.5, alpha = 0.5 ) + labs(color = NULL) + theme(legend.position = &quot;top&quot;) Repeat with more noise. d_more &lt;- tibble( x, y = -1 + 0.5*x + rnorm(100, 0, 0.5) ) lm_y_x_more &lt;- lm(y ~ x, data = d_more) p &lt;- ggplot(d_more) + geom_point(aes(x, y)) p d_lines &lt;- tribble( ~line, ~slope, ~intercept, &quot;Population&quot;, 0.5, -1, &quot;Least squares&quot;, coef(lm_y_x_more)[2], coef(lm_y_x_more)[1] ) p + geom_abline( data = d_lines, aes(slope = slope, intercept = intercept, color = line), size = 1.5, alpha = 0.5 ) + labs(color = NULL) + theme(legend.position = &quot;top&quot;) What are the confidence intervals of the coefficients for the different data? bind_rows( bind_cols(data = &quot;original&quot;, tidy(lm_y_x, conf.int = 0.95)), bind_cols(data = &quot;less&quot;, tidy(lm_y_x_less, conf.int = 0.95)), bind_cols(data = &quot;more&quot;, tidy(lm_y_x_more, conf.int = 0.95)) ) %&gt;% transmute( data, term, across(c(estimate, conf.low, conf.high), round, 3) ) %&gt;% group_by(data) %&gt;% gt(rowname_col = &quot;term&quot;) html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #aabxdtuftx .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #aabxdtuftx .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #aabxdtuftx .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #aabxdtuftx .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #aabxdtuftx .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #aabxdtuftx .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #aabxdtuftx .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #aabxdtuftx .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #aabxdtuftx .gt_column_spanner_outer:first-child { padding-left: 0; } #aabxdtuftx .gt_column_spanner_outer:last-child { padding-right: 0; } #aabxdtuftx .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #aabxdtuftx .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #aabxdtuftx .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #aabxdtuftx .gt_from_md > :first-child { margin-top: 0; } #aabxdtuftx .gt_from_md > :last-child { margin-bottom: 0; } #aabxdtuftx .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #aabxdtuftx .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #aabxdtuftx .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #aabxdtuftx .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #aabxdtuftx .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #aabxdtuftx .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #aabxdtuftx .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #aabxdtuftx .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #aabxdtuftx .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #aabxdtuftx .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #aabxdtuftx .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #aabxdtuftx .gt_sourcenote { font-size: 90%; padding: 4px; } #aabxdtuftx .gt_left { text-align: left; } #aabxdtuftx .gt_center { text-align: center; } #aabxdtuftx .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #aabxdtuftx .gt_font_normal { font-weight: normal; } #aabxdtuftx .gt_font_bold { font-weight: bold; } #aabxdtuftx .gt_font_italic { font-style: italic; } #aabxdtuftx .gt_super { font-size: 65%; } #aabxdtuftx .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } estimate conf.low conf.high original (Intercept) -1.009 -1.058 -0.961 x 0.500 0.446 0.553 less (Intercept) -0.991 -1.012 -0.970 x 0.483 0.459 0.506 more (Intercept) -1.023 -1.118 -0.927 x 0.549 0.443 0.656 14. Collineratiy simulation Simulate. set.seed(1) d &lt;- tibble( x1 = runif(100), x2 = 0.5 * x1 + rnorm(100) / 10, y = 2 + 2 * x1 + 0.3 * x2 + rnorm(100) ) \\[ Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\epsilon \\] \\(\\beta_0\\) = 2, \\(\\beta_1\\) = 2, and \\(\\beta_2\\) = 0.3. Correlation between \\(X_1\\) and \\(X_2\\). cor(d) ## x1 x2 y ## x1 1.0000000 0.8351212 0.4498446 ## x2 0.8351212 1.0000000 0.4199171 ## y 0.4498446 0.4199171 1.0000000 Unsurprisingly very high, \\(r\\) = 0.835. Fit the regression model. lm_y_x1_x2 &lt;- linear_reg() %&gt;% fit(y ~ x1 + x2, data = d) tidy_custom(lm_y_x1_x2) %&gt;% gt() html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #swqeswtyiu .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #swqeswtyiu .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #swqeswtyiu .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #swqeswtyiu .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #swqeswtyiu .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #swqeswtyiu .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #swqeswtyiu .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #swqeswtyiu .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #swqeswtyiu .gt_column_spanner_outer:first-child { padding-left: 0; } #swqeswtyiu .gt_column_spanner_outer:last-child { padding-right: 0; } #swqeswtyiu .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #swqeswtyiu .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #swqeswtyiu .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #swqeswtyiu .gt_from_md > :first-child { margin-top: 0; } #swqeswtyiu .gt_from_md > :last-child { margin-bottom: 0; } #swqeswtyiu .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #swqeswtyiu .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #swqeswtyiu .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #swqeswtyiu .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #swqeswtyiu .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #swqeswtyiu .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #swqeswtyiu .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #swqeswtyiu .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #swqeswtyiu .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #swqeswtyiu .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #swqeswtyiu .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #swqeswtyiu .gt_sourcenote { font-size: 90%; padding: 4px; } #swqeswtyiu .gt_left { text-align: left; } #swqeswtyiu .gt_center { text-align: center; } #swqeswtyiu .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #swqeswtyiu .gt_font_normal { font-weight: normal; } #swqeswtyiu .gt_font_bold { font-weight: bold; } #swqeswtyiu .gt_font_italic { font-style: italic; } #swqeswtyiu .gt_super { font-size: 65%; } #swqeswtyiu .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } term coefficient std.error t-statistic p-value (Intercept) 2.13 0.2319 9.19 &lt;0.001 x1 1.44 0.7212 2.00 0.049 x2 1.01 1.1337 0.89 0.375 We can reject the null that \\(\\beta_2 = 0\\), but not for \\(\\beta_1\\). The estimates are nowhere close to the true values. Fit the model of \\(Y\\) and \\(X_1\\). lm_y_x1 &lt;- linear_reg() %&gt;% fit(y ~ x1, data = d) tidy_custom(lm_y_x1) %&gt;% gt() html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #uosexngzmz .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #uosexngzmz .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #uosexngzmz .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #uosexngzmz .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #uosexngzmz .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #uosexngzmz .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #uosexngzmz .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #uosexngzmz .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #uosexngzmz .gt_column_spanner_outer:first-child { padding-left: 0; } #uosexngzmz .gt_column_spanner_outer:last-child { padding-right: 0; } #uosexngzmz .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #uosexngzmz .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #uosexngzmz .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #uosexngzmz .gt_from_md > :first-child { margin-top: 0; } #uosexngzmz .gt_from_md > :last-child { margin-bottom: 0; } #uosexngzmz .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #uosexngzmz .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #uosexngzmz .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #uosexngzmz .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #uosexngzmz .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #uosexngzmz .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #uosexngzmz .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #uosexngzmz .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #uosexngzmz .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #uosexngzmz .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #uosexngzmz .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #uosexngzmz .gt_sourcenote { font-size: 90%; padding: 4px; } #uosexngzmz .gt_left { text-align: left; } #uosexngzmz .gt_center { text-align: center; } #uosexngzmz .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #uosexngzmz .gt_font_normal { font-weight: normal; } #uosexngzmz .gt_font_bold { font-weight: bold; } #uosexngzmz .gt_font_italic { font-style: italic; } #uosexngzmz .gt_super { font-size: 65%; } #uosexngzmz .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } term coefficient std.error t-statistic p-value (Intercept) 2.112 0.2307 9.15 &lt;0.001 x1 1.976 0.3963 4.99 &lt;0.001 We recover the approximate true parameter, and reject the null. Fit the model of \\(Y\\) and \\(X_2\\). lm_y_x2 &lt;- linear_reg() %&gt;% fit(y ~ x2, data = d) tidy_custom(lm_y_x2) %&gt;% gt() html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #orfbuaqmum .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #orfbuaqmum .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #orfbuaqmum .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #orfbuaqmum .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #orfbuaqmum .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #orfbuaqmum .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #orfbuaqmum .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #orfbuaqmum .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #orfbuaqmum .gt_column_spanner_outer:first-child { padding-left: 0; } #orfbuaqmum .gt_column_spanner_outer:last-child { padding-right: 0; } #orfbuaqmum .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #orfbuaqmum .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #orfbuaqmum .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #orfbuaqmum .gt_from_md > :first-child { margin-top: 0; } #orfbuaqmum .gt_from_md > :last-child { margin-bottom: 0; } #orfbuaqmum .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #orfbuaqmum .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #orfbuaqmum .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #orfbuaqmum .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #orfbuaqmum .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #orfbuaqmum .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #orfbuaqmum .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #orfbuaqmum .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #orfbuaqmum .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #orfbuaqmum .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #orfbuaqmum .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #orfbuaqmum .gt_sourcenote { font-size: 90%; padding: 4px; } #orfbuaqmum .gt_left { text-align: left; } #orfbuaqmum .gt_center { text-align: center; } #orfbuaqmum .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #orfbuaqmum .gt_font_normal { font-weight: normal; } #orfbuaqmum .gt_font_bold { font-weight: bold; } #orfbuaqmum .gt_font_italic { font-style: italic; } #orfbuaqmum .gt_super { font-size: 65%; } #orfbuaqmum .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } term coefficient std.error t-statistic p-value (Intercept) 2.39 0.1949 12.26 &lt;0.001 x2 2.90 0.6330 4.58 &lt;0.001 We can reject the null, but dont recover \\(\\beta_2 = 0.3\\). Do the results contradict each other? Yes, the models give much different results. 15. Univariable and multivariable regression on Boston Fit univariable models. lm_crim_uni &lt;- tibble( # Get a list of predictors predictor = names(boston)[names(boston) != &quot;crim&quot;] ) %&gt;% mutate( mod = map( predictor, ~lm(as.formula(paste0(&quot;crim ~ &quot;, .x)), data = boston) ), mod_tidy = map(mod, broom::tidy) ) These associations were statistical significant at \\(\\alpha = 0.05\\): lm_crim_uni %&gt;% unnest(mod_tidy) %&gt;% filter(term != &quot;(Intercept)&quot;, p.value &lt; 0.05) %&gt;% transmute( predictor, estimate = signif(estimate, 4), p.value = scales::pvalue(p.value) ) %&gt;% gt() html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #zhbiyhxytn .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #zhbiyhxytn .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #zhbiyhxytn .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #zhbiyhxytn .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #zhbiyhxytn .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #zhbiyhxytn .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #zhbiyhxytn .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #zhbiyhxytn .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #zhbiyhxytn .gt_column_spanner_outer:first-child { padding-left: 0; } #zhbiyhxytn .gt_column_spanner_outer:last-child { padding-right: 0; } #zhbiyhxytn .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #zhbiyhxytn .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #zhbiyhxytn .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #zhbiyhxytn .gt_from_md > :first-child { margin-top: 0; } #zhbiyhxytn .gt_from_md > :last-child { margin-bottom: 0; } #zhbiyhxytn .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #zhbiyhxytn .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #zhbiyhxytn .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #zhbiyhxytn .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #zhbiyhxytn .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #zhbiyhxytn .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #zhbiyhxytn .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #zhbiyhxytn .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #zhbiyhxytn .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #zhbiyhxytn .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #zhbiyhxytn .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #zhbiyhxytn .gt_sourcenote { font-size: 90%; padding: 4px; } #zhbiyhxytn .gt_left { text-align: left; } #zhbiyhxytn .gt_center { text-align: center; } #zhbiyhxytn .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #zhbiyhxytn .gt_font_normal { font-weight: normal; } #zhbiyhxytn .gt_font_bold { font-weight: bold; } #zhbiyhxytn .gt_font_italic { font-style: italic; } #zhbiyhxytn .gt_super { font-size: 65%; } #zhbiyhxytn .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } predictor estimate p.value zn -0.07393 &lt;0.001 indus 0.50980 &lt;0.001 nox 31.25000 &lt;0.001 rm -2.68400 &lt;0.001 age 0.10780 &lt;0.001 dis -1.55100 &lt;0.001 rad 0.61790 &lt;0.001 tax 0.02974 &lt;0.001 ptratio 1.15200 &lt;0.001 lstat 0.54880 &lt;0.001 medv -0.36320 &lt;0.001 Fit the multiple regression. lm_crim_mult &lt;- lm(crim ~ ., data = boston) tidy_custom(lm_crim_mult) %&gt;% gt() html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #ztejltwxob .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #ztejltwxob .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #ztejltwxob .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #ztejltwxob .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #ztejltwxob .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #ztejltwxob .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #ztejltwxob .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #ztejltwxob .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #ztejltwxob .gt_column_spanner_outer:first-child { padding-left: 0; } #ztejltwxob .gt_column_spanner_outer:last-child { padding-right: 0; } #ztejltwxob .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #ztejltwxob .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #ztejltwxob .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #ztejltwxob .gt_from_md > :first-child { margin-top: 0; } #ztejltwxob .gt_from_md > :last-child { margin-bottom: 0; } #ztejltwxob .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #ztejltwxob .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #ztejltwxob .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #ztejltwxob .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #ztejltwxob .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #ztejltwxob .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #ztejltwxob .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #ztejltwxob .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #ztejltwxob .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #ztejltwxob .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #ztejltwxob .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #ztejltwxob .gt_sourcenote { font-size: 90%; padding: 4px; } #ztejltwxob .gt_left { text-align: left; } #ztejltwxob .gt_center { text-align: center; } #ztejltwxob .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #ztejltwxob .gt_font_normal { font-weight: normal; } #ztejltwxob .gt_font_bold { font-weight: bold; } #ztejltwxob .gt_font_italic { font-style: italic; } #ztejltwxob .gt_super { font-size: 65%; } #ztejltwxob .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } term coefficient std.error t-statistic p-value (Intercept) 13.778 7.0818 1.95 0.052 zn 0.046 0.0188 2.43 0.015 indus -0.058 0.0836 -0.70 0.486 chas -0.825 1.1834 -0.70 0.486 nox -9.958 5.2898 -1.88 0.060 rm 0.629 0.6071 1.04 0.301 age -0.001 0.0179 -0.05 0.962 dis -1.012 0.2825 -3.58 &lt;0.001 rad 0.612 0.0875 7.00 &lt;0.001 tax -0.004 0.0052 -0.73 0.466 ptratio -0.304 0.1864 -1.63 0.103 lstat 0.139 0.0757 1.83 0.067 medv -0.220 0.0598 -3.68 &lt;0.001 We reject the null for these predictors: zn, dis, rad, medv Compare regression estimates. lm_crim_estimates &lt;- lm_crim_uni %&gt;% unnest(mod_tidy) %&gt;% filter(term != &quot;(Intercept)&quot;) %&gt;% transmute( model = &quot;univariable&quot;, term, estimate ) %&gt;% bind_rows( tidy(lm_crim_mult) %&gt;% filter(term != &quot;(Intercept)&quot;) %&gt;% transmute( model = &quot;multivariable&quot;, term, estimate ) ) %&gt;% pivot_wider(names_from = model, values_from = estimate) lm_crim_estimates %&gt;% ggplot(aes(x = univariable, y = multivariable)) + geom_point(size = 2) + geom_abline(slope = 1, intercept = 0) One really bad outlier: lm_crim_estimates %&gt;% filter(univariable &gt; 20) ## # A tibble: 1 x 3 ## term univariable multivariable ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 nox 31.2 -9.96 Exclude that term and label the points: lm_crim_estimates %&gt;% filter(univariable &lt; 20) %&gt;% ggplot(aes(x = univariable, y = multivariable)) + geom_point(size = 2) + ggrepel::geom_text_repel(aes(label = term)) + geom_abline(slope = 1, intercept = 0) Is there evidence of non-linear association for any predictors? lm_crim_uni_poly &lt;- tibble( predictor = names(boston)[names(boston) != &quot;crim&quot;] ) %&gt;% mutate( mod = map( predictor, ~lm(as.formula(paste0(&quot;crim ~ poly(&quot;, .x, &quot;, 3)&quot;)), data = boston) ), mod_tidy = map(mod, broom::tidy) ) ## Error in `mutate()`: ## ! Problem while computing `mod = map(...)`. ## Caused by error in `poly()`: ## ! &#39;degree&#39; must be less than number of unique points One of these models returned an error because the predictor does not have enough unique points to use polynomial regression. Look at the number of unique values for each variable in boston: boston %&gt;% pivot_longer(everything()) %&gt;% group_by(name) %&gt;% summarise(n_unique_vals = n_distinct(value), .groups = &quot;drop&quot;) %&gt;% arrange(n_unique_vals) ## # A tibble: 13 x 2 ## name n_unique_vals ## &lt;chr&gt; &lt;int&gt; ## 1 chas 2 ## 2 rad 9 ## 3 zn 26 ## 4 ptratio 46 ## 5 tax 66 ## 6 indus 76 ## 7 nox 81 ## 8 medv 229 ## 9 age 356 ## 10 dis 412 ## 11 rm 446 ## 12 lstat 455 ## 13 crim 504 The chas variable is a dummy variable to indicate the Charles River. Exclude it and fit again: lm_crim_uni_poly &lt;- tibble( predictor = names(boston)[names(boston) != &quot;crim&quot;] ) %&gt;% filter(predictor != &quot;chas&quot;) %&gt;% mutate( mod = map( predictor, ~lm(as.formula(paste0(&quot;crim ~ poly(&quot;, .x, &quot;, 3)&quot;)), data = boston) ), mod_tidy = map(mod, broom::tidy) ) These predictors have significant polynomial terms: lm_crim_uni_poly %&gt;% unnest(mod_tidy) %&gt;% filter(str_detect(term, &quot;poly&quot;)) %&gt;% group_by(predictor) %&gt;% filter(sum(p.value &lt; 0.05) &gt; 1) %&gt;% transmute( predictor, term, estimate = signif(estimate, 4), std.error = signif(std.error, 4), p.value = scales::pvalue(p.value) ) %&gt;% gt(rowname_col = &quot;term&quot;) html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #czrnmwoxbz .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #czrnmwoxbz .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #czrnmwoxbz .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #czrnmwoxbz .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #czrnmwoxbz .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #czrnmwoxbz .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #czrnmwoxbz .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #czrnmwoxbz .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #czrnmwoxbz .gt_column_spanner_outer:first-child { padding-left: 0; } #czrnmwoxbz .gt_column_spanner_outer:last-child { padding-right: 0; } #czrnmwoxbz .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #czrnmwoxbz .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #czrnmwoxbz .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #czrnmwoxbz .gt_from_md > :first-child { margin-top: 0; } #czrnmwoxbz .gt_from_md > :last-child { margin-bottom: 0; } #czrnmwoxbz .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #czrnmwoxbz .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #czrnmwoxbz .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #czrnmwoxbz .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #czrnmwoxbz .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #czrnmwoxbz .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #czrnmwoxbz .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #czrnmwoxbz .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #czrnmwoxbz .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #czrnmwoxbz .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #czrnmwoxbz .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #czrnmwoxbz .gt_sourcenote { font-size: 90%; padding: 4px; } #czrnmwoxbz .gt_left { text-align: left; } #czrnmwoxbz .gt_center { text-align: center; } #czrnmwoxbz .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #czrnmwoxbz .gt_font_normal { font-weight: normal; } #czrnmwoxbz .gt_font_bold { font-weight: bold; } #czrnmwoxbz .gt_font_italic { font-style: italic; } #czrnmwoxbz .gt_super { font-size: 65%; } #czrnmwoxbz .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } estimate std.error p.value zn poly(zn, 3)1 -38.750 8.372 &lt;0.001 poly(zn, 3)2 23.940 8.372 0.004 poly(zn, 3)3 -10.070 8.372 0.230 indus poly(indus, 3)1 78.590 7.423 &lt;0.001 poly(indus, 3)2 -24.390 7.423 0.001 poly(indus, 3)3 -54.130 7.423 &lt;0.001 nox poly(nox, 3)1 81.370 7.234 &lt;0.001 poly(nox, 3)2 -28.830 7.234 &lt;0.001 poly(nox, 3)3 -60.360 7.234 &lt;0.001 rm poly(rm, 3)1 -42.380 8.330 &lt;0.001 poly(rm, 3)2 26.580 8.330 0.002 poly(rm, 3)3 -5.510 8.330 0.509 age poly(age, 3)1 68.180 7.840 &lt;0.001 poly(age, 3)2 37.480 7.840 &lt;0.001 poly(age, 3)3 21.350 7.840 0.007 dis poly(dis, 3)1 -73.390 7.331 &lt;0.001 poly(dis, 3)2 56.370 7.331 &lt;0.001 poly(dis, 3)3 -42.620 7.331 &lt;0.001 rad poly(rad, 3)1 120.900 6.682 &lt;0.001 poly(rad, 3)2 17.490 6.682 0.009 poly(rad, 3)3 4.698 6.682 0.482 tax poly(tax, 3)1 112.600 6.854 &lt;0.001 poly(tax, 3)2 32.090 6.854 &lt;0.001 poly(tax, 3)3 -7.997 6.854 0.244 ptratio poly(ptratio, 3)1 56.050 8.122 &lt;0.001 poly(ptratio, 3)2 24.770 8.122 0.002 poly(ptratio, 3)3 -22.280 8.122 0.006 lstat poly(lstat, 3)1 88.070 7.629 &lt;0.001 poly(lstat, 3)2 15.890 7.629 0.038 poly(lstat, 3)3 -11.570 7.629 0.130 medv poly(medv, 3)1 -75.060 6.569 &lt;0.001 poly(medv, 3)2 88.090 6.569 &lt;0.001 poly(medv, 3)3 -48.030 6.569 &lt;0.001 Reproducibility Reproducibility receipt Sys.time() ## [1] &quot;2022-04-09 16:06:46 AST&quot; if (&quot;git2r&quot; %in% installed.packages()) { if (git2r::in_repository()) { git2r::repository() } } ## Local: main C:/Users/tdunn/Documents/learning/islr-tidy ## Remote: main @ origin (https://github.com/taylordunn/islr-tidy) ## Head: [00046ed] 2022-04-08: Finished chapter 6 sessioninfo::session_info() ## - Session info --------------------------------------------------------------- ## setting value ## version R version 4.1.3 (2022-03-10) ## os Windows 10 x64 ## system x86_64, mingw32 ## ui RTerm ## language (EN) ## collate English_Canada.1252 ## ctype English_Canada.1252 ## tz America/Curacao ## date 2022-04-09 ## ## - Packages ------------------------------------------------------------------- ## package * version date lib source ## abind 1.4-5 2016-07-21 [1] CRAN (R 4.1.1) ## assertthat 0.2.1 2019-03-21 [1] CRAN (R 4.1.0) ## backports 1.2.1 2020-12-09 [1] CRAN (R 4.1.0) ## bayestestR 0.10.5 2021-07-26 [1] CRAN (R 4.1.0) ## bit 4.0.4 2020-08-04 [1] CRAN (R 4.1.2) ## bit64 4.0.5 2020-08-30 [1] CRAN (R 4.1.2) ## bookdown 0.24 2021-09-02 [1] CRAN (R 4.1.1) ## broom * 0.7.10 2021-10-31 [1] CRAN (R 4.1.2) ## bslib 0.2.5.1 2021-05-18 [1] CRAN (R 4.1.0) ## cachem 1.0.6 2021-08-19 [1] CRAN (R 4.1.1) ## car 3.0-12 2021-11-06 [1] CRAN (R 4.1.2) ## carData 3.0-4 2020-05-22 [1] CRAN (R 4.1.1) ## cellranger 1.1.0 2016-07-27 [1] CRAN (R 4.1.0) ## checkmate 2.0.0 2020-02-06 [1] CRAN (R 4.1.0) ## class 7.3-20 2022-01-16 [2] CRAN (R 4.1.3) ## cli 3.2.0 2022-02-14 [1] CRAN (R 4.1.3) ## coda 0.19-4 2020-09-30 [1] CRAN (R 4.1.0) ## codetools 0.2-18 2020-11-04 [2] CRAN (R 4.1.3) ## colorspace 2.0-3 2022-02-21 [1] CRAN (R 4.1.3) ## corrr * 0.4.3 2020-11-24 [1] CRAN (R 4.1.0) ## crayon 1.5.1 2022-03-26 [1] CRAN (R 4.1.3) ## datawizard 0.1.0 2021-06-18 [1] CRAN (R 4.1.0) ## DBI 1.1.2 2021-12-20 [1] CRAN (R 4.1.2) ## dbplyr 2.1.1 2021-04-06 [1] CRAN (R 4.1.0) ## DEoptimR 1.0-9 2021-05-24 [1] CRAN (R 4.1.0) ## dials * 0.0.10 2021-09-10 [1] CRAN (R 4.1.1) ## DiceDesign 1.9 2021-02-13 [1] CRAN (R 4.1.0) ## digest 0.6.29 2021-12-01 [1] CRAN (R 4.1.2) ## distill 1.3 2021-10-13 [1] CRAN (R 4.1.2) ## downlit 0.4.0 2021-10-29 [1] CRAN (R 4.1.1) ## dplyr * 1.0.8 2022-02-08 [1] CRAN (R 4.1.3) ## dunnr * 0.2.5 2022-01-15 [1] Github (taylordunn/dunnr@c83b30e) ## effectsize 0.4.5 2021-05-25 [1] CRAN (R 4.1.0) ## ellipsis 0.3.2 2021-04-29 [1] CRAN (R 4.1.0) ## emmeans 1.7.0 2021-09-29 [1] CRAN (R 4.1.2) ## equatiomatic 0.2.0 2021-01-30 [1] CRAN (R 4.1.0) ## estimability 1.3 2018-02-11 [1] CRAN (R 4.1.1) ## evaluate 0.14 2019-05-28 [1] CRAN (R 4.1.0) ## extrafont 0.17 2014-12-08 [1] CRAN (R 4.1.0) ## extrafontdb 1.0 2012-06-11 [1] CRAN (R 4.1.0) ## fansi 1.0.3 2022-03-24 [1] CRAN (R 4.1.3) ## farver 2.1.0 2021-02-28 [1] CRAN (R 4.1.0) ## fastmap 1.1.0 2021-01-25 [1] CRAN (R 4.1.0) ## forcats * 0.5.1 2021-01-27 [1] CRAN (R 4.1.0) ## foreach 1.5.2 2022-02-02 [1] CRAN (R 4.1.3) ## fs 1.5.2 2021-12-08 [1] CRAN (R 4.1.2) ## furrr 0.2.3 2021-06-25 [1] CRAN (R 4.1.2) ## future 1.24.0 2022-02-19 [1] CRAN (R 4.1.3) ## future.apply 1.8.1 2021-08-10 [1] CRAN (R 4.1.3) ## generics 0.1.2 2022-01-31 [1] CRAN (R 4.1.3) ## GGally 2.1.2 2021-06-21 [1] CRAN (R 4.1.0) ## ggplot2 * 3.3.5 2021-06-25 [1] CRAN (R 4.1.0) ## ggrepel 0.9.1 2021-01-15 [1] CRAN (R 4.1.0) ## ggridges 0.5.3 2021-01-08 [1] CRAN (R 4.1.0) ## git2r 0.28.0 2021-01-10 [1] CRAN (R 4.1.0) ## globals 0.14.0 2020-11-22 [1] CRAN (R 4.1.0) ## glue 1.6.2 2022-02-24 [1] CRAN (R 4.1.3) ## gower 0.2.2 2020-06-23 [1] CRAN (R 4.1.0) ## GPfit 1.0-8 2019-02-08 [1] CRAN (R 4.1.0) ## gridExtra 2.3 2017-09-09 [1] CRAN (R 4.1.0) ## gt * 0.3.1 2021-08-07 [1] CRAN (R 4.1.2) ## gtable 0.3.0 2019-03-25 [1] CRAN (R 4.1.0) ## hardhat 0.2.0 2022-01-24 [1] CRAN (R 4.1.3) ## haven 2.4.1 2021-04-23 [1] CRAN (R 4.1.0) ## here * 1.0.1 2020-12-13 [1] CRAN (R 4.1.0) ## highr 0.9 2021-04-16 [1] CRAN (R 4.1.0) ## hms 1.1.1 2021-09-26 [1] CRAN (R 4.1.2) ## htmltools 0.5.2 2021-08-25 [1] CRAN (R 4.1.1) ## httr 1.4.2 2020-07-20 [1] CRAN (R 4.1.0) ## infer * 1.0.0 2021-08-13 [1] CRAN (R 4.1.1) ## insight 0.14.2 2021-06-22 [1] CRAN (R 4.1.0) ## ipred 0.9-12 2021-09-15 [1] CRAN (R 4.1.1) ## ISLR2 * 1.3-1 2022-01-10 [1] CRAN (R 4.1.2) ## iterators 1.0.14 2022-02-05 [1] CRAN (R 4.1.3) ## jquerylib 0.1.4 2021-04-26 [1] CRAN (R 4.1.0) ## jsonlite 1.7.3 2022-01-17 [1] CRAN (R 4.1.2) ## knitr 1.37 2021-12-16 [1] CRAN (R 4.1.2) ## labeling 0.4.2 2020-10-20 [1] CRAN (R 4.1.0) ## lattice 0.20-45 2021-09-22 [2] CRAN (R 4.1.3) ## lava 1.6.10 2021-09-02 [1] CRAN (R 4.1.3) ## lhs 1.1.1 2020-10-05 [1] CRAN (R 4.1.0) ## lifecycle 1.0.1 2021-09-24 [1] CRAN (R 4.1.1) ## listenv 0.8.0 2019-12-05 [1] CRAN (R 4.1.0) ## lubridate 1.8.0 2021-10-07 [1] CRAN (R 4.1.1) ## magrittr 2.0.2 2022-01-26 [1] CRAN (R 4.1.3) ## MASS 7.3-55 2022-01-16 [2] CRAN (R 4.1.3) ## Matrix 1.4-0 2021-12-08 [2] CRAN (R 4.1.3) ## memoise 2.0.1 2021-11-26 [1] CRAN (R 4.1.2) ## mgcv 1.8-39 2022-02-24 [2] CRAN (R 4.1.3) ## modeldata * 0.1.1 2021-07-14 [1] CRAN (R 4.1.0) ## modelr 0.1.8 2020-05-19 [1] CRAN (R 4.1.0) ## munsell 0.5.0 2018-06-12 [1] CRAN (R 4.1.0) ## mvtnorm 1.1-3 2021-10-08 [1] CRAN (R 4.1.1) ## nlme 3.1-155 2022-01-16 [2] CRAN (R 4.1.3) ## nnet 7.3-17 2022-01-16 [2] CRAN (R 4.1.3) ## parallelly 1.30.0 2021-12-17 [1] CRAN (R 4.1.2) ## parameters 0.14.0 2021-05-29 [1] CRAN (R 4.1.0) ## parsnip * 0.1.7 2021-07-21 [1] CRAN (R 4.1.0) ## patchwork * 1.1.1 2020-12-17 [1] CRAN (R 4.1.0) ## performance 0.7.3 2021-07-21 [1] CRAN (R 4.1.1) ## pillar 1.7.0 2022-02-01 [1] CRAN (R 4.1.2) ## pkgconfig 2.0.3 2019-09-22 [1] CRAN (R 4.1.0) ## plyr 1.8.7 2022-03-24 [1] CRAN (R 4.1.3) ## pROC 1.17.0.1 2021-01-13 [1] CRAN (R 4.1.0) ## prodlim 2019.11.13 2019-11-17 [1] CRAN (R 4.1.0) ## purrr * 0.3.4 2020-04-17 [1] CRAN (R 4.1.2) ## qqplotr 0.0.5 2021-04-23 [1] CRAN (R 4.1.0) ## R6 2.5.1 2021-08-19 [1] CRAN (R 4.1.1) ## RColorBrewer 1.1-3 2022-04-03 [1] CRAN (R 4.1.3) ## Rcpp 1.0.8.3 2022-03-17 [1] CRAN (R 4.1.3) ## readr * 2.1.1 2021-11-30 [1] CRAN (R 4.1.2) ## readxl 1.3.1 2019-03-13 [1] CRAN (R 4.1.0) ## recipes * 0.1.17 2021-09-27 [1] CRAN (R 4.1.1) ## reprex 2.0.0 2021-04-02 [1] CRAN (R 4.1.0) ## reshape 0.8.8 2018-10-23 [1] CRAN (R 4.1.0) ## rlang 1.0.2 2022-03-04 [1] CRAN (R 4.1.3) ## rmarkdown 2.11 2021-09-14 [1] CRAN (R 4.1.1) ## robustbase 0.93-8 2021-06-02 [1] CRAN (R 4.1.0) ## rpart 4.1.16 2022-01-24 [2] CRAN (R 4.1.3) ## rprojroot 2.0.2 2020-11-15 [1] CRAN (R 4.1.0) ## rsample * 0.1.0 2021-05-08 [1] CRAN (R 4.1.0) ## rstudioapi 0.13 2020-11-12 [1] CRAN (R 4.1.0) ## Rttf2pt1 1.3.8 2020-01-10 [1] CRAN (R 4.1.1) ## rvest 1.0.0 2021-03-09 [1] CRAN (R 4.1.0) ## sass 0.4.0 2021-05-12 [1] CRAN (R 4.1.0) ## scales * 1.1.1 2020-05-11 [1] CRAN (R 4.1.0) ## see 0.6.4 2021-05-29 [1] CRAN (R 4.1.0) ## sessioninfo 1.1.1 2018-11-05 [1] CRAN (R 4.1.0) ## stringi 1.7.6 2021-11-29 [1] CRAN (R 4.1.2) ## stringr * 1.4.0 2019-02-10 [1] CRAN (R 4.1.0) ## survival 3.2-13 2021-08-24 [2] CRAN (R 4.1.3) ## tibble * 3.1.6 2021-11-07 [1] CRAN (R 4.1.1) ## tidymodels * 0.1.4 2021-10-01 [1] CRAN (R 4.1.1) ## tidyr * 1.2.0 2022-02-01 [1] CRAN (R 4.1.3) ## tidyselect 1.1.2 2022-02-21 [1] CRAN (R 4.1.3) ## tidyverse * 1.3.1 2021-04-15 [1] CRAN (R 4.1.3) ## timeDate 3043.102 2018-02-21 [1] CRAN (R 4.1.0) ## tune * 0.1.6 2021-07-21 [1] CRAN (R 4.1.0) ## tzdb 0.2.0 2021-10-27 [1] CRAN (R 4.1.2) ## usethis 2.1.5 2021-12-09 [1] CRAN (R 4.1.2) ## utf8 1.2.2 2021-07-24 [1] CRAN (R 4.1.0) ## vctrs 0.3.8 2021-04-29 [1] CRAN (R 4.1.3) ## vroom 1.5.7 2021-11-30 [1] CRAN (R 4.1.2) ## withr 2.5.0 2022-03-03 [1] CRAN (R 4.1.3) ## workflows * 0.2.3 2021-07-16 [1] CRAN (R 4.1.0) ## workflowsets * 0.1.0 2021-07-22 [1] CRAN (R 4.1.0) ## xfun 0.29 2021-12-14 [1] CRAN (R 4.1.2) ## xml2 1.3.3 2021-11-30 [1] CRAN (R 4.1.2) ## xtable 1.8-4 2019-04-21 [1] CRAN (R 4.1.0) ## yaml 2.2.1 2020-02-01 [1] CRAN (R 4.1.0) ## yardstick * 0.0.8 2021-03-28 [1] CRAN (R 4.1.0) ## ## [1] C:/Users/tdunn/Documents/R/win-library/4.1 ## [2] C:/Program Files/R/R-4.1.3/library References "],["classification.html", "4 Classification 4.1 An Overview of Classification 4.2 Why Not Linear Regression? 4.3 Logistic Regression 4.4 Generative Models for Classification 4.5 A Comparison of Classification Methods 4.6 Generalized Linear Models 4.7 Lab: Classification Methods 4.8 Exercises Reproducibility", " 4 Classification But in many situations, the response variable is instead qualitative. For example, eye color is qualitative. Often qualitative variables are referred to as categorical; we will use these terms interchangeably. In this chapter, we study approaches for predicting qualitative responses, a process that is known as classification. The methods covered in this chapter include logistic regression (and Poisson regression), linear discriminant analysis, quadratic discriminant analysis, naive Bayes, and \\(K\\)-nearest neighbors. 4.1 An Overview of Classification In this chapter, we will illustrate the concept of classification using the simulated Default data set. We are interested in predicting whether an individual will default on his or her credit card payment, on the basis of annual income and monthly credit card balance. Load the go-to packages and the default data set: library(tidyverse) library(broom) library(gt) library(patchwork) # for composing plots # Load my R package and set the ggplot theme library(dunnr) extrafont::loadfonts(device = &quot;win&quot;, quiet = TRUE) theme_set(theme_td()) set_geom_fonts() set_palette() default &lt;- ISLR2::Default glimpse(default) ## Rows: 10,000 ## Columns: 4 ## $ default &lt;fct&gt; No, No, No, No, No, No, No, No, No, No, No, No, No, No, No, No~ ## $ student &lt;fct&gt; No, Yes, No, No, No, Yes, No, Yes, No, No, Yes, Yes, No, No, N~ ## $ balance &lt;dbl&gt; 729.5265, 817.1804, 1073.5492, 529.2506, 785.6559, 919.5885, 8~ ## $ income &lt;dbl&gt; 44361.625, 12106.135, 31767.139, 35704.494, 38463.496, 7491.55~ Randomly choose a subset of the 10000 observations and re-create Figure 4.1: d &lt;- default %&gt;% add_count(default, name = &quot;n_group&quot;) %&gt;% slice_sample( n = 1000, # Inversely weight by group size to get more even distribution weight_by = n() - n_group ) p1 &lt;- d %&gt;% ggplot(aes(x = balance, y = income)) + geom_point(aes(color = default, shape = default), alpha = 0.5, show.legend = FALSE) p2 &lt;- d %&gt;% ggplot(aes(x = default, y = balance)) + geom_boxplot(aes(fill = default), show.legend = FALSE) p3 &lt;- d %&gt;% ggplot(aes(x = default, y = income)) + geom_boxplot(aes(fill = default), show.legend = FALSE) p1 | (p2 | p3) 4.2 Why Not Linear Regression? Linear regression cannot predict un-ordered qualitative responses with more than two levels. Unfortunately, in general there is no natural way to convert a qualitative response variable with more than two levels into a quantitative response that is ready for linear regression. It is possible to use linear regression to predict a binary (two level) response. For example, if we code stroke and drug overdose as dummy variables: \\[ Y = \\begin{cases} 0 &amp; \\text{if stroke;} \\\\ 1 &amp; \\text{if drug overdose}. \\end{cases} \\] Then we predict stroke if \\(\\hat{Y} &lt;= 0.5\\) and overdose if \\(\\hat{Y} &gt; 0.5\\). It turns out that these probability estimates are not unreasonble, but there can be issues: However, if we use linear regression, some of our estimates might be outside the [0, 1] interval (see Figure 4.2), making them hard to interpret as probabilities! Nevertheless, the predictions provide an ordering and can be interpreted as crude probability estimates. 4.3 Logistic Regression In logistic regression, we model the probability of \\(Y\\) belonging to a class, rather than the response \\(Y\\) itself. The probability of default given balance can be written: \\[ \\text{Pr}(\\text{default = Yes}|\\text{balance}) = p(\\text{balance}). \\] One might predict a default for an individual with \\(p(\\text{balance}) &gt; 0.5\\). Or they may alter the threshold to be conservative, e.g. \\(p(\\text{balance}) &gt; 0.1\\) 4.3.1 The Logistic Model As previously discussed, we could model the probability as linear: \\[ p(X) = \\beta_0 + \\beta_1 X \\] but this could give probabilities outside of the range 0-1. We must instead model \\(p(X)\\) using a function that gives outputs 0-1. Many functions meet this description, but logistic regression uses the logistic function: \\[ p(X) = \\frac{e^{\\beta_0 + \\beta_1X}}{1 + e^{\\beta_0 + \\beta_1 X}}. \\] Fit the linear and logistic probability models and re-create Figure 4.2: lm_default_balance &lt;- lm( default ~ balance, # Turn the factor levels into 0 and 1 data = default %&gt;% mutate(default = as.numeric(default) - 1) ) glm_default_balance &lt;- glm(default ~ balance, data = default, family = binomial(link = &quot;logit&quot;)) # Plot the data p &lt;- default %&gt;% ggplot(aes(x = balance)) + geom_point(aes(y = as.numeric(default) - 1), color = td_colors$nice$soft_orange, alpha = 0.5) # Plot the linear model p1 &lt;- p + geom_abline(slope = coef(lm_default_balance)[&quot;balance&quot;], intercept = coef(lm_default_balance)[&quot;(Intercept)&quot;], size = 1.5, color = td_colors$nice$strong_blue) + labs(y = &quot;Probability of default&quot;) # Plot the logistic model p2 &lt;- p + geom_line( aes(y = pred_default), data = tibble(balance = seq(0, 2700, 1)) %&gt;% mutate( sum_beta = coef(glm_default_balance)[&quot;(Intercept)&quot;] + balance * coef(glm_default_balance)[&quot;balance&quot;], pred_default = plogis(sum_beta) ), size = 1.5, color = td_colors$nice$strong_blue ) + labs(y = NULL) p1 | p2 A very clear improvement. The mean of the fitted probabilities in both models return the overall proportion of defaulters in the data set: predict(lm_default_balance, newdata = default) %&gt;% mean() ## [1] 0.0333 predict(glm_default_balance, newdata = default) %&gt;% plogis() %&gt;% mean() ## [1] 0.0333 The odds is found by re-arranging the logistic function: \\[ \\frac{p(X)}{1 - p(X)} = e^{\\beta_0 + \\beta_1 X}. \\] This can take any value between 0 (\\(p(X) = 0\\)) and \\(\\infty\\) (\\(p(X) = 1\\)). Basic interpretation: A probability of 0.2 gives 1:4 odds. A probability of 0.9 gives 9:1 odds. Taking the logarithm of both sides gives us the log odds or logit which is linear in \\(X\\): \\[ \\log \\left(\\frac{p(X)}{1 - p(X)}\\right) = \\beta_0 + \\beta_1 X. \\] A one unit change in \\(X\\) increases the log odds by \\(\\beta_1\\). Equivalently, it multiplies the odds by \\(e^{\\beta_1}\\). 4.3.2 Estimating the Regression Coefficients We fit logistic regression models with maximum likelihood, which seeks estimates for \\(\\beta_0\\) and \\(\\beta_1\\) such that the predicted probabilities \\(\\hat{p}(x_i)\\) corresponds as closely as possible to the values \\(y_i\\). This idea is formalized using a likelihood function: \\[ \\ell (\\beta_0, \\beta_1) = \\prod_{i: y_i = 1} p(x_i) \\prod_{i&#39;: y_{i&#39;} = 0} (1 - p(x_{i&#39;})). \\] We find the estimates \\(\\hat{\\beta}_0\\) and \\(\\hat{\\beta}_1\\) by maximizing this likelihood function. Note that the least squares approach to linear regression is a special case of maximum likelihood. Re-produce Table 4.1 using the fitted model: # Since I will be reproducing this table often, write a function tidy_custom &lt;- function(mod, coef_round = 4, se_round = 4, z_round = 2) { tidy(mod) %&gt;% transmute( term, coefficient = round(estimate, coef_round), std.error = round(std.error, se_round), `z-statistic` = round(statistic, z_round), `p-value` = scales::pvalue(p.value) ) } tidy_custom(glm_default_balance) %&gt;% gt() html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #iitolowwom .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #iitolowwom .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #iitolowwom .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #iitolowwom .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #iitolowwom .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #iitolowwom .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #iitolowwom .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #iitolowwom .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #iitolowwom .gt_column_spanner_outer:first-child { padding-left: 0; } #iitolowwom .gt_column_spanner_outer:last-child { padding-right: 0; } #iitolowwom .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #iitolowwom .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #iitolowwom .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #iitolowwom .gt_from_md > :first-child { margin-top: 0; } #iitolowwom .gt_from_md > :last-child { margin-bottom: 0; } #iitolowwom .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #iitolowwom .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #iitolowwom .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #iitolowwom .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #iitolowwom .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #iitolowwom .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #iitolowwom .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #iitolowwom .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #iitolowwom .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #iitolowwom .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #iitolowwom .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #iitolowwom .gt_sourcenote { font-size: 90%; padding: 4px; } #iitolowwom .gt_left { text-align: left; } #iitolowwom .gt_center { text-align: center; } #iitolowwom .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #iitolowwom .gt_font_normal { font-weight: normal; } #iitolowwom .gt_font_bold { font-weight: bold; } #iitolowwom .gt_font_italic { font-style: italic; } #iitolowwom .gt_super { font-size: 65%; } #iitolowwom .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } term coefficient std.error z-statistic p-value (Intercept) -10.6513 0.3612 -29.49 &lt;0.001 balance 0.0055 0.0002 24.95 &lt;0.001 The \\(z\\)-statistic plays the same role at the \\(t\\)-statistic from linear regression. It equals \\(\\hat{\\beta}_1 / \\text{SE}(\\hat{\\beta}_1)\\) and large (absolute) values indiciate evidence against the null hypothesis \\(H_0: \\beta_1 = 0\\). The small \\(p\\)-value associated with balance in the above table is small, so we reject the null hypothesis. 4.3.3 Making Predictions With the estimates, we can compute default probabilities for an individual with a balance of $1,000 and $2,000. example_balance &lt;- c(1000, 2000) # For convenience, add together the linear terms to get the log-odds sum_beta &lt;- coef(glm_default_balance)[&quot;(Intercept)&quot;] + example_balance * coef(glm_default_balance)[&quot;balance&quot;] exp(sum_beta) / (1 + exp(sum_beta)) ## [1] 0.005752145 0.585769370 Instead of manually writing out the full equation, here are some alternatives: This logistic distribution function stats::plogis (sometimes called the inverse logit) returns probabilities from the given log-odds values: stats::plogis(sum_beta) ## [1] 0.005752145 0.585769370 Calling the generic predict on a glm uses predict.glm(): # By default, predict.glm() returns log-odds predict(glm_default_balance, newdata = tibble(balance = example_balance)) %&gt;% # So use the inverse logit plogis() ## 1 2 ## 0.005752145 0.585769370 There is an argument to predict.glm() called type that specifies the scale of the returned predictions. By default, type = link which refers to the link function which means log-odds are returned. Setting type = response returns probabilities: predict(glm_default_balance, newdata = tibble(balance = example_balance), type = &quot;response&quot;) ## 1 2 ## 0.005752145 0.585769370 Fit the model with student as the predictor and re-create Table 4.2: glm_default_student &lt;- glm(default ~ student, data = default, # Note: don&#39;t need to specify binomial(link = &quot;logit&quot;) because it is the # default link family = binomial) tidy_custom(glm_default_student) %&gt;% gt() html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #dzgapspvwl .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #dzgapspvwl .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #dzgapspvwl .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #dzgapspvwl .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #dzgapspvwl .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #dzgapspvwl .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #dzgapspvwl .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #dzgapspvwl .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #dzgapspvwl .gt_column_spanner_outer:first-child { padding-left: 0; } #dzgapspvwl .gt_column_spanner_outer:last-child { padding-right: 0; } #dzgapspvwl .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #dzgapspvwl .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #dzgapspvwl .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #dzgapspvwl .gt_from_md > :first-child { margin-top: 0; } #dzgapspvwl .gt_from_md > :last-child { margin-bottom: 0; } #dzgapspvwl .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #dzgapspvwl .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #dzgapspvwl .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #dzgapspvwl .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #dzgapspvwl .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #dzgapspvwl .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #dzgapspvwl .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #dzgapspvwl .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #dzgapspvwl .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #dzgapspvwl .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #dzgapspvwl .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #dzgapspvwl .gt_sourcenote { font-size: 90%; padding: 4px; } #dzgapspvwl .gt_left { text-align: left; } #dzgapspvwl .gt_center { text-align: center; } #dzgapspvwl .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #dzgapspvwl .gt_font_normal { font-weight: normal; } #dzgapspvwl .gt_font_bold { font-weight: bold; } #dzgapspvwl .gt_font_italic { font-style: italic; } #dzgapspvwl .gt_super { font-size: 65%; } #dzgapspvwl .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } term coefficient std.error z-statistic p-value (Intercept) -3.5041 0.0707 -49.55 &lt;0.001 studentYes 0.4049 0.1150 3.52 &lt;0.001 The probabilities for student and non-students: predict(glm_default_student, newdata = tibble(student = c(&quot;Yes&quot;, &quot;No&quot;)), type = &quot;response&quot;) ## 1 2 ## 0.04313859 0.02919501 4.3.4 Multiple Logistic Regression The extension to multiple predictors \\(p\\) is straightfoward: \\[ \\log \\left( \\frac{p(X)}{1 - p(X)} \\right) = \\beta_0 + \\beta_1 X_1 + \\dots + \\beta_p X_p. \\] Fit the model with all three predictors (income in thousands of dollars): glm_default_all &lt;- glm(default ~ ., data = default %&gt;% mutate(income = income / 1000), family = binomial) tidy_custom(glm_default_all) %&gt;% gt() html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #qbqjvrdpgf .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #qbqjvrdpgf .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #qbqjvrdpgf .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #qbqjvrdpgf .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #qbqjvrdpgf .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #qbqjvrdpgf .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #qbqjvrdpgf .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #qbqjvrdpgf .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #qbqjvrdpgf .gt_column_spanner_outer:first-child { padding-left: 0; } #qbqjvrdpgf .gt_column_spanner_outer:last-child { padding-right: 0; } #qbqjvrdpgf .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #qbqjvrdpgf .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #qbqjvrdpgf .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #qbqjvrdpgf .gt_from_md > :first-child { margin-top: 0; } #qbqjvrdpgf .gt_from_md > :last-child { margin-bottom: 0; } #qbqjvrdpgf .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #qbqjvrdpgf .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #qbqjvrdpgf .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #qbqjvrdpgf .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #qbqjvrdpgf .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #qbqjvrdpgf .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #qbqjvrdpgf .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #qbqjvrdpgf .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #qbqjvrdpgf .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #qbqjvrdpgf .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #qbqjvrdpgf .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #qbqjvrdpgf .gt_sourcenote { font-size: 90%; padding: 4px; } #qbqjvrdpgf .gt_left { text-align: left; } #qbqjvrdpgf .gt_center { text-align: center; } #qbqjvrdpgf .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #qbqjvrdpgf .gt_font_normal { font-weight: normal; } #qbqjvrdpgf .gt_font_bold { font-weight: bold; } #qbqjvrdpgf .gt_font_italic { font-style: italic; } #qbqjvrdpgf .gt_super { font-size: 65%; } #qbqjvrdpgf .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } term coefficient std.error z-statistic p-value (Intercept) -10.8690 0.4923 -22.08 &lt;0.001 studentYes -0.6468 0.2363 -2.74 0.006 balance 0.0057 0.0002 24.74 &lt;0.001 income 0.0030 0.0082 0.37 0.712 The coefficient for student is statistically significant and negative, whereas it was positive in the univariable model. To understand this apparent paradox, re-create Figure 4.3: balance_breaks &lt;- seq(0, 2700, by = 270) balance_midpoints &lt;- (balance_breaks[1:(length(balance_breaks) - 1)] + balance_breaks[2:length(balance_breaks)]) / 2 p1 &lt;- default %&gt;% mutate( balance_binned = cut(balance, breaks = balance_breaks, include.lowest = TRUE, labels = balance_midpoints), balance_binned = as.numeric(as.character(balance_binned)) ) %&gt;% group_by(student, balance_binned) %&gt;% summarise(p_default = mean(default == &quot;Yes&quot;), .groups = &quot;drop&quot;) %&gt;% ggplot(aes(x = balance_binned, y = p_default, color = student)) + geom_line(size = 1.5) + geom_hline( data = default %&gt;% group_by(student) %&gt;% summarise(p_mean_default = mean(default == &quot;Yes&quot;), .groups = &quot;drop&quot;), aes(yintercept = p_mean_default, color = student), lty = 2, size = 1 ) + scale_color_manual(values = c(td_colors$nice$strong_blue, td_colors$nice$strong_red)) + theme(legend.position = c(0.2, 0.7)) p2 &lt;- default %&gt;% ggplot(aes(x = student, y = balance)) + geom_boxplot(aes(fill = student)) + scale_fill_manual(values = c(td_colors$nice$strong_blue, td_colors$nice$strong_red)) + theme(legend.position = &quot;none&quot;) p1 | p2 In the left panel, we see that students have a higher overall default rate (4.3%) than non-students (2.9%) as shown by the dashed lines. This is why, in the univariable regression, student was associated with an increase in probability of default. But by the solid lines, we see that for most values of balance, students have lower default rates. And that is what the multiple logistic regression model tells us: for fixed values of balance and income, a student is less likely to default. This is explained by the right panel above: student and balance are correlated in that students tend to hold higher levels of debt, which is then associated with higher probability of default. Taken altogether, we can conclude that a student is less likely to default than a non-student with the same credit card balance. Without any information about their balance, however, a student is more likely to default because they are also more likely to carry a higher balance. This simple example illustrates the dangers and subtleties associated with performing regressions involving only a single predictor when other predictors may also be relevant. As in the linear regression setting, the results obtained using one predictor may be quite different from those obtained using multiple predictors, especially when there is correlation among the predictors. In general, the phenomenon seen in Figure 4.3 is known as confounding. Make predictions for a student and non-student: d &lt;- tibble( student = c(&quot;Yes&quot;, &quot;No&quot;), balance = 1500, # Income in thousands income = 40000 / 1000 ) predict(glm_default_all, newdata = d, type = &quot;response&quot;) ## 1 2 ## 0.05788194 0.10499192 4.3.5 Multinomial Logistic Regression For predicting \\(K &gt; 2\\) classes, we can extend logistic regression in a method called multinomial logistic regression. To do this, we choose a single class \\(K\\) to serve as the baseline. Then the probability of another class \\(k\\) is: \\[ \\text{Pr}(Y = k|X = x) = \\frac{e^{\\beta_{k0} + \\beta_{k1} x_1 + \\beta_{kp} x_p}}{1 + \\sum_{l=1}^{K-1} e^{\\beta_{l0} + \\beta_{l1} x_1 + \\beta_{lp} x_p}} \\] for \\(k = 1, \\dots, K - 1\\). Then for the baseline class \\(K\\): \\[ \\text{Pr}(Y = K|X = x) = \\frac{1}{1 + \\sum_{l=1}^{K-1} e^{\\beta_{l0} + \\beta_{l1} x_1 + \\beta_{lp} x_p}}. \\] The log-odds of a class \\(k\\) is then linear in the predictors: \\[ \\log \\left( \\frac{\\text{Pr} (Y = k| X = x)}{\\text{Pr} (Y = K| X = x)}\\right) = \\beta_{k0} + \\beta_{k1} x_1 + \\dots + \\beta_{kp} x_p. \\] Note that in the case of \\(K = 2\\), the numerator becomes \\(p(X)\\) and the denominator \\(1 - p(X)\\), which is exactly the same the two-class logistic regression formula (Equation 4.6). The choice of class \\(K\\) as baseline was arbitrary. The only thing that will change by choosing a different baseline will be the coefficient estimates, but the predictions (fitted values), and model metrics will be the same. When performing multinomial logistic regression, we will sometimes use an alternative to dummy coding called softmax coding. The softmax coding is equivalent to the coding just described in the sense that the fitted values, log odds between any pair of classes, and other key model outputs will remain the same, regardless of coding. But the softmax coding is used extensively in some areas of the machine learning literature (and will appear again in Chapter 10), so it is worth being aware of it. In the softmax coding, rather than selecting a baseline class, we treat all \\(K\\) classes symmetrically, and assume that for \\(k = 1,...,K\\), \\[ \\text{Pr}(Y = k|X = x) = \\frac{e^{\\beta_{k0} + \\beta_{k1} x_1 + \\beta_{kp} x_p}}{ \\sum_{l=1}^{K} e^{\\beta_{l0} + \\beta_{l1} x_1 + \\beta_{lp} x_p}}. \\] Thus, rather than estimating coefficients for \\(K  1\\) classes, we actually estimate coefficients for all \\(K\\) classes. It is not hard to see that as a result of (4.13), the log odds ratio between the \\(k\\)th and \\(k\\)th classes equals \\[ \\frac{\\log \\text{Pr} (Y = k| X = x)}{\\log \\text{Pr} (Y = k&#39;| X = x)} = (\\beta_{k0} - \\beta_{k&#39;0}) + (\\beta_{k1} - \\beta_{k&#39;1}) x_1 + \\dots + (\\beta_{kp} - \\beta_{k&#39;p}) x_p. \\] 4.4 Generative Models for Classification Logistic regression involves directly modeling \\(\\text{Pr} (Y = k|X = x)\\) using the logistic function, given by (4.7) for the case of two response classes. In statistical jargon, we model the conditional distribution of the response \\(Y\\), given the predictor(s) \\(X\\). We now consider an alternative and less direct approach to estimating these probabilities. In this new approach, we model the distribution of the predictors \\(X\\) separately in each of the response classes (i.e. for each value of \\(Y\\)). We then use Bayes theorem to flip these around into estimates for \\(\\text{Pr} (Y = k|X = x)\\). When the distribution of \\(X\\) within each class is assumed to be normal, it turns out that the model is very similar in form to logistic regression. There are several reasons to choose this method over logistic regression: When there is substantial separation between the two classes, the parameter estimates for the logistic regression model are surprisingly unstable. The methods that we consider in this section do not suffer from this problem. If the distribution of the predictors \\(X\\) is approximately normal in each of the classes and the sample size is small, then the approaches in this section may be more accurate than logistic regression. The methods in this section can be naturally extended to the case of more than two response classes. (In the case of more than two response classes, we can also use multinomial logistic regression from Section 4.3.5.) Consider a classification problem with \\(K \\geq 2\\) unordered classes. Let \\(\\pi_k\\) represent the prior probability that a random observation is class \\(k\\). Let \\(f_k(X) \\equiv \\text{Pr}(X | Y = k)\\) denote the density function of \\(X\\) for an observation in the \\(k\\)th class. Then Bayes theorem states that the posterior probability than observation \\(X = x\\) belongs to the \\(k\\)th class is \\[ \\text{Pr} (Y = k|X = x) = \\frac{\\pi_k f_k(x)}{\\sum_{l=1}^K \\pi_l f_l (x)} = p_k(x). \\] Aside: Bayes theorem in the most simplistic form is \\[ P(Y | X) = \\frac{P(X | Y) P (Y)}{P(X)}. \\] So the probability of \\(X\\) given class \\(Y\\) (= \\(k\\)) is \\(P(X|Y) = f_k (x)\\), the independent probability of a class \\(Y\\) is \\(P(Y) = \\pi_k\\), and the denominator is a normalizing factor which sums over all possible values \\(Y\\) to give the independent probability \\(P(X) = \\sum \\pi_l f_l (x)\\). Estimating \\(\\pi_k\\) is easy if we have a random sample from the population  just take the fraction of the training observations belonging to class \\(k\\). Estimating the density function \\(f_k (x)\\) is much more challenging. We know from Chapter 2 that the Bayes classifier, which classifies an observation \\(x\\) to the class for which \\(p_k(x)\\) is largest, has the lowest possible error rate out of all classifiers. (Of course, this is only true if all of the terms in (4.15) are correctly specified.) Therefore, if we can find a way to estimate \\(f_k(x)\\), then we can plug it into (4.15) in order to approximate the Bayes classifier. We now discuss three classifiers that use different estimates of \\(f_k (x)\\). 4.4.1 Linear Discriminant Analysis for \\(p = 1\\) For the case of one predictor, we start by assuming that \\(f_k (x)\\) is normal or Gaussian, which has the following density in one dimension: \\[ f_k (x) = \\frac{1}{\\sqrt{2 \\pi} \\sigma_k} \\exp \\left( - \\frac{1}{2\\sigma_k^2} (x - \\mu_k)^2\\right) \\] where \\(\\mu_k\\) and \\(\\sigma_k^2\\) are the mean and variance of the \\(k\\)th class. For now, assume all classes have the same variance \\(\\sigma^2\\). Plugging the above into Bayes theorem, we have: \\[ p_k (x) = \\frac{\\pi_k \\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp \\left( - \\frac{1}{2\\sigma^2} (x - \\mu_k)^2\\right)} {\\sum_{l=1}^K \\pi_l \\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp \\left( - \\frac{1}{2\\sigma^2} (x - \\mu_l)^2\\right)}. \\] The Bayes classifier assigns an observation \\(X = x\\) to the class for which the above is largest. Taking the log and rearranging, this is equivalent to choosing the class for which: \\[ \\delta_k (x) = x \\frac{\\mu_k}{\\sigma^2} - \\frac{\\mu_k^2}{2 \\sigma^2} + \\log(\\pi_k) \\] is largest. For instance, if \\(K = 2\\) and \\(\\pi_1 = \\pi_2\\), then the Bayes classifier assigns an observation to class 1 if \\(2x (\\mu_1  \\mu_2) &gt; \\mu_1^2 - \\mu_2^2\\), and to class 2 otherwise. The Bayes decision boundary is the point for which \\(\\delta_1 (x) = \\delta_2 (x)\\); one can show that this amounts to \\[ x = \\frac{\\mu_1^2 - \\mu_2^2}{2 (\\mu_1 - \\mu_2)} = \\frac{\\mu_1 + \\mu_2}{2}. \\] Note that in the real world, we do not know that \\(X\\) is drawn from a Gaussian distribution within each class, or all the parameters involved, so we are not able to calculate the decision boundary for the Bayes classifier. This is where the linear discriminant analysis (LDA) method comes in. If we are quite certain that \\(X\\) is Gaussian within each class, then we can use LDA to approximate the Bayes classifier with these estimates: \\[ \\begin{align} \\hat{\\mu}_k &amp;= \\frac{1}{n_k} \\sum_{i: y_i = k} x_i\\\\ \\hat{\\sigma}^2 &amp;= \\frac{1}{n - K} \\sum^K_{k=1} \\sum_{i: y_i = k} (x_i - \\hat{u}_k)^2 \\end{align} \\] where \\(n\\) is the total number of training observations, and \\(n_k\\) is the number in the \\(k\\)th class. The estimate for \\(\\hat{\\mu}_k\\) is simply the average of the \\(k\\)th class, and \\(\\hat{\\sigma}^2\\) is the weighted average of the sample variances for each of the \\(K\\) classes. Sometimes we know the true fractions of class membership \\(\\pi_k\\) which can be used directly. Otherwise, LDA simply uses the proportion from the training observations: \\[ \\hat{\\pi}_k = n_k / n. \\] Observation \\(X = x\\) is then assigned to the class for which \\[ \\hat{\\delta}_k (x) = x \\frac{\\hat{\\mu}_k}{\\hat{\\sigma}^2} - \\frac{\\hat{\\mu}_k^2}{2 \\hat{\\sigma}^2} + \\log(\\hat{\\pi}_k) \\] The word linear in the classifiers name stems from the fact that the discriminant functions \\(\\hat{\\delta}_k (x)\\) in (4.22) are linear functions of x (as opposed to a more complex function of \\(x\\)) Re-create the example in Figure 4.4: mu1 &lt;- -1.25 mu2 &lt;- 1.25 sigma1 &lt;- 1 sigma2 &lt;- 1 bayes_boundary &lt;- (mu1 + mu2) / 2 p1 &lt;- ggplot(data = tibble(x = seq(-4, 4, 0.1)), aes(x)) + stat_function(fun = dnorm, args = list(mean = mu1, sd = sigma1), geom = &quot;line&quot;, size = 1.5, color = td_colors$nice$emerald) + stat_function(fun = dnorm, args = list(mean = mu2, sd = sigma2), geom = &quot;line&quot;, size = 1.5, color = td_colors$nice$opera_mauve) + geom_vline(xintercept = bayes_boundary, lty = 2, size = 1.5) + remove_axis(&quot;y&quot;) set.seed(42) d &lt;- tribble( ~class, ~x, 1, rnorm(20, mean = mu1, sd = sigma1), 2, rnorm(20, mean = mu2, sd = sigma2) ) %&gt;% unnest(x) lda_boundary &lt;- (mean(filter(d, class == 1)$x) + mean(filter(d, class == 2)$x)) / 2 p2 &lt;- d %&gt;% ggplot(aes(x, fill = factor(class), color = factor(class))) + geom_histogram(bins = 13, alpha = 0.5, position = &quot;identity&quot;) + geom_vline(xintercept = bayes_boundary, lty = 2, size = 1.5) + geom_vline(xintercept = lda_boundary, lty = 1, size = 1.5) + scale_fill_manual(values = c(td_colors$nice$emerald, td_colors$nice$opera_mauve)) + scale_color_manual(values = c(td_colors$nice$emerald, td_colors$nice$opera_mauve)) + theme(legend.position = &quot;none&quot;) p1 | p2 Simulate a large number of test observations and compute the Bayes and LDA test error rates: set.seed(2021) d &lt;- tribble( ~class, ~x, 1, rnorm(1e3, mean = mu1, sd = sigma1), 2, rnorm(1e3, mean = mu2, sd = sigma2) ) %&gt;% unnest(x) # The LDA boundary must be recomputed with the new data lda_boundary &lt;- (mean(filter(d, class == 1)$x) + mean(filter(d, class == 2)$x)) / 2 d %&gt;% mutate( bayes_class = ifelse(x &gt; bayes_boundary, 1, 2), lda_class = ifelse(x &gt; lda_boundary, 1, 2) ) %&gt;% summarise( `Bayes error rate` = mean(class == bayes_class), `LDA error rate` = mean(class == lda_class) ) ## # A tibble: 1 x 2 ## `Bayes error rate` `LDA error rate` ## &lt;dbl&gt; &lt;dbl&gt; ## 1 0.104 0.107 Pretty close but, as expected, the Bayes classifier has the lower error rate. To reiterate, the LDA classifier results from assuming that the observations within each class come from a normal distribution with a class-specific mean and a common variance \\(\\sigma^2\\), and plugging estimates for these parameters into the Bayes classifier. In Section 4.4.3, we will consider a less stringent set of assumptions, by allowing the observations in the \\(k\\)th class to have a class-specific variance, \\(\\sigma_k^2\\). 4.4.2 Linear Discriminant Analysis for \\(p &gt; 1\\) Extending the LDA classifier for multiple predictors involves a multi-variate Gaussian distribution with class-specific mean vector and a common covariance matrix. The multivariate Gaussian distribution assumes that each individual predictor follows a one-dimensional normal distribution, as in (4.16), with some correlation between each pair of predictors. Ill simulate some data with the mvtnorm package and plot probabilities with a 2D density plot (instead of the 3D in Figure 4.5): d &lt;- crossing(x1 = seq(-2, 2, 0.1), x2 = seq(-2, 2, 0.1)) d1 &lt;- d %&gt;% bind_cols( prob = mvtnorm::dmvnorm( x = as.matrix(d), mean = c(0, 0), sigma = matrix(c(1, 0, 0, 1), nrow = 2) ) ) d2 &lt;- d %&gt;% bind_cols( prob = mvtnorm::dmvnorm( x = as.matrix(d), mean = c(0, 0), sigma = matrix(c(1, 0.7, 0.7, 1), nrow = 2) ) ) p1 &lt;- d1 %&gt;% ggplot(aes(x = x1, y = x2)) + geom_tile(aes(fill = prob)) + scale_x_continuous(expand = c(0, 0)) + scale_y_continuous(expand = c(0, 0)) + theme(legend.position = &quot;none&quot;) p2 &lt;- d2 %&gt;% ggplot(aes(x = x1, y = x2)) + geom_tile(aes(fill = prob)) + scale_x_continuous(expand = c(0, 0)) + scale_y_continuous(expand = c(0, 0)) + theme(legend.position = &quot;none&quot;) p1 | p2 To indicate that a \\(p\\)-dimensional random variable \\(X\\) has a multivariate Gaussian distribution, we write \\(X \\sim N(\\mu, \\Sigma)\\). Here \\(E(X) = \\mu\\) is the mean of \\(X\\) (a vector with \\(p\\) components), and \\(\\text{Cov}(X) = \\Sigma\\) is the \\(p \\times p\\) covariance matrix of \\(X\\). The LDA classifier assumes that the observations in the \\(k\\)th class are drawn from a multivariate Gaussian distribution \\(N(\\mu_k, \\Sigma)\\). The Bayes classifier assigns an observation \\(X = x\\) to the class for which \\[ \\delta_k (x) = x^T \\Sigma^{-1} \\mu_k - \\frac{1}{2} \\mu_k^T \\Sigma^{-1} \\mu_k + \\log \\pi_k \\] is largest. As with the univariable case, the LDA method involves estimating the unknown parameters \\(\\mu_k\\), \\(\\pi_k\\) and \\(\\Sigma\\). Then the quantities \\(\\hat{\\delta}_k (x)\\) are calculated and the observations \\(X\\) are classified into the largest \\(\\hat{\\delta}_k (k)\\). We can perform LDA using the MASS package to predict default from student and balance: lda_default_balance_student &lt;- MASS::lda(default ~ balance + student, data = default) lda_default_balance_student ## Call: ## lda(default ~ balance + student, data = default) ## ## Prior probabilities of groups: ## No Yes ## 0.9667 0.0333 ## ## Group means: ## balance studentYes ## No 803.9438 0.2914037 ## Yes 1747.8217 0.3813814 ## ## Coefficients of linear discriminants: ## LD1 ## balance 0.002244397 ## studentYes -0.249059498 The resulting training error rate: mean( predict(lda_default_balance_student, newdata = default)$class != default$default ) ## [1] 0.0275 This sounds like a low error rate, but two caveats must be noted. First of all, training error rates will usually be lower than test error rates, which are the real quantity of interest. In other words, we might expect this classifier to perform worse if we use it to predict whether or not a new set of individuals will default. The reason is that we specifically adjust the parameters of our model to do well on the training data. The higher the ratio of parameters \\(p\\) to number of samples \\(n\\), the more we expect this overfitting to play a role. For these data we dont expect this to be a problem, since \\(p = 2\\) and \\(n = 10,000\\). Second, since only 3.33% of the individuals in the training sample defaulted, a simple but useless classifier that always predicts that an individual will not default, regardless of his or her credit card balance and student status, will result in an error rate of 3.33%. In other words, the trivial null classifier will achieve an error rate that is only a bit higher than the LDA training set error rate. Make predictions and produce the confusion matrix in Table 4.4: lda_pred &lt;- bind_cols( pred_default = predict(lda_default_balance_student, newdata = default)$class, default ) lda_pred %&gt;% count(pred_default, default) %&gt;% pivot_wider(names_from = default, values_from = n) %&gt;% mutate(Total = No + Yes) %&gt;% gt(rowname_col = &quot;pred_default&quot;) %&gt;% gt::tab_spanner(label = &quot;True default status&quot;, columns = everything()) %&gt;% gt::tab_stubhead(&quot;Predicted&quot;) %&gt;% # Can&#39;t get the Total row to round to 0 decimals gt::summary_rows(fns = list(Total = ~round(sum(.), 0))) html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #skvtyzcjea .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #skvtyzcjea .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #skvtyzcjea .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #skvtyzcjea .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #skvtyzcjea .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #skvtyzcjea .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #skvtyzcjea .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #skvtyzcjea .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #skvtyzcjea .gt_column_spanner_outer:first-child { padding-left: 0; } #skvtyzcjea .gt_column_spanner_outer:last-child { padding-right: 0; } #skvtyzcjea .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #skvtyzcjea .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #skvtyzcjea .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #skvtyzcjea .gt_from_md > :first-child { margin-top: 0; } #skvtyzcjea .gt_from_md > :last-child { margin-bottom: 0; } #skvtyzcjea .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #skvtyzcjea .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #skvtyzcjea .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #skvtyzcjea .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #skvtyzcjea .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #skvtyzcjea .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #skvtyzcjea .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #skvtyzcjea .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #skvtyzcjea .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #skvtyzcjea .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #skvtyzcjea .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #skvtyzcjea .gt_sourcenote { font-size: 90%; padding: 4px; } #skvtyzcjea .gt_left { text-align: left; } #skvtyzcjea .gt_center { text-align: center; } #skvtyzcjea .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #skvtyzcjea .gt_font_normal { font-weight: normal; } #skvtyzcjea .gt_font_bold { font-weight: bold; } #skvtyzcjea .gt_font_italic { font-style: italic; } #skvtyzcjea .gt_super { font-size: 65%; } #skvtyzcjea .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } Predicted True default status No Yes Total No 9644 252 9896 Yes 23 81 104 Total 9,667.00 333.00 10,000.00 We only missed 23 individuals who did not default, out of 9667. This is great, but we did quite poorly in predicting defaulters. However, of the 333 individuals who defaulted, 252 (or 75.7%) were missed by LDA. So while the overall error rate is low, the error rate among individuals who defaulted is very high. From the perspective of a credit card company that is trying to identify high-risk individuals, an error rate of 252/333 = 75.7% among individuals who default may well be unacceptable. Class-specific performance is also important in medicine and biology, where the terms sensitivity and specificity characterize the performance of a classifier or screening test. In this case the sensitivity is the percentage of true defaulters that are identified; it equals 24.3%. The specificity is the percentage of non-defaulters that are correctly identified; it equals (1  23/9667) = 99.8%. LDA has poor sensitivity here because it attempts to reduce the total error rate, regardless of class. In the case of a credit card company, it is probably more valuable to correctly identify individuals who will default. The LDA classifier, like the Bayes classifier to which it approximates, assigns an observation to the default = Yes class if \\[ \\text{Pr}(\\text{default = Yes}| X = x) &gt; 0.5. \\] That is to say, these classifiers have a default threshold of 50% posterior probability. We may lower these probability as needed. To adjust this with the MASS::lda package, we can get the posterior probabilities directly via predict.lda(): lda_posterior &lt;- predict(lda_default_balance_student, newdata = default)$posterior head(lda_posterior) ## No Yes ## 1 0.9968680 0.003131975 ## 2 0.9971925 0.002807531 ## 3 0.9843970 0.015603046 ## 4 0.9987769 0.001223133 ## 5 0.9959254 0.004074582 ## 6 0.9954627 0.004537289 Then use the threshold of 20% to re-create Table 4.5: lda_pred_20 &lt;- bind_cols( default, posterior_prob_default = lda_posterior[,2] ) %&gt;% mutate( pred_default = ifelse(posterior_prob_default &gt; 0.2, &quot;Yes&quot;, &quot;No&quot;) ) lda_pred_20 %&gt;% count(pred_default, default) %&gt;% pivot_wider(names_from = default, values_from = n) %&gt;% mutate(Total = No + Yes) %&gt;% gt(rowname_col = &quot;pred_default&quot;) %&gt;% tab_spanner(label = &quot;True default status&quot;, columns = everything()) %&gt;% tab_stubhead(&quot;Predicted&quot;) %&gt;% summary_rows(fns = list(Total = ~round(sum(.), 0))) html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #ggcbylpnri .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #ggcbylpnri .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #ggcbylpnri .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #ggcbylpnri .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #ggcbylpnri .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #ggcbylpnri .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #ggcbylpnri .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #ggcbylpnri .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #ggcbylpnri .gt_column_spanner_outer:first-child { padding-left: 0; } #ggcbylpnri .gt_column_spanner_outer:last-child { padding-right: 0; } #ggcbylpnri .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #ggcbylpnri .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #ggcbylpnri .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #ggcbylpnri .gt_from_md > :first-child { margin-top: 0; } #ggcbylpnri .gt_from_md > :last-child { margin-bottom: 0; } #ggcbylpnri .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #ggcbylpnri .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #ggcbylpnri .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #ggcbylpnri .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #ggcbylpnri .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #ggcbylpnri .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #ggcbylpnri .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #ggcbylpnri .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #ggcbylpnri .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #ggcbylpnri .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #ggcbylpnri .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #ggcbylpnri .gt_sourcenote { font-size: 90%; padding: 4px; } #ggcbylpnri .gt_left { text-align: left; } #ggcbylpnri .gt_center { text-align: center; } #ggcbylpnri .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #ggcbylpnri .gt_font_normal { font-weight: normal; } #ggcbylpnri .gt_font_bold { font-weight: bold; } #ggcbylpnri .gt_font_italic { font-style: italic; } #ggcbylpnri .gt_super { font-size: 65%; } #ggcbylpnri .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } Predicted True default status No Yes Total No 9432 138 9570 Yes 235 195 430 Total 9,667.00 333.00 10,000.00 The sensitivity to detect defaulters has improved to 58.8%, but the specificity has dropped 97.5%. The overall error rate has also increased to 3.7%. But a credit card company may consider this slight increase in the total error rate to be a small price to pay for more accurate identification of individuals who do indeed default. How can we decide which threshold value is best? Such a decision must be based on domain knowledge, such as detailed information about the costs associated with default. The receiver operating character (ROC) curve is one way to visualize the trade-off between two types of error for different threshold values. I like the yardstick::roc_curve() function for this purpose: lda_roc &lt;- yardstick::roc_curve( lda_pred_20, # Specify the class probability and the truth variables posterior_prob_default, truth = default, # This argument specifies which level of truth (default) is considered # &quot;positive&quot;, so it will flip the ROC curve vertically event_level = &quot;second&quot; ) autoplot(lda_roc) The area under the curve (AUC) summarizes the overall performance of the classifier: yardstick::roc_auc( lda_pred_20, posterior_prob_default, truth = default, event_level = &quot;second&quot; ) ## # A tibble: 1 x 3 ## .metric .estimator .estimate ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 roc_auc binary 0.950 We get the exact same ROC AUC with logistic regression: glm_default_balance_student &lt;- glm(default ~ balance + student, data = default, family = binomial) glm_pred &lt;- bind_cols( default, glm_prob_default = predict( glm_default_balance_student, newdata = default, type = &quot;response&quot; ) ) yardstick::roc_auc( glm_pred, glm_prob_default, truth = default, event_level = &quot;second&quot; ) ## # A tibble: 1 x 3 ## .metric .estimator .estimate ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 roc_auc binary 0.950 4.4.3 Quadratic Discriminant Analysis As we have discussed, LDA assumes that the observations within each class are drawn from a multivariate Gaussian distribution with a class-specific mean vector and a covariance matrix that is common to all \\(K\\) classes. Quadratic discriminant analysis (QDA) provides an alternative approach. Like LDA, the QDA classifier results from assuming that the observations from each class are drawn from a Gaussian distribution, and plugging estimates for the parameters into Bayes theorem in order to perform prediction. However, unlike LDA, QDA assumes that each class has its own covariance matrix. That is, it assumes that an observation from the \\(k\\)th class is of the form \\(X \\sim N(\\mu_k, \\Sigma_k)\\), where \\(\\Sigma_k\\) is a covariance matrix for the \\(k\\)th class. An observation \\(X = x\\) is assigned to the class for which \\[ \\begin{align} \\delta_k (x) = - \\frac{1}{2} (x - \\mu_k)^T \\Sigma^{-1}_k (x - \\mu_k) - \\frac{1}{2} \\log |\\Sigma_k|+ \\log \\pi_k. \\end{align} \\] is largest. QDA gets its name from how the quantity \\(x\\) appears as quadratic function in the first term of the above equation. Why does it matter whether or not we assume that the \\(K\\) classes share a common covariance matrix? In other words, why would one prefer LDA to QDA, or vice-versa? The answer lies in the bias-variance trade-off. When there are \\(p\\) predictors, then estimating a covariance matrix requires estimating \\(p(p+1)/2\\) parameters. QDA estimates a separate covariance matrix for each class, for a total of \\(Kp(p+1)/2\\) parameters. Consequently, LDA is a much less flexible classifier than QDA, and so has substantially lower variance. This can potentially lead to improved prediction performance. But there is a trade-off: if LDAs assumption that the \\(K\\) classes share a common covariance matrix is badly off, then LDA can suffer from high bias. In general, use LDA if there are relatively few training observations, and use QDA for many. Also consider QDA if you have some intuition about the decision boundary being non-linear. 4.4.4 Naive Bayes The naive Bayes classifier also estimates the conditional probability \\(f_k (x) = \\text{Pr}(X|Y = k)\\). In LDA, we made the very strong assumption that \\(f_k\\) is the density function of a multivariate normal distribution with mean \\(\\mu_k\\) and shared covariance \\(\\Sigma\\). In QDA, the covariance \\(\\Sigma_k\\) is class-specific. The naive Bayes classifier instead makes a single assumption: Within the \\(k\\)th class, the \\(p\\) predictors are independent. Mathematically: \\[ f_k (x) = f_{k1}(x_1) \\times f_{k2}(x_2) \\times \\dots \\times f_{kp}(x_p). \\] where \\(f_{kj}\\) is the density function of the \\(j\\)th predictor among observations in the \\(k\\)th class. Why is this assumption so powerful? Essentially, estimating a \\(p\\)-dimensional density function is challenging because we must consider not only the marginal distribution of each predictor  that is, the distribution of each predictor on its own  but also the joint distribution of the predictors  that is, the association between the different predictors. In the case of a multivariate normal distribution, the association between the different predictors is summarized by the off-diagonal elements of the covariance matrix. However, in general, this association can be very hard to characterize, and exceedingly challenging to estimate. But by assuming that the \\(p\\) covariates are independent within each class, we completely eliminate the need to worry about the association between the \\(p\\) predictors, because we have simply assumed that there is no association between the predictors! This is a very stringent assumption  most of the time, we believe there to be some degree of association between predictors. But naive Bayes can still perform well, especially when \\(n\\) is not large enough relative to \\(p\\) to effectively estimate the joint distribution of the predictors within each class. Essentially, the naive Bayes assumption introduces some bias, but reduces variance, leading to a classifier that works quite well in practice as a result of the bias-variance trade-off. Under the naive Bayes, assumption, the posterior probability becomes: \\[ \\text{Pr}(Y = k|X = x) = \\frac{\\pi_k \\times f_{k1}(x_1) \\times \\dots \\times f_{kp} (x_p)}{\\sum_{l=1}^K \\pi_l \\times f_{l1}(x_1) \\times \\dots \\times f_{lp} (x_p)} \\] for \\(k = 1, \\dots, K\\). To estimate the one-dimensional \\(f_{kj}\\) from \\(x_j\\), we have a few options: Assume that the \\(j\\)th predictor is drawn from a univariate normal distribution. \\(X_j | Y = k \\sim N(\\mu_{jk}, \\sigma_{jk}^2)\\). This is like QDA except the covariance matrix is diagonal because the predictors are independent. Use a non-parametric estimate for \\(f_{kj}\\). A simple way: Estimate \\(f_{kj}(x_j)\\) as the fraction of the training observations in the \\(k\\)th class belonging to a histogram bin. Alternatively, use a kernel density estimator, which is essentially a smoothed version of a histogram. For qualitative \\(X_j\\), simply count the proportion of training observations for the \\(j\\)th predictor corresponding to each class. Apply the naive Bayes classifier with the klaR package: nb_default &lt;- klaR::NaiveBayes(default ~ balance + student, data = default) nb_pred &lt;- bind_cols( default, nb_prob_default = predict(nb_default, newdata = default)$posterior[,2] ) If we take a posterior probability of 50% or 20% as the thresholds for predicting a default, we get Tables 4.8 and 4.9: nb_pred &lt;- nb_pred %&gt;% mutate( pred_default_0.5 = ifelse(nb_prob_default &gt; 0.5, &quot;Yes&quot;, &quot;No&quot;), pred_default_0.2 = ifelse(nb_prob_default &gt; 0.2, &quot;Yes&quot;, &quot;No&quot;) ) nb_pred %&gt;% count(pred_default_0.5, default) %&gt;% pivot_wider(names_from = default, values_from = n) %&gt;% mutate(Total = No + Yes) %&gt;% gt(rowname_col = &quot;pred_default_0.5&quot;) %&gt;% tab_spanner(label = &quot;True default status&quot;, columns = everything()) %&gt;% tab_stubhead(&quot;Predicted&quot;) %&gt;% summary_rows(fns = list(Total = ~round(sum(.), 0))) html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #ujgogwpkcm .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #ujgogwpkcm .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #ujgogwpkcm .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #ujgogwpkcm .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #ujgogwpkcm .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #ujgogwpkcm .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #ujgogwpkcm .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #ujgogwpkcm .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #ujgogwpkcm .gt_column_spanner_outer:first-child { padding-left: 0; } #ujgogwpkcm .gt_column_spanner_outer:last-child { padding-right: 0; } #ujgogwpkcm .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #ujgogwpkcm .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #ujgogwpkcm .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #ujgogwpkcm .gt_from_md > :first-child { margin-top: 0; } #ujgogwpkcm .gt_from_md > :last-child { margin-bottom: 0; } #ujgogwpkcm .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #ujgogwpkcm .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #ujgogwpkcm .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #ujgogwpkcm .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #ujgogwpkcm .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #ujgogwpkcm .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #ujgogwpkcm .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #ujgogwpkcm .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #ujgogwpkcm .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #ujgogwpkcm .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #ujgogwpkcm .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #ujgogwpkcm .gt_sourcenote { font-size: 90%; padding: 4px; } #ujgogwpkcm .gt_left { text-align: left; } #ujgogwpkcm .gt_center { text-align: center; } #ujgogwpkcm .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #ujgogwpkcm .gt_font_normal { font-weight: normal; } #ujgogwpkcm .gt_font_bold { font-weight: bold; } #ujgogwpkcm .gt_font_italic { font-style: italic; } #ujgogwpkcm .gt_super { font-size: 65%; } #ujgogwpkcm .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } Predicted True default status No Yes Total No 9621 244 9865 Yes 46 89 135 Total 9,667.00 333.00 10,000.00 nb_pred %&gt;% count(pred_default_0.2, default) %&gt;% pivot_wider(names_from = default, values_from = n) %&gt;% mutate(Total = No + Yes) %&gt;% gt(rowname_col = &quot;pred_default_0.2&quot;) %&gt;% tab_spanner(label = &quot;True default status&quot;, columns = everything()) %&gt;% tab_stubhead(&quot;Predicted&quot;) %&gt;% summary_rows(fns = list(Total = ~round(sum(.), 0))) html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #vfygpcxfsz .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #vfygpcxfsz .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #vfygpcxfsz .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #vfygpcxfsz .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #vfygpcxfsz .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #vfygpcxfsz .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #vfygpcxfsz .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #vfygpcxfsz .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #vfygpcxfsz .gt_column_spanner_outer:first-child { padding-left: 0; } #vfygpcxfsz .gt_column_spanner_outer:last-child { padding-right: 0; } #vfygpcxfsz .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #vfygpcxfsz .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #vfygpcxfsz .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #vfygpcxfsz .gt_from_md > :first-child { margin-top: 0; } #vfygpcxfsz .gt_from_md > :last-child { margin-bottom: 0; } #vfygpcxfsz .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #vfygpcxfsz .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #vfygpcxfsz .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #vfygpcxfsz .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #vfygpcxfsz .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #vfygpcxfsz .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #vfygpcxfsz .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #vfygpcxfsz .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #vfygpcxfsz .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #vfygpcxfsz .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #vfygpcxfsz .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #vfygpcxfsz .gt_sourcenote { font-size: 90%; padding: 4px; } #vfygpcxfsz .gt_left { text-align: left; } #vfygpcxfsz .gt_center { text-align: center; } #vfygpcxfsz .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #vfygpcxfsz .gt_font_normal { font-weight: normal; } #vfygpcxfsz .gt_font_bold { font-weight: bold; } #vfygpcxfsz .gt_font_italic { font-style: italic; } #vfygpcxfsz .gt_super { font-size: 65%; } #vfygpcxfsz .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } Predicted True default status No Yes Total No 9339 130 9469 Yes 328 203 531 Total 9,667.00 333.00 10,000.00 The numbers are slightly different from the text, which may have to do with how \\(f_{kj}\\) for the quantitative balance was estimated. The overall error rate, sensitivity, and specificity of the naive Bayes approach: nb_pred %&gt;% select(default, pred_default_0.2, pred_default_0.5) %&gt;% pivot_longer(c(pred_default_0.5, pred_default_0.2), names_to = &quot;threshold&quot;, values_to = &quot;pred_default&quot;) %&gt;% mutate(threshold = as.numeric(str_remove(threshold, &quot;pred_default_&quot;))) %&gt;% group_by(threshold) %&gt;% summarise( overall_error = mean(default != pred_default), sensitivity = sum(default == &quot;Yes&quot; &amp; pred_default == &quot;Yes&quot;) / sum(default == &quot;Yes&quot;), specificity = sum(default == &quot;No&quot; &amp; pred_default == &quot;No&quot;) / sum(default == &quot;No&quot;), .groups = &quot;drop&quot; ) %&gt;% mutate(across(everything(), scales::percent)) %&gt;% gt() html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #dolyxdntek .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #dolyxdntek .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #dolyxdntek .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #dolyxdntek .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #dolyxdntek .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #dolyxdntek .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #dolyxdntek .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #dolyxdntek .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #dolyxdntek .gt_column_spanner_outer:first-child { padding-left: 0; } #dolyxdntek .gt_column_spanner_outer:last-child { padding-right: 0; } #dolyxdntek .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #dolyxdntek .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #dolyxdntek .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #dolyxdntek .gt_from_md > :first-child { margin-top: 0; } #dolyxdntek .gt_from_md > :last-child { margin-bottom: 0; } #dolyxdntek .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #dolyxdntek .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #dolyxdntek .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #dolyxdntek .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #dolyxdntek .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #dolyxdntek .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #dolyxdntek .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #dolyxdntek .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #dolyxdntek .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #dolyxdntek .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #dolyxdntek .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #dolyxdntek .gt_sourcenote { font-size: 90%; padding: 4px; } #dolyxdntek .gt_left { text-align: left; } #dolyxdntek .gt_center { text-align: center; } #dolyxdntek .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #dolyxdntek .gt_font_normal { font-weight: normal; } #dolyxdntek .gt_font_bold { font-weight: bold; } #dolyxdntek .gt_font_italic { font-style: italic; } #dolyxdntek .gt_super { font-size: 65%; } #dolyxdntek .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } threshold overall_error sensitivity specificity 20% 4.6% 61% 96.6% 50% 2.9% 27% 99.5% The overall error rate is slightly higher, but a higher sensitivity was achieved. In this example, it should not be too surprising that naive Bayes does not convincingly outperform LDA: this data set has \\(n = 10,000\\) and \\(p = 4\\), and so the reduction in variance resulting from the naive Bayes assumption is not necessarily worthwhile. We expect to see a greater pay-off to using naive Bayes relative to LDA or QDA in instances where \\(p\\) is larger or \\(n\\) is smaller, so that reducing the variance is very important. 4.5 A Comparison of Classification Methods 4.5.1 An Analytical Comparison We now perform an analytical (or mathematical) comparison of LDA, QDA, naive Bayes, and logistic regression. We consider these approaches in a setting with \\(K\\) classes, so that we assign an observation to the class that maximizes \\(\\text{Pr}(Y = k|X = x)\\). Equivalently, we can set \\(K\\) as the baseline class and assign an observation to the class that maximizes \\[ \\log \\left(\\frac{\\text{Pr}(Y = k|X = x)}{\\text{Pr}(Y = K |X = x)}\\right) \\] for \\(k = 1, \\dots, K\\). This is the familiar log-odds of class \\(k\\) compared to baseline class \\(K\\). For LDA, we assumed the predictors within each class are drawn from a multivariate normal distribution with shared co-variance matrix. The log-odds can be represented as: \\[ \\begin{align} \\log \\left(\\frac{\\text{Pr}(Y = k|X = x)}{\\text{Pr}(Y = K |X = x)}\\right) &amp;= \\log \\left(\\frac{\\pi_k f_k(x)}{\\pi_K f_K(x)}\\right)\\\\ &amp;= a_k + \\sum_{j=1}^p b_{kj} x_j. \\end{align} \\] where \\(a_k\\) and \\(b_{kj}\\) are functions of \\(\\pi_k\\), \\(\\mu_k\\), and \\(\\Sigma_k\\). Like logistic regression, LDA assumes that the log-odds of the probabilities are linear in \\(x\\). Similarly, an additional function \\(c_{kjl}\\) gives the log-odds in the QDA setting: \\[ \\log \\left(\\frac{\\text{Pr}(Y = k|X = x)}{\\text{Pr}(Y = K |X = x)}\\right) = a_k + \\sum_{j=1}^p b_{kj} x_j + \\sum_{j=1}^p \\sum_{l=1}^p c_{kjl} x_j x_l \\] which is quadratic in \\(x\\). Finally, the naive Bayes setting, with one-dimensional \\(f_{kj}(x_j)\\): \\[ \\begin{align} \\log \\left(\\frac{\\text{Pr}(Y = k|X = x)}{\\text{Pr}(Y = K |X = x)}\\right) &amp;= \\log \\left(\\frac{\\pi_k f_k(x )}{\\pi_K f_K(x)}\\right)\\\\ &amp;= a_k + \\sum_{j=1}^p g_{kj} (x_j). \\end{align} \\] where \\(g_{kj} (x_j) = \\log \\frac{f_{kj}(x_j)}{f_{Kj} (x_j)}\\). This is the form of a generalized additive model, a topic that is discussed further in Chapter 7. Looking at these forms, we have the following observations: LDA is a special case of QDA with \\(c_{kjl} = 0\\). Any classifier with a linear decision boundary is a special case of naive Bayes with \\(b_{kj} (x_j) = b_{kj} x_j\\). In particular, this means that LDA is a special case of naive Bayes. Naive Bayes is also a special case of LDA if \\(f_{kj} (x_j)\\) is a modeled as a one-dimensional Gaussian distribution. QDA and naive Bayes are not special cases of the other. None of these methods uniformly dominates the others: in any setting, the choice of method will depend on the true distribution of the predictors in each of the \\(K\\) classes, as well as other considerations, such as the values of \\(n\\) and \\(p\\). The latter ties into the bias-variance trade-off. Then to tie this all to logistic regression, recall the multinomial form: \\[ \\log \\left( \\frac{\\text{Pr} (Y = k| X = x)}{\\text{Pr} (Y = K| X = x)}\\right) = \\beta_{k0} + \\sum_{j=1}^p \\beta_{kj} x_j. \\] This is identical to the linear form of the LDA as both are linear functions of the predictors. The estimation approach differs of course: In LDA, the coefficients in this linear function are functions of estimates for \\(\\pi_k\\), \\(\\pi_K\\), \\(\\mu_k\\), \\(\\mu_K\\), and \\(\\Sigma\\) obtained by assuming that \\(X_1,\\dots, X_p\\) follow a normal distribution within each class. By contrast, in logistic regression, the coefficients are chosen to maximize the likelihood function (4.5). Thus, we expect LDA to outperform logistic regression when the normality assumption (approximately) holds, and we expect logistic regression to perform better when it does not. Lastly, some observations about \\(K\\)-nearest neighbors, which is a non-parametric alternative to classification: Because KNN is completely non-parametric, we can expect this approach to dominate LDA and logistic regression when the decision boundary is highly non-linear, provided that \\(n\\) is very large and \\(p\\) is small. In order to provide accurate classification, KNN requires a lot of observations relative to the number of predictors  that is, \\(n\\) much larger than \\(p\\). This has to do with the fact that KNN is non-parametric, and thus tends to reduce the bias while incurring a lot of variance. In settings where the decision boundary is non-linear but \\(n\\) is only modest, or \\(p\\) is not very small, then QDA may be preferred to KNN. This is because QDA can provide a non-linear decision boundary while taking advantage of a parametric form, which means that it requires a smaller sample size for accurate classification, relative to KNN. Unlike logistic regression, KNN does not tell us which predictors are important: we dont get a table of coefficients as in Table 4.3. 4.5.2 An Empirical Comparison As I dont have access to the data, or the methodological details to simulate it, I wont reproduce the results of this section. But here is my summary of the six scenarios: Scenario 1: uncorrelated normal variables. LDA, logistic regression performed well due to linear decision boundary. KNN performed poorly. QDA worse than LDA because it was more flexible than necessary. Naive Bayes better than QDA because of independent predictors. Scenario 2: correlated normal variables. Similar to scenario 1, except naive Bayes performed much worse due to correlated predictors. Scenario 3: correlated \\(t\\)-distributed predictors (more extreme points than normal). Logistic regression best (linear decision boundary). LDA a bit worse because non-normal variables. Scenario 4: normal variables with different correlations per class. The QDA assumption was correct, and therefore greatly outperformed other. Scenario 5: uncorrelated normal variables, but responses samples from the logistic function applied to a complicated non-linear function of the predictors. The KNN-CV method gave the best results, followed by the more flexible QDA and naive Bayes. KNN with \\(K = 1\\) was the worst. Scenario 6: normal distribution with a different diagonal covariance matrix (uncorrelated) for each class, and with very small sample size. Naive Bayes performed very well. LDA and logistic regression performed worse due to unequal covariance matrices (non-linear decision boundary). QDA performed a bit worse than naive Bayes due to small sample size, and difficulty estimating correlations between predictors. KNNs performance also suffered due to very small sample size. These six examples illustrate that no one method will dominate the others in every situation. When the true decision boundaries are linear, then the LDA and logistic regression approaches will tend to perform well. When the boundaries are moderately non-linear, QDA or naive Bayes may give better results. Finally, for much more complicated decision boundaries, a non-parametric approach such as KNN can be superior. But the level of smoothness for a non-parametric approach must be chosen carefully. In the next chapter we examine a number of approaches for choosing the correct level of smoothness and, in general, for selecting the best overall method. Finally, recall from Chapter 3 that in the regression setting we can accommodate a non-linear relationship between the predictors and by performing regression using transformations of the predictors. A similar approach could be taken in the classification setting. For instance, we could create a more flexible version of logistic regression by including \\(X^2\\), \\(X^3\\), and even \\(X^4\\) as predictors. This may or may not improve logistic regressions performance, depending on whether the increase in variance due to the added flexibility is offset by a sufficiently large reduction in bias. We could do the same for LDA. If we added all possible quadratic terms and cross-products to LDA, the form of the model would be the same as the QDA model, although the parameter estimates would be different. This device allows us to move somewhere between an LDA and a QDA model. 4.6 Generalized Linear Models Thus far, we have considered both quantitative and qualitative response \\(Y\\). However, sometimes \\(Y\\) is neither, and so linear regression and classification are not applicable. The example data set to introduce generalized linear models in bikeshare: bikeshare &lt;- ISLR2::Bikeshare glimpse(bikeshare) ## Rows: 8,645 ## Columns: 15 ## $ season &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,~ ## $ mnth &lt;fct&gt; Jan, Jan, Jan, Jan, Jan, Jan, Jan, Jan, Jan, Jan, Jan, Jan,~ ## $ day &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,~ ## $ hr &lt;fct&gt; 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1~ ## $ holiday &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,~ ## $ weekday &lt;dbl&gt; 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,~ ## $ workingday &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,~ ## $ weathersit &lt;fct&gt; clear, clear, clear, clear, clear, cloudy/misty, clear, cle~ ## $ temp &lt;dbl&gt; 0.24, 0.22, 0.22, 0.24, 0.24, 0.24, 0.22, 0.20, 0.24, 0.32,~ ## $ atemp &lt;dbl&gt; 0.2879, 0.2727, 0.2727, 0.2879, 0.2879, 0.2576, 0.2727, 0.2~ ## $ hum &lt;dbl&gt; 0.81, 0.80, 0.80, 0.75, 0.75, 0.75, 0.80, 0.86, 0.75, 0.76,~ ## $ windspeed &lt;dbl&gt; 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0896, 0.0000, 0.0~ ## $ casual &lt;dbl&gt; 3, 8, 5, 3, 0, 0, 2, 1, 1, 8, 12, 26, 29, 47, 35, 40, 41, 1~ ## $ registered &lt;dbl&gt; 13, 32, 27, 10, 1, 1, 0, 2, 7, 6, 24, 30, 55, 47, 71, 70, 5~ ## $ bikers &lt;dbl&gt; 16, 40, 32, 13, 1, 1, 2, 3, 8, 14, 36, 56, 84, 94, 106, 110~ The response is bikers, the number of hourly users of a bike sharing program in Washington, DC. This response value is neither qualitative nor quantitative: instead, it takes on non-negative integer values, or counts. We will consider counts predicting bikers using the covariates mnth (month of the year), hr (hour of the day, from 0 to 23), workingday (an indicator variable that equals 1 if it is neither a weekend nor a holiday), temp (the normalized temperature, in Celsius), and weathersit (a qualitative variable that takes on one of four possible values: clear; misty or cloudy; light rain or light snow; or heavy rain or heavy snow.) In the analyses that follow, we will treat mnth, hr, and weathersit as qualitative variables. 4.6.1 Linear Regression on the Bikeshare Data Results of linear regression predicting bikers: lm_bikers &lt;- lm(bikers ~ mnth + hr + workingday + temp + weathersit, data = bikeshare) tidy_custom(lm_bikers, coef_round = 2, se_round = 2, z_round = 2) %&gt;% # Exclude mnth and hr due to space constraints filter(!str_detect(term, &quot;mnth|hr&quot;)) %&gt;% gt() html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #fxkprlntuf .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #fxkprlntuf .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #fxkprlntuf .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #fxkprlntuf .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #fxkprlntuf .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #fxkprlntuf .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #fxkprlntuf .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #fxkprlntuf .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #fxkprlntuf .gt_column_spanner_outer:first-child { padding-left: 0; } #fxkprlntuf .gt_column_spanner_outer:last-child { padding-right: 0; } #fxkprlntuf .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #fxkprlntuf .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #fxkprlntuf .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #fxkprlntuf .gt_from_md > :first-child { margin-top: 0; } #fxkprlntuf .gt_from_md > :last-child { margin-bottom: 0; } #fxkprlntuf .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #fxkprlntuf .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #fxkprlntuf .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #fxkprlntuf .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #fxkprlntuf .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #fxkprlntuf .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #fxkprlntuf .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #fxkprlntuf .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #fxkprlntuf .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #fxkprlntuf .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #fxkprlntuf .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #fxkprlntuf .gt_sourcenote { font-size: 90%; padding: 4px; } #fxkprlntuf .gt_left { text-align: left; } #fxkprlntuf .gt_center { text-align: center; } #fxkprlntuf .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #fxkprlntuf .gt_font_normal { font-weight: normal; } #fxkprlntuf .gt_font_bold { font-weight: bold; } #fxkprlntuf .gt_font_italic { font-style: italic; } #fxkprlntuf .gt_super { font-size: 65%; } #fxkprlntuf .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } term coefficient std.error z-statistic p-value (Intercept) -68.63 5.31 -12.93 &lt;0.001 workingday 1.27 1.78 0.71 0.477 temp 157.21 10.26 15.32 &lt;0.001 weathersitcloudy/misty -12.89 1.96 -6.56 &lt;0.001 weathersitlight rain/snow -66.49 2.97 -22.42 &lt;0.001 weathersitheavy rain/snow -109.74 76.67 -1.43 0.152 Re-creating Figure 4.13 takes some wrangling to get the appropriate coefficients: month_coefs &lt;- tidy(lm_bikers) %&gt;% filter(str_detect(term, &quot;Intercept|mnth&quot;)) %&gt;% transmute( Month = ifelse( # The reference level is January term == &quot;(Intercept)&quot;, &quot;Jan&quot;, str_remove(term, &quot;mnth&quot;) ) %&gt;% fct_inorder(), Coefficient = ifelse( # The coefficient for the reference level of just the intercept term == &quot;(Intercept)&quot;, estimate, # Otherwise the coefficient is relative to the intercept estimate + estimate[term == &quot;(Intercept)&quot;] ) ) hour_coefs &lt;- tidy(lm_bikers) %&gt;% filter(str_detect(term, &quot;Intercept|hr&quot;)) %&gt;% transmute( Hour = ifelse( # The reference level is 00 hours (midnight) term == &quot;(Intercept)&quot;, &quot;0&quot;, str_remove(term, &quot;hr&quot;) ) %&gt;% as.integer(), Coefficient = ifelse( # The coefficient for the reference level of just the intercept term == &quot;(Intercept)&quot;, estimate, # Otherwise the coefficient is relative to the intercept estimate + estimate[term == &quot;(Intercept)&quot;] ) ) p1 &lt;- month_coefs %&gt;% ggplot(aes(x = Month, y = Coefficient)) + geom_point(color = td_colors$nice$spanish_blue, size = 3) + geom_line(aes(group = 1), color = td_colors$nice$spanish_blue, size = 1) + theme(axis.text.x = element_text(angle = 45)) p2 &lt;- hour_coefs %&gt;% ggplot(aes(x = Hour, y = Coefficient)) + geom_point(color = td_colors$nice$spanish_blue, size = 3) + geom_line(aes(group = 1), color = td_colors$nice$spanish_blue, size = 1) p1 | p2 The coefficients make intuitive sense, but the issues with the linear regression become apparent when we look at the predictions: library(ggdist) # for the stat_halfeye() plotting function tibble( pred_bikers = predict(lm_bikers, newdata = bikeshare, type = &quot;response&quot;) ) %&gt;% ggplot(aes(x = pred_bikers, fill = stat(x &lt; 0))) + stat_halfeye() + scale_fill_manual(values = c(&quot;grey75&quot;, td_colors$nice$ruby_red)) + remove_axis(&quot;y&quot;) + theme(legend.position = &quot;none&quot;) 9.6% of predictions are negative. Another problem is heteroskedasticity, as shown in the left of Figure 4.14: p1 &lt;- bikeshare %&gt;% mutate(hr = as.integer(hr)) %&gt;% ggplot(aes(x = hr, y = bikers)) + geom_jitter(width = 0.1, height = 0, size = 0.5, color = td_colors$nice$spanish_blue) + # Draw a smoothling spline geom_smooth(method = lm, formula = y ~ splines::bs(x, 3), se = FALSE, size = 1.5, color = td_colors$nice$emerald) p2 &lt;- bikeshare %&gt;% mutate(hr = as.integer(hr)) %&gt;% ggplot(aes(x = hr, y = log(bikers))) + geom_jitter(width = 0.1, height = 0, size = 0.5, color = td_colors$nice$spanish_blue) + geom_smooth(method = lm, formula = y ~ splines::bs(x, 3), se = FALSE, size = 1.5, color = td_colors$nice$emerald) p1 | p2 Lastly, the response bikers is integer-valued, whereas the response in a linear model is continuous. One solution is to transform the response \\(Y\\). In the above figure, we see that log(bikers) can fix some of the heteroskedasticity, and also avoids negative predictions. This wont work if there are any values of bikers = 0, however, and leads to challenging interpretation of the coefficients on the log scale. 4.6.2 Poisson Regression on Bikeshare Data A much more natural approach to count data is Poisson regression. First, the Poisson distribution: Suppose that a random variable \\(Y\\) takes on nonnegative integer values, i.e. \\(Y \\in \\{0, 1, 2, \\dots\\}\\). If \\(Y\\) follows the Poisson distribution, then \\[ \\text{Pr}(Y = k) = \\frac{e^{}^k}{k!} \\text{ for } k = 0, 1, 2, \\dots \\] Here, \\( &gt; 0\\) is the expected value of \\(Y\\), i.e. \\(E(Y )\\). It turns out that \\(\\) also equals the variance of \\(Y\\), i.e. \\( = E(Y ) = \\text{Var}(Y )\\). This means that if \\(Y\\) follows the Poisson distribution, then the larger the mean of \\(Y\\), the larger its variance. (In (4.35), the notation \\(k!\\), pronounced k factorial, is defined as \\(k! = k × (k  1) × (k  2) × ... × 3 × 2 × 1.\\)) As an example, consider biker counts drawn from a Poisson distribution with mean \\(E(Y) = \\lambda = 5\\). Then the probability of 0, 1, 2, etc. bikers during a particular hour is: tibble( n_bikers = 0:6, prob = exp(-5) * 5^n_bikers / factorial(n_bikers) ) %&gt;% mutate( prob = scales::percent(prob) ) ## # A tibble: 7 x 2 ## n_bikers prob ## &lt;int&gt; &lt;chr&gt; ## 1 0 0.67% ## 2 1 3.37% ## 3 2 8.42% ## 4 3 14.04% ## 5 4 17.55% ## 6 5 17.55% ## 7 6 14.62% Of course, we expect \\(\\lambda = E(Y)\\) to vary under certain conditions, so we write it as a function of the covariates: \\[ \\log (\\lambda (X_1, \\dots, X_p)) = \\beta_0 + \\beta_1 X_1 + \\dots + \\beta_p X_p. \\] Taking the log of \\(\\lambda\\) ensures that \\(\\lambda(X_1, \\dots, X_p)\\) takes on non-negative values for all values of the covariates. The coefficients \\(\\beta_j\\) are estimated using the same maximum likelihood approach as logistic regression: \\[ \\ell (\\beta_0, \\dots, \\beta_p) = \\prod_{i = 1}^n p(y_i) = \\prod_{i = 1}^n \\frac{e^{-\\lambda (x_i)} \\lambda(x_i)^{y_i}}{y_i!} \\] where \\(\\lambda(x_i) = e^{\\beta_0 + \\dots + \\beta_p x_{i}}\\). Fit the Poisson model: glm_bikers &lt;- glm(bikers ~ mnth + hr + workingday + temp + weathersit, data = bikeshare, family = poisson) tidy_custom(glm_bikers, coef_round = 2, se_round = 2, z_round = 2) %&gt;% # Exclude mnth and hr due to space constraints filter(!str_detect(term, &quot;mnth|hr&quot;)) %&gt;% gt() html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #alvkobghjn .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #alvkobghjn .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #alvkobghjn .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #alvkobghjn .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #alvkobghjn .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #alvkobghjn .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #alvkobghjn .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #alvkobghjn .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #alvkobghjn .gt_column_spanner_outer:first-child { padding-left: 0; } #alvkobghjn .gt_column_spanner_outer:last-child { padding-right: 0; } #alvkobghjn .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #alvkobghjn .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #alvkobghjn .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #alvkobghjn .gt_from_md > :first-child { margin-top: 0; } #alvkobghjn .gt_from_md > :last-child { margin-bottom: 0; } #alvkobghjn .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #alvkobghjn .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #alvkobghjn .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #alvkobghjn .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #alvkobghjn .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #alvkobghjn .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #alvkobghjn .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #alvkobghjn .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #alvkobghjn .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #alvkobghjn .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #alvkobghjn .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #alvkobghjn .gt_sourcenote { font-size: 90%; padding: 4px; } #alvkobghjn .gt_left { text-align: left; } #alvkobghjn .gt_center { text-align: center; } #alvkobghjn .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #alvkobghjn .gt_font_normal { font-weight: normal; } #alvkobghjn .gt_font_bold { font-weight: bold; } #alvkobghjn .gt_font_italic { font-style: italic; } #alvkobghjn .gt_super { font-size: 65%; } #alvkobghjn .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } term coefficient std.error z-statistic p-value (Intercept) 2.69 0.01 277.12 &lt;0.001 workingday 0.01 0.00 7.50 &lt;0.001 temp 0.79 0.01 68.43 &lt;0.001 weathersitcloudy/misty -0.08 0.00 -34.53 &lt;0.001 weathersitlight rain/snow -0.58 0.00 -141.90 &lt;0.001 weathersitheavy rain/snow -0.93 0.17 -5.55 &lt;0.001 month_coefs &lt;- tidy(glm_bikers) %&gt;% filter(str_detect(term, &quot;Intercept|mnth&quot;)) %&gt;% transmute( Month = ifelse( term == &quot;(Intercept)&quot;, &quot;Jan&quot;, str_remove(term, &quot;mnth&quot;) ) %&gt;% fct_inorder(), Coefficient = ifelse( term == &quot;(Intercept)&quot;, estimate, estimate + estimate[term == &quot;(Intercept)&quot;] ) ) hour_coefs &lt;- tidy(glm_bikers) %&gt;% filter(str_detect(term, &quot;Intercept|hr&quot;)) %&gt;% transmute( Hour = ifelse( term == &quot;(Intercept)&quot;, &quot;0&quot;, str_remove(term, &quot;hr&quot;) ) %&gt;% as.integer(), Coefficient = ifelse( term == &quot;(Intercept)&quot;, estimate, estimate + estimate[term == &quot;(Intercept)&quot;] ) ) p1 &lt;- month_coefs %&gt;% ggplot(aes(x = Month, y = Coefficient)) + geom_point(color = td_colors$nice$spanish_blue, size = 3) + geom_line(aes(group = 1), color = td_colors$nice$spanish_blue, size = 1) + theme(axis.text.x = element_text(angle = 45)) p2 &lt;- hour_coefs %&gt;% ggplot(aes(x = Hour, y = Coefficient)) + geom_point(color = td_colors$nice$spanish_blue, size = 3) + geom_line(aes(group = 1), color = td_colors$nice$spanish_blue, size = 1) p1 | p2 Considerations of this model: Qualitatively quite similar to the linear regression model. One difference is that workingday was statistically significant with Poisson regression. A coefficient \\(\\beta_j\\) is interpreted as the associated change in \\(E(Y) = \\lambda\\) by a factor of \\(\\exp({\\beta_j})\\) for a one unit increase in \\(X_j\\). Example: a change in weather from clear to cloudy skies is associated with a change of exp(-0.075) = 0.928 = 93% as many people will use bikes. The key assumption of the Poisson model is that the variance increases with the mean, \\(\\lambda = E(Y) = \\text{Var}(Y)\\), which means it can deal with the heteroskedasticity we saw in the linear model. The predictions from the Poisson model, by construction, are non-negative: tibble( pred_bikers = predict(glm_bikers, newdata = bikeshare, type = &quot;response&quot;) ) %&gt;% ggplot(aes(x = pred_bikers, fill = stat(x &lt; 0))) + stat_halfeye() + scale_fill_manual(values = c(&quot;grey75&quot;, td_colors$nice$ruby_red)) + remove_axis(&quot;y&quot;) + theme(legend.position = &quot;none&quot;) 4.6.3 Generalized Linear Models in Greater Generality The three regression models we have seen so far (linear, logistic and Poisson) share these similarities. Predictors \\(X_1, \\dots, X_p\\) used to predict a response \\(Y\\), which we assume belongs to a certain family of distributions conditional on \\(X\\). For linear regression, we typically assume Gaussian/normal. For logistic regression, we assume a Bernoulli distribution. For Poisson regression, we assume a Poisson distribution. The mean of \\(Y\\) is modeled as a function of the predictors: \\[ \\begin{align} E(Y|X) &amp;= \\beta_0 + \\beta_1 X_1 + \\dots + \\beta_p X_p \\\\ E(Y|X) &amp;= \\frac{e^{\\beta_0 + \\dots + \\beta_pX_p}}{1 + e^{\\beta_0 + \\dots + \\beta_pX_p}} \\\\ E(Y|X) = \\lambda (X_1, \\dots, X_p) &amp;= e^{\\beta_0 + \\beta_1 X_1 + \\dots + \\beta_p X_p}. \\end{align} \\] These three equations can be expressed using a link function \\(\\eta\\), which applies a transformation to \\(E(Y|X)\\) so that the transformed mean is a lienar function of the predictors: \\[ \\eta(E(Y|X)) = \\beta_0 + \\beta_1 X_1 + \\dots + \\beta_p X_p. \\] The link functions for linear, logistic, and Poisson regression are, respectively: \\[ \\begin{align} \\eta(\\mu) &amp;= \\mu \\\\ \\eta(\\mu) &amp;= \\log \\left(\\frac{\\mu}{1 - \\mu} \\right) \\\\ \\eta(\\mu) &amp;= \\log (\\mu). \\end{align} \\] The Gaussian, Bernoulli, and Poisson distributions are all members of a wider class of distributions, known as the exponential family. Other well-known members of this family are the exponential distribution, the Gamma distribution, and the negative binomial distribution. In general, we can perform a regression by modeling the response \\(Y\\) as coming from a particular member of the exponential family, and then transforming the mean of the response so that the transformed mean is a linear function of the predictors via (4.42). Any regression approach that follows this very general recipe is known as a generalized linear model (GLM). Thus, linear regression, logistic regression, and Poisson regression and three examples of GLMs. Other examples not covered here include Gamma regression and negative binomial regerssion. 4.7 Lab: Classification Methods 4.7.1 The Stock Market Data We will begin by examining some numerical and graphical summaries of the Smarket data, which is part of the ISLR2 library. This data set consists of percentage returns for the S&amp;P 500 stock index over 1,250 days, from the beginning of 2001 until the end of 2005. For each date, we have recorded the percentage returns for each of the five previous trading days, Lag1 through Lag5. We have also recorded Volume (the number of shares traded on the previous day, in billions), Today (the percentage return on the date in question) and Direction (whether the market was Up or Down on this date). Our goal is to predict Direction (a qualitative response) using the other features. I like the skimr package for summarizing a data set: smarket &lt;- ISLR2::Smarket skimr::skim(smarket) Table 4.1: Data summary Name smarket Number of rows 1250 Number of columns 9 _______________________ Column type frequency: factor 1 numeric 8 ________________________ Group variables None Variable type: factor skim_variable n_missing complete_rate ordered n_unique top_counts Direction 0 1 FALSE 2 Up: 648, Dow: 602 Variable type: numeric skim_variable n_missing complete_rate mean sd p0 p25 p50 p75 p100 hist Year 0 1 2003.02 1.41 2001.00 2002.00 2003.00 2004.00 2005.00  Lag1 0 1 0.00 1.14 -4.92 -0.64 0.04 0.60 5.73  Lag2 0 1 0.00 1.14 -4.92 -0.64 0.04 0.60 5.73  Lag3 0 1 0.00 1.14 -4.92 -0.64 0.04 0.60 5.73  Lag4 0 1 0.00 1.14 -4.92 -0.64 0.04 0.60 5.73  Lag5 0 1 0.01 1.15 -4.92 -0.64 0.04 0.60 5.73  Volume 0 1 1.48 0.36 0.36 1.26 1.42 1.64 3.15  Today 0 1 0.00 1.14 -4.92 -0.64 0.04 0.60 5.73  To produce the pairwise correlations between predictors, Ill use another new package corrr, which returns a tidy tibble that we can turn into a nice gt table: smarket %&gt;% select(-Direction) %&gt;% corrr::correlate(method = &quot;pearson&quot;, quiet = TRUE) %&gt;% gt(rowname_col = &quot;term&quot;) %&gt;% gt::fmt_missing(columns = everything(), missing_text = &quot;&quot;) %&gt;% gt::data_color( columns = everything(), colors = scales::col_numeric( palette = td_pal(&quot;div5&quot;)(5), domain = c(-0.1, 0.6) ) ) %&gt;% gt::fmt_number(columns = everything(), decimals = 3) html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #uqrsmwixkt .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #uqrsmwixkt .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #uqrsmwixkt .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #uqrsmwixkt .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #uqrsmwixkt .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #uqrsmwixkt .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #uqrsmwixkt .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #uqrsmwixkt .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #uqrsmwixkt .gt_column_spanner_outer:first-child { padding-left: 0; } #uqrsmwixkt .gt_column_spanner_outer:last-child { padding-right: 0; } #uqrsmwixkt .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #uqrsmwixkt .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #uqrsmwixkt .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #uqrsmwixkt .gt_from_md > :first-child { margin-top: 0; } #uqrsmwixkt .gt_from_md > :last-child { margin-bottom: 0; } #uqrsmwixkt .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #uqrsmwixkt .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #uqrsmwixkt .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #uqrsmwixkt .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #uqrsmwixkt .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #uqrsmwixkt .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #uqrsmwixkt .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #uqrsmwixkt .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #uqrsmwixkt .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #uqrsmwixkt .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #uqrsmwixkt .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #uqrsmwixkt .gt_sourcenote { font-size: 90%; padding: 4px; } #uqrsmwixkt .gt_left { text-align: left; } #uqrsmwixkt .gt_center { text-align: center; } #uqrsmwixkt .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #uqrsmwixkt .gt_font_normal { font-weight: normal; } #uqrsmwixkt .gt_font_bold { font-weight: bold; } #uqrsmwixkt .gt_font_italic { font-style: italic; } #uqrsmwixkt .gt_super { font-size: 65%; } #uqrsmwixkt .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } Year Lag1 Lag2 Lag3 Lag4 Lag5 Volume Today Year 0.030 0.031 0.033 0.036 0.030 0.539 0.030 Lag1 0.030 &minus;0.026 &minus;0.011 &minus;0.003 &minus;0.006 0.041 &minus;0.026 Lag2 0.031 &minus;0.026 &minus;0.026 &minus;0.011 &minus;0.004 &minus;0.043 &minus;0.010 Lag3 0.033 &minus;0.011 &minus;0.026 &minus;0.024 &minus;0.019 &minus;0.042 &minus;0.002 Lag4 0.036 &minus;0.003 &minus;0.011 &minus;0.024 &minus;0.027 &minus;0.048 &minus;0.007 Lag5 0.030 &minus;0.006 &minus;0.004 &minus;0.019 &minus;0.027 &minus;0.022 &minus;0.035 Volume 0.539 0.041 &minus;0.043 &minus;0.042 &minus;0.048 &minus;0.022 0.015 Today 0.030 &minus;0.026 &minus;0.010 &minus;0.002 &minus;0.007 &minus;0.035 0.015 The only substantial correlation is between Volume and Year: smarket %&gt;% ggplot(aes(x = factor(Year), y = Volume)) + geom_jitter(width = 0.3, color = td_colors$nice$day9_yellow) + geom_boxplot(alpha = 0.3, outlier.shape = NA, width = 0.2) 4.7.2 Logistic Regression Use tidymodels to fit the model and produce the confusion matrix: library(tidymodels) glm_direction_fit &lt;- # Note that these options are the defaults # (and mode can only be &quot;classification&quot; for logistic) logistic_reg(mode = &quot;classification&quot;, engine = &quot;glm&quot;) %&gt;% fit(Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume, data = smarket) glm_direction_conf_mat &lt;- augment(glm_direction_fit, smarket) %&gt;% yardstick::conf_mat(.pred_class, Direction) glm_direction_conf_mat ## Truth ## Prediction Down Up ## Down 145 457 ## Up 141 507 This returns an object with some helpful built-in functions. Summary metrics: summary(glm_direction_conf_mat) ## # A tibble: 13 x 3 ## .metric .estimator .estimate ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 accuracy binary 0.522 ## 2 kap binary 0.0237 ## 3 sens binary 0.507 ## 4 spec binary 0.526 ## 5 ppv binary 0.241 ## 6 npv binary 0.782 ## 7 mcc binary 0.0277 ## 8 j_index binary 0.0329 ## 9 bal_accuracy binary 0.516 ## 10 detection_prevalence binary 0.482 ## 11 precision binary 0.241 ## 12 recall binary 0.507 ## 13 f_meas binary 0.327 We get the same accuracy (52.2%) as that in the text. There is also a couple autoplot() options autoplot(glm_direction_conf_mat, type = &quot;mosaic&quot;) | autoplot(glm_direction_conf_mat, type = &quot;heatmap&quot;) The next part of this lab is (I think) the first time we are splitting the data into training and testing data. Typically in tidymodels, we randomly split the data with rsample::initial_split, which takes a specified proportion (prop) and optional stratification variable (strata). In this lab, all the data for Year = 2005 is the hold out set. We can re-create this split manually with rsample::make_splits: smarket_split &lt;- make_splits( ind = list( # Get row numbers for &lt;2005 &quot;analysis&quot; = which(smarket$Year &lt; 2005), # Get row numbers for 2005 &quot;assessment&quot; = which(smarket$Year == 2005) ), data = smarket ) smarket_split ## &lt;Analysis/Assess/Total&gt; ## &lt;998/252/1250&gt; We then get the training and testing data with their matching functions: smarket_train &lt;- training(smarket_split) smarket_test &lt;- testing(smarket_split) Re-fit the model using the training data only: glm_direction_fit &lt;- logistic_reg(mode = &quot;classification&quot;, engine = &quot;glm&quot;) %&gt;% fit(Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume, data = smarket_train) Just as a demonstration, I will evaluate the model on the training data first: glm_direction_train_pred &lt;- glm_direction_fit %&gt;% augment(smarket_train) glm_direction_train_pred %&gt;% accuracy(truth = Direction, .pred_class) ## # A tibble: 1 x 3 ## .metric .estimator .estimate ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 accuracy binary 0.527 Quite poor. This was calculated using the 50% probability threshold, but we can also look at the ROC curve: glm_direction_train_pred %&gt;% roc_curve(truth = Direction, .pred_Up, event_level = &quot;second&quot;) %&gt;% autoplot() This doesnt give a lot of confidence in the performance on the testing set: glm_direction_test_pred &lt;- glm_direction_fit %&gt;% augment(smarket_test) glm_direction_test_pred %&gt;% accuracy(truth = Direction, .pred_class) ## # A tibble: 1 x 3 ## .metric .estimator .estimate ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 accuracy binary 0.480 We get an accuracy that is worse than random guessing. Disappointing, but not a surprise as the authors say: Of course this result is not all that surprising, given that one would not generally expect to be able to use previous days returns to predict future market performance. (After all, if it were possible to do so, then the authors of this book would be out striking it rich rather than writing a statistics textbook.) Perhaps a simpler model would be more effective. After all, using predictors that have no relationship with the response tends to cause a deterioration in the test error rate (since such predictors cause an increase in variance without a corresponding decrease in bias), and so removing such predictors may in turn yield an improvement. glm_direction_fit_simple &lt;- logistic_reg(mode = &quot;classification&quot;, engine = &quot;glm&quot;) %&gt;% fit(Direction ~ Lag1 + Lag2, data = smarket_train) glm_direction_fit_simple %&gt;% augment(smarket_test) %&gt;% accuracy(truth = Direction, .pred_class) ## # A tibble: 1 x 3 ## .metric .estimator .estimate ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 accuracy binary 0.560 Indeed it does. 4.7.3 Linear Discriminant Analysis Perform LDA to predict Direction from Lag1 and Lag2: library(discrim) lda_direction_fit &lt;- # Note that this model definition does not come with parsnip, but the # extension package discrim discrim::discrim_linear(mode = &quot;classification&quot;, engine = &quot;MASS&quot;) %&gt;% fit(Direction ~ Lag1 + Lag2, data = smarket_train) lda_direction_fit ## parsnip model object ## ## Fit time: 0ms ## Call: ## lda(Direction ~ Lag1 + Lag2, data = data) ## ## Prior probabilities of groups: ## Down Up ## 0.491984 0.508016 ## ## Group means: ## Lag1 Lag2 ## Down 0.04279022 0.03389409 ## Up -0.03954635 -0.03132544 ## ## Coefficients of linear discriminants: ## LD1 ## Lag1 -0.6420190 ## Lag2 -0.5135293 Performance on the testing data set: lda_direction_test_pred &lt;- lda_direction_fit %&gt;% augment(new_data = smarket_test) lda_direction_test_pred %&gt;% conf_mat(truth = Direction, estimate = .pred_class) ## Truth ## Prediction Down Up ## Down 35 35 ## Up 76 106 lda_direction_test_pred %&gt;% accuracy(truth = Direction, estimate = .pred_class) ## # A tibble: 1 x 3 ## .metric .estimator .estimate ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 accuracy binary 0.560 Though there is a package called probably for adjusting probability thresholds for classification metrics, I will just manually do so here: lda_direction_test_pred %&gt;% filter(.pred_Down &gt; 0.9) ## # A tibble: 0 x 12 ## # ... with 12 variables: Year &lt;dbl&gt;, Lag1 &lt;dbl&gt;, Lag2 &lt;dbl&gt;, Lag3 &lt;dbl&gt;, ## # Lag4 &lt;dbl&gt;, Lag5 &lt;dbl&gt;, Volume &lt;dbl&gt;, Today &lt;dbl&gt;, Direction &lt;fct&gt;, ## # .pred_class &lt;fct&gt;, .pred_Down &lt;dbl&gt;, .pred_Up &lt;dbl&gt; max(lda_direction_test_pred$.pred_Down) ## [1] 0.520235 4.7.4 Quadratic Discriminant Analysis Performing QDA will look very similar: qda_direction_fit &lt;- discrim_quad(mode = &quot;classification&quot;, engine = &quot;MASS&quot;) %&gt;% fit(Direction ~ Lag1 + Lag2, data = smarket_train) qda_direction_fit ## parsnip model object ## ## Fit time: 0ms ## Call: ## qda(Direction ~ Lag1 + Lag2, data = data) ## ## Prior probabilities of groups: ## Down Up ## 0.491984 0.508016 ## ## Group means: ## Lag1 Lag2 ## Down 0.04279022 0.03389409 ## Up -0.03954635 -0.03132544 qda_direction_test_pred &lt;- qda_direction_fit %&gt;% augment(new_data = smarket_test) qda_direction_test_pred %&gt;% conf_mat(truth = Direction, estimate = .pred_class) ## Truth ## Prediction Down Up ## Down 30 20 ## Up 81 121 qda_direction_test_pred %&gt;% accuracy(truth = Direction, estimate = .pred_class) ## # A tibble: 1 x 3 ## .metric .estimator .estimate ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 accuracy binary 0.599 This level of accuracy is quite impressive for stock market data, suggesting that the quadratic form may capture the true relationship more accurately. 4.7.5 Naive Bayes By default, the discrim::naive_Bayes() function uses the klaR package as the engine (e1071 is not an option). nb_direction_fit &lt;- naive_Bayes(mode = &quot;classification&quot;, engine = &quot;klaR&quot;) %&gt;% # The klaR engine has an argument usekernel that is always TRUE # We have to set it to FALSE to not use KDE, and instead use Gaussian # distributions, as in the text set_args(usekernel = FALSE) %&gt;% fit(Direction ~ Lag1 + Lag2, data = smarket_train) # The model output is quite long, so I won&#39;t print it here # nb_direction_fit nb_direction_test_pred &lt;- nb_direction_fit %&gt;% augment(new_data = smarket_test) nb_direction_test_pred %&gt;% conf_mat(truth = Direction, estimate = .pred_class) ## Truth ## Prediction Down Up ## Down 28 20 ## Up 83 121 nb_direction_test_pred %&gt;% accuracy(truth = Direction, estimate = .pred_class) ## # A tibble: 1 x 3 ## .metric .estimator .estimate ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 accuracy binary 0.591 The naive Bayes approach was quite close (a bit worse) than QDA. This makes sense. As we saw in the correlation matrix, the Lag1 and Lag2 are uncorrelated, so the assumption of naive Bayes is not violated. 4.7.6 \\(K\\)-Nearest Neighbors Ill skip right to the \\(K = 3\\) neighbors fit: knn_direction_fit &lt;- nearest_neighbor(mode = &quot;classification&quot;, engine = &quot;kknn&quot;, neighbors = 3) %&gt;% fit(Direction ~ Lag1 + Lag2, data = smarket_train) knn_direction_test_pred &lt;- knn_direction_fit %&gt;% augment(new_data = smarket_test) knn_direction_test_pred %&gt;% conf_mat(truth = Direction, estimate = .pred_class) ## Truth ## Prediction Down Up ## Down 43 58 ## Up 68 83 knn_direction_test_pred %&gt;% accuracy(truth = Direction, estimate = .pred_class) ## # A tibble: 1 x 3 ## .metric .estimator .estimate ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 accuracy binary 0.5 Essentially a coin flip. To show a case where KNN does perform well, load the Caravan data set: caravan &lt;- ISLR2::Caravan This data set includes a massive 85 predictors that measure demographics for 5822 individuals who did or did not Purchase a caravan insurance policy. caravan %&gt;% count(Purchase) %&gt;% mutate(p = n / sum(n)) ## Purchase n p ## 1 No 5474 0.94022673 ## 2 Yes 348 0.05977327 Split the data into training and testing based on row number: caravan_split &lt;- make_splits( ind = list(&quot;assessment&quot; = 1:1000, &quot;analysis&quot; = 1001:nrow(caravan)), data = caravan ) caravan_split ## &lt;Analysis/Assess/Total&gt; ## &lt;4822/1000/5822&gt; caravan_train &lt;- training(caravan_split) caravan_test &lt;- testing(caravan_split) KNN predicts a class based on nearby observations, and so the scale of the variables matters. For instance, imagine a data set that contains two variables, salary and age (measured in dollars and years, respectively). As far as KNN is concerned, a difference of $1,000 in salary is enormous compared to a difference of 50 years in age. Consequently, salary will drive the KNN classification results, and age will have almost no effect. This is contrary to our intuition that a salary difference of $1,000 is quite small compared to an age difference of 50 years. To deal with this, we standardize/normalize the data to have mean zero and standard deviation one. In tidymodels, this means we define a recipe with the step_normalize() step: caravan_rec &lt;- recipe(Purchase ~ ., data = caravan_train) %&gt;% step_normalize(all_numeric_predictors()) Then we define the models with 1, 3, and 5 neighbors: knn_spec1 &lt;- nearest_neighbor(mode = &quot;classification&quot;, engine = &quot;kknn&quot;, neighbors = 1) knn_spec3 &lt;- nearest_neighbor(mode = &quot;classification&quot;, engine = &quot;kknn&quot;, neighbors = 3) knn_spec5 &lt;- nearest_neighbor(mode = &quot;classification&quot;, engine = &quot;kknn&quot;, neighbors = 3) We put the model and recipe together into three separate workflows: knn_purchase_wf1 &lt;- workflow() %&gt;% add_recipe(caravan_rec) %&gt;% add_model(knn_spec1) knn_purchase_wf3 &lt;- workflow() %&gt;% add_recipe(caravan_rec) %&gt;% add_model(knn_spec3) knn_purchase_wf5 &lt;- workflow() %&gt;% add_recipe(caravan_rec) %&gt;% add_model(knn_spec5) Fit all the models: knn_purchase_fit1 &lt;- knn_purchase_wf1 %&gt;% fit(caravan_train) knn_purchase_fit3 &lt;- knn_purchase_wf3 %&gt;% fit(caravan_train) knn_purchase_fit5 &lt;- knn_purchase_wf5 %&gt;% fit(caravan_train) Compile the metrics: knn_metrics &lt;- metric_set(accuracy, sensitivity, specificity, ppv,) bind_rows( augment(knn_purchase_fit1, new_data = caravan_test) %&gt;% knn_metrics(truth = Purchase, estimate = .pred_class) %&gt;% mutate(neighbors = 1), augment(knn_purchase_fit3, new_data = caravan_test) %&gt;% knn_metrics(truth = Purchase, estimate = .pred_class) %&gt;% mutate(neighbors = 3), augment(knn_purchase_fit5, new_data = caravan_test) %&gt;% knn_metrics(truth = Purchase, estimate = .pred_class) %&gt;% mutate(neighbors = 5) ) %&gt;% transmute(neighbors, .metric, .estimate = round(.estimate, 3)) %&gt;% pivot_wider(names_from = .metric, values_from = .estimate) %&gt;% gt() html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #dukqkzdkue .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #dukqkzdkue .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #dukqkzdkue .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #dukqkzdkue .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #dukqkzdkue .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #dukqkzdkue .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #dukqkzdkue .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #dukqkzdkue .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #dukqkzdkue .gt_column_spanner_outer:first-child { padding-left: 0; } #dukqkzdkue .gt_column_spanner_outer:last-child { padding-right: 0; } #dukqkzdkue .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #dukqkzdkue .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #dukqkzdkue .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #dukqkzdkue .gt_from_md > :first-child { margin-top: 0; } #dukqkzdkue .gt_from_md > :last-child { margin-bottom: 0; } #dukqkzdkue .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #dukqkzdkue .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #dukqkzdkue .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #dukqkzdkue .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #dukqkzdkue .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #dukqkzdkue .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #dukqkzdkue .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #dukqkzdkue .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #dukqkzdkue .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #dukqkzdkue .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #dukqkzdkue .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #dukqkzdkue .gt_sourcenote { font-size: 90%; padding: 4px; } #dukqkzdkue .gt_left { text-align: left; } #dukqkzdkue .gt_center { text-align: center; } #dukqkzdkue .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #dukqkzdkue .gt_font_normal { font-weight: normal; } #dukqkzdkue .gt_font_bold { font-weight: bold; } #dukqkzdkue .gt_font_italic { font-style: italic; } #dukqkzdkue .gt_super { font-size: 65%; } #dukqkzdkue .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } neighbors accuracy sens spec ppv 1 0.883 0.929 0.153 0.946 3 0.884 0.930 0.153 0.946 5 0.884 0.930 0.153 0.946 The percentages reported in the text are the positive predictive value (TP / (TP + FP)). This is the ppv variable in the above table, which is way off. This is due to the event_level argument to the ppv() metric function (and sensitivity and specificity for that matter). It is calculated the PPV for the first level of the response, which is Purchase = No. Re-calculate PPV with the correctpositive\" event identified: bind_rows( augment(knn_purchase_fit1, new_data = caravan_test) %&gt;% ppv(truth = Purchase, estimate = .pred_class, event_level = &quot;second&quot;) %&gt;% mutate(neighbors = 1), augment(knn_purchase_fit3, new_data = caravan_test) %&gt;% ppv(truth = Purchase, estimate = .pred_class, event_level = &quot;second&quot;) %&gt;% mutate(neighbors = 3), augment(knn_purchase_fit5, new_data = caravan_test) %&gt;% ppv(truth = Purchase, estimate = .pred_class, event_level = &quot;second&quot;) %&gt;% mutate(neighbors = 5) ) %&gt;% transmute(neighbors, .metric, .estimate = round(.estimate, 3)) %&gt;% pivot_wider(names_from = .metric, values_from = .estimate) %&gt;% gt() html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #dnfbunaqxq .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #dnfbunaqxq .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #dnfbunaqxq .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #dnfbunaqxq .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #dnfbunaqxq .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #dnfbunaqxq .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #dnfbunaqxq .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #dnfbunaqxq .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #dnfbunaqxq .gt_column_spanner_outer:first-child { padding-left: 0; } #dnfbunaqxq .gt_column_spanner_outer:last-child { padding-right: 0; } #dnfbunaqxq .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #dnfbunaqxq .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #dnfbunaqxq .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #dnfbunaqxq .gt_from_md > :first-child { margin-top: 0; } #dnfbunaqxq .gt_from_md > :last-child { margin-bottom: 0; } #dnfbunaqxq .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #dnfbunaqxq .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #dnfbunaqxq .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #dnfbunaqxq .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #dnfbunaqxq .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #dnfbunaqxq .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #dnfbunaqxq .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #dnfbunaqxq .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #dnfbunaqxq .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #dnfbunaqxq .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #dnfbunaqxq .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #dnfbunaqxq .gt_sourcenote { font-size: 90%; padding: 4px; } #dnfbunaqxq .gt_left { text-align: left; } #dnfbunaqxq .gt_center { text-align: center; } #dnfbunaqxq .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #dnfbunaqxq .gt_font_normal { font-weight: normal; } #dnfbunaqxq .gt_font_bold { font-weight: bold; } #dnfbunaqxq .gt_font_italic { font-style: italic; } #dnfbunaqxq .gt_super { font-size: 65%; } #dnfbunaqxq .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } neighbors ppv 1 0.118 3 0.120 5 0.120 Im not getting the improved PPV with increasing neighbors as in the text. Not sure why. Lastly, get the PPV from a logistic regression: glm_purchase_wf &lt;- workflow() %&gt;% add_recipe(caravan_rec) %&gt;% add_model(logistic_reg()) glm_purchase_fit &lt;- glm_purchase_wf %&gt;% fit(caravan_train) ## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred PPV with a default 50% threshold: augment(glm_purchase_fit, new_data = caravan_test) %&gt;% ppv(truth = Purchase, estimate = .pred_class, event_level = &quot;second&quot;) ## # A tibble: 1 x 3 ## .metric .estimator .estimate ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 ppv binary 0 PPV with a 25% threshold: augment(glm_purchase_fit, new_data = caravan_test) %&gt;% mutate( .pred_class = ifelse(.pred_Yes &gt; 0.25, &quot;Yes&quot;, &quot;No&quot;) %&gt;% factor() ) %&gt;% ppv(truth = Purchase, estimate = .pred_class, event_level = &quot;second&quot;) ## # A tibble: 1 x 3 ## .metric .estimator .estimate ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 ppv binary 0.333 4.7.7 Poisson Regression We will again fit the bikeshare data with Poisson regression, but this time with tidymodels: library(poissonreg) glm_bikers_model &lt;- poisson_reg(mode = &quot;regression&quot;, engine = &quot;glm&quot;) The model specification for poisson_reg() is a model wrapper that comes from the poissonreg package. It is good practice to explicitly state that we are making dummy variables of the categorical predictors via step_dummy(): glm_bikers_rec &lt;- recipe(bikers ~ mnth + hr + workingday + temp + weathersit, data = bikeshare) %&gt;% step_dummy(all_nominal_predictors()) Define the workflow and fit the model: glm_bikers_wf &lt;- workflow() %&gt;% add_model(glm_bikers_model) %&gt;% add_recipe(glm_bikers_rec) glm_bikers_fit &lt;- glm_bikers_wf %&gt;% fit(bikeshare) Weve already re-created Figure 4.15 with this model, so wont repeat it here. Instead, here is a plot of predictions and, just for fun, it is stratified by the weather: augment(glm_bikers_fit, new_data = bikeshare) %&gt;% ggplot(aes(x = bikers, y = .pred)) + geom_point(color = td_colors$nice$opera_mauve, alpha = 0.4) + geom_abline(slope = 1, size = 1, lty = 2) + facet_wrap(~weathersit) + theme(legend.position = &quot;none&quot;) + add_facet_borders() 4.8 Exercises Applied 13. Predict returns with Weekly weekly &lt;- ISLR2::Weekly Data summaries. skimr::skim(weekly) Table 4.2: Data summary Name weekly Number of rows 1089 Number of columns 9 _______________________ Column type frequency: factor 1 numeric 8 ________________________ Group variables None Variable type: factor skim_variable n_missing complete_rate ordered n_unique top_counts Direction 0 1 FALSE 2 Up: 605, Dow: 484 Variable type: numeric skim_variable n_missing complete_rate mean sd p0 p25 p50 p75 p100 hist Year 0 1 2000.05 6.03 1990.00 1995.00 2000.00 2005.00 2010.00  Lag1 0 1 0.15 2.36 -18.20 -1.15 0.24 1.41 12.03  Lag2 0 1 0.15 2.36 -18.20 -1.15 0.24 1.41 12.03  Lag3 0 1 0.15 2.36 -18.20 -1.16 0.24 1.41 12.03  Lag4 0 1 0.15 2.36 -18.20 -1.16 0.24 1.41 12.03  Lag5 0 1 0.14 2.36 -18.20 -1.17 0.23 1.41 12.03  Volume 0 1 1.57 1.69 0.09 0.33 1.00 2.05 9.33  Today 0 1 0.15 2.36 -18.20 -1.15 0.24 1.41 12.03  weekly %&gt;% select(-Direction) %&gt;% corrr::correlate(method = &quot;pearson&quot;, quiet = TRUE) %&gt;% gt(rowname_col = &quot;term&quot;) %&gt;% gt::fmt_missing(columns = everything(), missing_text = &quot;&quot;) %&gt;% gt::data_color( columns = everything(), colors = scales::col_numeric( palette = td_pal(&quot;div5&quot;)(5), domain = c(-0.1, 0.9) ) ) %&gt;% gt::fmt_number(columns = everything(), decimals = 3) html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #xqxytsflgj .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #xqxytsflgj .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #xqxytsflgj .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #xqxytsflgj .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #xqxytsflgj .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #xqxytsflgj .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #xqxytsflgj .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #xqxytsflgj .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #xqxytsflgj .gt_column_spanner_outer:first-child { padding-left: 0; } #xqxytsflgj .gt_column_spanner_outer:last-child { padding-right: 0; } #xqxytsflgj .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #xqxytsflgj .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #xqxytsflgj .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #xqxytsflgj .gt_from_md > :first-child { margin-top: 0; } #xqxytsflgj .gt_from_md > :last-child { margin-bottom: 0; } #xqxytsflgj .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #xqxytsflgj .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #xqxytsflgj .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #xqxytsflgj .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #xqxytsflgj .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #xqxytsflgj .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #xqxytsflgj .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #xqxytsflgj .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #xqxytsflgj .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #xqxytsflgj .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #xqxytsflgj .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #xqxytsflgj .gt_sourcenote { font-size: 90%; padding: 4px; } #xqxytsflgj .gt_left { text-align: left; } #xqxytsflgj .gt_center { text-align: center; } #xqxytsflgj .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #xqxytsflgj .gt_font_normal { font-weight: normal; } #xqxytsflgj .gt_font_bold { font-weight: bold; } #xqxytsflgj .gt_font_italic { font-style: italic; } #xqxytsflgj .gt_super { font-size: 65%; } #xqxytsflgj .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } Year Lag1 Lag2 Lag3 Lag4 Lag5 Volume Today Year &minus;0.032 &minus;0.033 &minus;0.030 &minus;0.031 &minus;0.031 0.842 &minus;0.032 Lag1 &minus;0.032 &minus;0.075 0.059 &minus;0.071 &minus;0.008 &minus;0.065 &minus;0.075 Lag2 &minus;0.033 &minus;0.075 &minus;0.076 0.058 &minus;0.072 &minus;0.086 0.059 Lag3 &minus;0.030 0.059 &minus;0.076 &minus;0.075 0.061 &minus;0.069 &minus;0.071 Lag4 &minus;0.031 &minus;0.071 0.058 &minus;0.075 &minus;0.076 &minus;0.061 &minus;0.008 Lag5 &minus;0.031 &minus;0.008 &minus;0.072 0.061 &minus;0.076 &minus;0.059 0.011 Volume 0.842 &minus;0.065 &minus;0.086 &minus;0.069 &minus;0.061 &minus;0.059 &minus;0.033 Today &minus;0.032 &minus;0.075 0.059 &minus;0.071 &minus;0.008 0.011 &minus;0.033 As before with the smarket data set, there is increasing Volume with Year: weekly %&gt;% ggplot(aes(x = factor(Year), y = Volume)) + geom_jitter(width = 0.3, color = td_colors$nice$day9_yellow) + geom_boxplot(alpha = 0.3, outlier.shape = NA, width = 0.2) Logistic regression. Before fitting, I will reverse the order of the Direction factor so that the first level is Up because tidymodels treats the first level as positive. weekly &lt;- weekly %&gt;% mutate(Direction = fct_rev(Direction)) lr_weekly_fit &lt;- logistic_reg() %&gt;% fit(Direction ~ Year + Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume, data = weekly) tidy_custom(lr_weekly_fit) %&gt;% gt() html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #uskhvdnlih .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #uskhvdnlih .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #uskhvdnlih .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #uskhvdnlih .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #uskhvdnlih .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #uskhvdnlih .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #uskhvdnlih .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #uskhvdnlih .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #uskhvdnlih .gt_column_spanner_outer:first-child { padding-left: 0; } #uskhvdnlih .gt_column_spanner_outer:last-child { padding-right: 0; } #uskhvdnlih .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #uskhvdnlih .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #uskhvdnlih .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #uskhvdnlih .gt_from_md > :first-child { margin-top: 0; } #uskhvdnlih .gt_from_md > :last-child { margin-bottom: 0; } #uskhvdnlih .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #uskhvdnlih .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #uskhvdnlih .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #uskhvdnlih .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #uskhvdnlih .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #uskhvdnlih .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #uskhvdnlih .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #uskhvdnlih .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #uskhvdnlih .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #uskhvdnlih .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #uskhvdnlih .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #uskhvdnlih .gt_sourcenote { font-size: 90%; padding: 4px; } #uskhvdnlih .gt_left { text-align: left; } #uskhvdnlih .gt_center { text-align: center; } #uskhvdnlih .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #uskhvdnlih .gt_font_normal { font-weight: normal; } #uskhvdnlih .gt_font_bold { font-weight: bold; } #uskhvdnlih .gt_font_italic { font-style: italic; } #uskhvdnlih .gt_super { font-size: 65%; } #uskhvdnlih .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } term coefficient std.error z-statistic p-value (Intercept) -17.2258 37.8905 -0.45 0.649 Year 0.0085 0.0190 0.45 0.654 Lag1 0.0407 0.0264 1.54 0.124 Lag2 -0.0594 0.0270 -2.20 0.028 Lag3 0.0155 0.0267 0.58 0.562 Lag4 0.0273 0.0265 1.03 0.302 Lag5 0.0140 0.0264 0.53 0.595 Volume -0.0033 0.0688 -0.05 0.962 Only Lag2 was a significant predictor. Confusion matrix. lr_weekly_fit_conf_mat &lt;- augment(lr_weekly_fit, weekly) %&gt;% conf_mat(truth = Direction, estimate = .pred_class) lr_weekly_fit_conf_mat ## Truth ## Prediction Up Down ## Up 558 428 ## Down 47 56 The model predicts many more Direction = Up than Down. The overall accuracy was slightly better than guessing: 56%. The sensitivity, TP / (TP + FP) was very good: 92%. The specificity, TN / (TN + FN) was very poor: 12%. Logistic regression with Lag2 as the sole predictor. Split into training and testing: weekly_train &lt;- weekly %&gt;% filter(Year &lt;= 2008) weekly_test &lt;- weekly %&gt;% filter(Year &gt; 2008) lr_weekly_fit_lag2 &lt;- logistic_reg() %&gt;% fit(Direction ~ Lag2, data = weekly_train) lr_weekly_fit_lag2_conf_mat &lt;- augment(lr_weekly_fit_lag2, weekly_test) %&gt;% conf_mat(truth = Direction, estimate = .pred_class) lr_weekly_fit_lag2_conf_mat ## Truth ## Prediction Up Down ## Up 56 34 ## Down 5 9 The model still predicts many more Direction = Up than Down. The overall accuracy: 62%. The sensitivity: 92%. The specificity: 21%. (e-h) Repeat using LDA, QDA, KNN, naive Bayes. model_fits &lt;- list( &quot;logistic&quot; = lr_weekly_fit_lag2, &quot;LDA&quot; = discrim_linear() %&gt;% fit(Direction ~ Lag2, data = weekly_train), &quot;QDA&quot; = discrim_quad() %&gt;% fit(Direction ~ Lag2, data = weekly_train), &quot;KNN1&quot; = nearest_neighbor(mode = &quot;classification&quot;, neighbors = 1) %&gt;% fit(Direction ~ Lag2, data = weekly_train), &quot;NB&quot; = naive_Bayes() %&gt;% fit(Direction ~ Lag2, data = weekly_train) ) weekly_metrics &lt;- metric_set(accuracy, sens, spec, ppv) imap_dfr( model_fits, ~augment(.x, new_data = weekly_test) %&gt;% weekly_metrics(truth = Direction, estimate = .pred_class), .id = &quot;model&quot; ) %&gt;% select(model, .metric, .estimate) %&gt;% pivot_wider(names_from = .metric, values_from = .estimate) %&gt;% gt(rowname_col = &quot;model&quot;) %&gt;% fmt_percent(columns = -model) html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #zjiisepasw .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #zjiisepasw .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #zjiisepasw .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #zjiisepasw .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #zjiisepasw .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #zjiisepasw .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #zjiisepasw .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #zjiisepasw .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #zjiisepasw .gt_column_spanner_outer:first-child { padding-left: 0; } #zjiisepasw .gt_column_spanner_outer:last-child { padding-right: 0; } #zjiisepasw .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #zjiisepasw .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #zjiisepasw .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #zjiisepasw .gt_from_md > :first-child { margin-top: 0; } #zjiisepasw .gt_from_md > :last-child { margin-bottom: 0; } #zjiisepasw .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #zjiisepasw .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #zjiisepasw .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #zjiisepasw .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #zjiisepasw .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #zjiisepasw .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #zjiisepasw .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #zjiisepasw .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #zjiisepasw .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #zjiisepasw .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #zjiisepasw .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #zjiisepasw .gt_sourcenote { font-size: 90%; padding: 4px; } #zjiisepasw .gt_left { text-align: left; } #zjiisepasw .gt_center { text-align: center; } #zjiisepasw .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #zjiisepasw .gt_font_normal { font-weight: normal; } #zjiisepasw .gt_font_bold { font-weight: bold; } #zjiisepasw .gt_font_italic { font-style: italic; } #zjiisepasw .gt_super { font-size: 65%; } #zjiisepasw .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } accuracy sens spec ppv logistic 62.50&percnt; 91.80&percnt; 20.93&percnt; 62.22&percnt; LDA 62.50&percnt; 91.80&percnt; 20.93&percnt; 62.22&percnt; QDA 58.65&percnt; 100.00&percnt; 0.00&percnt; 58.65&percnt; KNN1 50.00&percnt; 49.18&percnt; 51.16&percnt; 58.82&percnt; NB 60.58&percnt; 91.80&percnt; 16.28&percnt; 60.87&percnt; Which method was best? LDA and logistic regression performed exactly the same, and did the best. QDA predicted everything as Up. KNN with 1 neighbor was a coin flip simulator. Naive Bayes did slightly worse than logistic and LDA. 14. Predict gas mileage with Auto Create a binary outcome mpg01. auto &lt;- ISLR2::Auto %&gt;% mutate(mpg01 = ifelse(mpg &gt; median(mpg), 1, 0), mpg01 = factor(mpg01)) glimpse(auto) ## Rows: 392 ## Columns: 10 ## $ mpg &lt;dbl&gt; 18, 15, 18, 16, 17, 15, 14, 14, 14, 15, 15, 14, 15, 14, 2~ ## $ cylinders &lt;int&gt; 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 4, 6, 6, 6, 4, ~ ## $ displacement &lt;dbl&gt; 307, 350, 318, 304, 302, 429, 454, 440, 455, 390, 383, 34~ ## $ horsepower &lt;int&gt; 130, 165, 150, 150, 140, 198, 220, 215, 225, 190, 170, 16~ ## $ weight &lt;int&gt; 3504, 3693, 3436, 3433, 3449, 4341, 4354, 4312, 4425, 385~ ## $ acceleration &lt;dbl&gt; 12.0, 11.5, 11.0, 12.0, 10.5, 10.0, 9.0, 8.5, 10.0, 8.5, ~ ## $ year &lt;int&gt; 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 7~ ## $ origin &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 3, ~ ## $ name &lt;fct&gt; chevrolet chevelle malibu, buick skylark 320, plymouth sa~ ## $ mpg01 &lt;fct&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, ~ Note that origin is a numeric coding for 1. American, 2. European, and 3. Japanese, and so should be a factor: auto &lt;- auto %&gt;% mutate(origin = factor(origin, levels = 1:3, labels = c(&quot;American&quot;, &quot;European&quot;, &quot;Japanese&quot;))) Explore the data. auto %&gt;% select(-name, -origin, -mpg) %&gt;% pivot_longer(-mpg01, names_to = &quot;var&quot;, values_to = &quot;val&quot;) %&gt;% ggplot(aes(y = mpg01, x = val)) + geom_boxplot(aes(fill = factor(mpg01))) + facet_wrap(~var, scales = &quot;free_x&quot;) + theme(legend.position = &quot;none&quot;) + add_facet_borders() auto %&gt;% count(origin, mpg01) %&gt;% ggplot(aes(y = origin, x = mpg01)) + geom_tile(aes(fill = n)) + geom_text(aes(label = n), color = &quot;white&quot;) + scale_x_discrete(expand = c(0, 0)) + scale_y_discrete(expand = c(0, 0)) + theme(legend.position = &quot;none&quot;) All of the variables here look useful for predicting mpg01, but cylinders, displacement, origin, and weight in particular. Look at the correlation between variables: auto %&gt;% select(-name, -mpg01, -origin) %&gt;% corrr::correlate(method = &quot;pearson&quot;, quiet = TRUE) %&gt;% gt(rowname_col = &quot;term&quot;) %&gt;% gt::fmt_missing(columns = everything(), missing_text = &quot;&quot;) %&gt;% gt::data_color( columns = everything(), colors = scales::col_numeric( palette = td_pal(&quot;div5&quot;)(5), domain = c(-1, 1) ) ) %&gt;% gt::fmt_number(columns = everything(), decimals = 2) html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #tvalyfqizi .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #tvalyfqizi .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #tvalyfqizi .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #tvalyfqizi .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #tvalyfqizi .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #tvalyfqizi .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #tvalyfqizi .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #tvalyfqizi .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #tvalyfqizi .gt_column_spanner_outer:first-child { padding-left: 0; } #tvalyfqizi .gt_column_spanner_outer:last-child { padding-right: 0; } #tvalyfqizi .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #tvalyfqizi .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #tvalyfqizi .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #tvalyfqizi .gt_from_md > :first-child { margin-top: 0; } #tvalyfqizi .gt_from_md > :last-child { margin-bottom: 0; } #tvalyfqizi .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #tvalyfqizi .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #tvalyfqizi .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #tvalyfqizi .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #tvalyfqizi .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #tvalyfqizi .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #tvalyfqizi .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #tvalyfqizi .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #tvalyfqizi .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #tvalyfqizi .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #tvalyfqizi .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #tvalyfqizi .gt_sourcenote { font-size: 90%; padding: 4px; } #tvalyfqizi .gt_left { text-align: left; } #tvalyfqizi .gt_center { text-align: center; } #tvalyfqizi .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #tvalyfqizi .gt_font_normal { font-weight: normal; } #tvalyfqizi .gt_font_bold { font-weight: bold; } #tvalyfqizi .gt_font_italic { font-style: italic; } #tvalyfqizi .gt_super { font-size: 65%; } #tvalyfqizi .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } mpg cylinders displacement horsepower weight acceleration year mpg &minus;0.78 &minus;0.81 &minus;0.78 &minus;0.83 0.42 0.58 cylinders &minus;0.78 0.95 0.84 0.90 &minus;0.50 &minus;0.35 displacement &minus;0.81 0.95 0.90 0.93 &minus;0.54 &minus;0.37 horsepower &minus;0.78 0.84 0.90 0.86 &minus;0.69 &minus;0.42 weight &minus;0.83 0.90 0.93 0.86 &minus;0.42 &minus;0.31 acceleration 0.42 &minus;0.50 &minus;0.54 &minus;0.69 &minus;0.42 0.29 year 0.58 &minus;0.35 &minus;0.37 &minus;0.42 &minus;0.31 0.29 Lots of inter-correlation. Split the data into a training set and test set. Use a 3:1 split: set.seed(49) auto_split &lt;- initial_split(auto, prop = 3 / 4) auto_train &lt;- training(auto_split) auto_test &lt;- testing(auto_split) Normally, I would set the strata argument to the output variable mpg01, but by construction (separated by the median) the data is split in half. auto_train %&gt;% count(mpg01) ## mpg01 n ## 1 0 148 ## 2 1 146 auto_test %&gt;% count(mpg01) ## mpg01 n ## 1 0 48 ## 2 1 50 (d-h) Perform LDA, QDA, logistic regression, naive Bayes, and KNN. Define the recipe, and add it to a generic workflow: auto_recipe &lt;- recipe( mpg01 ~ cylinders + displacement + horsepower + weight + acceleration + year + origin, data = auto_train ) %&gt;% # Normalize numerical predictors to work with KNN step_normalize(all_numeric_predictors()) %&gt;% step_dummy(origin) auto_workflow &lt;- workflow() %&gt;% add_recipe(auto_recipe) Fit and summarize metrics: model_fits &lt;- list( &quot;LDA&quot; = auto_workflow %&gt;% add_model(discrim_linear()) %&gt;% fit(data = auto_train), &quot;QDA&quot; = auto_workflow %&gt;% add_model(discrim_quad()) %&gt;% fit(data = auto_train), &quot;logistic&quot; = auto_workflow %&gt;% add_model(logistic_reg()) %&gt;% fit(data = auto_train), &quot;NB&quot; = auto_workflow %&gt;% add_model(naive_Bayes()) %&gt;% fit(data = auto_train), &quot;KNN1&quot; = auto_workflow %&gt;% add_model(nearest_neighbor(mode = &quot;classification&quot;, neighbors = 1)) %&gt;% fit(data = auto_train), &quot;KNN3&quot; = auto_workflow %&gt;% add_model(nearest_neighbor(mode = &quot;classification&quot;, neighbors = 3)) %&gt;% fit(data = auto_train), &quot;KNN5&quot; = auto_workflow %&gt;% add_model(nearest_neighbor(mode = &quot;classification&quot;, neighbors = 5)) %&gt;% fit(data = auto_train), &quot;KNN7&quot; = auto_workflow %&gt;% add_model(nearest_neighbor(mode = &quot;classification&quot;, neighbors = 7)) %&gt;% fit(data = auto_train) ) auto_metrics &lt;- metric_set(accuracy, sens, spec, ppv) imap_dfr( model_fits, ~augment(.x, new_data = auto_test) %&gt;% auto_metrics(truth = mpg01, estimate = .pred_class), .id = &quot;model&quot; ) %&gt;% select(model, .metric, .estimate) %&gt;% pivot_wider(names_from = .metric, values_from = .estimate) %&gt;% arrange(desc(accuracy)) %&gt;% gt(rowname_col = &quot;model&quot;) %&gt;% fmt_percent(columns = -model, decimals = 1) html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #bljlvhvupr .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #bljlvhvupr .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #bljlvhvupr .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #bljlvhvupr .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #bljlvhvupr .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #bljlvhvupr .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #bljlvhvupr .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #bljlvhvupr .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #bljlvhvupr .gt_column_spanner_outer:first-child { padding-left: 0; } #bljlvhvupr .gt_column_spanner_outer:last-child { padding-right: 0; } #bljlvhvupr .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #bljlvhvupr .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #bljlvhvupr .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #bljlvhvupr .gt_from_md > :first-child { margin-top: 0; } #bljlvhvupr .gt_from_md > :last-child { margin-bottom: 0; } #bljlvhvupr .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #bljlvhvupr .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #bljlvhvupr .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #bljlvhvupr .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #bljlvhvupr .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #bljlvhvupr .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #bljlvhvupr .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #bljlvhvupr .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #bljlvhvupr .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #bljlvhvupr .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #bljlvhvupr .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #bljlvhvupr .gt_sourcenote { font-size: 90%; padding: 4px; } #bljlvhvupr .gt_left { text-align: left; } #bljlvhvupr .gt_center { text-align: center; } #bljlvhvupr .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #bljlvhvupr .gt_font_normal { font-weight: normal; } #bljlvhvupr .gt_font_bold { font-weight: bold; } #bljlvhvupr .gt_font_italic { font-style: italic; } #bljlvhvupr .gt_super { font-size: 65%; } #bljlvhvupr .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } accuracy sens spec ppv LDA 90.8&percnt; 87.5&percnt; 94.0&percnt; 93.3&percnt; logistic 90.8&percnt; 91.7&percnt; 90.0&percnt; 89.8&percnt; QDA 89.8&percnt; 85.4&percnt; 94.0&percnt; 93.2&percnt; NB 89.8&percnt; 87.5&percnt; 92.0&percnt; 91.3&percnt; KNN1 89.8&percnt; 93.8&percnt; 86.0&percnt; 86.5&percnt; KNN3 89.8&percnt; 93.8&percnt; 86.0&percnt; 86.5&percnt; KNN5 89.8&percnt; 91.7&percnt; 88.0&percnt; 88.0&percnt; KNN7 89.8&percnt; 91.7&percnt; 88.0&percnt; 88.0&percnt; All models did well, but LDA and logistic regression were the best. There wasnt any difference in KNN accuracy for \\(K\\) = 1, 3, 5, and 7. 16. Predict crime rate with Boston boston &lt;- ISLR2::Boston %&gt;% mutate( crim01 = ifelse(crim &gt; median(crim), 1, 0), crim01 = factor(crim01), # Convert the binary chas variable to TRUE/FALSE chas = chas == 1 ) glimpse(boston) ## Rows: 506 ## Columns: 14 ## $ crim &lt;dbl&gt; 0.00632, 0.02731, 0.02729, 0.03237, 0.06905, 0.02985, 0.08829,~ ## $ zn &lt;dbl&gt; 18.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.5, 12.5, 12.5, 12.5, 12.5, 1~ ## $ indus &lt;dbl&gt; 2.31, 7.07, 7.07, 2.18, 2.18, 2.18, 7.87, 7.87, 7.87, 7.87, 7.~ ## $ chas &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE,~ ## $ nox &lt;dbl&gt; 0.538, 0.469, 0.469, 0.458, 0.458, 0.458, 0.524, 0.524, 0.524,~ ## $ rm &lt;dbl&gt; 6.575, 6.421, 7.185, 6.998, 7.147, 6.430, 6.012, 6.172, 5.631,~ ## $ age &lt;dbl&gt; 65.2, 78.9, 61.1, 45.8, 54.2, 58.7, 66.6, 96.1, 100.0, 85.9, 9~ ## $ dis &lt;dbl&gt; 4.0900, 4.9671, 4.9671, 6.0622, 6.0622, 6.0622, 5.5605, 5.9505~ ## $ rad &lt;int&gt; 1, 2, 2, 3, 3, 3, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4,~ ## $ tax &lt;dbl&gt; 296, 242, 242, 222, 222, 222, 311, 311, 311, 311, 311, 311, 31~ ## $ ptratio &lt;dbl&gt; 15.3, 17.8, 17.8, 18.7, 18.7, 18.7, 15.2, 15.2, 15.2, 15.2, 15~ ## $ lstat &lt;dbl&gt; 4.98, 9.14, 4.03, 2.94, 5.33, 5.21, 12.43, 19.15, 29.93, 17.10~ ## $ medv &lt;dbl&gt; 24.0, 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15~ ## $ crim01 &lt;fct&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,~ boston %&gt;% select(-chas) %&gt;% pivot_longer(-crim01, names_to = &quot;var&quot;, values_to = &quot;val&quot;) %&gt;% ggplot(aes(y = crim01, x = val)) + geom_boxplot(aes(fill = factor(crim01))) + facet_wrap(~var, scales = &quot;free_x&quot;) + theme(legend.position = &quot;none&quot;) + add_facet_borders() boston %&gt;% count(chas, crim01) %&gt;% ggplot(aes(y = chas, x = crim01)) + geom_tile(aes(fill = n)) + geom_text(aes(label = n), color = &quot;white&quot;) + scale_x_discrete(expand = c(0, 0)) + scale_y_discrete(expand = c(0, 0)) + theme(legend.position = &quot;none&quot;) The chas and rm (average number of rooms per dwelling) variables look the least useful of these predictors. Split the data: set.seed(98) # By default, splits 3:1 boston_split &lt;- initial_split(boston) boston_train &lt;- training(boston_split) boston_test &lt;- testing(boston_split) Fit and summarize metrics for all the models and a few different predictor sets: boston_models &lt;- list( &quot;LDA&quot; = discrim_linear(), &quot;QDA&quot; = discrim_quad(), &quot;logistic&quot; = logistic_reg(), &quot;NB&quot; = naive_Bayes(), &quot;KNN1&quot; = nearest_neighbor(mode = &quot;classification&quot;, neighbors = 1), &quot;KNN3&quot; = nearest_neighbor(mode = &quot;classification&quot;, neighbors = 3), &quot;KNN5&quot; = nearest_neighbor(mode = &quot;classification&quot;, neighbors = 5), &quot;KNN7&quot; = nearest_neighbor(mode = &quot;classification&quot;, neighbors = 7) ) boston_recs &lt;- list( &quot;rec1&quot; = recipe( crim01 ~ age + dis + indus + lstat + medv + nox + ptratio + rad + tax + zn, data = boston_train ) %&gt;% step_normalize(all_numeric_predictors()), # Drop medv and lstat &quot;rec2&quot; = recipe( crim01 ~ age + dis + indus + nox + ptratio + rad + tax + zn, data = boston_train ) %&gt;% step_normalize(all_numeric_predictors()), # Drop ptratio and tax &quot;rec3&quot; = recipe( crim01 ~ age + dis + indus + nox + rad + zn, data = boston_train ) %&gt;% step_normalize(all_numeric_predictors()) ) boston_fits &lt;- map( boston_models, function(model) { map( boston_recs, ~workflow() %&gt;% add_model(model) %&gt;% add_recipe(.x) %&gt;% fit(data = boston_train) ) } ) boston_metrics &lt;- metric_set(accuracy, sens, spec, ppv) imap_dfr( boston_fits, function(fit, y) { imap_dfr( fit, ~augment(.x, new_data = boston_test) %&gt;% boston_metrics(truth = crim01, estimate = .pred_class), .id = &quot;recipe&quot; ) }, .id = &quot;model&quot; ) %&gt;% select(model, recipe, .metric, .estimate) %&gt;% pivot_wider(names_from = .metric, values_from = .estimate) %&gt;% arrange(recipe, desc(accuracy)) %&gt;% group_by(recipe) %&gt;% gt(rowname_col = &quot;model&quot;) %&gt;% fmt_percent(columns = -model, decimals = 1) html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #wbsyrjdeoz .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #wbsyrjdeoz .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #wbsyrjdeoz .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #wbsyrjdeoz .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #wbsyrjdeoz .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #wbsyrjdeoz .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #wbsyrjdeoz .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #wbsyrjdeoz .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #wbsyrjdeoz .gt_column_spanner_outer:first-child { padding-left: 0; } #wbsyrjdeoz .gt_column_spanner_outer:last-child { padding-right: 0; } #wbsyrjdeoz .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #wbsyrjdeoz .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #wbsyrjdeoz .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #wbsyrjdeoz .gt_from_md > :first-child { margin-top: 0; } #wbsyrjdeoz .gt_from_md > :last-child { margin-bottom: 0; } #wbsyrjdeoz .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #wbsyrjdeoz .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #wbsyrjdeoz .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #wbsyrjdeoz .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #wbsyrjdeoz .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #wbsyrjdeoz .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #wbsyrjdeoz .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #wbsyrjdeoz .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #wbsyrjdeoz .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #wbsyrjdeoz .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #wbsyrjdeoz .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #wbsyrjdeoz .gt_sourcenote { font-size: 90%; padding: 4px; } #wbsyrjdeoz .gt_left { text-align: left; } #wbsyrjdeoz .gt_center { text-align: center; } #wbsyrjdeoz .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #wbsyrjdeoz .gt_font_normal { font-weight: normal; } #wbsyrjdeoz .gt_font_bold { font-weight: bold; } #wbsyrjdeoz .gt_font_italic { font-style: italic; } #wbsyrjdeoz .gt_super { font-size: 65%; } #wbsyrjdeoz .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } accuracy sens spec ppv rec1 QDA 95.3&percnt; 94.6&percnt; 95.8&percnt; 94.6&percnt; KNN1 94.5&percnt; 98.2&percnt; 91.5&percnt; 90.2&percnt; KNN3 94.5&percnt; 98.2&percnt; 91.5&percnt; 90.2&percnt; KNN5 94.5&percnt; 98.2&percnt; 91.5&percnt; 90.2&percnt; KNN7 94.5&percnt; 98.2&percnt; 91.5&percnt; 90.2&percnt; logistic 92.1&percnt; 98.2&percnt; 87.3&percnt; 85.9&percnt; NB 85.0&percnt; 80.4&percnt; 88.7&percnt; 84.9&percnt; LDA 83.5&percnt; 91.1&percnt; 77.5&percnt; 76.1&percnt; rec2 KNN5 96.1&percnt; 100.0&percnt; 93.0&percnt; 91.8&percnt; KNN1 95.3&percnt; 98.2&percnt; 93.0&percnt; 91.7&percnt; KNN3 95.3&percnt; 98.2&percnt; 93.0&percnt; 91.7&percnt; KNN7 95.3&percnt; 98.2&percnt; 93.0&percnt; 91.7&percnt; QDA 94.5&percnt; 94.6&percnt; 94.4&percnt; 93.0&percnt; logistic 89.0&percnt; 87.5&percnt; 90.1&percnt; 87.5&percnt; LDA 86.6&percnt; 96.4&percnt; 78.9&percnt; 78.3&percnt; NB 84.3&percnt; 80.4&percnt; 87.3&percnt; 83.3&percnt; rec3 KNN5 95.3&percnt; 98.2&percnt; 93.0&percnt; 91.7&percnt; KNN1 94.5&percnt; 98.2&percnt; 91.5&percnt; 90.2&percnt; KNN3 94.5&percnt; 98.2&percnt; 91.5&percnt; 90.2&percnt; KNN7 94.5&percnt; 96.4&percnt; 93.0&percnt; 91.5&percnt; logistic 89.0&percnt; 87.5&percnt; 90.1&percnt; 87.5&percnt; QDA 86.6&percnt; 91.1&percnt; 83.1&percnt; 81.0&percnt; NB 86.6&percnt; 76.8&percnt; 94.4&percnt; 91.5&percnt; LDA 84.3&percnt; 91.1&percnt; 78.9&percnt; 77.3&percnt; In general, performance was best for rec2 with these variables: boston_recs$rec2$term_info ## # A tibble: 9 x 4 ## variable type role source ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 age numeric predictor original ## 2 dis numeric predictor original ## 3 indus numeric predictor original ## 4 nox numeric predictor original ## 5 ptratio numeric predictor original ## 6 rad numeric predictor original ## 7 tax numeric predictor original ## 8 zn numeric predictor original ## 9 crim01 nominal outcome original And the models that performed best were KNN and QDA. Reproducibility Reproducibility receipt Sys.time() ## [1] &quot;2022-04-09 16:07:46 AST&quot; if (&quot;git2r&quot; %in% installed.packages()) { if (git2r::in_repository()) { git2r::repository() } } ## Local: main C:/Users/tdunn/Documents/learning/islr-tidy ## Remote: main @ origin (https://github.com/taylordunn/islr-tidy) ## Head: [00046ed] 2022-04-08: Finished chapter 6 sessioninfo::session_info() ## - Session info --------------------------------------------------------------- ## setting value ## version R version 4.1.3 (2022-03-10) ## os Windows 10 x64 ## system x86_64, mingw32 ## ui RTerm ## language (EN) ## collate English_Canada.1252 ## ctype English_Canada.1252 ## tz America/Curacao ## date 2022-04-09 ## ## - Packages ------------------------------------------------------------------- ## package * version date lib source ## abind 1.4-5 2016-07-21 [1] CRAN (R 4.1.1) ## assertthat 0.2.1 2019-03-21 [1] CRAN (R 4.1.0) ## backports 1.2.1 2020-12-09 [1] CRAN (R 4.1.0) ## base64enc 0.1-3 2015-07-28 [1] CRAN (R 4.1.0) ## bayestestR 0.10.5 2021-07-26 [1] CRAN (R 4.1.0) ## bit 4.0.4 2020-08-04 [1] CRAN (R 4.1.2) ## bit64 4.0.5 2020-08-30 [1] CRAN (R 4.1.2) ## bookdown 0.24 2021-09-02 [1] CRAN (R 4.1.1) ## broom * 0.7.10 2021-10-31 [1] CRAN (R 4.1.2) ## bslib 0.2.5.1 2021-05-18 [1] CRAN (R 4.1.0) ## cachem 1.0.6 2021-08-19 [1] CRAN (R 4.1.1) ## car 3.0-12 2021-11-06 [1] CRAN (R 4.1.2) ## carData 3.0-4 2020-05-22 [1] CRAN (R 4.1.1) ## cellranger 1.1.0 2016-07-27 [1] CRAN (R 4.1.0) ## checkmate 2.0.0 2020-02-06 [1] CRAN (R 4.1.0) ## class 7.3-20 2022-01-16 [2] CRAN (R 4.1.3) ## cli 3.2.0 2022-02-14 [1] CRAN (R 4.1.3) ## coda 0.19-4 2020-09-30 [1] CRAN (R 4.1.0) ## codetools 0.2-18 2020-11-04 [2] CRAN (R 4.1.3) ## colorspace 2.0-3 2022-02-21 [1] CRAN (R 4.1.3) ## combinat 0.0-8 2012-10-29 [1] CRAN (R 4.1.1) ## corrr * 0.4.3 2020-11-24 [1] CRAN (R 4.1.0) ## crayon 1.5.1 2022-03-26 [1] CRAN (R 4.1.3) ## datawizard 0.1.0 2021-06-18 [1] CRAN (R 4.1.0) ## DBI 1.1.2 2021-12-20 [1] CRAN (R 4.1.2) ## dbplyr 2.1.1 2021-04-06 [1] CRAN (R 4.1.0) ## DEoptimR 1.0-9 2021-05-24 [1] CRAN (R 4.1.0) ## dials * 0.0.10 2021-09-10 [1] CRAN (R 4.1.1) ## DiceDesign 1.9 2021-02-13 [1] CRAN (R 4.1.0) ## digest 0.6.29 2021-12-01 [1] CRAN (R 4.1.2) ## discrim * 0.1.3 2021-07-21 [1] CRAN (R 4.1.2) ## distill 1.3 2021-10-13 [1] CRAN (R 4.1.2) ## distributional 0.2.2 2021-02-02 [1] CRAN (R 4.1.2) ## downlit 0.4.0 2021-10-29 [1] CRAN (R 4.1.1) ## dplyr * 1.0.8 2022-02-08 [1] CRAN (R 4.1.3) ## dunnr * 0.2.5 2022-01-15 [1] Github (taylordunn/dunnr@c83b30e) ## effectsize 0.4.5 2021-05-25 [1] CRAN (R 4.1.0) ## ellipsis 0.3.2 2021-04-29 [1] CRAN (R 4.1.0) ## emmeans 1.7.0 2021-09-29 [1] CRAN (R 4.1.2) ## equatiomatic 0.2.0 2021-01-30 [1] CRAN (R 4.1.0) ## estimability 1.3 2018-02-11 [1] CRAN (R 4.1.1) ## evaluate 0.14 2019-05-28 [1] CRAN (R 4.1.0) ## extrafont 0.17 2014-12-08 [1] CRAN (R 4.1.0) ## extrafontdb 1.0 2012-06-11 [1] CRAN (R 4.1.0) ## fansi 1.0.3 2022-03-24 [1] CRAN (R 4.1.3) ## farver 2.1.0 2021-02-28 [1] CRAN (R 4.1.0) ## fastmap 1.1.0 2021-01-25 [1] CRAN (R 4.1.0) ## forcats * 0.5.1 2021-01-27 [1] CRAN (R 4.1.0) ## foreach 1.5.2 2022-02-02 [1] CRAN (R 4.1.3) ## fs 1.5.2 2021-12-08 [1] CRAN (R 4.1.2) ## furrr 0.2.3 2021-06-25 [1] CRAN (R 4.1.2) ## future 1.24.0 2022-02-19 [1] CRAN (R 4.1.3) ## future.apply 1.8.1 2021-08-10 [1] CRAN (R 4.1.3) ## generics 0.1.2 2022-01-31 [1] CRAN (R 4.1.3) ## GGally 2.1.2 2021-06-21 [1] CRAN (R 4.1.0) ## ggdist * 3.0.0 2021-07-19 [1] CRAN (R 4.1.2) ## ggplot2 * 3.3.5 2021-06-25 [1] CRAN (R 4.1.0) ## ggrepel 0.9.1 2021-01-15 [1] CRAN (R 4.1.0) ## ggridges 0.5.3 2021-01-08 [1] CRAN (R 4.1.0) ## git2r 0.28.0 2021-01-10 [1] CRAN (R 4.1.0) ## globals 0.14.0 2020-11-22 [1] CRAN (R 4.1.0) ## glue 1.6.2 2022-02-24 [1] CRAN (R 4.1.3) ## gower 0.2.2 2020-06-23 [1] CRAN (R 4.1.0) ## GPfit 1.0-8 2019-02-08 [1] CRAN (R 4.1.0) ## gridExtra 2.3 2017-09-09 [1] CRAN (R 4.1.0) ## gt * 0.3.1 2021-08-07 [1] CRAN (R 4.1.2) ## gtable 0.3.0 2019-03-25 [1] CRAN (R 4.1.0) ## hardhat 0.2.0 2022-01-24 [1] CRAN (R 4.1.3) ## haven 2.4.1 2021-04-23 [1] CRAN (R 4.1.0) ## here * 1.0.1 2020-12-13 [1] CRAN (R 4.1.0) ## highr 0.9 2021-04-16 [1] CRAN (R 4.1.0) ## hms 1.1.1 2021-09-26 [1] CRAN (R 4.1.2) ## htmltools 0.5.2 2021-08-25 [1] CRAN (R 4.1.1) ## httpuv 1.6.5 2022-01-05 [1] CRAN (R 4.1.2) ## httr 1.4.2 2020-07-20 [1] CRAN (R 4.1.0) ## igraph 1.2.11 2022-01-04 [1] CRAN (R 4.1.3) ## infer * 1.0.0 2021-08-13 [1] CRAN (R 4.1.1) ## insight 0.14.2 2021-06-22 [1] CRAN (R 4.1.0) ## ipred 0.9-12 2021-09-15 [1] CRAN (R 4.1.1) ## ISLR2 * 1.3-1 2022-01-10 [1] CRAN (R 4.1.2) ## iterators 1.0.14 2022-02-05 [1] CRAN (R 4.1.3) ## jquerylib 0.1.4 2021-04-26 [1] CRAN (R 4.1.0) ## jsonlite 1.7.3 2022-01-17 [1] CRAN (R 4.1.2) ## kknn 1.3.1 2016-03-26 [1] CRAN (R 4.1.2) ## klaR 0.6-15 2020-02-19 [1] CRAN (R 4.1.2) ## knitr 1.37 2021-12-16 [1] CRAN (R 4.1.2) ## labeling 0.4.2 2020-10-20 [1] CRAN (R 4.1.0) ## labelled 2.8.0 2021-03-08 [1] CRAN (R 4.1.0) ## later 1.3.0 2021-08-18 [1] CRAN (R 4.1.2) ## lattice 0.20-45 2021-09-22 [2] CRAN (R 4.1.3) ## lava 1.6.10 2021-09-02 [1] CRAN (R 4.1.3) ## lhs 1.1.1 2020-10-05 [1] CRAN (R 4.1.0) ## lifecycle 1.0.1 2021-09-24 [1] CRAN (R 4.1.1) ## listenv 0.8.0 2019-12-05 [1] CRAN (R 4.1.0) ## lubridate 1.8.0 2021-10-07 [1] CRAN (R 4.1.1) ## magrittr 2.0.2 2022-01-26 [1] CRAN (R 4.1.3) ## MASS 7.3-55 2022-01-16 [2] CRAN (R 4.1.3) ## Matrix 1.4-0 2021-12-08 [2] CRAN (R 4.1.3) ## memoise 2.0.1 2021-11-26 [1] CRAN (R 4.1.2) ## mgcv 1.8-39 2022-02-24 [2] CRAN (R 4.1.3) ## mime 0.12 2021-09-28 [1] CRAN (R 4.1.1) ## miniUI 0.1.1.1 2018-05-18 [1] CRAN (R 4.1.1) ## modeldata * 0.1.1 2021-07-14 [1] CRAN (R 4.1.0) ## modelr 0.1.8 2020-05-19 [1] CRAN (R 4.1.0) ## munsell 0.5.0 2018-06-12 [1] CRAN (R 4.1.0) ## mvtnorm 1.1-3 2021-10-08 [1] CRAN (R 4.1.1) ## nlme 3.1-155 2022-01-16 [2] CRAN (R 4.1.3) ## nnet 7.3-17 2022-01-16 [2] CRAN (R 4.1.3) ## parallelly 1.30.0 2021-12-17 [1] CRAN (R 4.1.2) ## parameters 0.14.0 2021-05-29 [1] CRAN (R 4.1.0) ## parsnip * 0.1.7 2021-07-21 [1] CRAN (R 4.1.0) ## patchwork * 1.1.1 2020-12-17 [1] CRAN (R 4.1.0) ## performance 0.7.3 2021-07-21 [1] CRAN (R 4.1.1) ## pillar 1.7.0 2022-02-01 [1] CRAN (R 4.1.2) ## pkgconfig 2.0.3 2019-09-22 [1] CRAN (R 4.1.0) ## plyr 1.8.7 2022-03-24 [1] CRAN (R 4.1.3) ## poissonreg * 0.1.1 2021-08-07 [1] CRAN (R 4.1.2) ## prettyunits 1.1.1 2020-01-24 [1] CRAN (R 4.1.0) ## pROC 1.17.0.1 2021-01-13 [1] CRAN (R 4.1.0) ## prodlim 2019.11.13 2019-11-17 [1] CRAN (R 4.1.0) ## promises 1.2.0.1 2021-02-11 [1] CRAN (R 4.1.0) ## purrr * 0.3.4 2020-04-17 [1] CRAN (R 4.1.2) ## qqplotr 0.0.5 2021-04-23 [1] CRAN (R 4.1.0) ## questionr 0.7.5 2021-10-06 [1] CRAN (R 4.1.2) ## R6 2.5.1 2021-08-19 [1] CRAN (R 4.1.1) ## RColorBrewer 1.1-3 2022-04-03 [1] CRAN (R 4.1.3) ## Rcpp 1.0.8.3 2022-03-17 [1] CRAN (R 4.1.3) ## readr * 2.1.1 2021-11-30 [1] CRAN (R 4.1.2) ## readxl 1.3.1 2019-03-13 [1] CRAN (R 4.1.0) ## recipes * 0.1.17 2021-09-27 [1] CRAN (R 4.1.1) ## repr 1.1.3 2021-01-21 [1] CRAN (R 4.1.1) ## reprex 2.0.0 2021-04-02 [1] CRAN (R 4.1.0) ## reshape 0.8.8 2018-10-23 [1] CRAN (R 4.1.0) ## rlang 1.0.2 2022-03-04 [1] CRAN (R 4.1.3) ## rmarkdown 2.11 2021-09-14 [1] CRAN (R 4.1.1) ## robustbase 0.93-8 2021-06-02 [1] CRAN (R 4.1.0) ## rpart 4.1.16 2022-01-24 [2] CRAN (R 4.1.3) ## rprojroot 2.0.2 2020-11-15 [1] CRAN (R 4.1.0) ## rsample * 0.1.0 2021-05-08 [1] CRAN (R 4.1.0) ## rstudioapi 0.13 2020-11-12 [1] CRAN (R 4.1.0) ## Rttf2pt1 1.3.8 2020-01-10 [1] CRAN (R 4.1.1) ## rvest 1.0.0 2021-03-09 [1] CRAN (R 4.1.0) ## sass 0.4.0 2021-05-12 [1] CRAN (R 4.1.0) ## scales * 1.1.1 2020-05-11 [1] CRAN (R 4.1.0) ## see 0.6.4 2021-05-29 [1] CRAN (R 4.1.0) ## sessioninfo 1.1.1 2018-11-05 [1] CRAN (R 4.1.0) ## shiny 1.6.0 2021-01-25 [1] CRAN (R 4.1.0) ## skimr 2.1.3 2021-03-07 [1] CRAN (R 4.1.1) ## stringi 1.7.6 2021-11-29 [1] CRAN (R 4.1.2) ## stringr * 1.4.0 2019-02-10 [1] CRAN (R 4.1.0) ## survival 3.2-13 2021-08-24 [2] CRAN (R 4.1.3) ## tibble * 3.1.6 2021-11-07 [1] CRAN (R 4.1.1) ## tidymodels * 0.1.4 2021-10-01 [1] CRAN (R 4.1.1) ## tidyr * 1.2.0 2022-02-01 [1] CRAN (R 4.1.3) ## tidyselect 1.1.2 2022-02-21 [1] CRAN (R 4.1.3) ## tidyverse * 1.3.1 2021-04-15 [1] CRAN (R 4.1.3) ## timeDate 3043.102 2018-02-21 [1] CRAN (R 4.1.0) ## tune * 0.1.6 2021-07-21 [1] CRAN (R 4.1.0) ## tzdb 0.2.0 2021-10-27 [1] CRAN (R 4.1.2) ## usethis 2.1.5 2021-12-09 [1] CRAN (R 4.1.2) ## utf8 1.2.2 2021-07-24 [1] CRAN (R 4.1.0) ## vctrs 0.3.8 2021-04-29 [1] CRAN (R 4.1.3) ## vroom 1.5.7 2021-11-30 [1] CRAN (R 4.1.2) ## withr 2.5.0 2022-03-03 [1] CRAN (R 4.1.3) ## workflows * 0.2.3 2021-07-16 [1] CRAN (R 4.1.0) ## workflowsets * 0.1.0 2021-07-22 [1] CRAN (R 4.1.0) ## xfun 0.29 2021-12-14 [1] CRAN (R 4.1.2) ## xml2 1.3.3 2021-11-30 [1] CRAN (R 4.1.2) ## xtable 1.8-4 2019-04-21 [1] CRAN (R 4.1.0) ## yaml 2.2.1 2020-02-01 [1] CRAN (R 4.1.0) ## yardstick * 0.0.8 2021-03-28 [1] CRAN (R 4.1.0) ## ## [1] C:/Users/tdunn/Documents/R/win-library/4.1 ## [2] C:/Program Files/R/R-4.1.3/library "],["resampling-methods.html", "5 Resampling Methods 5.1 Cross Validation 5.2 The Bootstrap 5.3 Lab: Cross-Validation and the Bootstrap 5.4 Exercises Reproducibility", " 5 Resampling Methods Resampling methods are an indispensable tool in modern statistics. They involve repeatedly drawing samples from a training set and refitting a model of interest on each sample in order to obtain additional information about the fitted model. For example, in order to estimate the variability of a linear regression fit, we can repeatedly draw different samples from the training data, fit a linear regression to each new sample, and then examine the extent to which the resulting fits differ. Such an approach may allow us to obtain information that would not be available from fitting the model only once using the original training sample. In this chapter, we discuss two of the most commonly used resampling methods, cross-validation and the bootstrap. Cross-validation is most often used to estimate test error associated with a statistical learning method, whereas the boostrap is most commonly used to provide a measure of accuracy for a given parameter/method. The process of evaluating a models performance is known as model assessment, whereas the process of selecting the proper level of flexibility for a model is known as model selection. 5.1 Cross Validation Sometimes we want to estimate the test error rate using the available training data. A number of approaches can be used for this. In this section we consider methods which involve holding out a subset of the training data from the fitting process, then applying the model to that hold-out set for model assessment. 5.1.1 The Validation Set Approach This simple strategy involves randomly dividing available observations into training and validation sets. The model is fit on the training set, and used to make predictions on the validation set. The corresponding metric from the validation set predictions  usually MSE in the case of a quantitative response  provides an estimate of the test error rate. To illustrate this, load the Auto data set and R packages: auto &lt;- ISLR2::Auto library(tidyverse) library(tidymodels) library(broom) library(gt) library(patchwork) library(tictoc) # Load my R package and set the ggplot theme library(dunnr) extrafont::loadfonts(device = &quot;win&quot;, quiet = TRUE) theme_set(theme_td()) set_geom_fonts() set_palette() Randomly split the data into 50% training and 50% validation, fit on the training set, and compute the MSE on the validation set. Since Ill be repeating this 10 times to reproduce the figure, make a couple functions. First, a function to set a random seed and split the data into training and validation set (called assessment set in the rsample package): auto_validation_split &lt;- function(seed) { set.seed(seed) validation_split(auto, prop = 0.5) } auto_splits &lt;- auto_validation_split(seed = 10) auto_splits ## # Validation Set Split (0.5/0.5) ## # A tibble: 1 x 2 ## splits id ## &lt;list&gt; &lt;chr&gt; ## 1 &lt;split [196/196]&gt; validation Similar to the initial_split workflow, I can access the training and validation sets as follows: training(auto_splits$splits[[1]]) %&gt;% head() ## mpg cylinders displacement horsepower weight acceleration year origin ## 139 14.0 8 318 150 4457 13.5 74 1 ## 333 29.8 4 89 62 1845 15.3 80 2 ## 373 27.0 4 151 90 2735 18.0 82 1 ## 73 15.0 8 304 150 3892 12.5 72 1 ## 213 16.5 8 350 180 4380 12.1 76 1 ## 348 37.0 4 85 65 1975 19.4 81 3 ## name ## 139 dodge coronet custom (sw) ## 333 vokswagen rabbit ## 373 pontiac phoenix ## 73 amc matador (sw) ## 213 cadillac seville ## 348 datsun 210 mpg assessment(auto_splits$splits[[1]]) %&gt;% head() ## mpg cylinders displacement horsepower weight acceleration year origin ## 1 18 8 307 130 3504 12.0 70 1 ## 2 15 8 350 165 3693 11.5 70 1 ## 3 18 8 318 150 3436 11.0 70 1 ## 5 17 8 302 140 3449 10.5 70 1 ## 6 15 8 429 198 4341 10.0 70 1 ## 7 14 8 454 220 4354 9.0 70 1 ## name ## 1 chevrolet chevelle malibu ## 2 buick skylark 320 ## 3 plymouth satellite ## 5 ford torino ## 6 ford galaxie 500 ## 7 chevrolet impala Second, a function to fit 10 models (1 to 10 polynomial degrees of freedom) on the training set, and evaluate on the validation set with fit_resamples():1 auto_rec &lt;- recipe(mpg ~ horsepower, data = auto) lm_workflow &lt;- workflow() %&gt;% add_model(linear_reg()) evaluate_poly_fits &lt;- function(auto_splits) { tibble(poly_df = 1:10) %&gt;% mutate( lm_rec = map( poly_df, ~ auto_rec %&gt;% step_poly(horsepower, degree = .x) ), lm_fit = map( lm_rec, ~ lm_workflow %&gt;% add_recipe(.x) %&gt;% fit_resamples(auto_splits) ), lm_metrics = map(lm_fit, collect_metrics) ) %&gt;% unnest(lm_metrics) %&gt;% filter(.metric == &quot;rmse&quot;) %&gt;% select(poly_df, rmse = mean) } auto_poly_fits_validation &lt;- evaluate_poly_fits(auto_splits) auto_poly_fits_validation ## # A tibble: 10 x 2 ## poly_df rmse ## &lt;int&gt; &lt;dbl&gt; ## 1 1 5.14 ## 2 2 4.46 ## 3 3 4.50 ## 4 4 4.49 ## 5 5 4.39 ## 6 6 4.36 ## 7 7 4.33 ## 8 8 4.33 ## 9 9 4.32 ## 10 10 4.60 Now reproduce Figure 5.2: auto_poly_fits_validation &lt;- bind_rows( # 9 additional sets of fits map_dfr( 1:9, function(seed) { auto_splits &lt;- auto_validation_split(seed) evaluate_poly_fits(auto_splits) }, .id = &quot;rep&quot; ), auto_poly_fits_validation %&gt;% mutate(rep = &quot;10&quot;) ) # Use a 10 color palette from the MetBrewer package pal &lt;- MetBrewer::met.brewer(&quot;Veronese&quot;, 10, type = &quot;continuous&quot;) p2 &lt;- auto_poly_fits_validation %&gt;% ggplot(aes(x = poly_df, y = rmse^2, fill = rep)) + geom_line(aes(color = rep), size = 1) + expand_limits(y = c(15, 30)) + scale_x_continuous(breaks = seq(2, 10, 2)) + scale_color_manual(values = pal) + scale_fill_manual(values = pal) + labs(x = &quot;Degree of polynomial&quot;, y = NULL) + theme(legend.position = &quot;none&quot;) p1 &lt;- p2 %+% filter(auto_poly_fits_validation, rep == &quot;1&quot;) + geom_point(aes(fill = rep), shape = 21, color = &quot;white&quot;, size = 4) + labs(y = &quot;MSE&quot;) p1 | p2 As is clear from the right-hand panel, this approach is highly variable depending on the testing/validation set split. Another downside is that, because the training set used to fit the data has fewer observations, it tends to overestimate the test error rate on the entire data set. 5.1.2 Leave-One-Out Cross Validation Leave-one-out cross validation (LOOCV) attempts to address the shortcomings of the validation set approach. It still involves splitting the \\(n\\) observations into two parts, but it repeats it \\(n\\) times, with a single observation \\((x_i, y_i)\\) as the hold-out set and the remaining \\(n-1\\) observations as the training set. The MSE for each iteration is simply \\(\\text{MSE}_i = (y_i - \\hat{y}_i)^2\\). Then the LOOCV estimate of the MSE is the average over all observations: \\[ \\text{CV}_{(n)} = \\frac{1}{n} \\sum_{i=1}^n \\text{MSE}_i. \\] The LOOCV approach has a few advantages over the validation set approach: First, it has far less bias. In LOOCV, we repeatedly fit the statistical learning method using training sets that contain \\(n  1\\) observations, almost as many as are in the entire data set. This is in contrast to the validation set approach, in which the training set is typically around half the size of the original data set. Consequently, the LOOCV approach tends not to overestimate the test error rate as much as the validation set approach does. Second, in contrast to the validation approach which will yield different results when applied repeatedly due to randomness in the training/validation set splits, performing LOOCV multiple times will always yield the same results: there is no randomness in the training/validation set splits. Define a new function to split the data by LOOCV:2 auto_splits &lt;- loo_cv(auto) auto_splits ## # Leave-one-out cross-validation ## # A tibble: 392 x 2 ## splits id ## &lt;list&gt; &lt;chr&gt; ## 1 &lt;split [391/1]&gt; Resample1 ## 2 &lt;split [391/1]&gt; Resample2 ## 3 &lt;split [391/1]&gt; Resample3 ## 4 &lt;split [391/1]&gt; Resample4 ## 5 &lt;split [391/1]&gt; Resample5 ## 6 &lt;split [391/1]&gt; Resample6 ## 7 &lt;split [391/1]&gt; Resample7 ## 8 &lt;split [391/1]&gt; Resample8 ## 9 &lt;split [391/1]&gt; Resample9 ## 10 &lt;split [391/1]&gt; Resample10 ## # ... with 382 more rows 392 splits, which is the number of observations, as expected. Fit: auto_poly_fits_loo_cv &lt;- evaluate_poly_fits(auto_splits) ## Error in `mutate()`: ## ! Problem while computing `lm_fit = map(lm_rec, ~lm_workflow %&gt;% ## add_recipe(.x) %&gt;% fit_resamples(auto_splits))`. ## Caused by error: ## ! Leave-one-out cross-validation is not currently supported with tune. As the error says, LOOCV is not supported. Heres an explanation I found online: Leave-one-out methods are deficient compared to almost any other method. For anything but pathologically small samples, LOO is computationally excessive and it may not have good statistical properties. Although rsample contains a loo_cv() function, these objects are not generally integrated into the broader tidymodels frameworks. Fair enough. For completeness, I will still get the LOOCV estimates using boot::cv.glm(): auto_poly_fits_loo_cv &lt;- tibble( poly_df = 1:10, mse = map_dbl(poly_df, function(poly_df) { glm_fit &lt;- glm(mpg ~ poly(horsepower, degree = poly_df), data = auto) boot::cv.glm(auto, glm_fit)$delta[1] } ) ) auto_poly_fits_loo_cv ## # A tibble: 10 x 2 ## poly_df mse ## &lt;int&gt; &lt;dbl&gt; ## 1 1 24.2 ## 2 2 19.2 ## 3 3 19.3 ## 4 4 19.4 ## 5 5 19.0 ## 6 6 19.0 ## 7 7 18.8 ## 8 8 19.0 ## 9 9 19.1 ## 10 10 19.5 5.1.3 \\(k\\)-fold Cross-Validation \\(k\\)-fold CV involves randomly dividing the observations into \\(k\\) groups/folds of approximately equal size. The first fold is used as the validation/assessment set, and the remaining \\(k-1\\) folds used to fit the model. This is repeated \\(k\\) times, with each fold being used as the assessment set once. The \\(k\\)-fold CV estimate of the test error is then the average: \\[ \\text{CV}_{(k)} = \\frac{1}{k} \\sum_{i=1}^k \\text{MSE}_i. \\] This should look familiar: It is not hard to see that LOOCV is a special case of \\(k\\)-fold CV in which \\(k\\) is set to equal \\(n\\). In practice, one typically performs \\(k\\)-fold CV using \\(k\\) = 5 or \\(k\\) = 10. What is the advantage of using \\(k\\) = 5 or \\(k\\) = 10 rather than \\(k\\) = \\(n\\)? The most obvious advantage is computational. LOOCV requires fitting the statistical learning method \\(n\\) times. This has the potential to be computationally expensive (except for linear models fit by least squares, in which case formula (5.2) can be used). But cross-validation is a very general approach that can be applied to almost any statistical learning method. Some statistical learning methods have computationally intensive fitting procedures, and so performing LOOCV may pose computational problems, especially if \\(n\\) is extremely large. In contrast, performing 10-fold CV requires fitting the learning procedure only ten times, which may be much more feasible. As we see in Section 5.1.4, there also can be other non-computational advantages to performing 5-fold or 10-fold CV, which involve the bias-variance trade-off. Fit the polynomial models with 10-fold CV: auto_10_fold_cv &lt;- function(seed) { set.seed(seed) vfold_cv(auto, v = 10) } auto_splits &lt;- auto_10_fold_cv(seed = 10) auto_splits ## # 10-fold cross-validation ## # A tibble: 10 x 2 ## splits id ## &lt;list&gt; &lt;chr&gt; ## 1 &lt;split [352/40]&gt; Fold01 ## 2 &lt;split [352/40]&gt; Fold02 ## 3 &lt;split [353/39]&gt; Fold03 ## 4 &lt;split [353/39]&gt; Fold04 ## 5 &lt;split [353/39]&gt; Fold05 ## 6 &lt;split [353/39]&gt; Fold06 ## 7 &lt;split [353/39]&gt; Fold07 ## 8 &lt;split [353/39]&gt; Fold08 ## 9 &lt;split [353/39]&gt; Fold09 ## 10 &lt;split [353/39]&gt; Fold10 auto_poly_fits_10_fold_cv &lt;- evaluate_poly_fits(auto_splits) auto_poly_fits_10_fold_cv ## # A tibble: 10 x 2 ## poly_df rmse ## &lt;int&gt; &lt;dbl&gt; ## 1 1 4.90 ## 2 2 4.35 ## 3 3 4.35 ## 4 4 4.37 ## 5 5 4.31 ## 6 6 4.31 ## 7 7 4.28 ## 8 8 4.29 ## 9 9 4.30 ## 10 10 4.37 Now repeat this another 9 times. Thought it wont take too long to run, Ill make use of parallel to speed it up a bit: n_cores &lt;- parallel::detectCores(logical = FALSE) library(doParallel) cl &lt;- makePSOCKcluster(n_cores - 1) registerDoParallel(cl) tic() auto_poly_fits_10_fold_cv &lt;- bind_rows( # 9 additional sets of fits map_dfr( 1:9, function(seed) { auto_splits &lt;- auto_10_fold_cv(seed) evaluate_poly_fits(auto_splits) }, .id = &quot;rep&quot; ), auto_poly_fits_10_fold_cv %&gt;% mutate(rep = &quot;10&quot;) ) toc() ## 93.12 sec elapsed Now reproduce Figure 5.4: p2 &lt;- auto_poly_fits_10_fold_cv %&gt;% mutate(mse = rmse^2) %&gt;% ggplot(aes(x = poly_df, y = mse, fill = rep)) + geom_line(aes(color = rep), size = 1) + expand_limits(y = c(15, 30)) + scale_x_continuous(breaks = seq(2, 10, 2)) + scale_color_manual(values = pal) + scale_fill_manual(values = pal) + labs(x = &quot;Degree of polynomial&quot;, y = NULL) + theme(legend.position = &quot;none&quot;) p1 &lt;- p2 %+% mutate(auto_poly_fits_loo_cv, rep = &quot;1&quot;) + geom_point(aes(fill = rep), shape = 21, color = &quot;white&quot;, size = 4) + labs(y = &quot;MSE&quot;) p1 | p2 The \\(k\\)-fold CV approach (right panel) still has some variability due to random splitting, but much less than the validation set approach. As a reminder, with cross-validation we are trying to approximate the true test MSE, which we cannot know for certain unless the data are simulated (like in Figure 5.6). The true error value itself is important if we want to know how a model will perform on independent data. However, if all we care about is parameter(s) that give the minimum error (like the degree of polynomial in these examples), then the CV estimate will usually come close to the true answer. 5.1.4 Bias-Variance Trade-Off for \\(k\\)-Fold Cross-Validation In addition to being computationally more efficient than LOOCV, \\(k\\)-fold CV with \\(k &lt; n\\) also often gives more accurate estimates of the test error rate due to the bias-variance tradeoff. \\(k\\)-fold CV has moderate bias in comparison to LOOCV, which is approximately unbiased. \\(k\\)-fold CV (average over \\(k\\) fitted models) tends to have lower variance than LOOCV (average over \\(n\\) fitted models, highly correlated with each other). To summarize, there is a bias-variance trade-off associated with the choice of \\(k\\) in \\(k\\)-fold cross-validation. Typically, given these considerations, one performs \\(k\\)-fold cross-validation using \\(k\\) = 5 or \\(k\\) = 10, as these values have been shown empirically to yield test error rate estimates that suffer neither from excessively high bias nor from very high variance. 5.1.5 Cross-Validation on Classification Problems Rather than quantitative \\(Y\\), cross-validation works just as well with qualitative \\(Y\\). Instead of MSE, we use the number of misclassified observations, \\(\\text{Err}_i = I(y_i \\neq \\hat{y}_i)\\). The LOOCV error rate: \\[ \\text{CV}_{(n)} = \\frac{1}{n} \\sum_{i=1}^n \\text{Err}_i. \\] The \\(k\\)-fold CV and validation set error rates are defined analogously. 5.2 The Bootstrap The bootstrap is a widely applicable and extremely powerful statistical tool that can be used to quantify the uncertainty associated with a given estimator or statistical learning method. As a simple example, the bootstrap can be used to estimate the standard errors of the coefficients from a linear regression fit. In the specific case of linear regression, this is not particularly useful, since we saw in Chapter 3 that standard statistical software such as R outputs such standard errors automatically. However, the power of the bootstrap lies in the fact that it can be easily applied to a wide range of statistical learning methods, including some for which a measure of variability is otherwise difficult to obtain and is not automatically output by statistical software. The toy example in this section is about investment in two assets \\(X\\) and \\(Y\\). We wish to choose a fraction \\(\\alpha\\) of investment into \\(X\\) which minimizes the total variance (risk) of the investment. In can be shown that the optimal value is given by: \\[ \\alpha = \\frac{\\sigma_Y^2 - \\sigma_{XY}}{\\sigma_X^2 + \\sigma_Y^2 - 2\\sigma_{XY}}, \\] where \\(\\sigma_X^2 = \\text{Var}(X)\\), \\(\\sigma_Y^2 = \\text{Var}(Y)\\), and \\(\\sigma_{XY} = \\text{Cov}(X, Y)\\). In reality, we dont know these variances and covariance, so we estimate them (e.g. \\(\\hat{\\sigma}_X^2\\)) using observations of \\(X\\) and \\(Y\\) to get an estimated \\(\\hat{\\alpha}\\). To illustrate, we simulate 100 pairs of \\(X\\) and \\(Y\\), and compute the estimated \\(\\alpha\\). The simulation parameters are \\(\\sigma_X^2 = 1\\), \\(\\sigma_Y^2 = 1.25\\), and \\(\\sigma_{XY} = 0.5\\). Presumably, these are bivariate normally distributed, which I can simulate with the mvtnorm package: library(mvtnorm) sigma_x &lt;- 1 sigma_y &lt;- sqrt(1.25) sigma_xy &lt;- 0.5 # The variance-covariance matrix sigma &lt;- matrix(c(sigma_x^2, sigma_xy, sigma_xy, sigma_y^2), nrow = 2) # Generate 5 observations rmvnorm(n = 5, mean = c(0, 0), sigma = sigma) ## [,1] [,2] ## [1,] -0.6198186 0.2723180 ## [2,] -0.4510171 -1.4568201 ## [3,] -0.0302161 -1.3962636 ## [4,] -0.3405990 -0.3004827 ## [5,] -0.3552014 1.1948117 Write a function to compute \\(\\alpha\\) from the simulated \\(X\\) and \\(Y\\): sim_alpha &lt;- function(xy = NULL) { if (is.null(xy)) { xy &lt;- rmvnorm(n = 100, mean = c(0, 0), sigma = sigma) } x &lt;- xy[,1]; y &lt;- xy[,2] (var(y) - cov(x, y)) / (var(x) + var(y) - 2 * cov(x, y)) } sim_alpha() ## [1] 0.577909 Run four simulations and plot \\(X\\) vs \\(Y\\) for Figure 5.9 set.seed(319) d4 &lt;- tibble(sim = 1:4) %&gt;% rowwise() %&gt;% mutate(xy = list(rmvnorm(n = 100, mean = c(0, 0), sigma = sigma))) %&gt;% ungroup() %&gt;% mutate(alpha = map_dbl(xy, sim_alpha) %&gt;% round(3), x = map(xy, ~ .x[,1]), y = map(xy, ~ .x[,2])) %&gt;% unnest(cols = c(x, y)) d4 %&gt;% ggplot(aes(x, y)) + geom_point(color = td_colors$nice$emerald, size = 2) + facet_wrap(~alpha, labeller = &quot;label_both&quot;) + add_facet_borders() For Figure 5.10, I first simulate 1000 data sets from the true population and estimate \\(\\alpha\\) for each: d &lt;- bind_rows( d4 %&gt;% distinct(sim, alpha), tibble(sim = 5:1000) %&gt;% rowwise() %&gt;% mutate(alpha = sim_alpha()) %&gt;% ungroup() ) d ## # A tibble: 1,000 x 2 ## sim alpha ## &lt;int&gt; &lt;dbl&gt; ## 1 1 0.555 ## 2 2 0.622 ## 3 3 0.615 ## 4 4 0.453 ## 5 5 0.588 ## 6 6 0.605 ## 7 7 0.483 ## 8 8 0.598 ## 9 9 0.602 ## 10 10 0.633 ## # ... with 990 more rows And then, using just the first simulated data set, use the rsample::boostraps() function to generate 1000 bootstrap resamples: d1_boot &lt;- d4 %&gt;% filter(sim == 1) %&gt;% select(x, y) %&gt;% rsample::bootstraps(times = 1000) d1_boot ## # Bootstrap sampling ## # A tibble: 1,000 x 2 ## splits id ## &lt;list&gt; &lt;chr&gt; ## 1 &lt;split [100/34]&gt; Bootstrap0001 ## 2 &lt;split [100/37]&gt; Bootstrap0002 ## 3 &lt;split [100/32]&gt; Bootstrap0003 ## 4 &lt;split [100/35]&gt; Bootstrap0004 ## 5 &lt;split [100/39]&gt; Bootstrap0005 ## 6 &lt;split [100/38]&gt; Bootstrap0006 ## 7 &lt;split [100/43]&gt; Bootstrap0007 ## 8 &lt;split [100/39]&gt; Bootstrap0008 ## 9 &lt;split [100/31]&gt; Bootstrap0009 ## 10 &lt;split [100/44]&gt; Bootstrap0010 ## # ... with 990 more rows Compute \\(\\hat{\\alpha}\\) from each split: d1_boot_alpha &lt;- map_dbl( d1_boot$splits, function(split) { xy &lt;- as.data.frame(split) sim_alpha(as.matrix(xy)) } ) Now reproduce the figure: d &lt;- bind_rows( d %&gt;% mutate(population = &quot;true&quot;), tibble(alpha = d1_boot_alpha, population = &quot;bootstrap resamples&quot;) ) %&gt;% mutate(population = fct_rev(population)) true_alpha &lt;- (sigma_y^2 - sigma_xy) / (sigma_x^2 + sigma_y^2 - 2 * sigma_xy) p1 &lt;- d %&gt;% ggplot(aes(x = alpha, fill = population)) + geom_histogram(binwidth = 0.05, show.legend = FALSE, color = &quot;black&quot;) + geom_vline(xintercept = true_alpha, color = td_colors$nice$light_coral, size = 1.5) + facet_wrap(~ population, nrow = 1) + scale_fill_manual(values = c(td_colors$nice$soft_orange, td_colors$nice$strong_blue)) p2 &lt;- d %&gt;% ggplot(aes(y = alpha, x = population)) + geom_boxplot(aes(fill = population), show.legend = FALSE) + geom_hline(yintercept = true_alpha, color = td_colors$nice$light_coral, size = 1.5) + scale_fill_manual(values = c(td_colors$nice$soft_orange, td_colors$nice$strong_blue)) p1 | p2 Note that the histogram looks very similar to the left-hand panel, which displays the idealized histogram of the estimates of  obtained by generating 1,000 simulated data sets from the true population. In particular the bootstrap estimate \\(\\text{SE}(\\hat{\\alpha})\\) from (5.8) is 0.087, very close to the estimate of 0.083 obtained using 1,000 simulated data sets. The right-hand panel displays the information in the center and left panels in a different way, via boxplots of the estimates for \\(\\alpha\\) obtained by generating 1,000 simulated data sets from the true population and using the bootstrap approach. Again, the boxplots have similar spreads, indicating that the bootstrap approach can be used to effectively estimate the variability associated with \\(\\hat{\\alpha}\\). 5.3 Lab: Cross-Validation and the Bootstrap 5.3.1 The Validation Set Approach Here are the MSE values as computed in 5.1.1: auto_poly_fits_validation %&gt;% filter(poly_df &lt;= 3, rep == 1) %&gt;% mutate(mse = rmse^2) ## # A tibble: 3 x 4 ## rep poly_df rmse mse ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1 4.82 23.3 ## 2 1 2 4.33 18.7 ## 3 1 3 4.34 18.8 5.3.2 Leave-One-Out Cross-Validation Because LOOCV is deterministic (not random), the process in 5.1.2 produces the same MSE values: auto_poly_fits_loo_cv ## # A tibble: 10 x 2 ## poly_df mse ## &lt;int&gt; &lt;dbl&gt; ## 1 1 24.2 ## 2 2 19.2 ## 3 3 19.3 ## 4 4 19.4 ## 5 5 19.0 ## 6 6 19.0 ## 7 7 18.8 ## 8 8 19.0 ## 9 9 19.1 ## 10 10 19.5 5.3.3 \\(k\\)-fold Cross-Validation The MSE values as computed in 5.1.3: auto_poly_fits_10_fold_cv %&gt;% filter(rep == 1) %&gt;% mutate(mse = rmse^2) ## # A tibble: 10 x 4 ## rep poly_df rmse mse ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1 4.87 23.7 ## 2 1 2 4.31 18.6 ## 3 1 3 4.31 18.6 ## 4 1 4 4.32 18.7 ## 5 1 5 4.28 18.3 ## 6 1 6 4.28 18.3 ## 7 1 7 4.24 18.0 ## 8 1 8 4.26 18.1 ## 9 1 9 4.26 18.2 ## 10 1 10 4.32 18.7 5.3.4 The Bootstrap Estimating the Accuracy of a Statistic of Interest portfolio &lt;- ISLR2::Portfolio glimpse(portfolio) ## Rows: 100 ## Columns: 2 ## $ X &lt;dbl&gt; -0.89525089, -1.56245433, -0.41708988, 1.04435573, -0.31556841, -1.7~ ## $ Y &lt;dbl&gt; -0.2349235, -0.8851760, 0.2718880, -0.7341975, 0.8419834, -2.0371910~ The tidymodels approach to bootstrap estimates, as in 5.2: portfolio_boot &lt;- bootstraps(portfolio, times = 1000) portfolio_boot_alpha &lt;- map_dbl( portfolio_boot$splits, function(split) { xy &lt;- as.data.frame(split) (var(xy$Y) - cov(xy$X, xy$Y)) / (var(xy$X) + var(xy$Y) - 2 * cov(xy$X, xy$Y)) } ) mean(portfolio_boot_alpha); sd(portfolio_boot_alpha) ## [1] 0.5784967 ## [1] 0.08952573 Estimating the Accuracy of a Regression Model The bootstrap approach can be used to assess the variability of the coefficient estimates and predictions from a statistical learning method. Here we use the bootstrap approach in order to assess the variability of the estimates for \\(\\beta_0\\) and \\(\\beta_1\\), the intercept and slope terms for the linear regression model that uses horsepower to predict mpg in the Auto data set. We will compare the estimates obtained using the bootstrap to those obtained using the formulas for \\(\\text{SE}(\\hat{\\beta}_0)\\) and \\(\\text{SE}(\\hat{\\beta}_1)\\) described in Section 3.1.2. auto_boot &lt;- bootstraps(auto, times = 1000) By default, the tune::fit_resamples() function does not keep the model object from each fit. Usually, all we care about is the performance metrics and (if were tuning) the best hyper parameters. So in order to get the actual regression coefficients, I need to provide a control_grid() object to the control argument of fit_resamples() (see this article for more explanation): get_lm_coefs &lt;- function(x) { x %&gt;% extract_fit_engine() %&gt;% broom::tidy() } tidy_ctrl &lt;- control_grid(extract = get_lm_coefs) Now fit the resamples with this with control object: tic() auto_boot_fit &lt;- workflow() %&gt;% add_model(linear_reg()) %&gt;% add_recipe(recipe(mpg ~ horsepower, data = auto)) %&gt;% fit_resamples(auto_boot, control = tidy_ctrl) toc() ## 72.1 sec elapsed auto_boot_fit %&gt;% head() ## # A tibble: 6 x 5 ## splits id .metrics .notes .extracts ## &lt;list&gt; &lt;chr&gt; &lt;list&gt; &lt;list&gt; &lt;list&gt; ## 1 &lt;split [392/152]&gt; Bootstrap0001 &lt;tibble [2 x 4]&gt; &lt;tibble [0 x 1]&gt; &lt;tibble [1 ~ ## 2 &lt;split [392/145]&gt; Bootstrap0002 &lt;tibble [2 x 4]&gt; &lt;tibble [0 x 1]&gt; &lt;tibble [1 ~ ## 3 &lt;split [392/152]&gt; Bootstrap0003 &lt;tibble [2 x 4]&gt; &lt;tibble [0 x 1]&gt; &lt;tibble [1 ~ ## 4 &lt;split [392/154]&gt; Bootstrap0004 &lt;tibble [2 x 4]&gt; &lt;tibble [0 x 1]&gt; &lt;tibble [1 ~ ## 5 &lt;split [392/139]&gt; Bootstrap0005 &lt;tibble [2 x 4]&gt; &lt;tibble [0 x 1]&gt; &lt;tibble [1 ~ ## 6 &lt;split [392/138]&gt; Bootstrap0006 &lt;tibble [2 x 4]&gt; &lt;tibble [0 x 1]&gt; &lt;tibble [1 ~ The .extracts column contains the tidy model objects. It is a bit clunky to work with  it is a list column with a list of tibbles, so requires tidyr::unnest() twice: # A single `.extracts` element, which contains a tibble auto_boot_fit$.extracts[[1]] ## # A tibble: 1 x 2 ## .extracts .config ## &lt;list&gt; &lt;chr&gt; ## 1 &lt;tibble [2 x 5]&gt; Preprocessor1_Model1 # Using `unnest` to get all `.extracts` auto_boot_fit_coefs &lt;- auto_boot_fit %&gt;% unnest(.extracts) %&gt;% unnest(.extracts) %&gt;% select(id, term, estimate, std.error) auto_boot_fit_coefs %&gt;% head() ## # A tibble: 6 x 4 ## id term estimate std.error ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Bootstrap0001 (Intercept) 39.4 0.695 ## 2 Bootstrap0001 horsepower -0.154 0.00601 ## 3 Bootstrap0002 (Intercept) 37.6 0.665 ## 4 Bootstrap0002 horsepower -0.139 0.00587 ## 5 Bootstrap0003 (Intercept) 39.6 0.688 ## 6 Bootstrap0003 horsepower -0.154 0.00620 Then taking the mean of the estimates, and applying equation 5.8 to get the standard error: auto_boot_fit_coefs %&gt;% group_by(term) %&gt;% summarise( mean_estimate = mean(estimate), se_estimate = sd(estimate), .groups = &quot;drop&quot; ) %&gt;% gt() %&gt;% fmt_number(columns = -term, decimals = 4) html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #ygtskbpuab .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #ygtskbpuab .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #ygtskbpuab .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #ygtskbpuab .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #ygtskbpuab .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #ygtskbpuab .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #ygtskbpuab .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #ygtskbpuab .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #ygtskbpuab .gt_column_spanner_outer:first-child { padding-left: 0; } #ygtskbpuab .gt_column_spanner_outer:last-child { padding-right: 0; } #ygtskbpuab .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #ygtskbpuab .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #ygtskbpuab .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #ygtskbpuab .gt_from_md > :first-child { margin-top: 0; } #ygtskbpuab .gt_from_md > :last-child { margin-bottom: 0; } #ygtskbpuab .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #ygtskbpuab .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #ygtskbpuab .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #ygtskbpuab .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #ygtskbpuab .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #ygtskbpuab .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #ygtskbpuab .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #ygtskbpuab .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #ygtskbpuab .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #ygtskbpuab .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #ygtskbpuab .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #ygtskbpuab .gt_sourcenote { font-size: 90%; padding: 4px; } #ygtskbpuab .gt_left { text-align: left; } #ygtskbpuab .gt_center { text-align: center; } #ygtskbpuab .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #ygtskbpuab .gt_font_normal { font-weight: normal; } #ygtskbpuab .gt_font_bold { font-weight: bold; } #ygtskbpuab .gt_font_italic { font-style: italic; } #ygtskbpuab .gt_super { font-size: 65%; } #ygtskbpuab .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } term mean_estimate se_estimate (Intercept) 39.9855 0.8707 horsepower &minus;0.1583 0.0075 Not exactly the same as those in the text due to the difference in the random bootstrap samples. And here are the SE estimates using the formula from section 3.1.2: tidy(lm(mpg ~ horsepower, data = auto)) %&gt;% select(term, estimate, se_estimate = std.error) %&gt;% gt() %&gt;% fmt_number(columns = -term, decimals = 4) html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #qtmzcvzhec .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #qtmzcvzhec .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #qtmzcvzhec .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #qtmzcvzhec .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #qtmzcvzhec .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #qtmzcvzhec .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #qtmzcvzhec .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #qtmzcvzhec .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #qtmzcvzhec .gt_column_spanner_outer:first-child { padding-left: 0; } #qtmzcvzhec .gt_column_spanner_outer:last-child { padding-right: 0; } #qtmzcvzhec .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #qtmzcvzhec .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #qtmzcvzhec .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #qtmzcvzhec .gt_from_md > :first-child { margin-top: 0; } #qtmzcvzhec .gt_from_md > :last-child { margin-bottom: 0; } #qtmzcvzhec .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #qtmzcvzhec .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #qtmzcvzhec .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #qtmzcvzhec .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #qtmzcvzhec .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #qtmzcvzhec .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #qtmzcvzhec .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #qtmzcvzhec .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #qtmzcvzhec .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #qtmzcvzhec .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #qtmzcvzhec .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #qtmzcvzhec .gt_sourcenote { font-size: 90%; padding: 4px; } #qtmzcvzhec .gt_left { text-align: left; } #qtmzcvzhec .gt_center { text-align: center; } #qtmzcvzhec .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #qtmzcvzhec .gt_font_normal { font-weight: normal; } #qtmzcvzhec .gt_font_bold { font-weight: bold; } #qtmzcvzhec .gt_font_italic { font-style: italic; } #qtmzcvzhec .gt_super { font-size: 65%; } #qtmzcvzhec .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } term estimate se_estimate (Intercept) 39.9359 0.7175 horsepower &minus;0.1578 0.0064 These estimates are similar, but you wouldnt be considered close. Does this indicate a problem with the bootstrap? In fact, it suggests the opposite. Recall that the standard formulas given in Equation 3.8 on page 66 rely on certain assumptions. For example, they depend on the unknown parameter \\(\\sigma^2\\), the noise variance. We then estimate \\(\\sigma^2\\) using the RSS. Now although the formulas for the standard errors do not rely on the linear model being correct, the estimate for \\(\\sigma^2\\) does. We see in Figure 3.8 on page 91 that there is a non-linear relationship in the data, and so the residuals from a linear fit will be inflated, and so will \\(\\hat{\\sigma}^2\\). Secondly, the standard formulas assume (somewhat unrealistically) that the \\(x_i\\) are fixed, and all the variability comes from the variation in the errors \\(\\epsilon_i\\). The bootstrap approach does not rely on any of these assumptions, and so it is likely giving a more accurate estimate of the standard errors of \\(\\hat{\\beta}_0\\) and \\(\\hat{\\beta}_1\\) than is the summary() function. We can find better correspondence between bootstrap and regression estimates if we use the quadratic model because it better fits the data: tic() auto_boot_quad_fit &lt;- workflow() %&gt;% add_model(linear_reg()) %&gt;% add_recipe( recipe(mpg ~ horsepower, data = auto) %&gt;% # Need to set `raw` = TRUE to not use orthogonal polynomials step_poly(horsepower, degree = 2, options = list(raw = TRUE)) ) %&gt;% fit_resamples(auto_boot, control = tidy_ctrl) toc() ## 76.58 sec elapsed auto_boot_quad_fit %&gt;% unnest(.extracts) %&gt;% unnest(.extracts) %&gt;% group_by(term) %&gt;% summarise( mean_estimate = mean(estimate), se_estimate = sd(estimate), .groups = &quot;drop&quot; ) %&gt;% gt() %&gt;% fmt_number(columns = -term, decimals = 4) html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #uyasfyvmkp .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #uyasfyvmkp .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #uyasfyvmkp .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #uyasfyvmkp .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #uyasfyvmkp .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #uyasfyvmkp .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #uyasfyvmkp .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #uyasfyvmkp .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #uyasfyvmkp .gt_column_spanner_outer:first-child { padding-left: 0; } #uyasfyvmkp .gt_column_spanner_outer:last-child { padding-right: 0; } #uyasfyvmkp .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #uyasfyvmkp .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #uyasfyvmkp .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #uyasfyvmkp .gt_from_md > :first-child { margin-top: 0; } #uyasfyvmkp .gt_from_md > :last-child { margin-bottom: 0; } #uyasfyvmkp .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #uyasfyvmkp .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #uyasfyvmkp .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #uyasfyvmkp .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #uyasfyvmkp .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #uyasfyvmkp .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #uyasfyvmkp .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #uyasfyvmkp .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #uyasfyvmkp .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #uyasfyvmkp .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #uyasfyvmkp .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #uyasfyvmkp .gt_sourcenote { font-size: 90%; padding: 4px; } #uyasfyvmkp .gt_left { text-align: left; } #uyasfyvmkp .gt_center { text-align: center; } #uyasfyvmkp .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #uyasfyvmkp .gt_font_normal { font-weight: normal; } #uyasfyvmkp .gt_font_bold { font-weight: bold; } #uyasfyvmkp .gt_font_italic { font-style: italic; } #uyasfyvmkp .gt_super { font-size: 65%; } #uyasfyvmkp .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } term mean_estimate se_estimate (Intercept) 56.9755 2.1490 horsepower_poly_1 &minus;0.4673 0.0340 horsepower_poly_2 0.0012 0.0001 # Need to set `raw` = TRUE to not use orthogonal polynomials tidy(lm(mpg ~ poly(horsepower, 2, raw = TRUE), data = auto)) %&gt;% select(term, estimate, se_estimate = std.error) %&gt;% gt() %&gt;% fmt_number(columns = -term, decimals = 4) html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #zkvxoecmrv .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #zkvxoecmrv .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #zkvxoecmrv .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #zkvxoecmrv .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #zkvxoecmrv .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #zkvxoecmrv .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #zkvxoecmrv .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #zkvxoecmrv .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #zkvxoecmrv .gt_column_spanner_outer:first-child { padding-left: 0; } #zkvxoecmrv .gt_column_spanner_outer:last-child { padding-right: 0; } #zkvxoecmrv .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #zkvxoecmrv .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #zkvxoecmrv .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #zkvxoecmrv .gt_from_md > :first-child { margin-top: 0; } #zkvxoecmrv .gt_from_md > :last-child { margin-bottom: 0; } #zkvxoecmrv .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #zkvxoecmrv .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #zkvxoecmrv .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #zkvxoecmrv .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #zkvxoecmrv .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #zkvxoecmrv .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #zkvxoecmrv .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #zkvxoecmrv .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #zkvxoecmrv .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #zkvxoecmrv .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #zkvxoecmrv .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #zkvxoecmrv .gt_sourcenote { font-size: 90%; padding: 4px; } #zkvxoecmrv .gt_left { text-align: left; } #zkvxoecmrv .gt_center { text-align: center; } #zkvxoecmrv .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #zkvxoecmrv .gt_font_normal { font-weight: normal; } #zkvxoecmrv .gt_font_bold { font-weight: bold; } #zkvxoecmrv .gt_font_italic { font-style: italic; } #zkvxoecmrv .gt_super { font-size: 65%; } #zkvxoecmrv .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } term estimate se_estimate (Intercept) 56.9001 1.8004 poly(horsepower, 2, raw = TRUE)1 &minus;0.4662 0.0311 poly(horsepower, 2, raw = TRUE)2 0.0012 0.0001 5.4 Exercises Applied 5. Logistic regression with default - validation set default &lt;- ISLR2::Default Fit a logistic regression model that uses income and balance to predict default. default_workflow &lt;- workflow() %&gt;% add_model(logistic_reg(mode = &quot;classification&quot;, engine = &quot;glm&quot;)) default_rec &lt;- recipe(default ~ income + balance, data = default) default_fit &lt;- default_workflow %&gt;% add_recipe(default_rec) %&gt;% fit(data = default) extract_fit_parsnip(default_fit) ## parsnip model object ## ## Fit time: 20ms ## ## Call: stats::glm(formula = ..y ~ ., family = stats::binomial, data = data) ## ## Coefficients: ## (Intercept) income balance ## -1.154e+01 2.081e-05 5.647e-03 ## ## Degrees of Freedom: 9999 Total (i.e. Null); 9997 Residual ## Null Deviance: 2921 ## Residual Deviance: 1579 AIC: 1585 Using the validation set approach, estimate the test error of this model. Set seed and split: set.seed(940) default_splits &lt;- validation_split(default, prop = 0.5) Fit and evaluate the model with the hold out: default_fit_validation &lt;- default_workflow %&gt;% add_recipe(default_rec) %&gt;% fit_resamples(default_splits) collect_metrics(default_fit_validation) ## # A tibble: 2 x 6 ## .metric .estimator mean n std_err .config ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 accuracy binary 0.973 1 NA Preprocessor1_Model1 ## 2 roc_auc binary 0.949 1 NA Preprocessor1_Model1 The accuracy of the model is 97.26% and so the test error is 2.74%. The tidymodels workflow made fitting and assessing this model very easy  just 5 lines of code. For comparison purposes, here is how you could do it without tidymodels (excluding the data splitting part): default_train &lt;- training(default_splits$splits[[1]]) default_assess &lt;- assessment(default_splits$splits[[1]]) default_glm &lt;- glm(default ~ income + balance, data = default_train, family = &quot;binomial&quot;) augment(default_glm, newdata = default_assess, type.predict = &quot;response&quot;) %&gt;% mutate(default_pred = ifelse(.fitted &gt; 0.5, &quot;Yes&quot;, &quot;No&quot;)) %&gt;% summarise(error_rate = mean(default != default_pred)) %&gt;% .$error_rate %&gt;% scales::percent(accuracy = 0.01) ## [1] &quot;2.74%&quot; Repeat the process in (b) three times, using three different splits of the observations. Comment on the results. set.seed(109) bind_rows( collect_metrics(default_fit_validation) %&gt;% mutate(rep = 1), map_dfr(2:4, function(rep) { default_workflow %&gt;% add_recipe(default_rec) %&gt;% fit_resamples(validation_split(default, prop = 0.5)) %&gt;% collect_metrics() %&gt;% mutate(rep = rep) } ) ) %&gt;% filter(.metric == &quot;accuracy&quot;) %&gt;% transmute( rep, accuracy = scales::percent(mean, accuracy = 0.01), test_error = scales::percent(1 - mean, accuracy = 0.01) ) %&gt;% gt() html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #zqpjldwoxf .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #zqpjldwoxf .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #zqpjldwoxf .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #zqpjldwoxf .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #zqpjldwoxf .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #zqpjldwoxf .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #zqpjldwoxf .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #zqpjldwoxf .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #zqpjldwoxf .gt_column_spanner_outer:first-child { padding-left: 0; } #zqpjldwoxf .gt_column_spanner_outer:last-child { padding-right: 0; } #zqpjldwoxf .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #zqpjldwoxf .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #zqpjldwoxf .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #zqpjldwoxf .gt_from_md > :first-child { margin-top: 0; } #zqpjldwoxf .gt_from_md > :last-child { margin-bottom: 0; } #zqpjldwoxf .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #zqpjldwoxf .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #zqpjldwoxf .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #zqpjldwoxf .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #zqpjldwoxf .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #zqpjldwoxf .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #zqpjldwoxf .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #zqpjldwoxf .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #zqpjldwoxf .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #zqpjldwoxf .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #zqpjldwoxf .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #zqpjldwoxf .gt_sourcenote { font-size: 90%; padding: 4px; } #zqpjldwoxf .gt_left { text-align: left; } #zqpjldwoxf .gt_center { text-align: center; } #zqpjldwoxf .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #zqpjldwoxf .gt_font_normal { font-weight: normal; } #zqpjldwoxf .gt_font_bold { font-weight: bold; } #zqpjldwoxf .gt_font_italic { font-style: italic; } #zqpjldwoxf .gt_super { font-size: 65%; } #zqpjldwoxf .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } rep accuracy test_error 1 97.26% 2.74% 2 97.52% 2.48% 3 97.46% 2.54% 4 97.26% 2.74% The estimates are actually quite stable. Add the dummy variable student to the logistic regression model. Comment on whether or not this leads to a reduction in the test error rate. default_rec_student &lt;- recipe(default ~ income + balance + student, data = default) %&gt;% step_dummy(student) default_fit_validation_student &lt;- default_workflow %&gt;% add_recipe(default_rec_student) %&gt;% fit_resamples(default_splits) collect_metrics(default_fit_validation_student) ## # A tibble: 2 x 6 ## .metric .estimator mean n std_err .config ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 accuracy binary 0.972 1 NA Preprocessor1_Model1 ## 2 roc_auc binary 0.949 1 NA Preprocessor1_Model1 Adding the student variable resulted in a test error rate of 2.78% and so did not lead to a reduction compared to the original model. 6. Logistic regression with default - standard error estimation Determine the estimated standard errors for the coefficients using summary() and glm(). Here it is in base R: glm(default ~ income + balance, data = default, family = &quot;binomial&quot;) %&gt;% summary() ## ## Call: ## glm(formula = default ~ income + balance, family = &quot;binomial&quot;, ## data = default) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -2.4725 -0.1444 -0.0574 -0.0211 3.7245 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -1.154e+01 4.348e-01 -26.545 &lt; 2e-16 *** ## income 2.081e-05 4.985e-06 4.174 2.99e-05 *** ## balance 5.647e-03 2.274e-04 24.836 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 2920.6 on 9999 degrees of freedom ## Residual deviance: 1579.0 on 9997 degrees of freedom ## AIC: 1585 ## ## Number of Fisher Scoring iterations: 8 In tidymodels, I can use the extract_fit_engine() function to get the same: logistic_reg() %&gt;% fit(default ~ income + balance, data = default) %&gt;% extract_fit_engine() %&gt;% summary() ## ## Call: ## stats::glm(formula = default ~ income + balance, family = stats::binomial, ## data = data) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -2.4725 -0.1444 -0.0574 -0.0211 3.7245 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -1.154e+01 4.348e-01 -26.545 &lt; 2e-16 *** ## income 2.081e-05 4.985e-06 4.174 2.99e-05 *** ## balance 5.647e-03 2.274e-04 24.836 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 2920.6 on 9999 degrees of freedom ## Residual deviance: 1579.0 on 9997 degrees of freedom ## AIC: 1585 ## ## Number of Fisher Scoring iterations: 8 Write a function that takes as input the default data set as well as the index of the observations, and that outputs the coefficient estimates for income and balance in the multiple logistic regression model. Instead of the workflow I used in 5.2 (with fit_resamples()), Ill show a different way. First, a function that takes a split object (a bootstrap sample), fits the model and returns the tidy regression coefficients: get_tidy_default_fit &lt;- function(split) { logistic_reg() %&gt;% fit(default ~ income + balance, data = as.data.frame(split)) %&gt;% broom::tidy() } Get the bootstrap estimates for the standard errors. Now I use purrr::map() to fit the models using the function from (b): default_boot &lt;- bootstraps(default, times = 100) tic() default_fits &lt;- map_dfr( default_boot$splits, get_tidy_default_fit, .id = &quot;split&quot; ) toc() ## 291.56 sec elapsed Then estimate the standard errors of the coefficients: default_fits %&gt;% group_by(term) %&gt;% summarise(mean_estimate = mean(estimate), se_estimate = sd(estimate)) %&gt;% gt() %&gt;% fmt_number(columns = -term, n_sigfig = 3) html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #xybuvpvhkb .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #xybuvpvhkb .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #xybuvpvhkb .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #xybuvpvhkb .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #xybuvpvhkb .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #xybuvpvhkb .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #xybuvpvhkb .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #xybuvpvhkb .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #xybuvpvhkb .gt_column_spanner_outer:first-child { padding-left: 0; } #xybuvpvhkb .gt_column_spanner_outer:last-child { padding-right: 0; } #xybuvpvhkb .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #xybuvpvhkb .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #xybuvpvhkb .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #xybuvpvhkb .gt_from_md > :first-child { margin-top: 0; } #xybuvpvhkb .gt_from_md > :last-child { margin-bottom: 0; } #xybuvpvhkb .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #xybuvpvhkb .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #xybuvpvhkb .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #xybuvpvhkb .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #xybuvpvhkb .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #xybuvpvhkb .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #xybuvpvhkb .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #xybuvpvhkb .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #xybuvpvhkb .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #xybuvpvhkb .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #xybuvpvhkb .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #xybuvpvhkb .gt_sourcenote { font-size: 90%; padding: 4px; } #xybuvpvhkb .gt_left { text-align: left; } #xybuvpvhkb .gt_center { text-align: center; } #xybuvpvhkb .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #xybuvpvhkb .gt_font_normal { font-weight: normal; } #xybuvpvhkb .gt_font_bold { font-weight: bold; } #xybuvpvhkb .gt_font_italic { font-style: italic; } #xybuvpvhkb .gt_super { font-size: 65%; } #xybuvpvhkb .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } term mean_estimate se_estimate (Intercept) &minus;11.6 0.443 balance 0.00566 0.000235 income 0.0000210 0.00000492 Comment on the estimated standard errors obtained using the glm() function and using your bootstrap function. glm(default ~ income + balance, data = default, family = &quot;binomial&quot;) %&gt;% broom::tidy() %&gt;% select(term, estimate, se_estimate = std.error) %&gt;% gt() %&gt;% fmt_number(columns = -term, n_sigfig = 3) html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #qotavlpmco .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #qotavlpmco .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #qotavlpmco .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #qotavlpmco .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #qotavlpmco .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #qotavlpmco .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #qotavlpmco .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #qotavlpmco .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #qotavlpmco .gt_column_spanner_outer:first-child { padding-left: 0; } #qotavlpmco .gt_column_spanner_outer:last-child { padding-right: 0; } #qotavlpmco .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #qotavlpmco .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #qotavlpmco .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #qotavlpmco .gt_from_md > :first-child { margin-top: 0; } #qotavlpmco .gt_from_md > :last-child { margin-bottom: 0; } #qotavlpmco .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #qotavlpmco .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #qotavlpmco .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #qotavlpmco .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #qotavlpmco .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #qotavlpmco .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #qotavlpmco .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #qotavlpmco .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #qotavlpmco .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #qotavlpmco .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #qotavlpmco .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #qotavlpmco .gt_sourcenote { font-size: 90%; padding: 4px; } #qotavlpmco .gt_left { text-align: left; } #qotavlpmco .gt_center { text-align: center; } #qotavlpmco .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #qotavlpmco .gt_font_normal { font-weight: normal; } #qotavlpmco .gt_font_bold { font-weight: bold; } #qotavlpmco .gt_font_italic { font-style: italic; } #qotavlpmco .gt_super { font-size: 65%; } #qotavlpmco .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } term estimate se_estimate (Intercept) &minus;11.5 0.435 income 0.0000208 0.00000499 balance 0.00565 0.000227 The estimates are essentially the same between the two methods. 7. LOOCV with weekly weekly &lt;- ISLR2::Weekly Fit a logistic regression model that predicts Direction using Lag1 and Lag2. direction_fit &lt;- logistic_reg() %&gt;% fit(Direction ~ Lag1 + Lag2, data = weekly) tidy(direction_fit) ## # A tibble: 3 x 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 0.221 0.0615 3.60 0.000319 ## 2 Lag1 -0.0387 0.0262 -1.48 0.140 ## 3 Lag2 0.0602 0.0265 2.27 0.0232 Fit the same model using all but the first observation. A shortcut to getting all but the first row of a data frame is tail(df, -1): direction_fit_1 &lt;- logistic_reg() %&gt;% fit(Direction ~ Lag1 + Lag2, data = tail(weekly, -1)) tidy(direction_fit_1) ## # A tibble: 3 x 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 0.223 0.0615 3.63 0.000283 ## 2 Lag1 -0.0384 0.0262 -1.47 0.143 ## 3 Lag2 0.0608 0.0266 2.29 0.0220 Use the model from (b) to predict the direction of the first observation. Was this observation correctly classified? augment(direction_fit_1, new_data = head(weekly, 1)) %&gt;% select(Lag1, Lag2, Direction, .pred_class, .pred_Down, .pred_Up) ## # A tibble: 1 x 6 ## Lag1 Lag2 Direction .pred_class .pred_Down .pred_Up ## &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.816 1.57 Down Up 0.429 0.571 It was predicted as Up, which is incorrect. Write a for loop from \\(i = 1\\) to \\(i = n\\), where \\(n\\) is the number of observations in the data set, that fits a model using all but the \\(i\\)th observation to prediction Direction. Then use that fit to predict the Direction of the held out observation. Instead of a for loop, Ill use purrr: tic() direction_loocv_preds &lt;- map_dfr( 1:nrow(weekly), ~logistic_reg() %&gt;% # Fit with `slice` to exclude the single row (`-.x`) fit(Direction ~ Lag1 + Lag2, data = slice(weekly, -.x)) %&gt;% # Predict with `slice` to get just that row (`.x`) augment(new_data = slice(weekly, .x)) %&gt;% select(Lag1, Lag2, Direction, starts_with(&quot;.pred&quot;)), .id = &quot;i&quot; ) toc() ## 296.35 sec elapsed When running long computations in an iterative way (with a for loop or mapping with purrr), it is very easy to take advantage of parallel computing with future and furrr: library(future) # Use all but one of my cores plan(multisession(workers = availableCores() - 1)) tic() direction_loocv_preds &lt;- furrr::future_map_dfr( 1:nrow(weekly), ~logistic_reg() %&gt;% fit(Direction ~ Lag1 + Lag2, data = slice(weekly, -.x)) %&gt;% augment(new_data = slice(weekly, .x)) %&gt;% select(Lag1, Lag2, Direction, starts_with(&quot;.pred&quot;)), .id = &quot;i&quot; ) toc() ## 23.19 sec elapsed Take the average of the \\(n\\) numbers obtained in (d) in order to obtain the LOOCV estimate for the test error. Comment on the results. I can compute the error, as well as some other metrics, manually like this: direction_loocv_preds %&gt;% summarise( n_correct = sum(Direction == .pred_class), accuracy = n_correct / n(), error_rate = 1 - accuracy, # Defining &quot;Up&quot; as positive, compute sensitivity and specificity sensitivity = sum(Direction == &quot;Up&quot; &amp; .pred_class == &quot;Up&quot;) / sum(Direction == &quot;Up&quot;), specificity = sum(Direction == &quot;Down&quot; &amp; .pred_class == &quot;Down&quot;) / sum(Direction == &quot;Down&quot;), across(c(accuracy, error_rate, sensitivity, specificity), scales::percent) ) %&gt;% gt() html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #yijtajtpbm .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #yijtajtpbm .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #yijtajtpbm .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #yijtajtpbm .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #yijtajtpbm .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #yijtajtpbm .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #yijtajtpbm .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #yijtajtpbm .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #yijtajtpbm .gt_column_spanner_outer:first-child { padding-left: 0; } #yijtajtpbm .gt_column_spanner_outer:last-child { padding-right: 0; } #yijtajtpbm .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #yijtajtpbm .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #yijtajtpbm .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #yijtajtpbm .gt_from_md > :first-child { margin-top: 0; } #yijtajtpbm .gt_from_md > :last-child { margin-bottom: 0; } #yijtajtpbm .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #yijtajtpbm .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #yijtajtpbm .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #yijtajtpbm .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #yijtajtpbm .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #yijtajtpbm .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #yijtajtpbm .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #yijtajtpbm .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #yijtajtpbm .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #yijtajtpbm .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #yijtajtpbm .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #yijtajtpbm .gt_sourcenote { font-size: 90%; padding: 4px; } #yijtajtpbm .gt_left { text-align: left; } #yijtajtpbm .gt_center { text-align: center; } #yijtajtpbm .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #yijtajtpbm .gt_font_normal { font-weight: normal; } #yijtajtpbm .gt_font_bold { font-weight: bold; } #yijtajtpbm .gt_font_italic { font-style: italic; } #yijtajtpbm .gt_super { font-size: 65%; } #yijtajtpbm .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } n_correct accuracy error_rate sensitivity specificity 599 55% 45% 93% 7% The yardstick package has a helpful metrics() function for quickly computing various metrics: metrics(direction_loocv_preds, truth = Direction, estimate = .pred_class) ## # A tibble: 2 x 3 ## .metric .estimator .estimate ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 accuracy binary 0.550 ## 2 kap binary 0.00451 For classification, this returns by default the accuracy and the Kappa statistic. The latter is a metric that compares the observed accuracy with a random chance classifier. It may be familiar in the context of inter-rater reliability, which is an important aspect of test/scale/measurement validity. Kappa values range from 0 to 1, with high values indicating better agreement. The threshold for an acceptable value will vary by context, but the value here (0.0045) is undoubtedly poor. I can define a custom metric_set() to get my desired classification metrics for this model:3 classification_metrics &lt;- metric_set(accuracy, sensitivity, specificity) classification_metrics(direction_loocv_preds, truth = Direction, estimate = .pred_class) %&gt;% pivot_wider(names_from = .metric, values_from = .estimate) %&gt;% transmute( error_rate = 1 - accuracy, across(c(accuracy, error_rate, sens, spec), scales::percent) ) %&gt;% gt() html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #rmujnfjuun .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #rmujnfjuun .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #rmujnfjuun .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #rmujnfjuun .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #rmujnfjuun .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #rmujnfjuun .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #rmujnfjuun .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #rmujnfjuun .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #rmujnfjuun .gt_column_spanner_outer:first-child { padding-left: 0; } #rmujnfjuun .gt_column_spanner_outer:last-child { padding-right: 0; } #rmujnfjuun .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #rmujnfjuun .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #rmujnfjuun .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #rmujnfjuun .gt_from_md > :first-child { margin-top: 0; } #rmujnfjuun .gt_from_md > :last-child { margin-bottom: 0; } #rmujnfjuun .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #rmujnfjuun .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #rmujnfjuun .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #rmujnfjuun .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #rmujnfjuun .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #rmujnfjuun .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #rmujnfjuun .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #rmujnfjuun .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #rmujnfjuun .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #rmujnfjuun .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #rmujnfjuun .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #rmujnfjuun .gt_sourcenote { font-size: 90%; padding: 4px; } #rmujnfjuun .gt_left { text-align: left; } #rmujnfjuun .gt_center { text-align: center; } #rmujnfjuun .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #rmujnfjuun .gt_font_normal { font-weight: normal; } #rmujnfjuun .gt_font_bold { font-weight: bold; } #rmujnfjuun .gt_font_italic { font-style: italic; } #rmujnfjuun .gt_super { font-size: 65%; } #rmujnfjuun .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } error_rate accuracy sens spec 45% 55% 7% 93% Note that the labels are switched from my manual calculation: sensitivity is swapped for specificity. This is because the positive level (called the event_level in yardstick) was manually chosen as Up by me, but automatically chosen as Down by yardstick. I can switch this by changing the event_level argument in the sensitivity() and specificity() functions: sensitivity(direction_loocv_preds, truth = Direction, estimate = .pred_class, event_level = &quot;second&quot;) ## # A tibble: 1 x 3 ## .metric .estimator .estimate ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 sens binary 0.934 But ideally this is something I would set before fitting the model  by setting Up as the first level of the Direction factor, tidymodels will interpret it as the event or positive level. 8. Cross-validation on simulated data Generate a simulated data set. What is \\(n\\) and \\(p\\)? Write out the model used to generate the data in equation form. set.seed(1) x &lt;- rnorm(100) y &lt;- x - 2 * x^2 + rnorm(100) The number of observations is \\(n\\) = 100, and the number of predictors is \\(p\\) = 1. \\[ \\begin{align} Y &amp;= \\beta_0 + \\beta_1 X + \\beta_2 X^2 + \\epsilon \\\\ X &amp;\\sim \\text{Normal}(0, 1) \\\\ \\epsilon &amp;\\sim \\text{Normal}(0, 1) \\\\ \\beta_0 &amp;= 0 \\\\ \\beta_1 &amp;= 1 \\\\ \\beta_2 &amp;= -2 \\end{align} \\] Create a scatterplot of \\(X\\) against \\(Y\\). d &lt;- tibble(x, y) ggplot(d, aes(x, y)) + geom_point() This is obviously a very non-linear relationship, with a negative parabola shape. A model without a polynomial term of \\(X\\) will definitely be a poor fit. Set a random seed, and then compute the LOOCV errors that result from fitting the following four models using least squares: \\[ \\begin{align} Y &amp;= \\beta_0 + \\beta_1 X + \\epsilon \\\\ Y &amp;= \\beta_0 + \\beta_1 X + \\beta_2 X^2 + \\epsilon \\\\ Y &amp;= \\beta_0 + \\beta_1 X + \\beta_2 X^2 + \\beta_3 X^3 + \\epsilon \\\\ Y &amp;= \\beta_0 + \\beta_1 X + \\beta_2 X^2 + \\beta_3 X^3 + \\beta_4 X^4 + \\epsilon \\end{align} \\] set.seed(927) tic() sim_fits_c &lt;- crossing(i = 1:nrow(d), poly_df = 1:4) %&gt;% mutate( fit = furrr::future_map2( i, poly_df, ~ linear_reg() %&gt;% fit(y ~ poly(x, degree = .y), data = slice(d, -.x)) ), resid_i = furrr::future_map2_dbl( i, fit, ~ augment(.y, new_data = slice(d, .x)) %&gt;% pull(.resid) ) ) toc() ## 18.86 sec elapsed sim_fits_c %&gt;% group_by(poly_df) %&gt;% summarise(mse = sum(resid_i^2)) %&gt;% gt() %&gt;% fmt_number(mse, decimals = 2) html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #xwcmvtolit .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #xwcmvtolit .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #xwcmvtolit .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #xwcmvtolit .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #xwcmvtolit .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #xwcmvtolit .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #xwcmvtolit .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #xwcmvtolit .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #xwcmvtolit .gt_column_spanner_outer:first-child { padding-left: 0; } #xwcmvtolit .gt_column_spanner_outer:last-child { padding-right: 0; } #xwcmvtolit .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #xwcmvtolit .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #xwcmvtolit .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #xwcmvtolit .gt_from_md > :first-child { margin-top: 0; } #xwcmvtolit .gt_from_md > :last-child { margin-bottom: 0; } #xwcmvtolit .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #xwcmvtolit .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #xwcmvtolit .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #xwcmvtolit .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #xwcmvtolit .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #xwcmvtolit .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #xwcmvtolit .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #xwcmvtolit .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #xwcmvtolit .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #xwcmvtolit .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #xwcmvtolit .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #xwcmvtolit .gt_sourcenote { font-size: 90%; padding: 4px; } #xwcmvtolit .gt_left { text-align: left; } #xwcmvtolit .gt_center { text-align: center; } #xwcmvtolit .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #xwcmvtolit .gt_font_normal { font-weight: normal; } #xwcmvtolit .gt_font_bold { font-weight: bold; } #xwcmvtolit .gt_font_italic { font-style: italic; } #xwcmvtolit .gt_super { font-size: 65%; } #xwcmvtolit .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } poly_df mse 1 728.82 2 93.74 3 95.66 4 95.39 Repeat (c) using another random seed. Are your results the same? Why? set.seed(213) sim_fits_d &lt;- crossing(i = 1:nrow(d), poly_df = 1:4) %&gt;% mutate( fit = furrr::future_map2( i, poly_df, ~ linear_reg() %&gt;% fit(y ~ poly(x, degree = .y), data = slice(d, -.x)) ), resid_i = furrr::future_map2_dbl( i, fit, ~ augment(.y, new_data = slice(d, .x)) %&gt;% pull(.resid) ) ) sim_fits_d %&gt;% group_by(poly_df) %&gt;% summarise(mse = sum(resid_i^2)) %&gt;% gt() %&gt;% fmt_number(mse, decimals = 2) html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #xlpiawbpcp .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #xlpiawbpcp .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #xlpiawbpcp .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #xlpiawbpcp .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #xlpiawbpcp .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #xlpiawbpcp .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #xlpiawbpcp .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #xlpiawbpcp .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #xlpiawbpcp .gt_column_spanner_outer:first-child { padding-left: 0; } #xlpiawbpcp .gt_column_spanner_outer:last-child { padding-right: 0; } #xlpiawbpcp .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #xlpiawbpcp .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #xlpiawbpcp .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #xlpiawbpcp .gt_from_md > :first-child { margin-top: 0; } #xlpiawbpcp .gt_from_md > :last-child { margin-bottom: 0; } #xlpiawbpcp .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #xlpiawbpcp .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #xlpiawbpcp .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #xlpiawbpcp .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #xlpiawbpcp .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #xlpiawbpcp .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #xlpiawbpcp .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #xlpiawbpcp .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #xlpiawbpcp .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #xlpiawbpcp .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #xlpiawbpcp .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #xlpiawbpcp .gt_sourcenote { font-size: 90%; padding: 4px; } #xlpiawbpcp .gt_left { text-align: left; } #xlpiawbpcp .gt_center { text-align: center; } #xlpiawbpcp .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #xlpiawbpcp .gt_font_normal { font-weight: normal; } #xlpiawbpcp .gt_font_bold { font-weight: bold; } #xlpiawbpcp .gt_font_italic { font-style: italic; } #xlpiawbpcp .gt_super { font-size: 65%; } #xlpiawbpcp .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } poly_df mse 1 728.82 2 93.74 3 95.66 4 95.39 Despite setting different random seeds, the results are exactly the same because none of the above code involved the generation of random numbers. LOOCV is an entirely deterministic process  each observation is used a single time as the holdout/evaluation data set. Which of the models had the smallest LOOCV error? The lowest MSE was the second model (\\(Y = \\beta_0 + \\beta_1 X + \\beta_2 X^2 + \\epsilon\\)) which is unsurprising because this is also the model used to generate the data. Comment on the statistical significance of the coefficient estimates that result from fitting each of the models in (c) using least squares. Do these results agree with the conclusions drawn based on the cross-validation results? sim_fits_c %&gt;% # For this, use the model fits that excluded the first (i = 1) observation filter(i == 1) %&gt;% mutate(fit_tidy = map(fit, tidy)) %&gt;% unnest(fit_tidy) %&gt;% transmute( poly_df = paste0(&quot;polynomial degree = &quot;, poly_df), term = factor(term, labels = c(&quot;beta_0&quot;, &quot;beta_1&quot;, &quot;beta_1&quot;, &quot;beta_2&quot;, &quot;beta_3&quot;, &quot;beta_4&quot;)), estimate = round(estimate, 2), std.error = round(std.error, 2), p.value = scales::pvalue(p.value) ) %&gt;% group_by(poly_df) %&gt;% gt() html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #skymurpgin .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #skymurpgin .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #skymurpgin .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #skymurpgin .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #skymurpgin .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #skymurpgin .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #skymurpgin .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #skymurpgin .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #skymurpgin .gt_column_spanner_outer:first-child { padding-left: 0; } #skymurpgin .gt_column_spanner_outer:last-child { padding-right: 0; } #skymurpgin .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #skymurpgin .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #skymurpgin .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #skymurpgin .gt_from_md > :first-child { margin-top: 0; } #skymurpgin .gt_from_md > :last-child { margin-bottom: 0; } #skymurpgin .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #skymurpgin .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #skymurpgin .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #skymurpgin .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #skymurpgin .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #skymurpgin .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #skymurpgin .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #skymurpgin .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #skymurpgin .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #skymurpgin .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #skymurpgin .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #skymurpgin .gt_sourcenote { font-size: 90%; padding: 4px; } #skymurpgin .gt_left { text-align: left; } #skymurpgin .gt_center { text-align: center; } #skymurpgin .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #skymurpgin .gt_font_normal { font-weight: normal; } #skymurpgin .gt_font_bold { font-weight: bold; } #skymurpgin .gt_font_italic { font-style: italic; } #skymurpgin .gt_super { font-size: 65%; } #skymurpgin .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } term estimate std.error p.value polynomial degree = 1 beta_0 -1.55 0.26 &lt;0.001 beta_1 6.17 2.61 0.020 polynomial degree = 2 beta_0 -1.55 0.10 &lt;0.001 beta_1 6.17 0.96 &lt;0.001 beta_2 -23.96 0.96 &lt;0.001 polynomial degree = 3 beta_0 -1.55 0.10 &lt;0.001 beta_1 6.17 0.97 &lt;0.001 beta_2 -23.96 0.97 &lt;0.001 beta_3 0.32 0.97 0.737 polynomial degree = 4 beta_0 -1.55 0.10 &lt;0.001 beta_1 6.17 0.96 &lt;0.001 beta_2 -23.96 0.96 &lt;0.001 beta_3 0.32 0.96 0.736 beta_4 1.24 0.96 0.201 This is aligned with the cross-validation results: the model with the 2nd degree polynomial (\\(\\beta_1\\) and \\(\\beta_2\\)) has statistically significant coefficients. The 3rd and 4th degree terms (\\(\\beta_3\\) and \\(\\beta_4\\)) are not significant in either model. 9. Bootstrap with boston boston &lt;- ISLR2::Boston Provide an estimate for the population mean of medv. Call this estimate \\(\\hat{\\mu}\\). mean(boston$medv) ## [1] 22.53281 Provide an estimate for the standard error of \\(\\hat{\\mu}\\). sd(boston$medv) / sqrt(nrow(boston)) ## [1] 0.4088611 Now estimate the standard error of \\(\\hat{\\mu}\\) using the bootstrap. How does this compare to your answer from (b)? set.seed(214) boston_boot &lt;- bootstraps(boston, times = 1000) boston_boot_mu &lt;- map_dbl( boston_boot$splits, ~ mean(as.data.frame(.x)$medv) ) mean_mu &lt;- mean(boston_boot_mu) se_mu &lt;- sd(boston_boot_mu) mean_mu; se_mu ## [1] 22.54254 ## [1] 0.4066961 For comparison, here is the implementation with the boot package: set.seed(214) medv_mean &lt;- function(data, i) mean(data$medv[i]) boot::boot(boston, statistic = medv_mean, R = 1000) ## ## ORDINARY NONPARAMETRIC BOOTSTRAP ## ## ## Call: ## boot::boot(data = boston, statistic = medv_mean, R = 1000) ## ## ## Bootstrap Statistics : ## original bias std. error ## t1* 22.53281 0.009737747 0.4181119 The results are slightly different, even with the same seed, because the inner workings of the functions use random numbers in different ways, but both are very close to the estimate from (b). Based on your bootstrap estimate from (c), provide a 95 % confidence interval for the mean of medv. Compare it to the results obtained using t.test(boston$medv). Approximate interval using the bootstrap estimates: mean_mu - 2 * se_mu; mean_mu + 2 * se_mu ## [1] 21.72915 ## [1] 23.35594 t.test(boston$medv) ## ## One Sample t-test ## ## data: boston$medv ## t = 55.111, df = 505, p-value &lt; 2.2e-16 ## alternative hypothesis: true mean is not equal to 0 ## 95 percent confidence interval: ## 21.72953 23.33608 ## sample estimates: ## mean of x ## 22.53281 The 95% confidence intervals are essentially equal. Provide an estimate, \\(\\hat{\\mu}_{\\text{med}}\\), for the median value of medv in the population. median(boston$medv) ## [1] 21.2 We now would like to estimate the standard error of \\(\\hat{\\mu}_{\\text{med}}\\). Unfortunately, there is no simple formula for computing the standard error of the median. Instead, estimate the standard error of the median using the bootstrap. set.seed(25) boston_boot_median &lt;- map_dbl( boston_boot$splits, ~ median(as.data.frame(.x)$medv) ) mean_median &lt;- mean(boston_boot_median) se_median &lt;- sd(boston_boot_median) mean_median; se_median ## [1] 21.19575 ## [1] 0.3749333 Provide an estimate, \\(\\hat{\\mu}_{0.1}\\), for the tenth percentile of medv. quantile(boston$medv, probs = 0.1) ## 10% ## 12.75 Use the bootstrap to estimate the standard error of \\(\\hat{\\mu}_{0.1}\\). set.seed(6929) boston_boot_p10 &lt;- map_dbl( boston_boot$splits, ~ quantile(as.data.frame(.x)$medv, probs = 0.1) ) mean_p10 &lt;- mean(boston_boot_p10) se_p10 &lt;- sd(boston_boot_p10) mean_p10; se_p10 ## [1] 12.78025 ## [1] 0.4978406 Reproducibility Sys.time() ## [1] &quot;2022-04-09 16:10:04 AST&quot; if (&quot;git2r&quot; %in% installed.packages()) { if (git2r::in_repository()) { git2r::repository() } } ## Local: main C:/Users/tdunn/Documents/learning/islr-tidy ## Remote: main @ origin (https://github.com/taylordunn/islr-tidy) ## Head: [00046ed] 2022-04-08: Finished chapter 6 sessioninfo::session_info() ## - Session info --------------------------------------------------------------- ## setting value ## version R version 4.1.3 (2022-03-10) ## os Windows 10 x64 ## system x86_64, mingw32 ## ui RTerm ## language (EN) ## collate English_Canada.1252 ## ctype English_Canada.1252 ## tz America/Curacao ## date 2022-04-09 ## ## - Packages ------------------------------------------------------------------- ## package * version date lib source ## abind 1.4-5 2016-07-21 [1] CRAN (R 4.1.1) ## assertthat 0.2.1 2019-03-21 [1] CRAN (R 4.1.0) ## backports 1.2.1 2020-12-09 [1] CRAN (R 4.1.0) ## base64enc 0.1-3 2015-07-28 [1] CRAN (R 4.1.0) ## bayestestR 0.10.5 2021-07-26 [1] CRAN (R 4.1.0) ## bit 4.0.4 2020-08-04 [1] CRAN (R 4.1.2) ## bit64 4.0.5 2020-08-30 [1] CRAN (R 4.1.2) ## bookdown 0.24 2021-09-02 [1] CRAN (R 4.1.1) ## boot 1.3-28 2021-05-03 [2] CRAN (R 4.1.3) ## broom * 0.7.10 2021-10-31 [1] CRAN (R 4.1.2) ## bslib 0.2.5.1 2021-05-18 [1] CRAN (R 4.1.0) ## cachem 1.0.6 2021-08-19 [1] CRAN (R 4.1.1) ## car 3.0-12 2021-11-06 [1] CRAN (R 4.1.2) ## carData 3.0-4 2020-05-22 [1] CRAN (R 4.1.1) ## cellranger 1.1.0 2016-07-27 [1] CRAN (R 4.1.0) ## checkmate 2.0.0 2020-02-06 [1] CRAN (R 4.1.0) ## class 7.3-20 2022-01-16 [2] CRAN (R 4.1.3) ## cli 3.2.0 2022-02-14 [1] CRAN (R 4.1.3) ## coda 0.19-4 2020-09-30 [1] CRAN (R 4.1.0) ## codetools 0.2-18 2020-11-04 [2] CRAN (R 4.1.3) ## colorspace 2.0-3 2022-02-21 [1] CRAN (R 4.1.3) ## combinat 0.0-8 2012-10-29 [1] CRAN (R 4.1.1) ## corrr * 0.4.3 2020-11-24 [1] CRAN (R 4.1.0) ## crayon 1.5.1 2022-03-26 [1] CRAN (R 4.1.3) ## datawizard 0.1.0 2021-06-18 [1] CRAN (R 4.1.0) ## DBI 1.1.2 2021-12-20 [1] CRAN (R 4.1.2) ## dbplyr 2.1.1 2021-04-06 [1] CRAN (R 4.1.0) ## DEoptimR 1.0-9 2021-05-24 [1] CRAN (R 4.1.0) ## dials * 0.0.10 2021-09-10 [1] CRAN (R 4.1.1) ## DiceDesign 1.9 2021-02-13 [1] CRAN (R 4.1.0) ## digest 0.6.29 2021-12-01 [1] CRAN (R 4.1.2) ## discrim * 0.1.3 2021-07-21 [1] CRAN (R 4.1.2) ## distill 1.3 2021-10-13 [1] CRAN (R 4.1.2) ## distributional 0.2.2 2021-02-02 [1] CRAN (R 4.1.2) ## doParallel * 1.0.16 2020-10-16 [1] CRAN (R 4.1.1) ## downlit 0.4.0 2021-10-29 [1] CRAN (R 4.1.1) ## dplyr * 1.0.8 2022-02-08 [1] CRAN (R 4.1.3) ## dunnr * 0.2.5 2022-01-15 [1] Github (taylordunn/dunnr@c83b30e) ## effectsize 0.4.5 2021-05-25 [1] CRAN (R 4.1.0) ## ellipsis 0.3.2 2021-04-29 [1] CRAN (R 4.1.0) ## emmeans 1.7.0 2021-09-29 [1] CRAN (R 4.1.2) ## equatiomatic 0.2.0 2021-01-30 [1] CRAN (R 4.1.0) ## estimability 1.3 2018-02-11 [1] CRAN (R 4.1.1) ## evaluate 0.14 2019-05-28 [1] CRAN (R 4.1.0) ## extrafont 0.17 2014-12-08 [1] CRAN (R 4.1.0) ## extrafontdb 1.0 2012-06-11 [1] CRAN (R 4.1.0) ## fansi 1.0.3 2022-03-24 [1] CRAN (R 4.1.3) ## farver 2.1.0 2021-02-28 [1] CRAN (R 4.1.0) ## fastmap 1.1.0 2021-01-25 [1] CRAN (R 4.1.0) ## forcats * 0.5.1 2021-01-27 [1] CRAN (R 4.1.0) ## foreach * 1.5.2 2022-02-02 [1] CRAN (R 4.1.3) ## fs 1.5.2 2021-12-08 [1] CRAN (R 4.1.2) ## furrr 0.2.3 2021-06-25 [1] CRAN (R 4.1.2) ## future 1.24.0 2022-02-19 [1] CRAN (R 4.1.3) ## future.apply 1.8.1 2021-08-10 [1] CRAN (R 4.1.3) ## generics 0.1.2 2022-01-31 [1] CRAN (R 4.1.3) ## GGally 2.1.2 2021-06-21 [1] CRAN (R 4.1.0) ## ggdist * 3.0.0 2021-07-19 [1] CRAN (R 4.1.2) ## ggplot2 * 3.3.5 2021-06-25 [1] CRAN (R 4.1.0) ## ggrepel 0.9.1 2021-01-15 [1] CRAN (R 4.1.0) ## ggridges 0.5.3 2021-01-08 [1] CRAN (R 4.1.0) ## git2r 0.28.0 2021-01-10 [1] CRAN (R 4.1.0) ## globals 0.14.0 2020-11-22 [1] CRAN (R 4.1.0) ## glue 1.6.2 2022-02-24 [1] CRAN (R 4.1.3) ## gower 0.2.2 2020-06-23 [1] CRAN (R 4.1.0) ## GPfit 1.0-8 2019-02-08 [1] CRAN (R 4.1.0) ## gridExtra 2.3 2017-09-09 [1] CRAN (R 4.1.0) ## gt * 0.3.1 2021-08-07 [1] CRAN (R 4.1.2) ## gtable 0.3.0 2019-03-25 [1] CRAN (R 4.1.0) ## hardhat 0.2.0 2022-01-24 [1] CRAN (R 4.1.3) ## haven 2.4.1 2021-04-23 [1] CRAN (R 4.1.0) ## here * 1.0.1 2020-12-13 [1] CRAN (R 4.1.0) ## highr 0.9 2021-04-16 [1] CRAN (R 4.1.0) ## hms 1.1.1 2021-09-26 [1] CRAN (R 4.1.2) ## htmltools 0.5.2 2021-08-25 [1] CRAN (R 4.1.1) ## httpuv 1.6.5 2022-01-05 [1] CRAN (R 4.1.2) ## httr 1.4.2 2020-07-20 [1] CRAN (R 4.1.0) ## igraph 1.2.11 2022-01-04 [1] CRAN (R 4.1.3) ## infer * 1.0.0 2021-08-13 [1] CRAN (R 4.1.1) ## insight 0.14.2 2021-06-22 [1] CRAN (R 4.1.0) ## ipred 0.9-12 2021-09-15 [1] CRAN (R 4.1.1) ## ISLR2 * 1.3-1 2022-01-10 [1] CRAN (R 4.1.2) ## iterators * 1.0.14 2022-02-05 [1] CRAN (R 4.1.3) ## jquerylib 0.1.4 2021-04-26 [1] CRAN (R 4.1.0) ## jsonlite 1.7.3 2022-01-17 [1] CRAN (R 4.1.2) ## kknn 1.3.1 2016-03-26 [1] CRAN (R 4.1.2) ## klaR 0.6-15 2020-02-19 [1] CRAN (R 4.1.2) ## knitr 1.37 2021-12-16 [1] CRAN (R 4.1.2) ## labeling 0.4.2 2020-10-20 [1] CRAN (R 4.1.0) ## labelled 2.8.0 2021-03-08 [1] CRAN (R 4.1.0) ## later 1.3.0 2021-08-18 [1] CRAN (R 4.1.2) ## lattice 0.20-45 2021-09-22 [2] CRAN (R 4.1.3) ## lava 1.6.10 2021-09-02 [1] CRAN (R 4.1.3) ## lhs 1.1.1 2020-10-05 [1] CRAN (R 4.1.0) ## lifecycle 1.0.1 2021-09-24 [1] CRAN (R 4.1.1) ## listenv 0.8.0 2019-12-05 [1] CRAN (R 4.1.0) ## lubridate 1.8.0 2021-10-07 [1] CRAN (R 4.1.1) ## magrittr 2.0.2 2022-01-26 [1] CRAN (R 4.1.3) ## MASS 7.3-55 2022-01-16 [2] CRAN (R 4.1.3) ## Matrix 1.4-0 2021-12-08 [2] CRAN (R 4.1.3) ## memoise 2.0.1 2021-11-26 [1] CRAN (R 4.1.2) ## MetBrewer 0.1.0 2022-01-05 [1] CRAN (R 4.1.2) ## mgcv 1.8-39 2022-02-24 [2] CRAN (R 4.1.3) ## mime 0.12 2021-09-28 [1] CRAN (R 4.1.1) ## miniUI 0.1.1.1 2018-05-18 [1] CRAN (R 4.1.1) ## modeldata * 0.1.1 2021-07-14 [1] CRAN (R 4.1.0) ## modelr 0.1.8 2020-05-19 [1] CRAN (R 4.1.0) ## munsell 0.5.0 2018-06-12 [1] CRAN (R 4.1.0) ## mvtnorm * 1.1-3 2021-10-08 [1] CRAN (R 4.1.1) ## nlme 3.1-155 2022-01-16 [2] CRAN (R 4.1.3) ## nnet 7.3-17 2022-01-16 [2] CRAN (R 4.1.3) ## parallelly 1.30.0 2021-12-17 [1] CRAN (R 4.1.2) ## parameters 0.14.0 2021-05-29 [1] CRAN (R 4.1.0) ## parsnip * 0.1.7 2021-07-21 [1] CRAN (R 4.1.0) ## patchwork * 1.1.1 2020-12-17 [1] CRAN (R 4.1.0) ## performance 0.7.3 2021-07-21 [1] CRAN (R 4.1.1) ## pillar 1.7.0 2022-02-01 [1] CRAN (R 4.1.2) ## pkgconfig 2.0.3 2019-09-22 [1] CRAN (R 4.1.0) ## plyr 1.8.7 2022-03-24 [1] CRAN (R 4.1.3) ## poissonreg * 0.1.1 2021-08-07 [1] CRAN (R 4.1.2) ## prettyunits 1.1.1 2020-01-24 [1] CRAN (R 4.1.0) ## pROC 1.17.0.1 2021-01-13 [1] CRAN (R 4.1.0) ## prodlim 2019.11.13 2019-11-17 [1] CRAN (R 4.1.0) ## promises 1.2.0.1 2021-02-11 [1] CRAN (R 4.1.0) ## purrr * 0.3.4 2020-04-17 [1] CRAN (R 4.1.2) ## qqplotr 0.0.5 2021-04-23 [1] CRAN (R 4.1.0) ## questionr 0.7.5 2021-10-06 [1] CRAN (R 4.1.2) ## R6 2.5.1 2021-08-19 [1] CRAN (R 4.1.1) ## RColorBrewer 1.1-3 2022-04-03 [1] CRAN (R 4.1.3) ## Rcpp 1.0.8.3 2022-03-17 [1] CRAN (R 4.1.3) ## readr * 2.1.1 2021-11-30 [1] CRAN (R 4.1.2) ## readxl 1.3.1 2019-03-13 [1] CRAN (R 4.1.0) ## recipes * 0.1.17 2021-09-27 [1] CRAN (R 4.1.1) ## repr 1.1.3 2021-01-21 [1] CRAN (R 4.1.1) ## reprex 2.0.0 2021-04-02 [1] CRAN (R 4.1.0) ## reshape 0.8.8 2018-10-23 [1] CRAN (R 4.1.0) ## rlang * 1.0.2 2022-03-04 [1] CRAN (R 4.1.3) ## rmarkdown 2.11 2021-09-14 [1] CRAN (R 4.1.1) ## robustbase 0.93-8 2021-06-02 [1] CRAN (R 4.1.0) ## rpart 4.1.16 2022-01-24 [2] CRAN (R 4.1.3) ## rprojroot 2.0.2 2020-11-15 [1] CRAN (R 4.1.0) ## rsample * 0.1.0 2021-05-08 [1] CRAN (R 4.1.0) ## rstudioapi 0.13 2020-11-12 [1] CRAN (R 4.1.0) ## Rttf2pt1 1.3.8 2020-01-10 [1] CRAN (R 4.1.1) ## rvest 1.0.0 2021-03-09 [1] CRAN (R 4.1.0) ## sass 0.4.0 2021-05-12 [1] CRAN (R 4.1.0) ## scales * 1.1.1 2020-05-11 [1] CRAN (R 4.1.0) ## see 0.6.4 2021-05-29 [1] CRAN (R 4.1.0) ## sessioninfo 1.1.1 2018-11-05 [1] CRAN (R 4.1.0) ## shiny 1.6.0 2021-01-25 [1] CRAN (R 4.1.0) ## skimr 2.1.3 2021-03-07 [1] CRAN (R 4.1.1) ## stringi 1.7.6 2021-11-29 [1] CRAN (R 4.1.2) ## stringr * 1.4.0 2019-02-10 [1] CRAN (R 4.1.0) ## survival 3.2-13 2021-08-24 [2] CRAN (R 4.1.3) ## tibble * 3.1.6 2021-11-07 [1] CRAN (R 4.1.1) ## tictoc * 1.0.1 2021-04-19 [1] CRAN (R 4.1.1) ## tidymodels * 0.1.4 2021-10-01 [1] CRAN (R 4.1.1) ## tidyr * 1.2.0 2022-02-01 [1] CRAN (R 4.1.3) ## tidyselect 1.1.2 2022-02-21 [1] CRAN (R 4.1.3) ## tidyverse * 1.3.1 2021-04-15 [1] CRAN (R 4.1.3) ## timeDate 3043.102 2018-02-21 [1] CRAN (R 4.1.0) ## tune * 0.1.6 2021-07-21 [1] CRAN (R 4.1.0) ## tzdb 0.2.0 2021-10-27 [1] CRAN (R 4.1.2) ## usethis 2.1.5 2021-12-09 [1] CRAN (R 4.1.2) ## utf8 1.2.2 2021-07-24 [1] CRAN (R 4.1.0) ## vctrs * 0.3.8 2021-04-29 [1] CRAN (R 4.1.3) ## vroom 1.5.7 2021-11-30 [1] CRAN (R 4.1.2) ## withr 2.5.0 2022-03-03 [1] CRAN (R 4.1.3) ## workflows * 0.2.3 2021-07-16 [1] CRAN (R 4.1.0) ## workflowsets * 0.1.0 2021-07-22 [1] CRAN (R 4.1.0) ## xfun 0.29 2021-12-14 [1] CRAN (R 4.1.2) ## xml2 1.3.3 2021-11-30 [1] CRAN (R 4.1.2) ## xtable 1.8-4 2019-04-21 [1] CRAN (R 4.1.0) ## yaml 2.2.1 2020-02-01 [1] CRAN (R 4.1.0) ## yardstick * 0.0.8 2021-03-28 [1] CRAN (R 4.1.0) ## ## [1] C:/Users/tdunn/Documents/R/win-library/4.1 ## [2] C:/Program Files/R/R-4.1.3/library In the text, they compute the MSE but here I am computing RMSE then squaring it. This is because yardstick has a rmse() function but not an mse() function. If I wanted to, I could define a custom metric like this. Since there is no random splitting with this approach, I dont need use a function that sets the random seed. The list of available metrics in yardstick can be found in this article. "],["linear-model-selection-and-regularization.html", "6 Linear Model Selection and Regularization 6.1 Subset Selection 6.2 Shrinkage Methods 6.3 Dimension Reduction Methods 6.4 Considerations in High Dimensions 6.5 Lab: Linear Models and Regularization Methods 6.6 Exercises Reproducibility", " 6 Linear Model Selection and Regularization Load the packages used in this chapter: library(tidyverse) library(tidymodels) library(broom) library(gt) library(patchwork) library(tictoc) # Load my R package and set the ggplot theme library(dunnr) extrafont::loadfonts(device = &quot;win&quot;, quiet = TRUE) theme_set(theme_td()) set_geom_fonts() set_palette() Before discussing non-linear models in Chapters 7, 8 and 10, this chapter discusses some ways in which the simple linear model can be improved by replacing the familiar least squares fitting with some alternative fitting procedures. These alternatives can sometimes yield better prediction accuracy and model interpretability. Prediction Accuracy: Provided that the true relationship between the response and the predictors is approximately linear, the least squares estimates will have low bias. If \\(n &gt;&gt; p\\)that is, if \\(n\\), the number of observations, is much larger than \\(p\\), the number of variablesthen the least squares estimates tend to also have low variance, and hence will perform well on test observations. However, if \\(n\\) is not much larger than \\(p\\), then there can be a lot of variability in the least squares fit, resulting in overfitting and consequently poor predictions on future observations not used in model training. And if \\(p &gt; n\\), then there is no longer a unique least squares coefficient estimate: the variance is infinite so the method cannot be used at all. By constraining or shrinking the estimated coefficients, we can often substantially reduce the variance at the cost of a negligible increase in bias. This can lead to substantial improvements in the accuracy with which we can predict the response for observations not used in model training. Model Interpretability: It is often the case that some or many of the variables used in a multiple regression model are in fact not associated with the response. Including such irrelevant variables leads to unnecessary complexity in the resulting model. By removing these variablesthat is, by setting the corresponding coefficient estimates to zerowe can obtain a model that is more easily interpreted. Now least squares is extremely unlikely to yield any coefficient estimates that are exactly zero. In this chapter, we see some approaches for au- tomatically performing feature selection or variable selectionthat is, feature for excluding irrelevant variables from a multiple regression model. In this chapter, we discuss three important classes of methods: Subset Selection. This approach involves identifying a subset of the \\(p\\) predictors that we believe to be related to the response. We then fit a model using least squares on the reduced set of variables. Shrinkage. This approach involves fitting a model involving all \\(p\\) predictors. However, the estimated coefficients are shrunken towards zero relative to the least squares estimates. This shrinkage (also known as regularization) has the effect of reducing variance. Depending on what type of shrinkage is performed, some of the coefficients may be esti- mated to be exactly zero. Hence, shrinkage methods can also perform variable selection. Dimension Reduction. This approach involves projecting the \\(p\\) predictors into an \\(M\\)-dimensional subspace, where \\(M &lt; p\\). This is achieved by computing \\(M\\) different linear combinations, or projections, of the variables. Then these \\(M\\) projections are used as predictors to fit a linear regression model by least squares. Although this chapter is specifically about extensions to the linear model for regression, the same concepts apply to other methods, such as the classification models in Chapter 4. 6.1 Subset Selection Disclaimer at the top: as mentioned in section 3.1, there are a lot of reasons to avoid subset and stepwise model selection. Here are some resources on this topic: The 2018 paper by Smith (2018). A Stack Overflow response. Frank Harrell comments. Regardless, I will still work through the examples in the text as a programming exercise. However, tidymodels does not have the functionality for subset/stepwise selection, so I will be using alternatives. 6.1.1 Best Subset Selection To perform best subset selection, we fit \\(p\\) models that contain exactly one predictor, \\({p \\choose 2} = p(p-1)/2\\) models that contain exactly two predictors, and so on. In total, this involves fitting \\(2^p\\) models. Then we select the model that is best, usually following these steps Let \\(\\mathcal{M}_0\\) denote the null model, which contains no predictors. This model simply predicts the sample mean. For \\(k = 1, 2, \\dots, p\\): Fit all \\({p \\choose k}\\) models that contain exactly \\(k\\) predictors. Pick the best among these \\({p \\choose k}\\) models, and call it \\(\\mathcal{M}_k\\). Here, best is defined as having the smallest RSS, or equivalently the largest \\(R^2\\). Select a single best model from among \\(\\mathcal{M}_0, \\dots, \\mathcal{M}_p\\) using cross-validated prediction error \\(C_p\\) (AIC), BIC, or adjusted \\(R^2\\). Step 2 identifies the best model (on the training data) for each subset size, in order to reduce the problem from \\(2^p\\) to \\(p + 1\\) possible models. Choosing the single best model from the \\(p + 1\\) options must be done with care, because the RSS of these models decreases monotonically, and the \\(R^2\\) increases monotonically, as the number of predictors increases. A model that minimizes these metrics will have a low training error, but not necessarily a low test error, as we saw in Chapter 2 in Figures 2.9-2.11. Therefore, in step 3, we use a cross-validated prediction error \\(C_p\\), BIC, or adjusted \\(R^2\\) in order to select the best model. Figure 6.1 includes many least squares regression models predicting Balance, and fit using a different subsets of 10 predictors. Load the credit data set: credit &lt;- ISLR2::Credit glimpse(credit) ## Rows: 400 ## Columns: 11 ## $ Income &lt;dbl&gt; 14.891, 106.025, 104.593, 148.924, 55.882, 80.180, 20.996, 7~ ## $ Limit &lt;dbl&gt; 3606, 6645, 7075, 9504, 4897, 8047, 3388, 7114, 3300, 6819, ~ ## $ Rating &lt;dbl&gt; 283, 483, 514, 681, 357, 569, 259, 512, 266, 491, 589, 138, ~ ## $ Cards &lt;dbl&gt; 2, 3, 4, 3, 2, 4, 2, 2, 5, 3, 4, 3, 1, 1, 2, 3, 3, 3, 1, 2, ~ ## $ Age &lt;dbl&gt; 34, 82, 71, 36, 68, 77, 37, 87, 66, 41, 30, 64, 57, 49, 75, ~ ## $ Education &lt;dbl&gt; 11, 15, 11, 11, 16, 10, 12, 9, 13, 19, 14, 16, 7, 9, 13, 15,~ ## $ Own &lt;fct&gt; No, Yes, No, Yes, No, No, Yes, No, Yes, Yes, No, No, Yes, No~ ## $ Student &lt;fct&gt; No, Yes, No, No, No, No, No, No, No, Yes, No, No, No, No, No~ ## $ Married &lt;fct&gt; Yes, Yes, No, No, Yes, No, No, No, No, Yes, Yes, No, Yes, Ye~ ## $ Region &lt;fct&gt; South, West, West, West, South, South, East, West, South, Ea~ ## $ Balance &lt;dbl&gt; 333, 903, 580, 964, 331, 1151, 203, 872, 279, 1350, 1407, 0,~ For \\(p = 10\\) predictors, there are \\(2^{10} = 1024\\) possible combinations for models (including the null model, but this example doesnt include it). To get every combination, Ill use the utils::combn() function: credit_predictors &lt;- names(credit) credit_predictors &lt;- credit_predictors[credit_predictors != &quot;Balance&quot;] credit_model_subsets &lt;- tibble( n_preds = 1:10, predictors = map(n_preds, ~ utils::combn(credit_predictors, .x, simplify = FALSE)) ) %&gt;% unnest(predictors) %&gt;% mutate( model_formula = map(predictors, ~ as.formula(paste(&quot;Balance ~&quot;, paste(.x, collapse = &quot;+&quot;)))) ) glimpse(credit_model_subsets) ## Rows: 1,023 ## Columns: 3 ## $ n_preds &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,~ ## $ predictors &lt;list&gt; &quot;Income&quot;, &quot;Limit&quot;, &quot;Rating&quot;, &quot;Cards&quot;, &quot;Age&quot;, &quot;Education~ ## $ model_formula &lt;list&gt; &lt;Balance ~ Income&gt;, &lt;Balance ~ Limit&gt;, &lt;Balance ~ Ratin~ For differing numbers of predictors \\(k = 1, 2, \\dots, p\\), we should have \\({p \\choose k}\\) models: credit_model_subsets %&gt;% count(n_preds) %&gt;% mutate(p_choose_k = choose(10, n_preds)) ## # A tibble: 10 x 3 ## n_preds n p_choose_k ## &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 1 10 10 ## 2 2 45 45 ## 3 3 120 120 ## 4 4 210 210 ## 5 5 252 252 ## 6 6 210 210 ## 7 7 120 120 ## 8 8 45 45 ## 9 9 10 10 ## 10 10 1 1 Fit all of the models and extract RSS and \\(R^2\\) metrics: credit_model_subsets &lt;- credit_model_subsets %&gt;% mutate( model_fit = map(model_formula, ~ lm(.x, data = credit)), RSS = map_dbl(model_fit, ~ sum(.x$residuals^2)), R2 = map_dbl(model_fit, ~ summary(.x)$r.squared), # Because of one of the categorical variables (Region) having three levels, # some models will have +1 dummy variable predictor, which I can calculate # from the number of coefficients returned from the fit n_preds_adj = map_int(model_fit, ~ length(.x$coefficients) - 1L) ) Figure 6.1: credit_model_subsets %&gt;% pivot_longer(cols = c(RSS, R2), names_to = &quot;metric&quot;, values_to = &quot;value&quot;) %&gt;% mutate(metric = factor(metric, levels = c(&quot;RSS&quot;, &quot;R2&quot;))) %&gt;% group_by(n_preds_adj, metric) %&gt;% mutate( # The &quot;best&quot; model has the lowest value by RSS... best_model = (metric == &quot;RSS&quot; &amp; value == min(value)) | # ... and the highest value by R2 (metric == &quot;R2&quot; &amp; value == max(value)) ) %&gt;% ungroup() %&gt;% ggplot(aes(x = n_preds_adj, y = value)) + geom_line(data = . %&gt;% filter(best_model), color = &quot;red&quot;, size = 1) + geom_jitter(width = 0.05, height = 0, alpha = 0.3, color = td_colors$nice$opera_mauve) + facet_wrap(~ metric, ncol = 2, scales = &quot;free_y&quot;) + scale_x_continuous(&quot;Number of predictors&quot;, breaks = seq(2, 10, 2)) As expected, the values are monotonically decreasing (RSS) and increasing (\\(R^2\\)) with number of predictors. There is little improvement past 3 predictors, however. Although we have presented best subset selection here for least squares regression, the same ideas apply to other types of models, such as logistic regression. In the case of logistic regression, instead of ordering models by RSS in Step 2 of Algorithm 6.1, we instead use the deviance, a measure that plays the role of RSS for a broader class of models. The deviance is negative two times the maximized log-likelihood; the smaller the deviance, the better the fit. Because it scales as \\(2^p\\) models, best subset selection can quickly become computationally expensive. The next sections explore computationally efficient alternatives. 6.1.2 Stepwise Selection Forward Stepwise Selection Forward stepwise selection begins with a model containing no predictors, and then adds predictors to the model, one-at-a-time, until all predictors are in the model. Let \\(\\mathcal{M}_0\\) denote the null model, which contains no predictors. For \\(k = 0, 1, \\dots, p-1\\): Consider all \\(p - k\\) models that augment the predictors in \\(\\mathcal{M}_k\\) with one additional predictor. Choose the best among these \\(p - k\\) models, and call it \\(\\mathcal{M}_{k+1}\\). Here, best is defined as having smallest RSS or highest \\(R^2\\). Select a single best model from among \\(\\mathcal{M}_0, \\dots, \\mathcal{M}_p\\) using cross-validated prediction error \\(C_p\\) (AIC), BIC, or adjusted \\(R^2\\). Step 2 is similar to step 2 in best subset selection, in that we simply choose the model with the lowest RSS or highest \\(R^2\\). Step 3 is more tricky, and is discussed in Section 6.1.3. Though much more computationally efficient, it is not guaranteed to find the best possible model (via best subset selection) out of all \\(2^p\\) possible models. As a comparison, the example in the text involves performing four forward steps to find the best predictors. The MASS package has an addTerm() function for taking a single step: # Model with no predictors balance_null &lt;- lm(Balance ~ 1, data = credit) # Model with all predictors balance_full &lt;- lm(Balance ~ ., data = credit) MASS::addterm(balance_null, scope = balance_full, sorted = TRUE) ## Single term additions ## ## Model: ## Balance ~ 1 ## Df Sum of Sq RSS AIC ## Rating 1 62904790 21435122 4359.6 ## Limit 1 62624255 21715657 4364.8 ## Income 1 18131167 66208745 4810.7 ## Student 1 5658372 78681540 4879.8 ## Cards 1 630416 83709496 4904.6 ## &lt;none&gt; 84339912 4905.6 ## Own 1 38892 84301020 4907.4 ## Education 1 5481 84334431 4907.5 ## Married 1 2715 84337197 4907.5 ## Age 1 284 84339628 4907.6 ## Region 2 18454 84321458 4909.5 Here, the Rating variable offers the best improvement over the null model (by both RSS and AIC). To run this four times, Ill use a for loop: balance_preds &lt;- c(&quot;1&quot;) for (forward_step in 1:4) { balance_formula &lt;- as.formula( paste(&quot;Balance ~&quot;, str_replace_all(balance_preds[forward_step], &quot;,&quot;, &quot;+&quot;)) ) balance_model &lt;- lm(balance_formula, data = credit) # Find the next predictor by RSS new_predictor &lt;- MASS::addterm(balance_model, scope = balance_full) %&gt;% broom::tidy() %&gt;% filter(rss == min(rss)) %&gt;% pull(term) balance_preds &lt;- append(balance_preds, paste(balance_preds[forward_step], new_predictor, sep = &quot;, &quot;)) } balance_preds ## [1] &quot;1&quot; &quot;1, Rating&quot; ## [3] &quot;1, Rating, Income&quot; &quot;1, Rating, Income, Student&quot; ## [5] &quot;1, Rating, Income, Student, Limit&quot; Now re-create Table 6.1: bind_cols( credit_model_subsets %&gt;% filter(n_preds_adj &lt;= 4) %&gt;% group_by(n_preds_adj) %&gt;% filter(RSS == min(RSS)) %&gt;% ungroup() %&gt;% transmute( `# variables` = n_preds_adj, `Best subset` = map_chr(predictors, str_c, collapse = &quot;, &quot;) ), `Forward stepwise` = balance_preds[2:5] %&gt;% str_remove(&quot;1, &quot;) ) %&gt;% gt(rowname_col = &quot;# variables&quot;) html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #gehakohhxl .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #gehakohhxl .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #gehakohhxl .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #gehakohhxl .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #gehakohhxl .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #gehakohhxl .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #gehakohhxl .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #gehakohhxl .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #gehakohhxl .gt_column_spanner_outer:first-child { padding-left: 0; } #gehakohhxl .gt_column_spanner_outer:last-child { padding-right: 0; } #gehakohhxl .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #gehakohhxl .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #gehakohhxl .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #gehakohhxl .gt_from_md > :first-child { margin-top: 0; } #gehakohhxl .gt_from_md > :last-child { margin-bottom: 0; } #gehakohhxl .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #gehakohhxl .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #gehakohhxl .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #gehakohhxl .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #gehakohhxl .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #gehakohhxl .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #gehakohhxl .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #gehakohhxl .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #gehakohhxl .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #gehakohhxl .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #gehakohhxl .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #gehakohhxl .gt_sourcenote { font-size: 90%; padding: 4px; } #gehakohhxl .gt_left { text-align: left; } #gehakohhxl .gt_center { text-align: center; } #gehakohhxl .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #gehakohhxl .gt_font_normal { font-weight: normal; } #gehakohhxl .gt_font_bold { font-weight: bold; } #gehakohhxl .gt_font_italic { font-style: italic; } #gehakohhxl .gt_super { font-size: 65%; } #gehakohhxl .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } Best subset Forward stepwise 1 Rating Rating 2 Income, Rating Rating, Income 3 Income, Rating, Student Rating, Income, Student 4 Income, Limit, Cards, Student Rating, Income, Student, Limit Backward Stepwise Selection Backwards stepwise selection begins with the full model containing all \\(p\\) predictors, and then iteratively removes the least useful predictor. Let \\(\\mathcal{M}_p\\) denote the full model, which contains all \\(p\\) predictors. For \\(k = p, p-1, \\dots, 1\\): Consider all \\(k\\) models that contain all but one of the predictors in \\(\\mathcal{M}_k\\) for a total of \\(k - 1\\) predictors. Choose the best among these \\(k\\) models, and call it \\(\\mathcal{M}_{k-1}\\). Here, best is defined as having smallest RSS or highest \\(R^2\\). Select a single best model from among \\(\\mathcal{M}_0, \\dots, \\mathcal{M}_p\\) using cross-validated prediction error \\(C_p\\) (AIC), BIC, or adjusted \\(R^2\\). Like forward stepwise selection, the backward selection approach searches through only \\(1+p(p+1)/2\\) models, and so can be applied in settings where \\(p\\) is too large to apply best subset selection. Also like forward stepwise selection, backward stepwise selection is not guaranteed to yield the best model containing a subset of the \\(p\\) predictors. Backward selection requires that the number of samples \\(n\\) is larger than the number of variables \\(p\\) (so that the full model can be fit). In contrast, forward stepwise can be used even when \\(n &lt; p\\), and so is the only viable subset method when \\(p\\) is very large. Hybrid Approaches The best subset, forward stepwise, and backward stepwise selection approaches generally give similar but not identical models. As another alternative, hybrid versions of forward and backward stepwise selection are available, in which variables are added to the model sequentially, in analogy to forward selection. However, after adding each new variable, the method may also remove any variables that no longer provide an improvement in the model fit. Such an approach attempts to more closely mimic best subset selection while retaining the computational advantages of forward and backward stepwise selection. 6.1.3 Choosing the Optimal Model To apply these subset selection methods, we need to determine which model is best. Since more predictors will always lead to smaller RSS and larger \\(R^2\\) (training error), we need to estimate the test error. There are two common approaches: We can indirectly estimate test error by making an adjustment to the training error to account for the bias due to overfitting. We can directly estimate the test error, using either a validation set approach or a cross-validation approach, as discussed in Chapter 5. \\(C_p\\), AIC, BIC, and Adjusted \\(R^2\\) These techniques involve adjusting the training error to select among a set a models with different numbers of variables. For a fitted least squares model containg \\(d\\) predictors, the \\(C_p\\) estimate of test MSE is computed as: \\[ C_p = \\frac{1}{n} (\\text{RSS} + 2d \\hat{\\sigma}^2), \\] where \\(\\hat{\\sigma}^2\\) is an estimate of the variance of the error \\(\\epsilon\\) associated with each response measurement. Typically, this is estimated using the full model containing all predictors. Essentially, the \\(C_p\\) statistic adds a penalty of \\(2d\\hat{\\sigma}^2\\) to the training RSS in order to adjust for the fact that the training error tends to underestimate the test error. Clearly, the penalty increases as the number of predictors in the model increases; this is intended to adjust for the corresponding decrease in training RSS. Though it is beyond the scope of this book, one can show that if \\(\\hat{\\sigma}^2\\) is an unbiased estimate of \\(\\sigma^2\\) in (6.2), then \\(C_p\\) is an unbiased estimate of test MSE. As a consequence, the \\(C_p\\) statistic tends to take on a small value for models with a low test error, so when determining which of a set of models is best, we choose the model with the lowest \\(C_p\\) value. Compute \\(\\hat{\\sigma}\\) and \\(C_p\\) for the best model at the different numbers of predictors: # Get the estimated variance of the error for calculating C_p sigma_hat &lt;- summary(balance_full)$sigma credit_model_best &lt;- credit_model_subsets %&gt;% group_by(n_preds_adj) %&gt;% filter(RSS == min(RSS)) %&gt;% ungroup() %&gt;% mutate( `C_p` = (1 / nrow(credit)) * (RSS + 2 * n_preds_adj * sigma_hat^2) ) The AIC criterion is defined for a large class of models fit by maximum likelihood. In the case of the model (6.1) with Gaussian errors, maximum likelihood and least squares are the same thing. In this case AIC is given by \\[ \\text{AIC} = \\frac{1}{n} (\\text{RSS} + 2 d \\hat{\\sigma}^2), \\] where, for simplicity, we have omitted irrelevant constants. Hence for least squares models, \\(C_p\\) and AIC are proportional to each other, and so only \\(C_p\\) is displayed in Figure 6.2. BIC is derived from a Bayesian point of view, and looks similar to the AIC/\\(C_p\\): \\[ \\text{BIC} = \\frac{1}{n} (\\text{RSS} + \\log (n) d \\hat{\\sigma}^2), \\] where irrelevant constants were excluded. Here, the factor of 2 in the AIC/\\(C_p\\) is replaced with \\(\\log (n)\\). Since \\(\\log n &gt; 2\\) for any \\(n &gt; 7\\), the BIC statistic generally penalizes models with many variables more heavily. credit_model_best &lt;- credit_model_best %&gt;% mutate( BIC = (1 / nrow(credit)) * (RSS + log(nrow(credit)) * n_preds_adj * sigma_hat^2) ) Recall that the usual \\(R^2\\) is defined as 1 - RSS/TSS, where TSS = \\(\\sum (y_i - \\bar{y})^2\\) is the total sum of squares for the response. The adjusted \\(R^2\\) statistic is calculated as \\[ \\text{Adjusted } R^2 = 1 - \\frac{\\text{RSS}/(n - d - 1)}{\\text{TSS}/(n - 1)} \\] Unlike \\(C_p\\), AIC, and BIC, for which a smaller value indicates a lower test error, a larger value of adjusted \\(R^2\\) indicates smaller test error. The intuition behind the adjusted \\(R^2\\) is that once all of the correct variables have been included in the model, adding additional noise variables will lead to only a very small decrease in RSS. Since adding noise variables leads to an increase in \\(d\\), such variables will lead to an increase in \\(\\text{RSS}/(nd1)\\), and consequently a decrease in the adjusted \\(R^2\\). Therefore, in theory, the model with the largest adjusted \\(R^2\\) will have only correct variables and no noise variables. Unlike the \\(R^2\\) statistic, the adjusted \\(R^2\\) statistic pays a price for the inclusion of unnecessary variables in the model. A models \\(R^2\\) value can be obtained directly from the lm object, so I dont need to manually compute it: credit_model_best &lt;- credit_model_best %&gt;% mutate( `Adjusted R2` = map_dbl(model_fit, ~ summary(.x)$adj.r.squared) ) Figure 6.2: credit_model_best %&gt;% pivot_longer(cols = c(&quot;C_p&quot;, &quot;BIC&quot;, &quot;Adjusted R2&quot;), names_to = &quot;metric&quot;, values_to = &quot;value&quot;) %&gt;% group_by(metric) %&gt;% mutate( best_model = ifelse(metric == &quot;Adjusted R2&quot;, value == max(value), value == min(value)) ) %&gt;% ungroup() %&gt;% mutate(metric = factor(metric, levels = c(&quot;C_p&quot;, &quot;BIC&quot;, &quot;Adjusted R2&quot;))) %&gt;% filter(n_preds_adj &gt;= 2) %&gt;% ggplot(aes(x = n_preds_adj, y = value)) + geom_point(color = td_colors$nice$spanish_blue) + geom_line(color = td_colors$nice$opera_mauve) + geom_point(data = . %&gt;% filter(best_model), size = 5, shape = 4, color = td_colors$nice$spanish_blue) + facet_wrap(~ metric, nrow = 1, scales = &quot;free_y&quot;) + scale_x_continuous(&quot;Number of predictors&quot;, breaks = seq(2, 10, 2)) \\(C_p\\), AIC, and BIC all have rigorous theoretical justifications that are beyond the scope of this book. These justifications rely on asymptotic arguments (scenarios where the sample size \\(n\\) is very large). Despite its popularity, and even though it is quite intuitive, the adjusted \\(R^2\\) is not as well motivated in statistical theory as AIC, BIC, and \\(C_p\\). All of these measures are simple to use and compute. Here we have presented their formulas in the case of a linear model fit using least squares; however, AIC and BIC can also be defined for more general types of models. Validation and Cross-validation Validation and cross-validation from Chapter 5 provide an advantage over AIC, BIC, \\(C_p\\) and adjusted \\(R^2\\), in that they provide a direct estimate of the test error, and make fewer assumptions about the true underlying model. It can also be used in a wider ranger of model selection tasks, including scenarios where the model degrees of freedom (e.g. the number of predictors) or error variance \\(\\sigma^2\\) are hard to estimate. To re-create Figure 6.3, Ill use the tidymodels approach with rsample to make the validation set and cross-validation splits: set.seed(499) tic() credit_model_best &lt;- credit_model_best %&gt;% mutate( validation_set_error = map( model_formula, function(model_formula) { workflow() %&gt;% add_model(linear_reg()) %&gt;% add_recipe(recipe(model_formula, credit)) %&gt;% fit_resamples(validation_split(credit, prop = 0.75)) %&gt;% collect_metrics() %&gt;% filter(.metric == &quot;rmse&quot;) %&gt;% select(`Validation set error` = mean, validation_std_err = std_err) } ), cross_validation_error = map( model_formula, function(model_formula) { workflow() %&gt;% add_model(linear_reg()) %&gt;% add_recipe(recipe(model_formula, credit)) %&gt;% fit_resamples(vfold_cv(credit, v = 10)) %&gt;% collect_metrics() %&gt;% filter(.metric == &quot;rmse&quot;) %&gt;% select(`Cross-validation error` = mean, cv_std_err = std_err) } ), `Square root of BIC` = sqrt(BIC) ) %&gt;% unnest(c(validation_set_error, cross_validation_error)) toc() ## 13.95 sec elapsed credit_model_best %&gt;% pivot_longer(cols = c(&quot;Validation set error&quot;, &quot;Cross-validation error&quot;, &quot;Square root of BIC&quot;), names_to = &quot;metric&quot;, values_to = &quot;value&quot;) %&gt;% group_by(metric) %&gt;% mutate(best_model = value == min(value)) %&gt;% ungroup() %&gt;% mutate( metric = factor(metric, levels = c(&quot;Square root of BIC&quot;, &quot;Validation set error&quot;, &quot;Cross-validation error&quot;)) ) %&gt;% ggplot(aes(x = n_preds_adj, y = value)) + geom_point(color = td_colors$nice$spanish_blue) + geom_line(color = td_colors$nice$opera_mauve) + geom_point(data = . %&gt;% filter(best_model), size = 5, shape = 4, color = td_colors$nice$spanish_blue) + facet_wrap(~ metric, nrow = 1, scales = &quot;free_y&quot;) + scale_x_continuous(&quot;Number of predictors&quot;, breaks = seq(2, 10, 2)) Because the randomness associated with splitting the data in the validation set and cross-validation approaches, we will likely find a different best model with different splits. In this case, we can select a model using the one-standard-error rule, where we calculate the standard error of the test MSE for each model, and then select the smallest model for which the estimated test error is within one standard error of the lowest test error. credit_model_best %&gt;% transmute( `# predictors` = n_preds_adj, `Cross-validation error`, cv_std_err, lowest_error = min(`Cross-validation error`), lowest_std_error = cv_std_err[`Cross-validation error` == lowest_error], # The best model is the minimum `n_preds_adj` (number of predictors) for # which the CV test error is within the standard error of the lowest error best_model = n_preds_adj == min(n_preds_adj[`Cross-validation error` &lt; lowest_error + lowest_std_error]) ) %&gt;% gt() %&gt;% tab_style(style = cell_text(weight = &quot;bold&quot;), locations = cells_body(rows = best_model)) html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #nzusayavvr .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #nzusayavvr .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #nzusayavvr .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #nzusayavvr .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #nzusayavvr .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #nzusayavvr .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #nzusayavvr .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #nzusayavvr .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #nzusayavvr .gt_column_spanner_outer:first-child { padding-left: 0; } #nzusayavvr .gt_column_spanner_outer:last-child { padding-right: 0; } #nzusayavvr .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #nzusayavvr .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #nzusayavvr .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #nzusayavvr .gt_from_md > :first-child { margin-top: 0; } #nzusayavvr .gt_from_md > :last-child { margin-bottom: 0; } #nzusayavvr .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #nzusayavvr .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #nzusayavvr .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #nzusayavvr .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #nzusayavvr .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #nzusayavvr .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #nzusayavvr .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #nzusayavvr .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #nzusayavvr .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #nzusayavvr .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #nzusayavvr .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #nzusayavvr .gt_sourcenote { font-size: 90%; padding: 4px; } #nzusayavvr .gt_left { text-align: left; } #nzusayavvr .gt_center { text-align: center; } #nzusayavvr .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #nzusayavvr .gt_font_normal { font-weight: normal; } #nzusayavvr .gt_font_bold { font-weight: bold; } #nzusayavvr .gt_font_italic { font-style: italic; } #nzusayavvr .gt_super { font-size: 65%; } #nzusayavvr .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } # predictors Cross-validation error cv_std_err lowest_error lowest_std_error best_model 1 230.43401 12.663270 98.69851 3.405358 FALSE 2 161.43387 8.886096 98.69851 3.405358 FALSE 3 103.70715 2.457797 98.69851 3.405358 FALSE 4 99.24797 4.544705 98.69851 3.405358 TRUE 5 99.34556 3.231063 98.69851 3.405358 FALSE 6 99.01851 4.147442 98.69851 3.405358 FALSE 7 98.69851 3.405358 98.69851 3.405358 FALSE 8 99.65805 2.937664 98.69851 3.405358 FALSE 9 99.63657 4.109147 98.69851 3.405358 FALSE 10 99.67476 3.288357 98.69851 3.405358 FALSE 11 99.95464 3.082506 98.69851 3.405358 FALSE The rationale here is that if a set of models appear to be more or less equally good, then we might as well choose the simplest modelthat is, the model with the smallest number of predictors. In this case, applying the one-standard-error rule to the validation set or cross-validation approach leads to selection of the three-variable model. Here, the four-variable model was selected, not the three-variable model like in the text, but I would chalk that up to the random sampling. 6.2 Shrinkage Methods As already discussed, subset selection has a lot of issues. A much better alternative is use a technique that contrains or regularizes or shrinks the coefficient estimates towards zero in a model fit with all \\(p\\) predictors. It turns out that shrinking the coefficient estimates can significantly reduce the variance. 6.2.1 Ridge Regression Recall from Chapter 3 that the least squares fitting procedure involves estimating \\(\\beta_0, \\beta_1, \\dots, \\beta_p\\) by minimizing the RSS: \\[ \\text{RSS} = \\sum_{i=1}^n \\left(y_i - \\hat{y}_i \\right)^2 = \\sum_{i=1}^n \\left(y_i - \\beta_0 - \\sum_{j=1}^p \\beta_j x_{ij} \\right)^2. \\] Ridge regression is very similar to least squares, except the quantity minimized is slightly different: \\[ \\sum_{i=1}^n \\left(y_i - \\beta_0 - \\sum_{j=1}^p \\beta_j x_{ij} \\right)^2 + \\lambda \\sum_{j=1}^p \\beta_j^2 = \\text{RSS} + \\lambda \\sum_{j=1}^p \\beta_j^2, \\] where \\(\\lambda \\geq 0\\) is a tuning parameter, to be determined separately. The second term above, called a shrinkage penalty is small when the coefficients are close to zero, and so has the effect of shrinking the estimates \\(\\beta_j\\) towards zero. The tuning parameter \\(\\lambda\\) serves to control the relative impact of these two terms on the regression coefficient estimates. When \\(\\lambda = 0\\), the penalty term has no effect, and ridge regression will produce the same least squares estimates. Unlike least squares, which generates only one set of coefficient estimates (the best fit), ridge regression will produce a different set of coefficient estimates \\(\\hat{\\beta}_{\\lambda}^R\\) for each value \\(\\lambda\\). Selecting a good value for \\(\\lambda\\) is critical. Note that the shrinkage penalty is not applied to the intercept \\(\\beta_0\\), which is simply a measure of the mean value of the response when all predictors are zero (\\(x_{i1} = x_{i2} = \\dots = 0\\)) An Application to the Credit Data In tidymodels, regularized least squares is done with the glmnet engine. (See this article for a list of models available in parnsip and this article for examples using glmnet.) Specify the model: ridge_spec &lt;- linear_reg(penalty = 0, mixture = 0) %&gt;% set_engine(&quot;glmnet&quot;) # The `parnship::translate()` function is a helpful way to &quot;decode&quot; a model spec ridge_spec %&gt;% translate() ## Linear Regression Model Specification (regression) ## ## Main Arguments: ## penalty = 0 ## mixture = 0 ## ## Computational engine: glmnet ## ## Model fit template: ## glmnet::glmnet(x = missing_arg(), y = missing_arg(), weights = missing_arg(), ## alpha = 0, family = &quot;gaussian&quot;) The penalty argument above refers to the \\(\\lambda\\) tuning parameter. The mixture variable ranges from 0 to 1, with 0 corresponding to ridge regression, 1 corresponding to lasso regression, and values between using a mixture of both. Fit Balance to all the predictors: credit_ridge_fit &lt;- fit(ridge_spec, Balance ~ ., data = credit) tidy(credit_ridge_fit) ## # A tibble: 12 x 3 ## term estimate penalty ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) -401. 0 ## 2 Income -5.18 0 ## 3 Limit 0.114 0 ## 4 Rating 1.66 0 ## 5 Cards 15.8 0 ## 6 Age -0.957 0 ## 7 Education -0.474 0 ## 8 OwnYes -4.86 0 ## 9 StudentYes 382. 0 ## 10 MarriedYes -12.1 0 ## 11 RegionSouth 9.11 0 ## 12 RegionWest 13.1 0 Because our ridge_spec had penalty = 0, the coefficients here correspond to no penalty, but the glmnet::glmnet() function fits a range of penalty values all at once, which we can extract with broom::tidy like so: tidy(credit_ridge_fit, penalty = 100) ## # A tibble: 12 x 3 ## term estimate penalty ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) -307. 100 ## 2 Income -3.04 100 ## 3 Limit 0.0951 100 ## 4 Rating 1.40 100 ## 5 Cards 16.4 100 ## 6 Age -1.10 100 ## 7 Education -0.178 100 ## 8 OwnYes -0.341 100 ## 9 StudentYes 335. 100 ## 10 MarriedYes -12.4 100 ## 11 RegionSouth 7.45 100 ## 12 RegionWest 8.79 100 To re-create Figure 6.4, Ill first re-fit the data on standardized data (continuous variables re-scaled to have mean of 0, standard deviation of 1): credit_recipe &lt;- recipe(Balance ~ ., data = credit) %&gt;% step_dummy(all_nominal_predictors()) %&gt;% step_normalize(all_predictors()) credit_ridge_workflow &lt;- workflow() %&gt;% add_recipe(credit_recipe) %&gt;% add_model(ridge_spec) credit_ridge_fit &lt;- fit(credit_ridge_workflow, data = credit) Then Ill compile coefficient estimates for a wide range of \\(\\lambda\\) values with purrr::map_dfr(): map_dfr(seq(-2, 5, 0.1), ~ tidy(credit_ridge_fit, penalty = 10^.x)) %&gt;% filter(term != &quot;(Intercept)&quot;) %&gt;% mutate( term_highlight = fct_other( term, keep = c(&quot;Income&quot;, &quot;Limit&quot;, &quot;Rating&quot;, &quot;Student_Yes&quot;) ) ) %&gt;% ggplot(aes(x = penalty, y = estimate)) + geom_line(aes(group = term, color = term_highlight), size = 1) + scale_x_log10(breaks = 10^c(-2, 0, 2, 4)) + geom_vline(xintercept = 40, lty = 2, size = 1) + labs(x = expression(lambda), y = &quot;Standardized coefficients&quot;, color = NULL) + scale_color_manual(values = c(td_colors$pastel6[1:4], &quot;grey80&quot;)) + theme(legend.position = c(0.8, 0.8)) From this figure, it is clear that the fitting procedure is truncated at a penalty values of \\(\\lambda\\) = 40 (the vertical line above). This has to do with the regularization path chosen by glmnet. We can see from the grid of values for \\(\\lambda\\) that the minimum value is 40: extract_fit_engine(credit_ridge_fit)$lambda ## [1] 396562.69957 361333.16232 329233.32005 299985.13930 273335.28632 ## [6] 249052.93283 226927.75669 206768.12023 188399.41030 171662.52594 ## [11] 156412.50026 142517.24483 129856.40559 118320.32042 107809.06926 ## [16] 98231.60868 89504.98330 81553.60727 74308.60957 67707.23750 ## [21] 61692.31313 56211.73806 51218.04218 46667.97247 42522.11842 ## [26] 38744.57062 35302.60975 32166.42320 29308.84681 26705.12964 ## [31] 24332.71953 22171.06779 20201.45123 18406.80998 16771.59971 ## [36] 15281.65702 13924.07673 12687.10013 11560.01312 10533.05342 ## [41] 9597.32598 8744.72599 7967.86864 7260.02515 6615.06452 ## [46] 6027.40042 5491.94278 5004.05372 4559.50738 4154.45331 ## [51] 3785.38313 3449.10012 3142.69158 2863.50352 2609.11776 ## [56] 2377.33093 2166.13540 1973.70190 1798.36366 1638.60199 ## [61] 1493.03311 1360.39616 1239.54232 1129.42479 1029.08981 ## [66] 937.66830 854.36844 778.46870 709.31169 646.29839 ## [71] 588.88302 536.56828 488.90103 445.46841 405.89423 ## [76] 369.83570 336.98052 307.04410 279.76714 254.91340 ## [81] 232.26760 211.63359 192.83264 175.70192 160.09305 ## [86] 145.87082 132.91206 121.10452 110.34593 100.54310 ## [91] 91.61113 83.47265 76.05717 69.30046 63.14400 ## [96] 57.53446 52.42326 47.76612 43.52271 39.65627 The regularization path can be set manually using the path_values argument (see this article for more details): coef_path_values &lt;- 10^seq(-2, 5, 0.1) ridge_spec_path &lt;- linear_reg(penalty = 0, mixture = 0) %&gt;% set_engine(&quot;glmnet&quot;, path_values = coef_path_values) credit_ridge_workflow_path &lt;- workflow() %&gt;% add_recipe(credit_recipe) %&gt;% add_model(ridge_spec_path) credit_ridge_fit &lt;- fit(credit_ridge_workflow_path, data = credit) Now with the full range of \\(\\lambda\\) values, I can re-create the figure properly: # Compute the l2 norm for the least squares model credit_lm_fit &lt;- lm(Balance ~ ., data = credit) credit_lm_fit_l2_norm &lt;- sum(credit_lm_fit$coefficients[-1]^2) d &lt;- map_dfr(seq(-2, 5, 0.1), ~ tidy(credit_ridge_fit, penalty = 10^.x)) %&gt;% filter(term != &quot;(Intercept)&quot;) %&gt;% group_by(penalty) %&gt;% mutate(l2_norm = sum(estimate^2), l2_norm_ratio = l2_norm / credit_lm_fit_l2_norm) %&gt;% ungroup() %&gt;% mutate( term_highlight = fct_other( term, keep = c(&quot;Income&quot;, &quot;Limit&quot;, &quot;Rating&quot;, &quot;Student_Yes&quot;) ) ) p1 &lt;- d %&gt;% ggplot(aes(x = penalty, y = estimate)) + geom_line(aes(group = term, color = term_highlight), size = 1) + scale_x_log10(breaks = 10^c(-2, 0, 2, 4)) + labs(x = expression(lambda), y = &quot;Standardized coefficients&quot;, color = NULL) + scale_color_manual(values = c(td_colors$pastel6[1:4], &quot;grey80&quot;)) + theme(legend.position = c(0.7, 0.8)) p2 &lt;- d %&gt;% ggplot(aes(x = l2_norm_ratio, y = estimate)) + geom_line(aes(group = term, color = term_highlight), size = 1) + labs( x = expression(paste(&quot;||&quot;, hat(beta[lambda]), &quot;||2 / ||&quot;, hat(beta), &quot;||2&quot;)), y = NULL, color = NULL ) + scale_color_manual(values = c(td_colors$pastel6[1:4], &quot;grey80&quot;)) + theme(legend.position = &quot;none&quot;) p1 | p2 On the subject of standardizing predictors: The standard least squares coefficient estimates discussed in Chapter 3 are scale equivariant: multiplying \\(X_j\\) by a constant \\(c\\) simply leads to a scaling of the least squares coefficient estimates by a factor of \\(1/c\\). In other words, regardless of how the \\(j\\)th predictor is scaled, \\(X_j \\hat{\\beta}_j\\) will remain the same. In contrast, the ridge regression coefficient estimates can change substantially when multiplying a given predictor by a constant. For instance, consider the income variable, which is measured in dollars. One could reasonably have measured income in thousands of dollars, which would result in a reduction in the observed values of income by a factor of 1,000. Now due to the sum of squared coefficients term in the ridge regression formulation (6.5), such a change in scale will not simply cause the ridge regression coefficient estimate for income to change by a factor of 1,000. In other words, \\(X_j \\hat{\\beta}^R_{j,}\\) will depend not only on the value of \\(\\lambda\\), but also on the scaling of the \\(j\\)th predictor. In fact, the value of \\(X_j \\hat{\\beta}^R_{j, \\lambda}\\) may even depend on the scaling of the other predictors! Therefore, it is best to apply ridge regression after standardizing the predictors,  so that they are all on the same scale. Why Does Ridge Regression Improve Over Least Squares? Ridge regressions advantage over least squares has to do with the bias-variance trade-off. As \\(\\lambda\\) increases, the flexibility of the fit decreases, leading to decreased variance but increased bias. So ridge regression works best in situations where the least squares estimates have high variance, like when the number of variables \\(p\\) is almost as large as the number of observations \\(n\\) (as in Figure 6.5). Ridge regression also has substantial computational advantages over best subset selection, which requires searching through \\(2p\\) models. As we discussed previously, even for moderate values of \\(p\\), such a search can be computationally infeasible. In contrast, for any fixed value of \\(\\lambda\\), ridge regression only fits a single model, and the model-fitting procedure can be performed quite quickly. In fact, one can show that the computations required to solve (6.5), simultaneously for all values of \\(\\lambda\\), are almost identical to those for fitting a model using least squares. 6.2.2 The Lasso Ridge regression will shrink all coefficients towards zero, but will not set them to exactly zero (unless \\(\\lambda = \\infty\\)). This doesnt affect prediction accuracy, but may cause challenges in model interpretation for large numbers of variables \\(p\\). The lasso is a relatively recent alternative to ridge regression with a similar formulation as ridge regression. The coefficients \\(\\hat{\\beta}_{\\lambda}^L\\) minimize the quantity: \\[ \\sum_{i=1}^n \\left(y_i - \\beta_0 - \\sum_{j=1}^p \\beta_j x_{ij} \\right)^2 + \\lambda \\sum_{j=1}^p | \\beta_j | = \\text{RSS} + \\lambda \\sum_{j=1}^p | \\beta_j |. \\] The only difference is that the \\(\\beta_j^2\\) term in the ridge regression penalty (6.5) has been replaced by \\(|\\beta_j|\\) in the lasso penalty (6.7). In statistical parlance, the lasso uses an \\(\\mathcal{l}_1\\) (pronounced ell 1) penalty instead of an \\(\\mathcal{l}_2\\) penalty. The \\(\\mathcal{l}_1\\) norm of a coefficient vector \\(\\beta\\) is given by \\(||\\beta||_1 = \\sum |\\beta_j|\\). The \\(\\mathcal{l}_1\\) penalty has the effect of forcing some of the coefficient estimates to be exactly equal to zero for sufficiently large \\(\\lambda\\). Functionally, this is a form of automatic variable selection like the best subset techniques. We say that the lasso yields sparse models which only involve a subset of the variables. This makes lasso models much easier to interpret than those produced by ridge regression. Fit the credit model with lasso regression: credit_recipe &lt;- recipe(Balance ~ ., data = credit) %&gt;% step_dummy(all_nominal_predictors()) %&gt;% step_normalize(all_predictors()) lasso_spec &lt;- linear_reg(penalty = 20, mixture = 1) %&gt;% set_engine(&quot;glmnet&quot;) credit_lasso_workflow &lt;- workflow() %&gt;% add_recipe(credit_recipe) %&gt;% add_model(lasso_spec) credit_lasso_fit &lt;- fit(credit_lasso_workflow, data = credit) # Compute the l1 norm for the least squares model credit_lm_fit_l1_norm &lt;- sum(abs(credit_lm_fit$coefficients[-1])) d &lt;- map_dfr(seq(-1, 3, 0.1), ~ tidy(credit_lasso_fit, penalty = 10^.x)) %&gt;% filter(term != &quot;(Intercept)&quot;) %&gt;% group_by(penalty) %&gt;% mutate(l1_norm = sum(abs(estimate)), l1_norm_ratio = l1_norm / credit_lm_fit_l1_norm) %&gt;% ungroup() %&gt;% mutate( term_highlight = fct_other( term, keep = c(&quot;Income&quot;, &quot;Limit&quot;, &quot;Rating&quot;, &quot;Student_Yes&quot;) ) ) p1 &lt;- d %&gt;% ggplot(aes(x = penalty, y = estimate)) + geom_line(aes(group = term, color = term_highlight), size = 1) + scale_x_log10() + labs(x = expression(lambda), y = &quot;Standardized coefficients&quot;, color = NULL) + scale_color_manual(values = c(td_colors$pastel6[1:4], &quot;grey80&quot;)) + theme(legend.position = c(0.7, 0.2)) p2 &lt;- d %&gt;% ggplot(aes(x = l1_norm_ratio, y = estimate)) + geom_line(aes(group = term, color = term_highlight), size = 1) + labs( x = expression(paste(&quot;||&quot;, hat(beta[lambda]), &quot;||1 / ||&quot;, hat(beta), &quot;||1&quot;)), y = NULL, color = NULL ) + scale_color_manual(values = c(td_colors$pastel6[1:4], &quot;grey80&quot;)) + theme(legend.position = &quot;none&quot;) p1 | p2 The shapes of the curves are right, but the scale of the \\(\\lambda\\) parameter in the left panel and the ratio in the right panel are much different from the text  not sure what happened there. Another Formulation for Ridge Regression and the Lasso One can show that the lasso and ridge regression coefficient estimates solve the problems: \\[ \\begin{align} &amp;\\text{minimize } \\beta \\left[ \\sum_{i=1}^n \\left(y_i - \\beta_0 - \\sum_{j=1}^p \\beta_j x_{ij} \\right)^2 \\right] \\text{ subject to } \\sum_{j=1}^p |\\beta_j| \\leq s \\\\ &amp;\\text{minimize } \\beta \\left[ \\sum_{i=1}^n \\left(y_i - \\beta_0 - \\sum_{j=1}^p \\beta_j x_{ij} \\right)^2 \\right] \\text{ subject to } \\sum_{j=1}^p \\beta_j^2 \\leq s, \\end{align} \\] respectively. In other words, for every value of \\(\\lambda\\), there is some \\(s\\) associated with the lasso/ridge coefficient estimates. For \\(p = 2\\), then the lasso coefficient estimates have the smallest RSS out of all points that lie within the diamond defined by \\(|\\beta_1| + |\\beta_2| \\leq s\\); likewise, the circle \\(\\beta_1^2 + \\beta_2^2 \\leq s\\) for ridge regression. This formulation with \\(s\\) can be though of in terms of a budget of coefficient size: When we perform the lasso we are trying to find the set of coefficient estimates that lead to the smallest RSS, subject to the constraint that there is a budget \\(s\\) for how large \\(\\sum_{j=1}^p |\\beta_j|\\) can be. When \\(s\\) is extremely large, then this budget is not very restrictive, and so the coefficient estimates can be large. In fact, if \\(s\\) is large enough that the least squares solution falls within the budget, then (6.8) will simply yield the least squares solution. In contrast, if \\(s\\) is small, then \\(\\sum_{j=1}^p |\\beta_j|\\) must be small in order to avoid violating the budget. Similarly, (6.9) indicates that when we perform ridge regression, we seek a set of coefficient estimates such that the RSS is as small as possible, subject to the requirement that \\(\\sum^p_{j=1} \\beta_j^2\\) does not exceed the budget \\(s\\). This formulation also allows us to see the close connection between lasso, ridge and best subset selection. Best subset selection is the minimization problem: \\[ \\text{minimize } \\beta \\left[ \\sum_{i=1}^n \\left(y_i - \\beta_0 - \\sum_{j=1}^p \\beta_j x_{ij} \\right)^2 \\right] \\text{ subject to } \\sum_{j=1}^p I(\\beta_j \\neq 0) \\leq s. \\] The Variable Selection Property of the Lasso To understand why the lasso can remove predictors by shrinking coefficients to exactly zero, we can think of the shapes of the constraint functions, and the contours of RSS around the least squares estimate (see Figure 6.7 in the book for a visualization). For \\(p = 2\\), this is a circle (\\(\\beta_1^2 + \\beta_2^2 \\leq s\\)) for ridge, and square (\\(|\\beta_1| + |\\beta_2| \\leq s\\)) for lasso regression. Each of the ellipses centered around \\(\\hat{\\beta}\\) represents a contour: this means that all of the points on a particular ellipse have the same RSS value. As the ellipses expand away from the least squares coefficient estimates, the RSS increases. Equations (6.8) and (6.9) indicate that the lasso and ridge regression coefficient estimates are given by the first point at which an ellipse contacts the constraint region. Since ridge regression has a circular constraint with no sharp points, this intersection will not generally occur on an axis, and so the ridge regression coefficient estimates will be exclusively non-zero. However, the lasso constraint has corners at each of the axes, and so the ellipse will often intersect the constraint region at an axis. When this occurs, one of the coefficients will equal zero. In higher dimensions, many of the coefficient estimates may equal zero simultaneously. In Figure 6.7, the intersection occurs at \\(\\beta_1 = 0\\), and so the resulting model will only include \\(\\beta_2\\). This key idea holds for large dimension \\(p &gt; 2\\)  the lasso constraint will always have sharp corners, and the ridge constraint will not. Comparing the Lasso and Ridge Regression Generally, the lasso leads to qualitatively similar behavior to ridge regression, in that a larger \\(\\lambda\\) increases bias and decreases variance. A helpful way to compare models with different types of regularization is to plot \\(R^2\\) as in Figure 6.8 comparing lasso and ridge MSE. In this example, the results are almost identical, with a slight edge to the ridge regression due to lower variance. This advantage is due to the fact that the simulated data consisted of 45 predictors, that were all related to the response  that is, none of the true coefficients equaled zero. Lasso implicitly assumes that a number of the coefficients are truly zero, so it is not surprising it performs slightly worse on this example. By contrast, the example in Figure 6.9 was simulated so that only 2 out of 45 predictors were related to the response. In this case, the lasso tends to outperform ridge regression in terms of bias, variance and MSE. These two examples illustrate that neither ridge regression nor the lasso will universally dominate the other. In general, one might expect the lasso to perform better in a setting where a relatively small number of predictors have substantial coefficients, and the remaining predictors have coefficients that are very small or that equal zero. Ridge regression will perform better when the response is a function of many predictors, all with coefficients of roughly equal size. However, the number of predictors that is related to the response is never known a priori for real data sets. A technique such as cross-validation can be used in order to determine which approach is better on a particular data set. As with ridge regression, when the least squares estimates have excessively high variance, the lasso solution can yield a reduction in variance at the expense of a small increase in bias, and consequently can gener- ate more accurate predictions. Unlike ridge regression, the lasso performs variable selection, and hence results in models that are easier to interpret. There are very efficient algorithms for fitting both ridge and lasso models; in both cases the entire coefficient paths can be computed with about the same amount of work as a single least squares fit. A Simple Special Case for Ridge Regression and the Lasso Consider a simple case with \\(n = p\\) and a diagonal matrix \\(\\bf{X}\\) with 1s on the diagonal and 0s in all off-diagonal elements. To simplify further, assume that we are performing regression without an intercept. Then the usual least squares problem involves minimizing: \\[ \\sum_{j=1}^p (y_j - \\beta_j)^2. \\] Which has the solution \\(\\hat{\\beta}_j = y_j\\). In ridge and lasso regression, the following are minimized: \\[ \\begin{align} &amp;\\sum_{j=1}^p (y_j - \\beta_j)^2 + \\lambda \\sum_{j=1}^p \\beta_j^2 \\\\ &amp;\\sum_{j=1}^p (y_j - \\beta_j)^2 + \\lambda \\sum_{j=1}^p |\\beta_j|. \\end{align} \\] One can show that the ridge regression estimates take the form \\[ \\hat{\\beta}_j^R = y_j / (1 + \\lambda) \\] and the lasso estimates take the form \\[ \\hat{\\beta}_j^L = \\left\\{\\begin{array}{lr} y_j - \\lambda / 2, &amp;\\text{if } y_j &gt; \\lambda / 2 \\\\ y_j + \\lambda / 2, &amp;\\text{if } y_j &lt; - \\lambda / 2 \\\\ 0, &amp;\\text{if } |y_j| \\leq \\lambda / 2 \\end{array}\\right. \\] The coefficient estimates are shown in Figure 6.10. The ridge regression estimates are all shrunken towards zero by the same proportion, while the lasso shrinks each coefficient by the same amount and values less than \\(\\lambda / 2\\) are shrunken to exactly zero. This latter type of shrinkage is known as soft-thresholding, and is how lasso performs feature selection. ridge regression more or less shrinks every dimension of the data by the same proportion, whereas the lasso more or less shrinks all coefficients toward zero by a similar amount, and sufficiently small coefficients are shrunken all the way to zero. Bayesian Interpretation for Ridge Regression and the Lasso A Bayesian viewpoint for regression assumes that the vector of coefficients \\(\\beta\\) has some prior distribution \\(p(\\beta)\\), where \\(\\beta = (\\beta_0, \\dots , \\beta_p)^T\\). The likelihood of the data is then \\(f(Y|X,\\beta)\\). Multiplying the prior by the likelihood gives us (up to a proportionality constant) the posterior distribution from Bayes theorem: \\[ p (\\beta|X, Y) \\propto f(Y|X,\\beta) p(\\beta|X) = f(Y|X,\\beta) p(\\beta). \\] If we assume the usual linear model \\(Y = \\beta_0 + X_1 \\beta_1 + \\dots X_p \\beta_p + \\epsilon\\), the errors are independent and drawn from a normal distribution, that \\(p(\\beta) = \\Pi_{j=1}^p g(\\beta_j)\\) for some density function \\(g\\). It turns out that ridge and lasso follow naturally from two special cases of \\(g\\): If \\(g\\) is a Gaussian distribution with mean zero and standard deviation a function of \\(\\lambda\\), then it follow that the posterior mode for \\(\\beta\\)  that is, the most likely value for \\(\\beta\\), given the data  is given by the ridge regression solution. (In fact, the ridge regression solution is also the posterior mean.) If \\(g\\) is a double-exponential (Laplace) distribution with mean zero and scale parameter a function of \\(\\lambda\\), then it follow that the posterior mode for \\(\\beta\\) is the lasso solution. (However, the lasso solution is not the posterior mean, and in fact, the posterior mean does not yield a spare coefficient vector). The Gaussian and double-exponential priors are displayed in Figure 6.11. Therefore, from a Bayesian viewpoint, ridge regression and the lasso follow directly from assuming the usual linear model with normal errors, together with a simple prior distribution for \\(\\). Notice that the lasso prior is steeply peaked at zero, while the Gaussian is flatter and fatter at zero. Hence, the lasso expects a priori that many of the coefficients are (exactly) zero, while ridge assumes the coefficients are randomly distributed about zero. 6.2.3 Selecting the Tuning Parameter Just like subset selection requires a method to determine which models are best, these regularization methods require a method for selecting a value for the tuning parameter \\(\\lambda\\) (or constraint \\(s\\)). Cross-validation is the simple way to tackle this. We choose a grid of \\(\\lambda\\) values, and compute CV error for each value of \\(\\lambda\\), and select the value for which error is smallest. The model is then re-fit using all available observations with the selected tuning parameter \\(\\lambda\\). As explained previously, the tidydmodels framework does not allow fitting by LOOCV. credit_splits &lt;- vfold_cv(credit, v = 10) Then the recipe (nothing new here): credit_ridge_recipe &lt;- recipe(Balance ~ ., data = credit) %&gt;% step_dummy(all_nominal_predictors()) %&gt;% step_normalize(all_predictors()) In the model specification, I set mixture = 0 for ridge regression, and set penalty = tune() to indicate it as a tunable parameter: ridge_spec &lt;- linear_reg(mixture = 0, penalty = tune()) %&gt;% set_engine(&quot;glmnet&quot;) Combine into a workflow: credit_ridge_workflow &lt;- workflow() %&gt;% add_recipe(credit_ridge_recipe) %&gt;% add_model(ridge_spec) credit_ridge_workflow ## == Workflow ==================================================================== ## Preprocessor: Recipe ## Model: linear_reg() ## ## -- Preprocessor ---------------------------------------------------------------- ## 2 Recipe Steps ## ## * step_dummy() ## * step_normalize() ## ## -- Model ----------------------------------------------------------------------- ## Linear Regression Model Specification (regression) ## ## Main Arguments: ## penalty = tune() ## mixture = 0 ## ## Computational engine: glmnet Lastly, because we are tuning penalty (\\(\\lambda\\)), we need to define a grid of values to try when fitting the model. The dials package provides many tools for tuning in tidymodels. grid_regular() creates a grid of evenly spaced points. As the first argument, I provide a penalty() with argument range that takes minimum and maximum values on a log scale: penalty_grid &lt;- grid_regular(penalty(range = c(-2, 4)), levels = 10) penalty_grid ## # A tibble: 10 x 1 ## penalty ## &lt;dbl&gt; ## 1 0.01 ## 2 0.0464 ## 3 0.215 ## 4 1 ## 5 4.64 ## 6 21.5 ## 7 100 ## 8 464. ## 9 2154. ## 10 10000 To fit the models using this grid of values, we use tune_grid(): tic() credit_ridge_tune &lt;- tune_grid( credit_ridge_workflow, resamples = credit_splits, grid = penalty_grid ) toc() ## 2.09 sec elapsed credit_ridge_tune %&gt;% autoplot() 6.3 Dimension Reduction Methods The methods that we have discussed so far in this chapter have controlled variance in two different ways, either by using a subset of the original variables, or by shrinking their coefficients toward zero. All of these methods are defined using the original predictors, \\(X_1, X_2, \\dots , X_p\\). We now explore a class of approaches that transform the predictors and then fit a least squares model using the transformed variables. We will refer to these techniques as dimension reduction methods. We represent our original \\(p\\) predictors \\(X_j\\) as \\(M\\) (\\(&lt; p\\)) linear combinations: \\[ Z_m = \\sum_{j=1}^p \\phi_{jm} X_j \\] for some constants \\(\\phi_{1m}, \\phi_{2m}, \\dots \\phi_{pm}\\) , \\(m = 1, \\dots, M\\). We can then fit a linear regression model: \\[ y_i = \\theta_0 + \\sum_{m=1}^M \\theta_m z_{im} + \\epsilon_i, \\ \\ \\ \\ i = 1, \\dots, n, \\] using least squares. Note that the regression coefficients here are represented by \\(\\theta_0, \\theta_1, \\dots, \\theta_M\\). If the constants \\(\\phi_{1m}, \\phi_{2m}, \\dots , \\phi_{pm}\\) are chosen wisely, then such dimension reduction approaches can often outperform least squares regression. This method is called dimension reduction because it involves reducing the \\(p+1\\) coefficients \\(\\beta_0, \\dots, \\beta_p\\) down to \\(M + 1\\) coefficients \\(\\theta_0, \\dots, \\theta_M\\) (\\(M &lt; p\\)). Notice that the models are numerically equivalent: \\[ \\sum_{m=1}^M \\theta_m z_{im} = \\sum_{m=1}^M \\theta_m \\sum_{j=1}^p \\phi_{jm} x_{ij} = \\sum_{j=1}^p \\sum_{m=1}^M \\theta_m \\phi_{jm} x_{ij} = \\sum_{j=1}^p \\beta_j x_{ij}, \\] where \\[ \\beta_j = \\sum_{m=1}^M \\theta_m \\phi_{jm}. \\] Hence, this can be thought of as a special case of the original linear regression model. Dimension reduction serves to constrain the estimated \\(\\beta_j\\) coefficients to the above form, which has the potential to bias the estimates. However, in situations where \\(p\\) is large relative to \\(n\\), selecting a value of \\(M \\ll p\\) can significantly reduce the variance of the fitted coefficients. All dimension reduction methods work in two steps. First, the transformed predictors \\(Z_1, Z_2, \\dots Z_M\\) are obtained. Second, the model is fit using these \\(M\\) predictors. However, the choice of \\(Z_1, Z_2, \\dots Z_M\\), or equivalently, the selection of the \\(\\phi_{jm}\\)s, can be achieved in different ways. In this chapter, we will consider two approaches for this task: principal components and partial least squares. 6.3.1 Principal Components Regression An Overview of Principal Components Analysis Principal components analysis (PCA) is a technique for reducing the dimension of an \\(n \\times p\\) data matrix \\(\\textbf{X}\\). The first principal component direction of the data is that along which the observations vary the most. If the observations were to be projected onto the line defined by this principal component, then the resulting projected observations would have the largest possible variance. Alternatively: the first principal component defines the line that is as close as possible to the data. The principal component can be summarized mathematically as a linear combination of the variables, \\(Z_1\\). The second principal component \\(Z_2\\) is a linear combination of the variables that is uncorrelated with \\(Z_1\\), and has the largest variance subject to this constraint. Visually, the direction of this line must be perpendicular or orthogonal to the first principal component. Up to \\(p\\) distinct principal components can be constructed, but the first component will contain the most information. Each component successively maximizes variance, subject to the constraint of being uncorrelated with the previous components. The Principal Components Regression Approach The principal components regression (PCR) approach involves constructing the first \\(M\\) principal components, \\(Z_1, \\dots, Z_M\\), and then using these components as the predictors in a linear regression model that is fit using least squares. The key idea is that often a small number of principal components suffice to explain most of the variability in the data, as well as the relationship with the response. In other words, we assume that the directions in which \\(X_1, \\dots, X_p\\) show the most variation are the directions that are associated with \\(Y\\). While this assumption is not guaranteed to be true, it often turns out to be a reasonable enough approximation to give good results. If the assumption underlying PCR holds, then fitting a least squares model to \\(Z_1,\\dots, Z_M\\) will lead to better results than fitting a least squares model to \\(X_1,\\dots,X_p\\), since most or all of the information in the data that relates to the response is contained in \\(Z_1,\\dots,Z_M\\), and by estimating only \\(M  p\\) coefficients we can mitigate overfitting It is important to note that, although PCR offers a simple way to perform regression using a smaller number of predictors (\\(M &lt; p\\)), it is not a feature selection method. The \\(M\\) principal components used in the regression is a linear combination of all \\(p\\) of the original features. In this sense, PCR is more closely related to ridge regression than the lasso (because the lasso shrinks coefficients to exactly zero, essentially removing them). In fact, ridge regression can be considered a continuous version of PCR. In tidymodels, principal components are extracted in pre-processing via recipes::step_pca(). Here is the workflow applied to the credit data set with a linear model: lm_spec &lt;- linear_reg() %&gt;% set_engine(&quot;lm&quot;) credit_splits &lt;- vfold_cv(credit, v = 10) credit_pca_recipe &lt;- recipe(Balance ~ ., data = credit) %&gt;% step_dummy(all_nominal_predictors()) %&gt;% step_normalize(all_predictors()) %&gt;% step_pca(all_predictors(), num_comp = tune()) credit_pca_workflow &lt;- workflow() %&gt;% add_recipe(credit_pca_recipe) %&gt;% add_model(lm_spec) The num_comp = tune() argument to step_pca() allows variation in the number of principal components \\(M\\). To tune_grid(), I only need to provide a data frame of possible num_comp values, but here is the dials::grid_regular() approach to doing that: pca_grid &lt;- grid_regular(num_comp(range = c(1, 11)), levels = 11) pca_grid ## # A tibble: 11 x 1 ## num_comp ## &lt;int&gt; ## 1 1 ## 2 2 ## 3 3 ## 4 4 ## 5 5 ## 6 6 ## 7 7 ## 8 8 ## 9 9 ## 10 10 ## 11 11 Perform 10 fold cross-validation for PCR with 1 to 11 components: credit_pca_tune &lt;- tune_grid( credit_pca_workflow, resamples = credit_splits, grid = pca_grid, # This option extracts the model fits, which are otherwise discarded control = control_grid(extract = function(m) extract_fit_engine(m)) ) And re-create the right panel of Figure 6.20: credit_pca_tune %&gt;% collect_metrics() %&gt;% filter(.metric == &quot;rmse&quot;) %&gt;% mutate(mse = mean^2) %&gt;% ggplot(aes(x = num_comp, y = mse)) + geom_line(color = td_colors$nice$spanish_blue, size = 1) + geom_point(shape = 21, size = 3, fill = td_colors$nice$spanish_blue, color = &quot;white&quot;) + scale_y_continuous(&quot;Cross-validation MSE&quot;, breaks = c(20000, 40000, 60000, 80000)) + scale_x_continuous(&quot;Number of components&quot;, breaks = c(2, 4, 6, 8, 10)) By MSE, the best performing models are \\(M\\) = 10 and 11 principal components, which mean that dimension reduction is not needed here because \\(p = 11\\). Note the step_normalize() function in the recipe used here. This is important when performing PCR: We generally recommend standardizing each predictor, using (6.6), prior to generating the principal components. This standardization ensures that all variables are on the same scale. In the absence of standardization, the high-variance variables will tend to play a larger role in the principal components obtained, and the scale on which the variables are measured will ultimately have an effect on the final PCR model. However, if the variables are all measured in the same units (say, kilograms, or inches), then one might choose not to standardize them. 6.3.2 Partial Least Squares The PCR approach that we just described involves identifying linear combinations, or directions, that best represent the predictors \\(X1,\\dots,X_p\\). These directions are identified in an unsupervised way, since the response \\(Y\\) is not used to help determine the principal component directions. That is, the response does not supervise the identification of the principal components. Consequently, PCR suffers from a drawback: there is no guarantee that the directions that best explain the predictors will also be the best directions to use for predicting the response. Unsupervised methods are discussed further in Chapter 12. Like PCR, partial least squares (PLS) is a dimension reduction method which identifies a set of features \\(Z_1, \\dots, Z_M\\) that are linear combinations of the \\(p\\) original predictors. Unlike PCR, PLS identifies the new features which are related to the response \\(Y\\). In this way, PLS is a supervised alternative to PCR. Roughly speaking, the PLS approach attempts to find directions that help explain both the response and the predictors. After standardizing the \\(p\\) predictors, the first PLS direction \\(Z_1 = \\sum_{j=1}^p \\phi_{j1} X_j\\) is found from the simple linear regression of \\(Y\\) onto \\(X_j\\). This means that PLS places the highest weight on the variables that are most strongly related to the response. For the second PLS direction, each of the variables is adjusted by regression on \\(Z_1\\) and taking residuals. These residuals can be interpreted as the remanining information that has not been explained by the first PLS direction. \\(Z_2\\) is then computed using this orthogonalized data in the same way as \\(Z_1\\) was computed on the original data. This iterative approach is repeated \\(M\\) times, and the final step is to fit the linear model to predict \\(Y\\) using \\(Z_1, \\dots, Z_M\\) in exactly the same way as for PCR. As with PCR, the number \\(M\\) of partial least squares directions used in PLS is a tuning parameter that is typically chosen by cross-validation. We generally standardize the predictors and response before performing PLS. In practice, PLS often performs no better than ridge regression or PCR. It can often reduce bias, but it also has the potential to increase variance, so it evens out relative to other methods. 6.4 Considerations in High Dimensions 6.4.1 High-Dimensional Data Most traditional statistical techniques for regression and classification are intended for the low-dimensional setting in which \\(n\\), the number of observations, is much greater than \\(p\\), the number of features. This is due in part to the fact that throughout most of the fields history, the bulk of scientific problems requiring the use of statistics have been low-dimensional. To be clear, by dimension, we are referring to the size of \\(p\\). In the past 20 years, new technologies have changed the way that data are collected in fields as diverse as finance, marketing, and medicine. It is now commonplace to collect an almost unlimited number of feature measurements (\\(p\\) very large). While \\(p\\) can be extremely large, the number of observations \\(n\\) is often limited due to cost, sample availability, or other considerations. These high-dimensional problems, in which the number of features \\(p\\) is larger than observations \\(n\\), are becoming more commonplace. 6.4.2 What Goes Wrong in High Dimensions? To illustrate the \\(p &gt; n\\) issue, we examine least squares regression (but the same concepts apply to logistic regression, linear discriminant analysis and others). Least squares cannot be (or rather should not) be performed in this setting because it will yield coefficient estimates that perfectly fit the data, such that the residuals are zero. tibble(n_obs = c(2, 20)) %&gt;% mutate(x = map(n_obs, rnorm)) %&gt;% unnest(x) %&gt;% mutate(y = 5 * x + rnorm(n(), 0, 3)) %&gt;% ggplot(aes(x, y)) + geom_point(color = &quot;red&quot;, size = 3) + geom_smooth(method = &quot;lm&quot;, formula = &quot;y ~ x&quot;, color = &quot;black&quot;) + facet_wrap(~ fct_rev(paste0(&quot;n = &quot;, as.character(n_obs)))) + add_facet_borders() ## Warning in qt((1 - level)/2, df): NaNs produced ## Warning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning ## -Inf Note the warning returned by geom_smooth (NaNs and Infs produced) and the lack of errors around the best fit line in the right panel. On the other hand, when there are only two observations, then regardless of the values of those observations, the regression line will fit the data exactly. This is problematic because this perfect fit will almost certainly lead to overfitting of the data. In other words, though it is possible to perfectly fit the training data in the high-dimensional setting, the resulting linear model will perform extremely poorly on an independent test set, and therefore does not constitute a useful model. In fact, we can see that this happened in Figure 6.22: the least squares line obtained in the right-hand panel will perform very poorly on a test set comprised of the observations in the lefth-and panel. The problem is simple: when \\(p&gt;n\\) or \\(p \\approx n\\), a simple least squares regression line is too flexible and hence overfits the data. Previously we saw a number of approaches for adjusting the training set error to account for the number of variables used to fit a least squares model. Unfortunately, the \\(C_p\\), AIC, and BIC approaches are not appropriate in this setting, because estimating \\(\\hat{\\sigma}^2\\) is problematic). Similarly, a model can easily obtain an adjusted \\(R^2\\) value of 1. Clearly, alternative approaches that are better-suited to the high-dimensional setting are required. 6.4.3 Regression in High Dimensions The methods learned in this chapter  stepwise selection, ridge and lasso regression, and principal components regression  are useful for performing regression in the high-dimensional setting because they are less flexible fitting procedures. The lasso example in Figure 6.24 highlights three important points: regularlization or shrinkage plays a key role in high-dimensional problems, appropriate tuning parameter selection is crucial for good predictive performance, and the test error tends to increase as the dimensionality of the problem (i.e. the number of feature or predictors) increases, unless those additional features are truly associated with the response. The third point is known as the curve of dimensionality. In general, adding additional signal features that are truly associated with the response will improve the fitted model (and a reduction in test set error). However, adding noise features that are not truly associated with teh response will lead to a worse fitted model (and an increase in test set error). Thus, we see that new technologies that allow for the collection of measurements for thousands or millions of features are a double-edged sword: they can lead to improved predictive models if these features are in fact relevant to the problem at hand, but will lead to worse results if the features are not relevant. Even if they are relevant, the variance incurred in fitting their coefficients may outweigh the reduction in bias that they bring. 6.4.4 Interpreting Results in High Dimensions When performing lasso, ridge or other regression in the high-dimensional setting, multicollinearity (where variables in a regression are correlated with each other) can be a big problem. Any variable in the model can be written as a linear combination of all other variables in the model, so we can never know exactly which variables (if any) truly are predictive of the outcome, and can never identify the best coefficients for use in regression. A model like this can still have very high predictive value, but we must be careful not to overstate the results and make it clear that we have identified one of many possible models for predicting the outcome, and that is must be further validated on independent data sets. It is also important to be careful in reporting errors. We have seen in the example that when \\(p &gt; n\\), it is easy to obtain a useless model that has zero residuals. In this case, traditional measures of model fit (e.g. \\(R^2\\)) are misleading; instead, models should be assessed on an independent test set or cross-validation errors. 6.5 Lab: Linear Models and Regularization Methods 6.5.1 Subset Selection Methods Best Subset Selection Here, we aim to predict a baseball players Salary from performance statistics in the previous year: hitters &lt;- as_tibble(ISLR2::Hitters) %&gt;% filter(!is.na(Salary)) glimpse(hitters) ## Rows: 263 ## Columns: 20 ## $ AtBat &lt;int&gt; 315, 479, 496, 321, 594, 185, 298, 323, 401, 574, 202, 418, ~ ## $ Hits &lt;int&gt; 81, 130, 141, 87, 169, 37, 73, 81, 92, 159, 53, 113, 60, 43,~ ## $ HmRun &lt;int&gt; 7, 18, 20, 10, 4, 1, 0, 6, 17, 21, 4, 13, 0, 7, 20, 2, 8, 16~ ## $ Runs &lt;int&gt; 24, 66, 65, 39, 74, 23, 24, 26, 49, 107, 31, 48, 30, 29, 89,~ ## $ RBI &lt;int&gt; 38, 72, 78, 42, 51, 8, 24, 32, 66, 75, 26, 61, 11, 27, 75, 8~ ## $ Walks &lt;int&gt; 39, 76, 37, 30, 35, 21, 7, 8, 65, 59, 27, 47, 22, 30, 73, 15~ ## $ Years &lt;int&gt; 14, 3, 11, 2, 11, 2, 3, 2, 13, 10, 9, 4, 6, 13, 15, 5, 8, 1,~ ## $ CAtBat &lt;int&gt; 3449, 1624, 5628, 396, 4408, 214, 509, 341, 5206, 4631, 1876~ ## $ CHits &lt;int&gt; 835, 457, 1575, 101, 1133, 42, 108, 86, 1332, 1300, 467, 392~ ## $ CHmRun &lt;int&gt; 69, 63, 225, 12, 19, 1, 0, 6, 253, 90, 15, 41, 4, 36, 177, 5~ ## $ CRuns &lt;int&gt; 321, 224, 828, 48, 501, 30, 41, 32, 784, 702, 192, 205, 309,~ ## $ CRBI &lt;int&gt; 414, 266, 838, 46, 336, 9, 37, 34, 890, 504, 186, 204, 103, ~ ## $ CWalks &lt;int&gt; 375, 263, 354, 33, 194, 24, 12, 8, 866, 488, 161, 203, 207, ~ ## $ League &lt;fct&gt; N, A, N, N, A, N, A, N, A, A, N, N, A, N, N, A, N, N, A, N, ~ ## $ Division &lt;fct&gt; W, W, E, E, W, E, W, W, E, E, W, E, E, E, W, W, W, E, W, W, ~ ## $ PutOuts &lt;int&gt; 632, 880, 200, 805, 282, 76, 121, 143, 0, 238, 304, 211, 121~ ## $ Assists &lt;int&gt; 43, 82, 11, 40, 421, 127, 283, 290, 0, 445, 45, 11, 151, 45,~ ## $ Errors &lt;int&gt; 10, 14, 3, 4, 25, 7, 9, 19, 0, 22, 11, 7, 6, 8, 10, 16, 2, 5~ ## $ Salary &lt;dbl&gt; 475.000, 480.000, 500.000, 91.500, 750.000, 70.000, 100.000,~ ## $ NewLeague &lt;fct&gt; N, A, N, N, A, A, A, N, A, A, N, N, A, N, N, A, N, N, N, N, ~ As in the text, Ill use the leaps package to perform best subset selection via RSS. library(leaps) regsubsets_hitters_salary &lt;- regsubsets(Salary ~ ., data = hitters) summary(regsubsets_hitters_salary) ## Subset selection object ## Call: regsubsets.formula(Salary ~ ., data = hitters) ## 19 Variables (and intercept) ## Forced in Forced out ## AtBat FALSE FALSE ## Hits FALSE FALSE ## HmRun FALSE FALSE ## Runs FALSE FALSE ## RBI FALSE FALSE ## Walks FALSE FALSE ## Years FALSE FALSE ## CAtBat FALSE FALSE ## CHits FALSE FALSE ## CHmRun FALSE FALSE ## CRuns FALSE FALSE ## CRBI FALSE FALSE ## CWalks FALSE FALSE ## LeagueN FALSE FALSE ## DivisionW FALSE FALSE ## PutOuts FALSE FALSE ## Assists FALSE FALSE ## Errors FALSE FALSE ## NewLeagueN FALSE FALSE ## 1 subsets of each size up to 8 ## Selection Algorithm: exhaustive ## AtBat Hits HmRun Runs RBI Walks Years CAtBat CHits CHmRun CRuns CRBI ## 1 ( 1 ) &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot;*&quot; ## 2 ( 1 ) &quot; &quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot;*&quot; ## 3 ( 1 ) &quot; &quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot;*&quot; ## 4 ( 1 ) &quot; &quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot;*&quot; ## 5 ( 1 ) &quot;*&quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot;*&quot; ## 6 ( 1 ) &quot;*&quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot;*&quot; ## 7 ( 1 ) &quot; &quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot;*&quot; &quot; &quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot; &quot; ## 8 ( 1 ) &quot;*&quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot;*&quot; &quot;*&quot; &quot; &quot; ## CWalks LeagueN DivisionW PutOuts Assists Errors NewLeagueN ## 1 ( 1 ) &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; ## 2 ( 1 ) &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; ## 3 ( 1 ) &quot; &quot; &quot; &quot; &quot; &quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; ## 4 ( 1 ) &quot; &quot; &quot; &quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; ## 5 ( 1 ) &quot; &quot; &quot; &quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; ## 6 ( 1 ) &quot; &quot; &quot; &quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; ## 7 ( 1 ) &quot; &quot; &quot; &quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; ## 8 ( 1 ) &quot;*&quot; &quot; &quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; An asterisk indicates the variable is included in the model, so the best variables in the three-predictor model are Hits, CRBI and PutOuts. Note that there is a broom::tidy() function available for these objects: broom::tidy(regsubsets_hitters_salary) %&gt;% glimpse() ## Rows: 8 ## Columns: 24 ## $ `(Intercept)` &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE ## $ AtBat &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, TRUE, TRUE, FALSE, TRUE ## $ Hits &lt;lgl&gt; FALSE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE ## $ HmRun &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE ## $ Runs &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE ## $ RBI &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE ## $ Walks &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, TRUE, TRUE ## $ Years &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE ## $ CAtBat &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, FALSE ## $ CHits &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, FALSE ## $ CHmRun &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, TRUE ## $ CRuns &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, TRUE ## $ CRBI &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, FALSE, FALSE ## $ CWalks &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, TRUE ## $ LeagueN &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE ## $ DivisionW &lt;lgl&gt; FALSE, FALSE, FALSE, TRUE, TRUE, TRUE, TRUE, TRUE ## $ PutOuts &lt;lgl&gt; FALSE, FALSE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE ## $ Assists &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE ## $ Errors &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE ## $ NewLeagueN &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE ## $ r.squared &lt;dbl&gt; 0.3214501, 0.4252237, 0.4514294, 0.4754067, 0.4908036, 0~ ## $ adj.r.squared &lt;dbl&gt; 0.3188503, 0.4208024, 0.4450753, 0.4672734, 0.4808971, 0~ ## $ BIC &lt;dbl&gt; -90.84637, -128.92622, -135.62693, -141.80892, -144.0714~ ## $ mallows_cp &lt;dbl&gt; 104.281319, 50.723090, 38.693127, 27.856220, 21.613011, ~ Instead of a formatted table of asterisks, this gives us a tibble of booleans which are nice to work with for producing custom outputs like: broom::tidy(regsubsets_hitters_salary) %&gt;% select(-`(Intercept)`) %&gt;% rownames_to_column(var = &quot;n_vars&quot;) %&gt;% gt(rowname_col = &quot;n_vars&quot;) %&gt;% gt::data_color( columns = AtBat:NewLeagueN, colors = col_numeric( palette = c(td_colors$nice$soft_orange, td_colors$nice$lime_green), domain = c(0, 1)) ) %&gt;% gt::fmt_number(r.squared:mallows_cp, n_sigfig = 4) html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #evgzjwkzar .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #evgzjwkzar .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #evgzjwkzar .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #evgzjwkzar .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #evgzjwkzar .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #evgzjwkzar .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #evgzjwkzar .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #evgzjwkzar .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #evgzjwkzar .gt_column_spanner_outer:first-child { padding-left: 0; } #evgzjwkzar .gt_column_spanner_outer:last-child { padding-right: 0; } #evgzjwkzar .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #evgzjwkzar .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #evgzjwkzar .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #evgzjwkzar .gt_from_md > :first-child { margin-top: 0; } #evgzjwkzar .gt_from_md > :last-child { margin-bottom: 0; } #evgzjwkzar .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #evgzjwkzar .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #evgzjwkzar .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #evgzjwkzar .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #evgzjwkzar .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #evgzjwkzar .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #evgzjwkzar .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #evgzjwkzar .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #evgzjwkzar .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #evgzjwkzar .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #evgzjwkzar .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #evgzjwkzar .gt_sourcenote { font-size: 90%; padding: 4px; } #evgzjwkzar .gt_left { text-align: left; } #evgzjwkzar .gt_center { text-align: center; } #evgzjwkzar .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #evgzjwkzar .gt_font_normal { font-weight: normal; } #evgzjwkzar .gt_font_bold { font-weight: bold; } #evgzjwkzar .gt_font_italic { font-style: italic; } #evgzjwkzar .gt_super { font-size: 65%; } #evgzjwkzar .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } AtBat Hits HmRun Runs RBI Walks Years CAtBat CHits CHmRun CRuns CRBI CWalks LeagueN DivisionW PutOuts Assists Errors NewLeagueN r.squared adj.r.squared BIC mallows_cp 1 FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE 0.3215 0.3189 &minus;90.85 104.3 2 FALSE TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE 0.4252 0.4208 &minus;128.9 50.72 3 FALSE TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE TRUE FALSE FALSE FALSE TRUE FALSE FALSE FALSE 0.4514 0.4451 &minus;135.6 38.69 4 FALSE TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE TRUE FALSE FALSE TRUE TRUE FALSE FALSE FALSE 0.4754 0.4673 &minus;141.8 27.86 5 TRUE TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE TRUE FALSE FALSE TRUE TRUE FALSE FALSE FALSE 0.4908 0.4809 &minus;144.1 21.61 6 TRUE TRUE FALSE FALSE FALSE TRUE FALSE FALSE FALSE FALSE FALSE TRUE FALSE FALSE TRUE TRUE FALSE FALSE FALSE 0.5087 0.4972 &minus;147.9 14.02 7 FALSE TRUE FALSE FALSE FALSE TRUE FALSE TRUE TRUE TRUE FALSE FALSE FALSE FALSE TRUE TRUE FALSE FALSE FALSE 0.5141 0.5008 &minus;145.3 13.13 8 TRUE TRUE FALSE FALSE FALSE TRUE FALSE FALSE FALSE TRUE TRUE FALSE TRUE FALSE TRUE TRUE FALSE FALSE FALSE 0.5286 0.5137 &minus;147.6 7.401 Note that, by default, regsubsets() fits models with up to 8 predictors, this can be adjusted with the nvmax argument: regsubsets_hitters_salary &lt;- regsubsets(Salary ~ ., data = hitters, nvmax = 19) To help choose the best model, plot \\(R^2\\), adjusted \\(R^2\\), \\(C_p\\) and BIC versus number of predictors for all the models: tidy(regsubsets_hitters_salary) %&gt;% select(r.squared:mallows_cp) %&gt;% mutate(n_vars = 1:n()) %&gt;% pivot_longer(cols = -n_vars, names_to = &quot;metric&quot;) %&gt;% ggplot(aes(x = n_vars, y = value)) + geom_point(size = 2) + geom_line(size = 1) + geom_vline( data = . %&gt;% group_by(metric) %&gt;% filter(value == ifelse(str_detect(metric, &quot;r.squared&quot;), max(value), min(value))), aes(xintercept = n_vars), lty = 2 ) + facet_wrap(~ metric, scales = &quot;free_y&quot;) As expected, \\(R^2\\) increases monotonically. The best number of variables by adjusted \\(R^2\\), \\(C_p\\) and BIC are 11, 10 and 6, respectively. We can use coef() to get the coefficient estimates associated with the model with a specified number of variables: coef(regsubsets_hitters_salary, 6) ## (Intercept) AtBat Hits Walks CRBI DivisionW ## 91.5117981 -1.8685892 7.6043976 3.6976468 0.6430169 -122.9515338 ## PutOuts ## 0.2643076 Forward and Backward Stepwise Selection Forward and backward stepwise selection can be performed with the method = \"forward\" and \"backward\" arguments: regsubsets_hitters_salary_forward &lt;- regsubsets(Salary ~ ., data = hitters, nvmax = 19, method = &quot;forward&quot;) regsubsets_hitters_salary_backward &lt;- regsubsets(Salary ~ ., data = hitters, nvmax = 19, method = &quot;backward&quot;) Choosing Among Models Using the Validation-Set Approach and Cross-Validation Use rsample to perform a 50-50 split into training and testing data: set.seed(8) hitters_split &lt;- initial_split(hitters, prop = 0.5) hitters_train &lt;- training(hitters_split) hitters_test &lt;- testing(hitters_split) hitters_train_best &lt;- regsubsets(Salary ~ ., data = hitters_train, nvmax = 19) Ill use a different approach to extracting model coefficients from the regsubsets object and getting MSE from the testing set: hitters_test_mse &lt;- tibble(n_vars = 1:19) %&gt;% mutate( model_coefs = map( n_vars, ~ names(coef(hitters_train_best, i = .x)) %&gt;% # Annoyingly, need to rename the categorical coefficients str_replace(&quot;NewLeagueN&quot;, &quot;NewLeague&quot;) %&gt;% str_replace(&quot;DivisionW&quot;, &quot;Division&quot;) %&gt;% str_replace(&quot;LeagueN&quot;, &quot;League&quot;) ), model_formula = map( model_coefs, ~ formula(paste0(&quot;Salary ~ &quot;, paste(.x[-1], collapse = &quot;+&quot;))) ), model_fit = map(model_formula, ~ lm(.x, data = hitters_test)), mse = map_dbl(model_fit, ~ mean(.x$residuals^2)) ) hitters_test_mse %&gt;% select(n_vars, model_coefs, mse) %&gt;% gt() %&gt;% data_color(columns = mse, colors = c(td_colors$nice$charcoal, td_colors$nice$lime_green)) html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #tpgnuzerro .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #tpgnuzerro .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #tpgnuzerro .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #tpgnuzerro .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #tpgnuzerro .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #tpgnuzerro .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #tpgnuzerro .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #tpgnuzerro .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #tpgnuzerro .gt_column_spanner_outer:first-child { padding-left: 0; } #tpgnuzerro .gt_column_spanner_outer:last-child { padding-right: 0; } #tpgnuzerro .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #tpgnuzerro .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #tpgnuzerro .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #tpgnuzerro .gt_from_md > :first-child { margin-top: 0; } #tpgnuzerro .gt_from_md > :last-child { margin-bottom: 0; } #tpgnuzerro .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #tpgnuzerro .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #tpgnuzerro .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #tpgnuzerro .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #tpgnuzerro .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #tpgnuzerro .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #tpgnuzerro .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #tpgnuzerro .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #tpgnuzerro .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #tpgnuzerro .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #tpgnuzerro .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #tpgnuzerro .gt_sourcenote { font-size: 90%; padding: 4px; } #tpgnuzerro .gt_left { text-align: left; } #tpgnuzerro .gt_center { text-align: center; } #tpgnuzerro .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #tpgnuzerro .gt_font_normal { font-weight: normal; } #tpgnuzerro .gt_font_bold { font-weight: bold; } #tpgnuzerro .gt_font_italic { font-style: italic; } #tpgnuzerro .gt_super { font-size: 65%; } #tpgnuzerro .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } n_vars model_coefs mse 1 (Intercept), CRuns 123433.20 2 (Intercept), Walks, CHits 111877.57 3 (Intercept), Walks, CAtBat, CHits 105330.24 4 (Intercept), Walks, CAtBat, CHits, Division 100607.93 5 (Intercept), Walks, CAtBat, CHits, Division, PutOuts 95384.83 6 (Intercept), Walks, CAtBat, CHits, Division, PutOuts, Assists 94286.58 7 (Intercept), Walks, CAtBat, CHits, CRuns, Division, PutOuts, Assists 94187.18 8 (Intercept), Walks, CAtBat, CHits, CRuns, League, Division, PutOuts, Assists 94126.34 9 (Intercept), AtBat, HmRun, Walks, CAtBat, CHits, Division, PutOuts, Assists, Errors 90507.07 10 (Intercept), AtBat, HmRun, Walks, Years, CAtBat, CHits, Division, PutOuts, Assists, Errors 90078.74 11 (Intercept), AtBat, HmRun, Walks, CAtBat, CHits, CRuns, Division, PutOuts, Assists, Errors, NewLeague 90011.36 12 (Intercept), AtBat, Hits, HmRun, Walks, CAtBat, CHits, CRuns, Division, PutOuts, Assists, Errors, NewLeague 83725.73 13 (Intercept), AtBat, Hits, HmRun, Walks, Years, CAtBat, CHits, CRuns, Division, PutOuts, Assists, Errors, NewLeague 83645.01 14 (Intercept), AtBat, Hits, HmRun, Walks, Years, CAtBat, CHits, CHmRun, CRuns, Division, PutOuts, Assists, Errors, NewLeague 70781.78 15 (Intercept), AtBat, Hits, HmRun, Walks, Years, CAtBat, CHits, CHmRun, CRuns, League, Division, PutOuts, Assists, Errors, NewLeague 69332.68 16 (Intercept), AtBat, Hits, HmRun, RBI, Walks, Years, CAtBat, CHits, CRuns, CRBI, League, Division, PutOuts, Assists, Errors, NewLeague 71043.96 17 (Intercept), AtBat, Hits, HmRun, RBI, Walks, Years, CAtBat, CHits, CHmRun, CRuns, CWalks, League, Division, PutOuts, Assists, Errors, NewLeague 65515.02 18 (Intercept), AtBat, Hits, HmRun, Runs, RBI, Walks, Years, CAtBat, CHits, CHmRun, CRuns, CWalks, League, Division, PutOuts, Assists, Errors, NewLeague 64117.21 19 (Intercept), AtBat, Hits, HmRun, Runs, RBI, Walks, Years, CAtBat, CHits, CHmRun, CRuns, CRBI, CWalks, League, Division, PutOuts, Assists, Errors, NewLeague 63726.78 6.5.2 Ridge Regression and the Lasso Ridge Regression The glmnet::glmnet() function uses a different syntax for fitting models: x &lt;- model.matrix(Salary ~ ., hitters)[, -1] y &lt;- hitters$Salary lambda_grid &lt;- 10^seq(10, -2, length = 100) ridge_salary &lt;- glmnet::glmnet(x, y, alpha = 0, lambda = lambda_grid) And the results are also extracted in a particular way. Here are the coefficients associated with the 50th \\(\\lambda\\) value (= 11498) and the 60th (= 705): coef(ridge_salary)[, 50]; coef(ridge_salary)[, 60] ## (Intercept) AtBat Hits HmRun Runs ## 407.356050200 0.036957182 0.138180344 0.524629976 0.230701523 ## RBI Walks Years CAtBat CHits ## 0.239841459 0.289618741 1.107702929 0.003131815 0.011653637 ## CHmRun CRuns CRBI CWalks LeagueN ## 0.087545670 0.023379882 0.024138320 0.025015421 0.085028114 ## DivisionW PutOuts Assists Errors NewLeagueN ## -6.215440973 0.016482577 0.002612988 -0.020502690 0.301433531 ## (Intercept) AtBat Hits HmRun Runs RBI ## 54.32519950 0.11211115 0.65622409 1.17980910 0.93769713 0.84718546 ## Walks Years CAtBat CHits CHmRun CRuns ## 1.31987948 2.59640425 0.01083413 0.04674557 0.33777318 0.09355528 ## CRBI CWalks LeagueN DivisionW PutOuts Assists ## 0.09780402 0.07189612 13.68370191 -54.65877750 0.11852289 0.01606037 ## Errors NewLeagueN ## -0.70358655 8.61181213 The coefficients in the first model are smaller compared to the second, as expected. This can also be seen with the \\(\\mathcal{l}_2\\) norm: sqrt(sum(coef(ridge_salary)[-1, 50]^2)); sqrt(sum(coef(ridge_salary)[-1, 60]^2)) ## [1] 6.360612 ## [1] 57.11001 Part of the reason I really like tidymodels (and one of the reasons it was created in the first place) is the consistency. It provides a unified interface and syntax for working with models from many different packages. Without ISLR walking me through the steps, it would take me a long time to learn the syntax of glmnet and how to extract the results I want. The tidymodels implementation of this workflow might be longer, but it is standardized  these are lines of code Ive written variations of hundreds of times now. ridge_spec &lt;- linear_reg(penalty = 0, mixture = 0) %&gt;% set_engine(&quot;glmnet&quot;, path_values = lambda_grid) hitters_ridge_fit &lt;- fit(ridge_spec, Salary ~ ., data = hitters) tidy(hitters_ridge_fit, penalty = lambda_grid[50]) ## # A tibble: 20 x 3 ## term estimate penalty ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 407. 11498. ## 2 AtBat 0.0370 11498. ## 3 Hits 0.138 11498. ## 4 HmRun 0.525 11498. ## 5 Runs 0.231 11498. ## 6 RBI 0.240 11498. ## 7 Walks 0.290 11498. ## 8 Years 1.11 11498. ## 9 CAtBat 0.00313 11498. ## 10 CHits 0.0117 11498. ## 11 CHmRun 0.0875 11498. ## 12 CRuns 0.0234 11498. ## 13 CRBI 0.0241 11498. ## 14 CWalks 0.0250 11498. ## 15 LeagueN 0.0850 11498. ## 16 DivisionW -6.22 11498. ## 17 PutOuts 0.0165 11498. ## 18 Assists 0.00261 11498. ## 19 Errors -0.0205 11498. ## 20 NewLeagueN 0.301 11498. tidy(hitters_ridge_fit, penalty = lambda_grid[60]) ## # A tibble: 20 x 3 ## term estimate penalty ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 54.3 705. ## 2 AtBat 0.112 705. ## 3 Hits 0.656 705. ## 4 HmRun 1.18 705. ## 5 Runs 0.938 705. ## 6 RBI 0.847 705. ## 7 Walks 1.32 705. ## 8 Years 2.60 705. ## 9 CAtBat 0.0108 705. ## 10 CHits 0.0467 705. ## 11 CHmRun 0.338 705. ## 12 CRuns 0.0936 705. ## 13 CRBI 0.0978 705. ## 14 CWalks 0.0719 705. ## 15 LeagueN 13.7 705. ## 16 DivisionW -54.7 705. ## 17 PutOuts 0.119 705. ## 18 Assists 0.0161 705. ## 19 Errors -0.704 705. ## 20 NewLeagueN 8.61 705. Visualize coefficient estimates: map_dfr(lambda_grid, ~ tidy(hitters_ridge_fit, penalty = .x)) %&gt;% filter(term != &quot;(Intercept)&quot;) %&gt;% ggplot(aes(x = penalty, y = estimate)) + geom_point() + scale_x_log10(breaks = 10^seq(-2, 10, 4), labels = c(&quot;1e-2&quot;, &quot;1e2&quot;, &quot;1e6&quot;, &quot;1e10&quot;)) + facet_wrap(~ term, scales = &quot;free_y&quot;, ncol = 5) + add_facet_borders() The predict() function also takes a penalty argument: predict(hitters_ridge_fit, penalty = 50, new_data = hitters) ## # A tibble: 263 x 1 ## .pred ## &lt;dbl&gt; ## 1 468. ## 2 663. ## 3 1023. ## 4 506. ## 5 550. ## 6 200. ## 7 79.6 ## 8 105. ## 9 836. ## 10 864. ## # ... with 253 more rows Split the data and fit to the training set: set.seed(10) hitters_split &lt;- initial_split(hitters, prop = 0.5) hitters_train &lt;- training(hitters_split) hitters_test &lt;- testing(hitters_split) hitters_ridge_fit &lt;- fit(ridge_spec, Salary ~ ., data = hitters_train) tidy(hitters_ridge_fit, penalty = 4) ## # A tibble: 20 x 3 ## term estimate penalty ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) -40.8 4 ## 2 AtBat -0.311 4 ## 3 Hits 2.60 4 ## 4 HmRun -4.02 4 ## 5 Runs -1.72 4 ## 6 RBI 0.609 4 ## 7 Walks 7.44 4 ## 8 Years -1.61 4 ## 9 CAtBat -0.0760 4 ## 10 CHits 0.239 4 ## 11 CHmRun 0.102 4 ## 12 CRuns 1.09 4 ## 13 CRBI 0.467 4 ## 14 CWalks -0.954 4 ## 15 LeagueN -60.8 4 ## 16 DivisionW -120. 4 ## 17 PutOuts 0.124 4 ## 18 Assists -0.133 4 ## 19 Errors 0.240 4 ## 20 NewLeagueN 55.5 4 Now fit to the testing set and get MSE for \\(\\lambda\\) = 4: # Note that `broom::augment()` is not implemented for glmnet models, so need to # use `predict()` with `penalty` argument bind_cols( hitters_test, predict(hitters_ridge_fit, new_data = hitters_test, penalty = 4) ) %&gt;% summarise(mse = mean((Salary - .pred)^2)) ## # A tibble: 1 x 1 ## mse ## &lt;dbl&gt; ## 1 142801. Aside: here is a shortcut with yardstick::rmse(): bind_cols( hitters_test, predict(hitters_ridge_fit, new_data = hitters_test, penalty = 4) ) %&gt;% yardstick::rmse(Salary, .pred) %&gt;% mutate(mse = .estimate^2) ## # A tibble: 1 x 4 ## .metric .estimator .estimate mse ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 rmse standard 378. 142801. We should find that the null model (just an intercept, so each test observation is predicted to be the mean of the training) gives the same fit as a ridge regression model with a very large \\(\\lambda\\) penalty: hitters_lm_null_fit &lt;- lm(Salary ~ 1, data = hitters_train) bind_cols( hitters_test, predict(hitters_ridge_fit, new_data = hitters_test, penalty = 1e10), .lm_pred = predict(hitters_lm_null_fit, newdata = hitters_test) ) %&gt;% summarise( mse_ridge = mean((Salary - .pred)^2), mse_null = mean((Salary - .lm_pred)^2) ) ## # A tibble: 1 x 2 ## mse_ridge mse_null ## &lt;dbl&gt; &lt;dbl&gt; ## 1 202640. 202640. Likewise, compare a penalty of 0 to least squares regression with all predictors: hitters_lm_fit &lt;- lm(Salary ~ ., data = hitters_train) bind_cols( hitters_test, predict(hitters_ridge_fit, new_data = hitters_test, penalty = 0), .lm_pred = predict(hitters_lm_fit, newdata = hitters_test) ) %&gt;% summarise( mse_ridge = mean((Salary - .pred)^2), mse_lm = mean((Salary - .lm_pred)^2) ) ## # A tibble: 1 x 2 ## mse_ridge mse_lm ## &lt;dbl&gt; &lt;dbl&gt; ## 1 145236. 145023. Close, but not exactly the same MSE. Reading the footnote in the text (page 279), it appears to be due to a numerical approximation on the part of glmnet(). Instead of arbitrarily choosing \\(\\lambda\\) = 4, lets use 10-fold cross-validation: hitters_recipe &lt;- recipe(Salary ~ ., data = hitters_train) %&gt;% step_dummy(all_nominal_predictors()) ridge_spec &lt;- linear_reg(penalty = tune(), mixture = 0) %&gt;% set_engine(&quot;glmnet&quot;) hitters_ridge_workflow &lt;- workflow() %&gt;% add_model(ridge_spec) %&gt;% add_recipe(hitters_recipe) set.seed(291) hitters_resamples &lt;- vfold_cv(hitters_train, v = 10) # Same values as previously, just showing the `dials` functionality lambda_grid &lt;- grid_regular(penalty(range = c(-2, 10)), levels = 100) hitters_ridge_tune &lt;- tune_grid( hitters_ridge_workflow, resamples = hitters_resamples, grid = lambda_grid ) The returned a bunch of warnings saying that A correlation computation is required, but estimate is constant and has 0 standard deviation, resulting in a divide by 0 error. NA will be returned. I can quickly see what values of the \\(\\lambda\\) penalty are causing this with autoplot(): autoplot(hitters_ridge_tune) So large values of regularization are causing the rsq metric to blow up. The full list of metrics can be collected like this: collect_metrics(hitters_ridge_tune) ## # A tibble: 200 x 7 ## penalty .metric .estimator mean n std_err .config ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 0.01 rmse standard 320. 10 27.9 Preprocessor1_Model001 ## 2 0.01 rsq standard 0.540 10 0.0739 Preprocessor1_Model001 ## 3 0.0132 rmse standard 320. 10 27.9 Preprocessor1_Model002 ## 4 0.0132 rsq standard 0.540 10 0.0739 Preprocessor1_Model002 ## 5 0.0175 rmse standard 320. 10 27.9 Preprocessor1_Model003 ## 6 0.0175 rsq standard 0.540 10 0.0739 Preprocessor1_Model003 ## 7 0.0231 rmse standard 320. 10 27.9 Preprocessor1_Model004 ## 8 0.0231 rsq standard 0.540 10 0.0739 Preprocessor1_Model004 ## 9 0.0305 rmse standard 320. 10 27.9 Preprocessor1_Model005 ## 10 0.0305 rsq standard 0.540 10 0.0739 Preprocessor1_Model005 ## # ... with 190 more rows Or find the best fit directly: select_best(hitters_ridge_tune, metric = &quot;rmse&quot;) ## # A tibble: 1 x 2 ## penalty .config ## &lt;dbl&gt; &lt;chr&gt; ## 1 534. Preprocessor1_Model040 With this penalty selected, finalize the workflow and perform the final fit: hitters_ridge_workflow_final &lt;- hitters_ridge_workflow %&gt;% finalize_workflow(select_best(hitters_ridge_tune, metric = &quot;rmse&quot;)) hitters_ridge_fit_final &lt;- fit(hitters_ridge_workflow_final, data = hitters_train) # Note that `broom::augment()` works here because the fit is finalized with a # single `penalty` value -- previously I had to use `bind_cols(predict(...))` # with an explicit `penalty` augment(hitters_ridge_fit_final, new_data = hitters_test) %&gt;% rmse(Salary, .pred) %&gt;% transmute(rmse = .estimate, mse = rmse^2) ## # A tibble: 1 x 2 ## rmse mse ## &lt;dbl&gt; &lt;dbl&gt; ## 1 376. 141380. Its pretty marginal, but this is an improvement over the MSE we got using \\(\\lambda\\) = 4. Lastly, here are the coefficient estimates of the final fit, none of which are exactly zero, as expected: tidy(hitters_ridge_fit_final) ## # A tibble: 20 x 3 ## term estimate penalty ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) -56.0 534. ## 2 AtBat 0.177 534. ## 3 Hits 0.689 534. ## 4 HmRun 0.129 534. ## 5 Runs 1.07 534. ## 6 RBI 0.794 534. ## 7 Walks 1.89 534. ## 8 Years 4.50 534. ## 9 CAtBat 0.0160 534. ## 10 CHits 0.0691 534. ## 11 CHmRun 0.417 534. ## 12 CRuns 0.137 534. ## 13 CRBI 0.133 534. ## 14 CWalks 0.100 534. ## 15 PutOuts 0.0964 534. ## 16 Assists -0.0226 534. ## 17 Errors -1.41 534. ## 18 League_N -2.39 534. ## 19 Division_W -54.9 534. ## 20 NewLeague_N 8.59 534. The Lasso Before performing cross-validation, plot coefficient estimates for a range of \\(\\lambda\\) values: lasso_spec &lt;- linear_reg(penalty = 0, mixture = 1) %&gt;% set_engine(&quot;glmnet&quot;, path_values = lambda_grid$penalty) hitters_lasso_fit &lt;- fit(lasso_spec, Salary ~ ., data = hitters) map_dfr(lambda_grid$penalty, ~ tidy(hitters_lasso_fit, penalty = .x)) %&gt;% filter(term != &quot;(Intercept)&quot;) %&gt;% ggplot(aes(x = penalty, y = estimate)) + geom_point() + scale_x_log10(breaks = 10^seq(-2, 10, 4), labels = c(&quot;1e-2&quot;, &quot;1e2&quot;, &quot;1e6&quot;, &quot;1e10&quot;)) + facet_wrap(~ term, scales = &quot;free_y&quot;, ncol = 5) + add_facet_borders() All of the coefficients quickly go to zero. Knowing this, and seeing how rsq blew up in the ridge example, Im going to constrain penalty_grid to a smaller range. Now follow the same procedure as the ridge regression model to find the best choice of \\(\\lambda\\): lasso_spec &lt;- linear_reg(penalty = tune(), mixture = 1) %&gt;% set_engine(&quot;glmnet&quot;) hitters_lasso_workflow &lt;- workflow() %&gt;% add_model(lasso_spec) %&gt;% add_recipe(hitters_recipe) lambda_grid &lt;- grid_regular(penalty(range = c(-2, 2)), levels = 50) hitters_lasso_tune &lt;- tune_grid( hitters_lasso_workflow, resamples = hitters_resamples, grid = lambda_grid ) autoplot(hitters_lasso_tune) select_best(hitters_lasso_tune, metric = &quot;rmse&quot;) ## # A tibble: 1 x 2 ## penalty .config ## &lt;dbl&gt; &lt;chr&gt; ## 1 22.2 Preprocessor1_Model42 hitters_lasso_workflow_final &lt;- hitters_lasso_workflow %&gt;% finalize_workflow(select_best(hitters_lasso_tune, metric = &quot;rmse&quot;)) hitters_lasso_fit_final &lt;- fit(hitters_lasso_workflow_final, data = hitters_train) augment(hitters_lasso_fit_final, new_data = hitters_test) %&gt;% rmse(Salary, .pred) %&gt;% transmute(rmse = .estimate, mse = rmse^2) ## # A tibble: 1 x 2 ## rmse mse ## &lt;dbl&gt; &lt;dbl&gt; ## 1 377. 142129. This is essentially the same performance as the ridge regression model. The advantage is that the lasso has performed variable selection for us by setting some coefficients to exactly zero: tidy(hitters_lasso_fit_final) %&gt;% arrange(estimate) ## # A tibble: 20 x 3 ## term estimate penalty ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Division_W -73.0 22.2 ## 2 (Intercept) -59.9 22.2 ## 3 AtBat 0 22.2 ## 4 HmRun 0 22.2 ## 5 Runs 0 22.2 ## 6 RBI 0 22.2 ## 7 Years 0 22.2 ## 8 CAtBat 0 22.2 ## 9 CHits 0 22.2 ## 10 CHmRun 0 22.2 ## 11 CWalks 0 22.2 ## 12 Assists 0 22.2 ## 13 Errors 0 22.2 ## 14 League_N 0 22.2 ## 15 NewLeague_N 0 22.2 ## 16 PutOuts 0.0979 22.2 ## 17 CRBI 0.407 22.2 ## 18 CRuns 0.416 22.2 ## 19 Hits 1.68 22.2 ## 20 Walks 3.36 22.2 6.5.3 PCR and PLS Regression 6.5.3.1 Principal Components Regression In the text, they use the pcr() function from the pls library to perform PCR. The syntax is the same as lm(), and it had scale and validation parameters for standardizing predictors and performing cross-validation. library(pls) ## ## Attaching package: &#39;pls&#39; ## The following object is masked from &#39;package:stats&#39;: ## ## loadings set.seed(1) hitters_pcr_fit &lt;- pcr(Salary ~ ., data = hitters, scale = TRUE, validation = &quot;CV&quot;) summary(hitters_pcr_fit) ## Data: X dimension: 263 19 ## Y dimension: 263 1 ## Fit method: svdpc ## Number of components considered: 19 ## ## VALIDATION: RMSEP ## Cross-validated using 10 random segments. ## (Intercept) 1 comps 2 comps 3 comps 4 comps 5 comps 6 comps ## CV 452 352.5 351.6 352.3 350.7 346.1 345.5 ## adjCV 452 352.1 351.2 351.8 350.1 345.5 344.6 ## 7 comps 8 comps 9 comps 10 comps 11 comps 12 comps 13 comps ## CV 345.4 348.5 350.4 353.2 354.5 357.5 360.3 ## adjCV 344.5 347.5 349.3 351.8 353.0 355.8 358.5 ## 14 comps 15 comps 16 comps 17 comps 18 comps 19 comps ## CV 352.4 354.3 345.6 346.7 346.6 349.4 ## adjCV 350.2 352.3 343.6 344.5 344.3 346.9 ## ## TRAINING: % variance explained ## 1 comps 2 comps 3 comps 4 comps 5 comps 6 comps 7 comps 8 comps ## X 38.31 60.16 70.84 79.03 84.29 88.63 92.26 94.96 ## Salary 40.63 41.58 42.17 43.22 44.90 46.48 46.69 46.75 ## 9 comps 10 comps 11 comps 12 comps 13 comps 14 comps 15 comps ## X 96.28 97.26 97.98 98.65 99.15 99.47 99.75 ## Salary 46.86 47.76 47.82 47.85 48.10 50.40 50.55 ## 16 comps 17 comps 18 comps 19 comps ## X 99.89 99.97 99.99 100.00 ## Salary 53.01 53.85 54.61 54.61 This summary() shows the RMSE and percentage variance in the predictors (X) and outcome (Salary) explained for different numbers of components. Note how 100% of the variance in predictors is explained with 19 components, because these is the number of predictors. The pls package includes a function for plotting prediction MSE vs number of components: validationplot(hitters_pcr_fit, val.type = &quot;MSEP&quot;) Here is the tidymodels approach: set.seed(994) lm_spec &lt;- linear_reg() %&gt;% set_engine(&quot;lm&quot;) hitters_resamples &lt;- vfold_cv(hitters, v = 10) hitters_pca_recipe &lt;- recipe(Salary ~ ., data = hitters) %&gt;% step_dummy(all_nominal()) %&gt;% step_normalize(all_predictors()) %&gt;% step_pca(all_predictors(), num_comp = tune()) hitters_pca_workflow &lt;- workflow() %&gt;% add_model(lm_spec) %&gt;% add_recipe(hitters_pca_recipe) num_comp_grid &lt;- grid_regular(num_comp(range = c(0, 19)), levels = 19) hitters_pca_tune &lt;- tune_grid(hitters_pca_workflow, resamples = hitters_resamples, grid = num_comp_grid) And here is that procedure applied to the training data and evaluated on the test set: set.seed(87) hitters_resamples &lt;- vfold_cv(hitters_train, v = 10) hitters_pca_tune &lt;- tune_grid(hitters_pca_workflow, resamples = hitters_resamples, grid = num_comp_grid) hitters_pca_workflow_final &lt;- finalize_workflow(hitters_pca_workflow, select_best(hitters_pca_tune, metric = &quot;rmse&quot;)) # Apply the workflow to the full training set, then evaluate on testing hitters_pca_fit_final &lt;- last_fit(hitters_pca_workflow_final, hitters_split) hitters_pca_fit_final %&gt;% collect_metrics() ## # A tibble: 2 x 4 ## .metric .estimator .estimate .config ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 rmse standard 400. Preprocessor1_Model1 ## 2 rsq standard 0.272 Preprocessor1_Model1 Partial least squares For PLS, there is the pls::plsr() function with the same syntax: set.seed(1) pls_fit &lt;- plsr(Salary ~ ., data = hitters_train, scale = TRUE, validation = &quot;CV&quot;) summary(pls_fit) ## Data: X dimension: 131 19 ## Y dimension: 131 1 ## Fit method: kernelpls ## Number of components considered: 19 ## ## VALIDATION: RMSEP ## Cross-validated using 10 random segments. ## (Intercept) 1 comps 2 comps 3 comps 4 comps 5 comps 6 comps ## CV 458 310.1 323.8 313.7 317.4 327.3 324.5 ## adjCV 458 309.5 321.0 311.7 315.1 324.4 321.6 ## 7 comps 8 comps 9 comps 10 comps 11 comps 12 comps 13 comps ## CV 324.0 324.3 323.9 325.7 327.9 329.9 330.4 ## adjCV 321.1 321.4 320.8 322.8 324.4 326.2 326.7 ## 14 comps 15 comps 16 comps 17 comps 18 comps 19 comps ## CV 329.8 331.0 332.2 333.2 334.1 335.3 ## adjCV 326.0 327.1 328.0 329.0 329.8 331.0 ## ## TRAINING: % variance explained ## 1 comps 2 comps 3 comps 4 comps 5 comps 6 comps 7 comps 8 comps ## X 40.99 47.38 56.18 69.65 77.68 84.90 89.05 91.73 ## Salary 58.00 61.75 62.57 63.21 64.31 64.95 65.35 65.81 ## 9 comps 10 comps 11 comps 12 comps 13 comps 14 comps 15 comps ## X 93.64 96.68 97.49 98.00 98.77 98.99 99.35 ## Salary 66.19 66.36 66.98 67.46 67.59 67.77 67.82 ## 16 comps 17 comps 18 comps 19 comps ## X 99.42 99.74 99.89 100.00 ## Salary 67.87 67.87 67.88 67.89 pls_pred &lt;- predict(pls_fit, hitters_test, ncomp = 1) mean((pls_pred - hitters_test$Salary)^2) ## [1] 158035.7 PLS in tidymodels is done with step_pls(). An issue I ran into for the below code is that the mixOmics package is required for PLS, which has a tune() function that masks the tidymodels tune(). There is a nice helper function to deal with name conflicts like this: tidymodels_prefer(quiet = FALSE) ## [conflicted] Will prefer dplyr::filter over any other package ## [conflicted] Will prefer dplyr::select over any other package ## [conflicted] Will prefer dplyr::slice over any other package ## [conflicted] Will prefer dplyr::rename over any other package ## [conflicted] Will prefer dials::neighbors over any other package ## [conflicted] Will prefer parsnip::fit over any other package ## [conflicted] Will prefer parsnip::bart over any other package ## [conflicted] Will prefer parsnip::pls over any other package ## [conflicted] Will prefer purrr::map over any other package ## [conflicted] Will prefer recipes::step over any other package ## [conflicted] Will prefer themis::step_downsample over any other package ## [conflicted] Will prefer themis::step_upsample over any other package ## [conflicted] Will prefer tune::tune over any other package ## [conflicted] Will prefer yardstick::precision over any other package ## [conflicted] Will prefer yardstick::recall over any other package ## -- Conflicts -------------------------------------------- tidymodels_prefer() -- ## Now back to the model: set.seed(220) hitters_resamples &lt;- vfold_cv(hitters_train, v = 10) hitters_pls_recipe &lt;- recipe(Salary ~ ., data = hitters_train) %&gt;% step_dummy(all_nominal_predictors()) %&gt;% step_normalize(all_predictors()) %&gt;% step_pls(all_predictors(), outcome = &quot;Salary&quot;, num_comp = tune()) hitters_pls_workflow &lt;- workflow() %&gt;% add_model(lm_spec) %&gt;% add_recipe(hitters_pls_recipe) hitters_pls_tune &lt;- tune_grid(hitters_pls_workflow, resamples = hitters_resamples, grid = num_comp_grid) autoplot(hitters_pls_tune) Finalize the workflow and fit to the test data: hitters_pls_workflow_final &lt;- finalize_workflow( hitters_pls_workflow, select_best(hitters_pls_tune, metric = &quot;rmse&quot;) ) hitters_pls_fit_testing &lt;- last_fit( hitters_pls_workflow_final, split = hitters_split, metrics = metric_set(rmse) ) hitters_pls_fit_testing %&gt;% collect_metrics() %&gt;% transmute(rmse = .estimate, mse = rmse^2) ## # A tibble: 1 x 2 ## rmse mse ## &lt;dbl&gt; &lt;dbl&gt; ## 1 398. 158036. And, as in the text, one last fit to the full data set: hitters_pls_fit_full &lt;- fit(hitters_pls_workflow_final, data = hitters) augment(hitters_pls_fit_full, new_data = hitters) %&gt;% rmse(truth = Salary, estimate = .pred) %&gt;% transmute(rmse = .estimate, mse = rmse^2) ## # A tibble: 1 x 2 ## rmse mse ## &lt;dbl&gt; &lt;dbl&gt; ## 1 340. 115453. Im not sure how to get the percent variance explained from the trained recipe, so here it is via plsr: plsr(Salary ~ ., data = hitters, scale = TRUE, ncomp = 1) %&gt;% summary() ## Data: X dimension: 263 19 ## Y dimension: 263 1 ## Fit method: kernelpls ## Number of components considered: 1 ## TRAINING: % variance explained ## 1 comps ## X 38.08 ## Salary 43.05 6.6 Exercises Applied 8. Best subset selection on simulated data (and b.) Simulate the data. set.seed(2997) # Randomly choose some regression coefficients # Range 2-10... betas &lt;- runif(4, min = 2, max = 10) * # ... but make some negative sample(c(-1, 1), size = 4, replace = TRUE) d &lt;- tibble(x = rnorm(100), epsilon = rnorm(100)) %&gt;% mutate( y = betas[1] + betas[2] * x + betas[3] * x^2 + betas[4] * x^3 + epsilon ) betas; glimpse(d) ## [1] 7.474564 9.429583 7.535502 -8.773099 ## Rows: 100 ## Columns: 3 ## $ x &lt;dbl&gt; -0.05453875, 1.05568168, 0.17502022, -0.64674666, -0.26412982,~ ## $ epsilon &lt;dbl&gt; 0.05251286, -0.48510475, 0.10033137, -0.60341432, -0.32059655,~ ## $ y &lt;dbl&gt; 7.036637, 15.020423, 9.409056, 6.297874, 5.350705, 15.462214, ~ Perform best subset selection with predictors \\(X, \\dots, X^{10}\\). # Note we have to use `raw = TRUE`, otherwise the orthogonalized polynomials # are used, which are hard to interpret (and compare to our simulated values) d_regsubsets &lt;- regsubsets(y ~ poly(x, degree = 10, raw = TRUE), data = d, nvmax = 10) tidy(d_regsubsets) %&gt;% transmute(n_vars = 1:n(), adj.r.squared, BIC, mallows_cp) %&gt;% pivot_longer(cols = -n_vars, names_to = &quot;metric&quot;) %&gt;% group_by(metric) %&gt;% mutate( best = ifelse(metric == &quot;adj.r.squared&quot;, value == max(value), value == min(value)) ) %&gt;% ungroup() %&gt;% ggplot(aes(x = n_vars, y = value)) + geom_line(size = 1) + geom_point(aes(color = best), size = 3) + scale_x_continuous(breaks = 1:10) + facet_wrap(~ metric, ncol = 1, scales = &quot;free_y&quot;) + theme(legend.position = &quot;none&quot;) The best model is one with 3 predictors (by adjusted \\(R^2\\), it is marginally 5 predictors). The coefficients match the simulation pretty well: coef(d_regsubsets, id = 3) ## (Intercept) poly(x, degree = 10, raw = TRUE)1 ## 7.419514 9.470313 ## poly(x, degree = 10, raw = TRUE)2 poly(x, degree = 10, raw = TRUE)3 ## 7.489994 -8.733921 Compare to forward and backward selection. d_regsubsets_forward &lt;- regsubsets(y ~ poly(x, degree = 10, raw = TRUE), data = d, nvmax = 10, method = &quot;forward&quot;) d_regsubsets_backward &lt;- regsubsets(y ~ poly(x, degree = 10, raw = TRUE), data = d, nvmax = 10, method = &quot;backward&quot;) bind_rows( tidy(d_regsubsets) %&gt;% transmute(n_vars = 1:n(), adj.r.squared, BIC, mallows_cp, method = &quot;best subset&quot;), tidy(d_regsubsets_forward) %&gt;% transmute(n_vars = 1:n(), adj.r.squared, BIC, mallows_cp, method = &quot;forward&quot;), tidy(d_regsubsets_backward) %&gt;% transmute(n_vars = 1:n(), adj.r.squared, BIC, mallows_cp, method = &quot;backward&quot;) ) %&gt;% pivot_longer(cols = -c(n_vars, method), names_to = &quot;metric&quot;) %&gt;% group_by(method, metric) %&gt;% filter( value == ifelse(metric == &quot;adj.r.squared&quot;, max(value), min(value)) ) %&gt;% group_by(method) %&gt;% gt() html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #pkmdrdcwge .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #pkmdrdcwge .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #pkmdrdcwge .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #pkmdrdcwge .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #pkmdrdcwge .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #pkmdrdcwge .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #pkmdrdcwge .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #pkmdrdcwge .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #pkmdrdcwge .gt_column_spanner_outer:first-child { padding-left: 0; } #pkmdrdcwge .gt_column_spanner_outer:last-child { padding-right: 0; } #pkmdrdcwge .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #pkmdrdcwge .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #pkmdrdcwge .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #pkmdrdcwge .gt_from_md > :first-child { margin-top: 0; } #pkmdrdcwge .gt_from_md > :last-child { margin-bottom: 0; } #pkmdrdcwge .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #pkmdrdcwge .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #pkmdrdcwge .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #pkmdrdcwge .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #pkmdrdcwge .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #pkmdrdcwge .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #pkmdrdcwge .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #pkmdrdcwge .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #pkmdrdcwge .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #pkmdrdcwge .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #pkmdrdcwge .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #pkmdrdcwge .gt_sourcenote { font-size: 90%; padding: 4px; } #pkmdrdcwge .gt_left { text-align: left; } #pkmdrdcwge .gt_center { text-align: center; } #pkmdrdcwge .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #pkmdrdcwge .gt_font_normal { font-weight: normal; } #pkmdrdcwge .gt_font_bold { font-weight: bold; } #pkmdrdcwge .gt_font_italic { font-style: italic; } #pkmdrdcwge .gt_super { font-size: 65%; } #pkmdrdcwge .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } n_vars metric value best subset 3 BIC -595.8146797 3 mallows_cp 0.3189762 5 adj.r.squared 0.9977838 forward 3 adj.r.squared 0.9977830 3 BIC -595.8146797 3 mallows_cp 0.3189762 backward 3 BIC -595.8146797 3 mallows_cp 0.3189762 5 adj.r.squared 0.9977835 The results from all three methods are nearly the same  forward selection chooses the 3 predictor model by adjusted \\(R^2\\). Fit a lasso model with cross-validation. lasso_spec &lt;- linear_reg(penalty = tune(), mixture = 1) %&gt;% set_engine(&quot;glmnet&quot;) d_recipe &lt;- recipe(y ~ x, data = d) %&gt;% # `raw = TRUE` gives weird results, might try to fix this later step_poly(x, degree = 10, options = list(raw = FALSE)) %&gt;% step_normalize(all_predictors()) d_workflow &lt;- workflow() %&gt;% add_model(lasso_spec) %&gt;% add_recipe(d_recipe) set.seed(5) d_resamples &lt;- vfold_cv(d, v = 10) d_tune_res &lt;- tune_grid(d_workflow, resamples = d_resamples, grid = grid_regular(penalty(range = c(-5, 1)), levels = 50)) autoplot(d_tune_res) Take the best \\(\\lambda\\) value by RMSE, fit it to the data, and get the selected coefficients (those &gt; 0): d_workflow_final &lt;- finalize_workflow(d_workflow, select_best(d_tune_res, metric = &quot;rmse&quot;)) fit(d_workflow_final, data = d) %&gt;% tidy() %&gt;% filter(estimate != 0) ## # A tibble: 4 x 3 ## term estimate penalty ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 13.7 0.146 ## 2 x_poly_1 -12.4 0.146 ## 3 x_poly_2 7.55 0.146 ## 4 x_poly_3 -14.5 0.146 The lasso model selected the 3 predictors, but coefficient estimates are much different because orthogonalized polynomials were used in step_poly(). Perform an alternate simulation and repeat. Ill use the following values for \\(\\beta_0\\) and \\(\\beta_7\\): betas[1]; betas[4] ## [1] 7.474564 ## [1] -8.773099 d &lt;- d %&gt;% mutate(y = betas[1] + betas[4] * x^7 + epsilon) d_regsubsets &lt;- regsubsets(y ~ poly(x, degree = 10, raw = TRUE), data = d, nvmax = 10) tidy(d_regsubsets) %&gt;% transmute(n_vars = 1:n(), adj.r.squared, BIC, mallows_cp) %&gt;% pivot_longer(cols = -n_vars, names_to = &quot;metric&quot;) %&gt;% group_by(metric) %&gt;% mutate( best = ifelse(metric == &quot;adj.r.squared&quot;, value == max(value), value == min(value)) ) %&gt;% ungroup() %&gt;% ggplot(aes(x = n_vars, y = value)) + geom_line(size = 1) + geom_point(aes(color = best), size = 3) + scale_x_continuous(breaks = 1:10) + facet_wrap(~ metric, ncol = 1, scales = &quot;free_y&quot;) + theme(legend.position = &quot;none&quot;) Just the correct coefficient was selected, with correct estimates: coef(d_regsubsets, 1) ## (Intercept) poly(x, degree = 10, raw = TRUE)7 ## 7.374704 -8.771151 Now the lasso model: d_recipe &lt;- recipe(y ~ x, data = d) %&gt;% step_poly(x, degree = 10, options = list(raw = TRUE)) %&gt;% step_normalize(all_predictors()) d_workflow &lt;- workflow() %&gt;% add_model(lasso_spec) %&gt;% add_recipe(d_recipe) d_tune_res &lt;- tune_grid(d_workflow, resamples = d_resamples, grid = grid_regular(penalty(range = c(-3, 1)), levels = 50)) autoplot(d_tune_res) finalize_workflow(d_workflow, select_best(d_tune_res, metric = &quot;rmse&quot;)) %&gt;% fit(data = d) %&gt;% tidy() %&gt;% filter(estimate != 0) ## # A tibble: 2 x 3 ## term estimate penalty ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) -41.3 0.001 ## 2 x_poly_7 -607. 0.001 Lasso also selects the 7th order coefficient, but the estimates are much different, I think due to ste_poly(). 9. Predict applications with College college &lt;- ISLR2::College %&gt;% janitor::clean_names() glimpse(college) ## Rows: 777 ## Columns: 18 ## $ private &lt;fct&gt; Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes~ ## $ apps &lt;dbl&gt; 1660, 2186, 1428, 417, 193, 587, 353, 1899, 1038, 582, 173~ ## $ accept &lt;dbl&gt; 1232, 1924, 1097, 349, 146, 479, 340, 1720, 839, 498, 1425~ ## $ enroll &lt;dbl&gt; 721, 512, 336, 137, 55, 158, 103, 489, 227, 172, 472, 484,~ ## $ top10perc &lt;dbl&gt; 23, 16, 22, 60, 16, 38, 17, 37, 30, 21, 37, 44, 38, 44, 23~ ## $ top25perc &lt;dbl&gt; 52, 29, 50, 89, 44, 62, 45, 68, 63, 44, 75, 77, 64, 73, 46~ ## $ f_undergrad &lt;dbl&gt; 2885, 2683, 1036, 510, 249, 678, 416, 1594, 973, 799, 1830~ ## $ p_undergrad &lt;dbl&gt; 537, 1227, 99, 63, 869, 41, 230, 32, 306, 78, 110, 44, 638~ ## $ outstate &lt;dbl&gt; 7440, 12280, 11250, 12960, 7560, 13500, 13290, 13868, 1559~ ## $ room_board &lt;dbl&gt; 3300, 6450, 3750, 5450, 4120, 3335, 5720, 4826, 4400, 3380~ ## $ books &lt;dbl&gt; 450, 750, 400, 450, 800, 500, 500, 450, 300, 660, 500, 400~ ## $ personal &lt;dbl&gt; 2200, 1500, 1165, 875, 1500, 675, 1500, 850, 500, 1800, 60~ ## $ ph_d &lt;dbl&gt; 70, 29, 53, 92, 76, 67, 90, 89, 79, 40, 82, 73, 60, 79, 36~ ## $ terminal &lt;dbl&gt; 78, 30, 66, 97, 72, 73, 93, 100, 84, 41, 88, 91, 84, 87, 6~ ## $ s_f_ratio &lt;dbl&gt; 18.1, 12.2, 12.9, 7.7, 11.9, 9.4, 11.5, 13.7, 11.3, 11.5, ~ ## $ perc_alumni &lt;dbl&gt; 12, 16, 30, 37, 2, 11, 26, 37, 23, 15, 31, 41, 21, 32, 26,~ ## $ expend &lt;dbl&gt; 7041, 10527, 8735, 19016, 10922, 9727, 8861, 11487, 11644,~ ## $ grad_rate &lt;dbl&gt; 60, 56, 54, 59, 15, 55, 63, 73, 80, 52, 73, 76, 74, 68, 55~ Split the data. Ill use a 80-20 split: set.seed(4912) college_split &lt;- initial_split(college, prop = 0.8) college_train &lt;- training(college_split) college_test &lt;- testing(college_split) Fit a linear model using least squares. lm_spec &lt;- linear_reg() college_lm_fit &lt;- lm_spec %&gt;% fit(apps ~ ., data = college_train) bind_rows( training = augment(college_lm_fit, new_data = college_train) %&gt;% rmse(apps, .pred), testing = augment(college_lm_fit, new_data = college_test) %&gt;% rmse(apps, .pred), .id = &quot;data_set&quot; ) ## # A tibble: 2 x 4 ## data_set .metric .estimator .estimate ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 training rmse standard 1035. ## 2 testing rmse standard 1054. Fit a ridge regression model, with \\(\\lambda\\) chosen by cross-validation. college_recipe &lt;- recipe(apps ~ ., data = college_train) %&gt;% step_novel(all_nominal_predictors()) %&gt;% step_dummy(all_nominal_predictors()) %&gt;% step_zv(all_predictors()) %&gt;% step_normalize(all_predictors()) ridge_spec &lt;- linear_reg(penalty = tune(), mixture = 0) %&gt;% set_engine(&quot;glmnet&quot;) college_ridge_workflow &lt;- workflow() %&gt;% add_recipe(college_recipe) %&gt;% add_model(ridge_spec) college_resamples &lt;- vfold_cv(college_train, v = 5) lambda_grid &lt;- grid_regular(penalty(range = c(-5, 3)), levels = 50) college_ridge_tune &lt;- tune_grid( college_ridge_workflow, resamples = college_resamples, grid = lambda_grid ) college_ridge_workflow_final &lt;- finalize_workflow( college_ridge_workflow, select_best(college_ridge_tune, metric = &quot;rmse&quot;) ) college_ridge_last_fit &lt;- last_fit(college_ridge_workflow_final, college_split) college_ridge_last_fit %&gt;% collect_metrics() ## # A tibble: 2 x 4 ## .metric .estimator .estimate .config ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 rmse standard 947. Preprocessor1_Model1 ## 2 rsq standard 0.933 Preprocessor1_Model1 The tune::last_fit() function I used above a nice shortcut to fitting the final model to the full training data and then evaluating it on the test set. Heres the fit() and augment() way: fit(college_ridge_workflow_final, data = college_train) %&gt;% augment(new_data = college_test) %&gt;% rmse(apps, .pred) ## # A tibble: 1 x 3 ## .metric .estimator .estimate ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 rmse standard 947. Fit a lasso regression model, with \\(\\lambda\\) chosen by cross-validation. lasso_spec &lt;- linear_reg(penalty = tune(), mixture = 1) %&gt;% set_engine(&quot;glmnet&quot;) college_lasso_workflow &lt;- workflow() %&gt;% add_recipe(college_recipe) %&gt;% add_model(lasso_spec) college_lasso_tune &lt;- tune_grid( college_lasso_workflow, resamples = college_resamples, grid = lambda_grid ) college_lasso_workflow_final &lt;- finalize_workflow( college_lasso_workflow, select_best(college_lasso_tune, metric = &quot;rmse&quot;) ) college_lasso_last_fit &lt;- last_fit( college_lasso_workflow_final, split = college_split ) college_lasso_last_fit %&gt;% collect_metrics() ## # A tibble: 2 x 4 ## .metric .estimator .estimate .config ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 rmse standard 1038. Preprocessor1_Model1 ## 2 rsq standard 0.921 Preprocessor1_Model1 The lasso model performed slightly better than least squares, but worse than ridge. Fit a PCR model, with \\(M\\) chosen by cross-validation. # Need to import `mixOmics` package, or else I get the error: # &#39;X&#39; must be a numeric matrix (possibly inculding NA&#39;s) with finite values library(mixOmics) ## Loading required package: MASS ## ## Attaching package: &#39;MASS&#39; ## The following object is masked from &#39;package:patchwork&#39;: ## ## area ## The following object is masked from &#39;package:dplyr&#39;: ## ## select ## The following object is masked from &#39;package:ISLR2&#39;: ## ## Boston ## Loading required package: lattice ## ## Loaded mixOmics 6.19.3 ## Thank you for using mixOmics! ## Tutorials: http://mixomics.org ## Bookdown vignette: https://mixomicsteam.github.io/Bookdown ## Questions, issues: Follow the prompts at http://mixomics.org/contact-us ## Cite us: citation(&#39;mixOmics&#39;) college_pcr_recipe &lt;- recipe(apps ~ ., data = college_train) %&gt;% step_novel(all_nominal_predictors()) %&gt;% step_dummy(all_nominal_predictors()) %&gt;% step_zv(all_predictors()) %&gt;% step_normalize(all_predictors()) %&gt;% step_pca(all_predictors(), num_comp = tune()) college_pcr_workflow &lt;- workflow() %&gt;% add_model(lm_spec) %&gt;% add_recipe(college_pcr_recipe) num_comp_grid &lt;- grid_regular(num_comp(range = c(1, 17)), levels = 17) college_pcr_tune &lt;- tune_grid( college_pcr_workflow, resamples = college_resamples, grid = num_comp_grid ) autoplot(college_pcr_tune) + geom_point( data = . %&gt;% group_by(.metric) %&gt;% filter( (.metric == &quot;rmse&quot; &amp; mean == min(mean)) | (.metric == &quot;rsq&quot;) &amp; mean == max(mean) ), color = &quot;red&quot;, size = 3 ) The best performing model is for \\(M\\) = 17 components, i.e. no dimensionality reduction since \\(p\\) = 17. This should return the exact same model as the least squares in part (b): college_pcr_workflow_final &lt;- finalize_workflow( college_pcr_workflow, select_best(college_pcr_tune, metric = &quot;rmse&quot;) ) college_pcr_last_fit &lt;- last_fit( college_pcr_workflow_final, college_split ) college_pcr_last_fit %&gt;% collect_metrics() ## # A tibble: 2 x 4 ## .metric .estimator .estimate .config ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 rmse standard 1054. Preprocessor1_Model1 ## 2 rsq standard 0.918 Preprocessor1_Model1 Yes, this is the exact same RMSE. Fit a PLS model, with \\(M\\) chosen by cross-validation. college_pls_recipe &lt;- recipe(apps ~ ., data = college_train) %&gt;% step_novel(all_nominal_predictors()) %&gt;% step_dummy(all_nominal_predictors()) %&gt;% step_zv(all_predictors()) %&gt;% step_normalize(all_predictors()) %&gt;% step_pls(all_predictors(), outcome = &quot;apps&quot;, num_comp = tune()) college_pls_workflow &lt;- workflow() %&gt;% add_model(lm_spec) %&gt;% add_recipe(college_pls_recipe) college_pls_tune &lt;- tune_grid( college_pls_workflow, resamples = college_resamples, grid = num_comp_grid ) autoplot(college_pls_tune) + geom_point( data = . %&gt;% group_by(.metric) %&gt;% filter( (.metric == &quot;rmse&quot; &amp; mean == min(mean)) | (.metric == &quot;rsq&quot;) &amp; mean == max(mean) ), color = &quot;red&quot;, size = 3 ) In this case, the best model has 11 components (though it looks to be a pretty marginal improvement over \\(M\\) = 17). college_pls_workflow_final &lt;- finalize_workflow( college_pls_workflow, select_best(college_pls_tune, metric = &quot;rmse&quot;) ) college_pls_last_fit &lt;- last_fit( college_pls_workflow_final, college_split ) college_pls_last_fit %&gt;% collect_metrics() ## # A tibble: 2 x 4 ## .metric .estimator .estimate .config ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 rmse standard 1045. Preprocessor1_Model1 ## 2 rsq standard 0.920 Preprocessor1_Model1 Comment on the results obtained. model_rmse &lt;- bind_rows( lm = augment(college_lm_fit, new_data = college_test) %&gt;% rmse(truth = apps, estimate = .pred), ridge = collect_metrics(college_ridge_last_fit), lasso = collect_metrics(college_lasso_last_fit), pcr = collect_metrics(college_pcr_last_fit), pls = collect_metrics(college_pls_last_fit), .id = &quot;model&quot; ) %&gt;% filter(.metric == &quot;rmse&quot;) %&gt;% select(model, RMSE = .estimate) gt(model_rmse) %&gt;% fmt_number(RMSE, decimals = 1) html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #nwxabeuixm .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #nwxabeuixm .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #nwxabeuixm .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #nwxabeuixm .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #nwxabeuixm .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #nwxabeuixm .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #nwxabeuixm .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #nwxabeuixm .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #nwxabeuixm .gt_column_spanner_outer:first-child { padding-left: 0; } #nwxabeuixm .gt_column_spanner_outer:last-child { padding-right: 0; } #nwxabeuixm .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #nwxabeuixm .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #nwxabeuixm .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #nwxabeuixm .gt_from_md > :first-child { margin-top: 0; } #nwxabeuixm .gt_from_md > :last-child { margin-bottom: 0; } #nwxabeuixm .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #nwxabeuixm .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #nwxabeuixm .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #nwxabeuixm .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #nwxabeuixm .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #nwxabeuixm .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #nwxabeuixm .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #nwxabeuixm .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #nwxabeuixm .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #nwxabeuixm .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #nwxabeuixm .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #nwxabeuixm .gt_sourcenote { font-size: 90%; padding: 4px; } #nwxabeuixm .gt_left { text-align: left; } #nwxabeuixm .gt_center { text-align: center; } #nwxabeuixm .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #nwxabeuixm .gt_font_normal { font-weight: normal; } #nwxabeuixm .gt_font_bold { font-weight: bold; } #nwxabeuixm .gt_font_italic { font-style: italic; } #nwxabeuixm .gt_super { font-size: 65%; } #nwxabeuixm .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } model RMSE lm 1,054.0 ridge 947.4 lasso 1,038.4 pcr 1,054.0 pls 1,044.9 Ridge regression is a clear winner here. Plot observed vs predicted apps: bind_rows( lm = augment(college_lm_fit, college_test), ridge = collect_predictions(college_ridge_last_fit), lasso = collect_predictions(college_lasso_last_fit), pcr = collect_predictions(college_pcr_last_fit), pls = collect_predictions(college_pls_last_fit), .id = &quot;model&quot; ) %&gt;% mutate(model = factor(model, c(&quot;lm&quot;, &quot;ridge&quot;, &quot;lasso&quot;, &quot;pcr&quot;, &quot;pls&quot;))) %&gt;% ggplot(aes(x = apps, y = .pred)) + geom_point() + geom_abline(slope = 1, intercept = 0, lty = 2, color = td_colors$nice$emerald) + facet_wrap(~ model, nrow = 2) + add_facet_borders() All of the models do pretty well. 10. Training/testing error vs features on simulated data Generate a data set. set.seed(25) betas &lt;- runif(n = 20, min = 0.5, max = 4) * # This randomly sets some to negative, zero, or positive sample(c(-1, 0, 1), size = 20, replace = TRUE, prob = c(1, 2, 1)) betas ## [1] 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 ## [7] 0.0000000 1.6813843 0.7337663 0.0000000 -1.6478853 0.0000000 ## [13] 0.0000000 0.0000000 -2.9339979 0.0000000 -2.3889042 0.0000000 ## [19] 0.0000000 0.0000000 15 out of 20 \\(\\beta\\)s were randomly set to 0. Putting together a data frame like this (with 20 variables, 1000 observations, and a dependent variable) is much easier to do with matrix compared to tidyverse: x &lt;- matrix(rnorm(n = 1000 * 20), ncol = 20) y &lt;- x %*% betas + rnorm(1000, mean = 0, sd = 3) d &lt;- as_tibble(x, .name_repair = &quot;unique&quot;) %&gt;% setNames(paste0(&quot;x&quot;, 1:20)) %&gt;% bind_cols(y = as.numeric(y)) glimpse(d) ## Rows: 1,000 ## Columns: 21 ## $ x1 &lt;dbl&gt; 0.55741085, 0.16878151, 0.15525886, 2.36776474, -1.58564441, -1.10~ ## $ x2 &lt;dbl&gt; 0.51837446, -1.41292341, -0.18944599, -0.72824687, -0.88881908, 0.~ ## $ x3 &lt;dbl&gt; 0.02541010, 0.25471606, -0.70085677, 2.17801311, 0.95900592, -1.61~ ## $ x4 &lt;dbl&gt; 1.1532548, -1.3619745, -0.1948377, 1.3573141, -1.5257245, 1.869370~ ## $ x5 &lt;dbl&gt; 1.0450179, -0.2112228, -0.8298719, 1.4875455, -0.5143980, 0.744894~ ## $ x6 &lt;dbl&gt; -2.1825508, -1.3252668, -1.1518960, 1.0004084, 1.6750643, 0.302776~ ## $ x7 &lt;dbl&gt; -2.350092411, -1.410953146, -0.401778457, 0.056619157, 2.747276383~ ## $ x8 &lt;dbl&gt; -0.57947560, 0.01562559, 0.20981345, 0.48256661, 0.22622039, -1.61~ ## $ x9 &lt;dbl&gt; 1.22610573, 0.15239477, 0.23263352, -1.84740747, -0.95566993, 0.52~ ## $ x10 &lt;dbl&gt; -0.089149665, 1.965955110, 0.464237958, 0.196057945, 0.017357951, ~ ## $ x11 &lt;dbl&gt; -0.34685131, 0.06462743, -1.26255074, -2.08710691, -0.92627491, -0~ ## $ x12 &lt;dbl&gt; -0.38362825, -0.68283780, 1.06412302, -0.04131600, -0.87304228, -0~ ## $ x13 &lt;dbl&gt; -1.68857838, -0.73079049, -0.04961324, 0.70012708, 0.38908045, 0.9~ ## $ x14 &lt;dbl&gt; 0.39112003, 1.15893091, 0.34779936, 0.06503513, 0.68921340, -0.672~ ## $ x15 &lt;dbl&gt; -2.318494584, -0.817184058, 0.006930491, 0.339792047, -1.904615032~ ## $ x16 &lt;dbl&gt; -1.88871130, 1.53245950, -0.88902775, 1.21602651, 0.33036601, -1.4~ ## $ x17 &lt;dbl&gt; -0.8704105608, 1.1918767610, 0.5642387337, 2.1831539430, 1.7217873~ ## $ x18 &lt;dbl&gt; -0.06663042, -0.97496945, -0.86277409, -0.46271611, 1.02453469, 0.~ ## $ x19 &lt;dbl&gt; 1.17884655, 1.10576578, -0.26440950, -1.25790497, 1.05538711, 0.74~ ## $ x20 &lt;dbl&gt; -1.54292535, -0.09295013, 2.33147494, -0.08453360, 0.28000909, -0.~ ## $ y &lt;dbl&gt; 10.5414028, -1.7097133, -0.4747322, -0.1199579, 5.3912334, -0.8517~ Just a few lines. For comparison, here is my ugly tidyverse code (not run): x &lt;- tibble(var = paste0(&quot;x&quot;, 1:20), beta = betas) %&gt;% rowwise() %&gt;% # For each predictor, generate 1000 normally-distributed random numbers mutate(val = list(rnorm(1000))) %&gt;% ungroup() %&gt;% unnest(val) %&gt;% group_by(var) %&gt;% # Use i to indicate observation number mutate(i = 1:n()) %&gt;% ungroup() %&gt;% # Multiply each predictor value by its coefficient mutate(beta_val = beta * val) y &lt;- x %&gt;% select(i, var, beta_val) %&gt;% pivot_wider(names_from = var, values_from = beta_val) %&gt;% # Generate some random noise mutate(epsilon = rnorm(1000)) %&gt;% rowwise() %&gt;% # Sum of the beta*x + epsilon values to get the response y mutate(val = sum(c_across(x1:epsilon))) %&gt;% ungroup() # Combine the x and y data frames d &lt;- x %&gt;% select(i, var, val) %&gt;% pivot_wider(names_from = var, values_from = val) %&gt;% left_join(y %&gt;% select(i, y = val), by = &quot;i&quot;) %&gt;% select(-i) glimpse(d) Split into training and testing set. d_split &lt;- initial_split(d, prop = 0.9) d_train &lt;- training(d_split) d_test &lt;- testing(d_split) Perform best subset selection on the training set. Plot the MSE. d_regsubsets &lt;- regsubsets(y ~ ., data = d_train, nvmax = 20) d_models &lt;- tibble(n_vars = 1:20) %&gt;% mutate( model_formula = map( n_vars, ~ as.formula( paste0( &quot;y ~ &quot;, paste(names(coef(d_regsubsets, .x))[-1], collapse = &quot;+&quot;) ) ) ) ) %&gt;% mutate( lm_fit = map(model_formula, ~ lm(.x, data = d_train)), train_mse = map_dbl(lm_fit, ~ mean(resid(.x)^2)) ) d_models %&gt;% ggplot(aes(x = n_vars, y = train_mse)) + geom_point() + geom_line() + geom_point(data = . %&gt;% filter(train_mse == min(train_mse)), color = &quot;red&quot;, size = 3) As expected, the training MSE decreases monotonically with the number of variables. Plot the test set MSE. d_models &lt;- d_models %&gt;% mutate( test_mse = map_dbl( lm_fit, ~ mean((predict(.x, newdata = d_test) - d_test$y)^2) ) ) d_models %&gt;% ggplot(aes(x = n_vars, y = test_mse)) + geom_point() + geom_line() + geom_point(data = . %&gt;% filter(test_mse == min(test_mse)), color = &quot;red&quot;, size = 3) For which model size does the test set MSE take on its minimum value. The test MSE is minimized for 5 variables. How does the best model compare to the true model used to generate the data? d_models %&gt;% filter(test_mse == min(test_mse)) %&gt;% pull(lm_fit) %&gt;% .[[1]] ## ## Call: ## lm(formula = .x, data = d_train) ## ## Coefficients: ## (Intercept) x8 x9 x11 x15 x17 ## -0.2306 1.7729 0.7139 -1.6024 -2.7555 -2.3012 These coefficient estimates are very close to the simulated values: setNames(betas, paste0(&quot;x&quot;, 1:20)) ## x1 x2 x3 x4 x5 x6 x7 ## 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 ## x8 x9 x10 x11 x12 x13 x14 ## 1.6813843 0.7337663 0.0000000 -1.6478853 0.0000000 0.0000000 0.0000000 ## x15 x16 x17 x18 x19 x20 ## -2.9339979 0.0000000 -2.3889042 0.0000000 0.0000000 0.0000000 Create a plot displaying \\(\\sqrt{\\sum^p_{j=1} (\\beta_j - \\hat{\\beta}_j^r)^2}\\) for a range of values of \\(r\\). d_models %&gt;% transmute( n_vars, lm_fit_tidy = map(lm_fit, tidy) ) %&gt;% unnest(lm_fit_tidy) %&gt;% filter(term != &quot;(Intercept)&quot;) %&gt;% left_join( tibble(term = paste0(&quot;x&quot;, 1:20), beta = betas), by = &quot;term&quot; ) %&gt;% group_by(n_vars) %&gt;% summarise(coef_diff = sqrt(sum((estimate - beta)^2)), .groups = &quot;drop&quot;) %&gt;% ggplot(aes(x = n_vars, y = coef_diff)) + geom_point() + geom_line() 11. Predict crime rate with Boston boston &lt;- as_tibble(ISLR2::Boston) glimpse(boston) ## Rows: 506 ## Columns: 13 ## $ crim &lt;dbl&gt; 0.00632, 0.02731, 0.02729, 0.03237, 0.06905, 0.02985, 0.08829,~ ## $ zn &lt;dbl&gt; 18.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.5, 12.5, 12.5, 12.5, 12.5, 1~ ## $ indus &lt;dbl&gt; 2.31, 7.07, 7.07, 2.18, 2.18, 2.18, 7.87, 7.87, 7.87, 7.87, 7.~ ## $ chas &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,~ ## $ nox &lt;dbl&gt; 0.538, 0.469, 0.469, 0.458, 0.458, 0.458, 0.524, 0.524, 0.524,~ ## $ rm &lt;dbl&gt; 6.575, 6.421, 7.185, 6.998, 7.147, 6.430, 6.012, 6.172, 5.631,~ ## $ age &lt;dbl&gt; 65.2, 78.9, 61.1, 45.8, 54.2, 58.7, 66.6, 96.1, 100.0, 85.9, 9~ ## $ dis &lt;dbl&gt; 4.0900, 4.9671, 4.9671, 6.0622, 6.0622, 6.0622, 5.5605, 5.9505~ ## $ rad &lt;int&gt; 1, 2, 2, 3, 3, 3, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4,~ ## $ tax &lt;dbl&gt; 296, 242, 242, 222, 222, 222, 311, 311, 311, 311, 311, 311, 31~ ## $ ptratio &lt;dbl&gt; 15.3, 17.8, 17.8, 18.7, 18.7, 18.7, 15.2, 15.2, 15.2, 15.2, 15~ ## $ lstat &lt;dbl&gt; 4.98, 9.14, 4.03, 2.94, 5.33, 5.21, 12.43, 19.15, 29.93, 17.10~ ## $ medv &lt;dbl&gt; 24.0, 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15~ Check the distribution of crim: p &lt;- boston %&gt;% ggplot(aes(x = crim)) + geom_boxplot(aes(y = 0), outlier.shape = NA) + geom_jitter(aes(y = 1), alpha = 0.5) + remove_axis(&quot;y&quot;) p It is a very heavily tailed distribution. I might want to predict log(crim) instead: p + scale_x_log10() Try out some of the regression methods explored in this chapter. Split into training and testing sets: set.seed(401) boston_split &lt;- initial_split(boston, prop = 0.75) boston_train &lt;- training(boston_split) boston_test &lt;- testing(boston_split) boston_resamples &lt;- vfold_cv(boston_train, v = 10) Best subset selection: boston_subsets &lt;- regsubsets(log(crim) ~ ., data = boston_train, nvmax = ncol(boston) - 1) boston_subsets_metrics &lt;- tibble(n_vars = 1:(ncol(boston) - 1)) %&gt;% mutate( model_formula = map( n_vars, ~ as.formula( paste0( &quot;log(crim) ~ &quot;, paste(names(coef(boston_subsets, .x))[-1], collapse = &quot;+&quot;) ) ) ) ) %&gt;% mutate( lm_fit = map(model_formula, ~ lm(.x, data = boston_train)), train_rmse = map_dbl(lm_fit, ~ sqrt(mean(resid(.x)^2))) ) boston_subsets_metrics %&gt;% ggplot(aes(x = n_vars, y = train_rmse)) + geom_point() + geom_line() + geom_point( data = . %&gt;% filter(train_rmse == min(train_rmse)), color = &quot;red&quot;, size = 3 ) + scale_x_continuous(breaks = 1:(ncol(boston) - 1)) The best model includes all the predictors. boston_subsets_metrics &lt;- boston_subsets_metrics %&gt;% filter(train_rmse == min(train_rmse)) %&gt;% pull(lm_fit) %&gt;% .[[1]] %&gt;% augment(newdata = boston_test) %&gt;% mutate(crim = log(crim)) %&gt;% metrics(truth = crim, estimate = .fitted) Lasso and ridge regression: boston_recipe &lt;- recipe(crim ~ ., data = boston_train) %&gt;% step_normalize(all_predictors()) %&gt;% step_zv(all_predictors()) %&gt;% step_log(all_outcomes()) boston_lasso_workflow &lt;- workflow() %&gt;% add_model(lasso_spec) %&gt;% add_recipe(boston_recipe) boston_ridge_workflow &lt;- workflow() %&gt;% add_model(ridge_spec) %&gt;% add_recipe(boston_recipe) lambda_grid &lt;- grid_regular(penalty(range = c(-5, 0)), levels = 50) boston_lasso_tune &lt;- tune_grid( boston_lasso_workflow, resamples = boston_resamples, grid = lambda_grid ) boston_ridge_tune &lt;- tune_grid( boston_ridge_workflow, resamples = boston_resamples, grid = lambda_grid ) (autoplot(boston_lasso_tune) + labs(title = &quot;lasso&quot;)) | (autoplot(boston_ridge_tune) + labs(title = &quot;ridge&quot;)) Use the minimum RMSE for the chosen \\(\\lambda\\) in each: boston_lasso_last_fit &lt;- boston_lasso_workflow %&gt;% finalize_workflow(select_best(boston_lasso_tune, &quot;rmse&quot;)) %&gt;% last_fit(split = boston_split) boston_ridge_last_fit &lt;- boston_ridge_workflow %&gt;% finalize_workflow(select_best(boston_ridge_tune, &quot;rmse&quot;)) %&gt;% last_fit(split = boston_split) Principal components and partial least squares regression: boston_pca_recipe &lt;- boston_recipe %&gt;% step_pca(all_predictors(), num_comp = tune()) boston_pls_recipe &lt;- boston_recipe %&gt;% step_pls(all_predictors(), num_comp = tune(), outcome = &quot;crim&quot;) boston_pca_workflow &lt;- workflow() %&gt;% add_model(lm_spec) %&gt;% add_recipe(boston_pca_recipe) boston_pls_workflow &lt;- workflow() %&gt;% add_model(lm_spec) %&gt;% add_recipe(boston_pls_recipe) num_comp_grid &lt;- grid_regular(num_comp(range = c(1, 12)), levels = 12) boston_pca_tune &lt;- tune_grid( boston_pca_workflow, resamples = boston_resamples, grid = num_comp_grid ) boston_pls_tune &lt;- tune_grid( boston_pls_workflow, resamples = boston_resamples, grid = num_comp_grid ) p1 &lt;- autoplot(boston_pca_tune) + geom_point( data = . %&gt;% group_by(.metric) %&gt;% filter(mean == ifelse(.metric == &quot;rmse&quot;, min(mean), max(mean))), color = &quot;red&quot;, size = 2 ) + labs(title = &quot;PCA&quot;) + scale_x_continuous(breaks = 1:12) p2 &lt;- autoplot(boston_pls_tune) + geom_point( data = . %&gt;% group_by(.metric) %&gt;% filter(mean == ifelse(.metric == &quot;rmse&quot;, min(mean), max(mean))), color = &quot;red&quot;, size = 2 ) + labs(title = &quot;PLS&quot;) + scale_x_continuous(breaks = 1:12) p1 | p2 In both cases, dimension reduction doesnt provide a big improvement to the model, although with PLS, the best model has 9 components. boston_pca_last_fit &lt;- boston_pca_workflow %&gt;% finalize_workflow(select_best(boston_pca_tune, &quot;rmse&quot;)) %&gt;% last_fit(split = boston_split) boston_pls_last_fit &lt;- boston_pls_workflow %&gt;% finalize_workflow(select_best(boston_pls_tune, &quot;rmse&quot;)) %&gt;% last_fit(split = boston_split) Propose a model or set of models that seem to perform well. # For a baseline comparison, use a simple least squares linear model boston_lm_metrics &lt;- lm(log(crim) ~ ., data = boston_train) %&gt;% augment(newdata = boston_test) %&gt;% mutate(crim = log(crim)) %&gt;% metrics(truth = crim, estimate = .fitted) bind_rows( lm = boston_lm_metrics, best_subsets = boston_subsets_metrics, lasso = collect_metrics(boston_lasso_last_fit), ridge = collect_metrics(boston_ridge_last_fit), pca = collect_metrics(boston_pca_last_fit), pls = collect_metrics(boston_pls_last_fit), .id = &quot;model&quot; ) %&gt;% filter(.metric != &quot;mae&quot;) %&gt;% select(model, .metric, .estimate) %&gt;% pivot_wider(names_from = .metric, values_from = .estimate) %&gt;% gt() %&gt;% data_color(columns = rmse, colors = c(&quot;green&quot;, &quot;red&quot;)) %&gt;% data_color(columns = rsq, colors = c(&quot;red&quot;, &quot;green&quot;)) %&gt;% fmt_number(c(rmse, rsq), decimals = 3) html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #hsqbxbvoai .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #hsqbxbvoai .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #hsqbxbvoai .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #hsqbxbvoai .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #hsqbxbvoai .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #hsqbxbvoai .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #hsqbxbvoai .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #hsqbxbvoai .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #hsqbxbvoai .gt_column_spanner_outer:first-child { padding-left: 0; } #hsqbxbvoai .gt_column_spanner_outer:last-child { padding-right: 0; } #hsqbxbvoai .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #hsqbxbvoai .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #hsqbxbvoai .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #hsqbxbvoai .gt_from_md > :first-child { margin-top: 0; } #hsqbxbvoai .gt_from_md > :last-child { margin-bottom: 0; } #hsqbxbvoai .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #hsqbxbvoai .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #hsqbxbvoai .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #hsqbxbvoai .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #hsqbxbvoai .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #hsqbxbvoai .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #hsqbxbvoai .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #hsqbxbvoai .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #hsqbxbvoai .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #hsqbxbvoai .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #hsqbxbvoai .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #hsqbxbvoai .gt_sourcenote { font-size: 90%; padding: 4px; } #hsqbxbvoai .gt_left { text-align: left; } #hsqbxbvoai .gt_center { text-align: center; } #hsqbxbvoai .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #hsqbxbvoai .gt_font_normal { font-weight: normal; } #hsqbxbvoai .gt_font_bold { font-weight: bold; } #hsqbxbvoai .gt_font_italic { font-style: italic; } #hsqbxbvoai .gt_super { font-size: 65%; } #hsqbxbvoai .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } model rmse rsq lm 0.715 0.884 best_subsets 0.715 0.884 lasso 0.719 0.881 ridge 0.694 0.888 pca 0.715 0.884 pls 0.714 0.884 Observations: The ridge regression model performed best. The least squares (lm) and best subset approach have the same metrics because our best subset tuning included every predictor. Likewise, the PCA approach included all features (no dimensionality reduction) so it is also equivalent. PLS found a very very marginal improvement by reducing from 12 to 9 components. Lasso regression performed the worst. So the ridge regression is my choice of model for this problem. Does your chosen model involve all the features in the data set. It does. The coefficient estimates are all non-zero (though some get close): extract_workflow(boston_ridge_last_fit) %&gt;% tidy() %&gt;% arrange(desc(abs(estimate))) %&gt;% rmarkdown::paged_table() In contrast, the worst-performing lasso regression model: extract_workflow(boston_lasso_last_fit) %&gt;% tidy() %&gt;% arrange(desc(abs(estimate))) %&gt;% rmarkdown::paged_table() Five of the coefficients were reduced to exactly zero, but they clearly add some value as we see in the other models. Reproducibility Sys.time() ## [1] &quot;2022-04-09 16:13:20 AST&quot; if (&quot;git2r&quot; %in% installed.packages()) { if (git2r::in_repository()) { git2r::repository() } } ## Local: main C:/Users/tdunn/Documents/learning/islr-tidy ## Remote: main @ origin (https://github.com/taylordunn/islr-tidy) ## Head: [00046ed] 2022-04-08: Finished chapter 6 sessioninfo::session_info() ## - Session info --------------------------------------------------------------- ## setting value ## version R version 4.1.3 (2022-03-10) ## os Windows 10 x64 ## system x86_64, mingw32 ## ui RTerm ## language (EN) ## collate English_Canada.1252 ## ctype English_Canada.1252 ## tz America/Curacao ## date 2022-04-09 ## ## - Packages ------------------------------------------------------------------- ## package * version date lib ## abind 1.4-5 2016-07-21 [1] ## assertthat 0.2.1 2019-03-21 [1] ## backports 1.2.1 2020-12-09 [1] ## base64enc 0.1-3 2015-07-28 [1] ## bayestestR 0.10.5 2021-07-26 [1] ## BiocParallel 1.28.3 2021-12-09 [1] ## bit 4.0.4 2020-08-04 [1] ## bit64 4.0.5 2020-08-30 [1] ## bookdown 0.24 2021-09-02 [1] ## boot 1.3-28 2021-05-03 [2] ## broom * 0.7.10 2021-10-31 [1] ## bslib 0.2.5.1 2021-05-18 [1] ## cachem 1.0.6 2021-08-19 [1] ## car 3.0-12 2021-11-06 [1] ## carData 3.0-4 2020-05-22 [1] ## cellranger 1.1.0 2016-07-27 [1] ## checkmate 2.0.0 2020-02-06 [1] ## class 7.3-20 2022-01-16 [2] ## cli 3.2.0 2022-02-14 [1] ## coda 0.19-4 2020-09-30 [1] ## codetools 0.2-18 2020-11-04 [2] ## colorspace 2.0-3 2022-02-21 [1] ## combinat 0.0-8 2012-10-29 [1] ## conflicted 1.0.4 2019-06-21 [1] ## corpcor 1.6.10 2021-09-16 [1] ## corrr * 0.4.3 2020-11-24 [1] ## crayon 1.5.1 2022-03-26 [1] ## datawizard 0.1.0 2021-06-18 [1] ## DBI 1.1.2 2021-12-20 [1] ## dbplyr 2.1.1 2021-04-06 [1] ## DEoptimR 1.0-9 2021-05-24 [1] ## dials * 0.0.10 2021-09-10 [1] ## DiceDesign 1.9 2021-02-13 [1] ## digest 0.6.29 2021-12-01 [1] ## discrim * 0.1.3 2021-07-21 [1] ## distill 1.3 2021-10-13 [1] ## distributional 0.2.2 2021-02-02 [1] ## doParallel * 1.0.16 2020-10-16 [1] ## downlit 0.4.0 2021-10-29 [1] ## dplyr * 1.0.8 2022-02-08 [1] ## dunnr * 0.2.5 2022-01-15 [1] ## effectsize 0.4.5 2021-05-25 [1] ## ellipse 0.4.2 2020-05-27 [1] ## ellipsis 0.3.2 2021-04-29 [1] ## emmeans 1.7.0 2021-09-29 [1] ## equatiomatic 0.2.0 2021-01-30 [1] ## estimability 1.3 2018-02-11 [1] ## evaluate 0.14 2019-05-28 [1] ## extrafont 0.17 2014-12-08 [1] ## extrafontdb 1.0 2012-06-11 [1] ## fansi 1.0.3 2022-03-24 [1] ## farver 2.1.0 2021-02-28 [1] ## fastmap 1.1.0 2021-01-25 [1] ## forcats * 0.5.1 2021-01-27 [1] ## foreach * 1.5.2 2022-02-02 [1] ## fs 1.5.2 2021-12-08 [1] ## furrr 0.2.3 2021-06-25 [1] ## future 1.24.0 2022-02-19 [1] ## future.apply 1.8.1 2021-08-10 [1] ## generics 0.1.2 2022-01-31 [1] ## GGally 2.1.2 2021-06-21 [1] ## ggdist * 3.0.0 2021-07-19 [1] ## ggplot2 * 3.3.5 2021-06-25 [1] ## ggrepel 0.9.1 2021-01-15 [1] ## ggridges 0.5.3 2021-01-08 [1] ## git2r 0.28.0 2021-01-10 [1] ## glmnet * 4.1-3 2021-11-02 [1] ## globals 0.14.0 2020-11-22 [1] ## glue 1.6.2 2022-02-24 [1] ## gower 0.2.2 2020-06-23 [1] ## GPfit 1.0-8 2019-02-08 [1] ## gridExtra 2.3 2017-09-09 [1] ## gt * 0.3.1 2021-08-07 [1] ## gtable 0.3.0 2019-03-25 [1] ## hardhat 0.2.0 2022-01-24 [1] ## haven 2.4.1 2021-04-23 [1] ## here * 1.0.1 2020-12-13 [1] ## highr 0.9 2021-04-16 [1] ## hms 1.1.1 2021-09-26 [1] ## htmltools 0.5.2 2021-08-25 [1] ## httpuv 1.6.5 2022-01-05 [1] ## httr 1.4.2 2020-07-20 [1] ## igraph 1.2.11 2022-01-04 [1] ## infer * 1.0.0 2021-08-13 [1] ## insight 0.14.2 2021-06-22 [1] ## ipred 0.9-12 2021-09-15 [1] ## ISLR2 * 1.3-1 2022-01-10 [1] ## iterators * 1.0.14 2022-02-05 [1] ## janitor 2.1.0 2021-01-05 [1] ## jquerylib 0.1.4 2021-04-26 [1] ## jsonlite 1.7.3 2022-01-17 [1] ## kknn 1.3.1 2016-03-26 [1] ## klaR 0.6-15 2020-02-19 [1] ## knitr 1.37 2021-12-16 [1] ## labeling 0.4.2 2020-10-20 [1] ## labelled 2.8.0 2021-03-08 [1] ## later 1.3.0 2021-08-18 [1] ## lattice * 0.20-45 2021-09-22 [2] ## lava 1.6.10 2021-09-02 [1] ## leaps * 3.1 2020-01-16 [1] ## lhs 1.1.1 2020-10-05 [1] ## lifecycle 1.0.1 2021-09-24 [1] ## listenv 0.8.0 2019-12-05 [1] ## lubridate 1.8.0 2021-10-07 [1] ## magrittr 2.0.2 2022-01-26 [1] ## MASS * 7.3-55 2022-01-16 [2] ## Matrix * 1.4-0 2021-12-08 [2] ## matrixStats 0.61.0 2021-09-17 [1] ## memoise 2.0.1 2021-11-26 [1] ## MetBrewer 0.1.0 2022-01-05 [1] ## mgcv 1.8-39 2022-02-24 [2] ## mime 0.12 2021-09-28 [1] ## miniUI 0.1.1.1 2018-05-18 [1] ## mixOmics * 6.19.3 2022-04-04 [1] ## modeldata * 0.1.1 2021-07-14 [1] ## modelr 0.1.8 2020-05-19 [1] ## munsell 0.5.0 2018-06-12 [1] ## mvtnorm * 1.1-3 2021-10-08 [1] ## nlme 3.1-155 2022-01-16 [2] ## nnet 7.3-17 2022-01-16 [2] ## parallelly 1.30.0 2021-12-17 [1] ## parameters 0.14.0 2021-05-29 [1] ## parsnip * 0.1.7 2021-07-21 [1] ## patchwork * 1.1.1 2020-12-17 [1] ## performance 0.7.3 2021-07-21 [1] ## pillar 1.7.0 2022-02-01 [1] ## pkgconfig 2.0.3 2019-09-22 [1] ## pls * 2.8-0 2021-09-03 [1] ## plyr 1.8.7 2022-03-24 [1] ## poissonreg * 0.1.1 2021-08-07 [1] ## prettyunits 1.1.1 2020-01-24 [1] ## pROC 1.17.0.1 2021-01-13 [1] ## prodlim 2019.11.13 2019-11-17 [1] ## promises 1.2.0.1 2021-02-11 [1] ## purrr * 0.3.4 2020-04-17 [1] ## qqplotr 0.0.5 2021-04-23 [1] ## questionr 0.7.5 2021-10-06 [1] ## R6 2.5.1 2021-08-19 [1] ## rARPACK 0.11-0 2016-03-10 [1] ## RColorBrewer 1.1-3 2022-04-03 [1] ## Rcpp 1.0.8.3 2022-03-17 [1] ## readr * 2.1.1 2021-11-30 [1] ## readxl 1.3.1 2019-03-13 [1] ## recipes * 0.1.17 2021-09-27 [1] ## repr 1.1.3 2021-01-21 [1] ## reprex 2.0.0 2021-04-02 [1] ## reshape 0.8.8 2018-10-23 [1] ## reshape2 1.4.4 2020-04-09 [1] ## rlang * 1.0.2 2022-03-04 [1] ## rmarkdown 2.11 2021-09-14 [1] ## robustbase 0.93-8 2021-06-02 [1] ## rpart 4.1.16 2022-01-24 [2] ## rprojroot 2.0.2 2020-11-15 [1] ## rsample * 0.1.0 2021-05-08 [1] ## RSpectra 0.16-0 2019-12-01 [1] ## rstudioapi 0.13 2020-11-12 [1] ## Rttf2pt1 1.3.8 2020-01-10 [1] ## rvest 1.0.0 2021-03-09 [1] ## sass 0.4.0 2021-05-12 [1] ## scales * 1.1.1 2020-05-11 [1] ## see 0.6.4 2021-05-29 [1] ## sessioninfo 1.1.1 2018-11-05 [1] ## shape 1.4.6 2021-05-19 [1] ## shiny 1.6.0 2021-01-25 [1] ## skimr 2.1.3 2021-03-07 [1] ## snakecase 0.11.0 2019-05-25 [1] ## stringi 1.7.6 2021-11-29 [1] ## stringr * 1.4.0 2019-02-10 [1] ## survival 3.2-13 2021-08-24 [2] ## tibble * 3.1.6 2021-11-07 [1] ## tictoc * 1.0.1 2021-04-19 [1] ## tidymodels * 0.1.4 2021-10-01 [1] ## tidyr * 1.2.0 2022-02-01 [1] ## tidyselect 1.1.2 2022-02-21 [1] ## tidyverse * 1.3.1 2021-04-15 [1] ## timeDate 3043.102 2018-02-21 [1] ## tune * 0.1.6 2021-07-21 [1] ## tzdb 0.2.0 2021-10-27 [1] ## usethis 2.1.5 2021-12-09 [1] ## utf8 1.2.2 2021-07-24 [1] ## vctrs * 0.3.8 2021-04-29 [1] ## vroom 1.5.7 2021-11-30 [1] ## withr 2.5.0 2022-03-03 [1] ## workflows * 0.2.3 2021-07-16 [1] ## workflowsets * 0.1.0 2021-07-22 [1] ## xfun 0.29 2021-12-14 [1] ## xml2 1.3.3 2021-11-30 [1] ## xtable 1.8-4 2019-04-21 [1] ## yaml 2.2.1 2020-02-01 [1] ## yardstick * 0.0.8 2021-03-28 [1] ## source ## CRAN (R 4.1.1) ## CRAN (R 4.1.0) ## CRAN (R 4.1.0) ## CRAN (R 4.1.0) ## CRAN (R 4.1.0) ## Bioconductor ## CRAN (R 4.1.2) ## CRAN (R 4.1.2) ## CRAN (R 4.1.1) ## CRAN (R 4.1.3) ## CRAN (R 4.1.2) ## CRAN (R 4.1.0) ## CRAN (R 4.1.1) ## CRAN (R 4.1.2) ## CRAN (R 4.1.1) ## CRAN (R 4.1.0) ## CRAN (R 4.1.0) ## CRAN (R 4.1.3) ## CRAN (R 4.1.3) ## CRAN (R 4.1.0) ## CRAN (R 4.1.3) ## CRAN (R 4.1.3) ## CRAN (R 4.1.1) ## CRAN (R 4.1.0) ## CRAN (R 4.1.1) ## CRAN (R 4.1.0) ## CRAN (R 4.1.3) ## CRAN (R 4.1.0) ## CRAN (R 4.1.2) ## CRAN (R 4.1.0) ## CRAN (R 4.1.0) ## CRAN (R 4.1.1) ## CRAN (R 4.1.0) ## CRAN (R 4.1.2) ## CRAN (R 4.1.2) ## CRAN (R 4.1.2) ## CRAN (R 4.1.2) ## CRAN (R 4.1.1) ## CRAN (R 4.1.1) ## CRAN (R 4.1.3) ## Github (taylordunn/dunnr@c83b30e) ## CRAN (R 4.1.0) ## CRAN (R 4.1.3) ## CRAN (R 4.1.0) ## CRAN (R 4.1.2) ## CRAN (R 4.1.0) ## CRAN (R 4.1.1) ## CRAN (R 4.1.0) ## CRAN (R 4.1.0) ## CRAN (R 4.1.0) ## CRAN (R 4.1.3) ## CRAN (R 4.1.0) ## CRAN (R 4.1.0) ## CRAN (R 4.1.0) ## CRAN (R 4.1.3) ## CRAN (R 4.1.2) ## CRAN (R 4.1.2) ## CRAN (R 4.1.3) ## CRAN (R 4.1.3) ## CRAN (R 4.1.3) ## CRAN (R 4.1.0) ## CRAN (R 4.1.2) ## CRAN (R 4.1.0) ## CRAN (R 4.1.0) ## CRAN (R 4.1.0) ## CRAN (R 4.1.0) ## CRAN (R 4.1.1) ## CRAN (R 4.1.0) ## CRAN (R 4.1.3) ## CRAN (R 4.1.0) ## CRAN (R 4.1.0) ## CRAN (R 4.1.0) ## CRAN (R 4.1.2) ## CRAN (R 4.1.0) ## CRAN (R 4.1.3) ## CRAN (R 4.1.0) ## CRAN (R 4.1.0) ## CRAN (R 4.1.0) ## CRAN (R 4.1.2) ## CRAN (R 4.1.1) ## CRAN (R 4.1.2) ## CRAN (R 4.1.0) ## CRAN (R 4.1.3) ## CRAN (R 4.1.1) ## CRAN (R 4.1.0) ## CRAN (R 4.1.1) ## CRAN (R 4.1.2) ## CRAN (R 4.1.3) ## CRAN (R 4.1.1) ## CRAN (R 4.1.0) ## CRAN (R 4.1.2) ## CRAN (R 4.1.2) ## CRAN (R 4.1.2) ## CRAN (R 4.1.2) ## CRAN (R 4.1.0) ## CRAN (R 4.1.0) ## CRAN (R 4.1.2) ## CRAN (R 4.1.3) ## CRAN (R 4.1.3) ## CRAN (R 4.1.3) ## CRAN (R 4.1.0) ## CRAN (R 4.1.1) ## CRAN (R 4.1.0) ## CRAN (R 4.1.1) ## CRAN (R 4.1.3) ## CRAN (R 4.1.3) ## CRAN (R 4.1.3) ## CRAN (R 4.1.1) ## CRAN (R 4.1.2) ## CRAN (R 4.1.2) ## CRAN (R 4.1.3) ## CRAN (R 4.1.1) ## CRAN (R 4.1.1) ## Github (mixOmicsTeam/mixOmics@974a8c9) ## CRAN (R 4.1.0) ## CRAN (R 4.1.0) ## CRAN (R 4.1.0) ## CRAN (R 4.1.1) ## CRAN (R 4.1.3) ## CRAN (R 4.1.3) ## CRAN (R 4.1.2) ## CRAN (R 4.1.0) ## CRAN (R 4.1.0) ## CRAN (R 4.1.0) ## CRAN (R 4.1.1) ## CRAN (R 4.1.2) ## CRAN (R 4.1.0) ## CRAN (R 4.1.3) ## CRAN (R 4.1.3) ## CRAN (R 4.1.2) ## CRAN (R 4.1.0) ## CRAN (R 4.1.0) ## CRAN (R 4.1.0) ## CRAN (R 4.1.0) ## CRAN (R 4.1.2) ## CRAN (R 4.1.0) ## CRAN (R 4.1.2) ## CRAN (R 4.1.1) ## CRAN (R 4.1.3) ## CRAN (R 4.1.3) ## CRAN (R 4.1.3) ## CRAN (R 4.1.2) ## CRAN (R 4.1.0) ## CRAN (R 4.1.1) ## CRAN (R 4.1.1) ## CRAN (R 4.1.0) ## CRAN (R 4.1.0) ## CRAN (R 4.1.1) ## CRAN (R 4.1.3) ## CRAN (R 4.1.1) ## CRAN (R 4.1.0) ## CRAN (R 4.1.3) ## CRAN (R 4.1.0) ## CRAN (R 4.1.0) ## CRAN (R 4.1.3) ## CRAN (R 4.1.0) ## CRAN (R 4.1.1) ## CRAN (R 4.1.0) ## CRAN (R 4.1.0) ## CRAN (R 4.1.0) ## CRAN (R 4.1.0) ## CRAN (R 4.1.0) ## CRAN (R 4.1.1) ## CRAN (R 4.1.0) ## CRAN (R 4.1.1) ## CRAN (R 4.1.1) ## CRAN (R 4.1.2) ## CRAN (R 4.1.0) ## CRAN (R 4.1.3) ## CRAN (R 4.1.1) ## CRAN (R 4.1.1) ## CRAN (R 4.1.1) ## CRAN (R 4.1.3) ## CRAN (R 4.1.3) ## CRAN (R 4.1.3) ## CRAN (R 4.1.0) ## CRAN (R 4.1.0) ## CRAN (R 4.1.2) ## CRAN (R 4.1.2) ## CRAN (R 4.1.0) ## CRAN (R 4.1.3) ## CRAN (R 4.1.2) ## CRAN (R 4.1.3) ## CRAN (R 4.1.0) ## CRAN (R 4.1.0) ## CRAN (R 4.1.2) ## CRAN (R 4.1.2) ## CRAN (R 4.1.0) ## CRAN (R 4.1.0) ## CRAN (R 4.1.0) ## ## [1] C:/Users/tdunn/Documents/R/win-library/4.1 ## [2] C:/Program Files/R/R-4.1.3/library "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
